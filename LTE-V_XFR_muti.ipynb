{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTE-V XFR (row-level training) + block-level row-fusion (mean logits)\n",
    "# - Training: same as your XFR script (row samples from XFR blocks)\n",
    "# - Evaluation: block-level row-fusion: mean logits over rows (S=all or S=selected)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# ================= 参数设置 =================\n",
    "data_path = \"E:/rf_datasets/\"  # 数据文件夹（*.mat）\n",
    "\n",
    "fs = 5e6\n",
    "fc = 5.9e9\n",
    "v_kmh = 120          # km/h\n",
    "apply_doppler = True\n",
    "apply_awgn = True\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "in_planes = 64\n",
    "dropout = 0.5\n",
    "patience = 5\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "\n",
    "# 评估：row-fusion 选择行数\n",
    "# S=None: 使用所有 L 行融合\n",
    "# S=64/32等: 等间隔选 S 行融合（更接近“可部署折中”）\n",
    "fusion_S = None\n",
    "\n",
    "# ================= 随机种子 =================\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "# ================= 多普勒和AWGN处理函数 =================\n",
    "def compute_doppler_shift(v_kmh, fc_hz):\n",
    "    c = 3e8\n",
    "    v_ms = v_kmh / 3.6\n",
    "    return (v_ms / c) * fc_hz\n",
    "\n",
    "def apply_doppler_shift(signal_c, fd, fs):\n",
    "    t = np.arange(signal_c.shape[-1]) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal_c * doppler_phase\n",
    "\n",
    "def add_awgn(signal_c, snr_db):\n",
    "    signal_power = np.mean(np.abs(signal_c)**2)\n",
    "    noise_power = signal_power / (10**(snr_db/10))\n",
    "    noise_real = np.random.randn(*signal_c.shape)\n",
    "    noise_imag = np.random.randn(*signal_c.shape)\n",
    "    noise = np.sqrt(noise_power/2) * (noise_real + 1j*noise_imag)\n",
    "    return signal_c + noise\n",
    "\n",
    "def power_normalize(signal_c, eps=1e-12):\n",
    "    return signal_c / (np.sqrt(np.mean(np.abs(signal_c)**2)) + eps)\n",
    "\n",
    "# ================= 兼容读取 v7.3 HDF5 dmrs 与 txID =================\n",
    "def read_tx_id_str(rfDataset):\n",
    "    txID_uint16 = rfDataset['txID'][:].flatten()\n",
    "    tx_id = ''.join(chr(int(c)) for c in txID_uint16 if int(c) != 0)\n",
    "    return tx_id\n",
    "\n",
    "def read_dmrs_complex(rfDataset):\n",
    "    dmrs = rfDataset['dmrs']\n",
    "    # 情形1：Group，含 real/imag\n",
    "    if isinstance(dmrs, h5py.Group):\n",
    "        real = dmrs['real'][:]\n",
    "        imag = dmrs['imag'][:]\n",
    "        return real + 1j * imag\n",
    "    # 情形2：Dataset，compound dtype\n",
    "    arr = dmrs[:]\n",
    "    if hasattr(arr, \"dtype\") and arr.dtype.fields is not None and ('real' in arr.dtype.fields) and ('imag' in arr.dtype.fields):\n",
    "        return arr['real'] + 1j * arr['imag']\n",
    "    # 情形3：已是 complex 或其它\n",
    "    return arr\n",
    "\n",
    "# ================= 数据加载（按 TX 聚合成 block，并做 XFR 转置） =================\n",
    "def load_and_preprocess_with_grouping(\n",
    "    mat_folder,\n",
    "    group_size=288,              # 这里就是 XFR 的 m（每行长度）\n",
    "    apply_doppler=False,\n",
    "    target_velocity_kmh=120,\n",
    "    apply_awgn=False,\n",
    "    snr_db=20,\n",
    "    fs=5e6,\n",
    "    fc=5.9e9\n",
    "):\n",
    "    \"\"\"\n",
    "    输出：\n",
    "      X_blocks: (num_blocks, L, m, 2)  其中 L=seg_len(=288), m=group_size\n",
    "      y_blocks: (num_blocks,)\n",
    "    逻辑：\n",
    "      - 按 tx_id 分组文件\n",
    "      - 每个 tx 的多个文件均衡抽样，拼成 group_size 帧\n",
    "      - 然后 transpose 得到 (L, m, 2) 的“行样本集合”\n",
    "    \"\"\"\n",
    "    mat_files = glob.glob(os.path.join(mat_folder, '*.mat'))\n",
    "    if len(mat_files) == 0:\n",
    "        raise RuntimeError(f\"在 {mat_folder} 未找到 .mat 文件\")\n",
    "\n",
    "    print(f\"[INFO] 共找到 {len(mat_files)} 个 .mat 文件\")\n",
    "    fd = compute_doppler_shift(target_velocity_kmh, fc)\n",
    "    print(f\"[INFO] v={target_velocity_kmh} km/h，多普勒 fd={fd:.2f} Hz | SNR={snr_db} dB\")\n",
    "\n",
    "    # 1) 先加载所有文件的 dmrs 与 tx_id\n",
    "    X_files, y_files, label_set = [], [], set()\n",
    "    for file in tqdm(mat_files, desc='读取数据'):\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            rfDataset = f['rfDataset']\n",
    "            dmrs_complex = read_dmrs_complex(rfDataset)      # (N, L) complex\n",
    "            tx_id = read_tx_id_str(rfDataset)\n",
    "\n",
    "        if dmrs_complex.ndim != 2:\n",
    "            raise RuntimeError(f\"dmrs维度异常: {dmrs_complex.shape} | file={file}\")\n",
    "\n",
    "        N, seg_len = dmrs_complex.shape\n",
    "\n",
    "        processed = np.empty((N, seg_len, 2), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            sig = dmrs_complex[i, :]\n",
    "\n",
    "            # 功率归一化（与 XFR 论文/代码一致）\n",
    "            sig = power_normalize(sig)\n",
    "\n",
    "            if apply_doppler:\n",
    "                sig = apply_doppler_shift(sig, fd, fs)\n",
    "\n",
    "            if apply_awgn:\n",
    "                sig = add_awgn(sig, snr_db)\n",
    "\n",
    "            processed[i, :, 0] = sig.real.astype(np.float32)\n",
    "            processed[i, :, 1] = sig.imag.astype(np.float32)\n",
    "\n",
    "        X_files.append(processed)     # (N, L, 2)\n",
    "        y_files.append(tx_id)\n",
    "        label_set.add(tx_id)\n",
    "\n",
    "    # 2) 标签映射\n",
    "    label_list = sorted(list(label_set))\n",
    "    label_to_idx = {label: i for i, label in enumerate(label_list)}\n",
    "    print(f\"[INFO] 类别数={len(label_to_idx)} | label_to_idx={label_to_idx}\")\n",
    "\n",
    "    # 3) 为每个 TX 构造 blocks\n",
    "    X_blocks_list = []\n",
    "    y_blocks_list = []\n",
    "\n",
    "    for label in label_list:\n",
    "        files_idx = [i for i, y in enumerate(y_files) if y == label]\n",
    "        num_files = len(files_idx)\n",
    "        if num_files == 0:\n",
    "            continue\n",
    "\n",
    "        # 每个文件贡献 samples_per_file 帧，共 group_size 帧\n",
    "        samples_per_file = group_size // num_files\n",
    "        if samples_per_file == 0:\n",
    "            print(f\"[WARN] TX {label} 文件过多({num_files})，导致 samples_per_file=0，跳过\")\n",
    "            continue\n",
    "\n",
    "        min_samples = min([X_files[i].shape[0] for i in files_idx])\n",
    "        max_groups = min_samples // samples_per_file\n",
    "        if max_groups == 0:\n",
    "            print(f\"[WARN] TX {label} 样本不足，跳过\")\n",
    "            continue\n",
    "\n",
    "        for g in range(max_groups):\n",
    "            pieces = []\n",
    "            for fi in files_idx:\n",
    "                start = g * samples_per_file\n",
    "                end = start + samples_per_file\n",
    "                piece = X_files[fi][start:end]      # (samples_per_file, L, 2)\n",
    "                pieces.append(piece)\n",
    "\n",
    "            big_block = np.concatenate(pieces, axis=0)       # (group_size, L, 2)\n",
    "\n",
    "            # XFR：transpose -> (L, group_size, 2)\n",
    "            big_block = np.transpose(big_block, (1, 0, 2))   # (L, m, 2)\n",
    "\n",
    "            X_blocks_list.append(big_block)\n",
    "            y_blocks_list.append(label_to_idx[label])\n",
    "\n",
    "    if len(X_blocks_list) == 0:\n",
    "        raise RuntimeError(\"没有生成任何 block，请检查 group_size 和数据文件。\")\n",
    "\n",
    "    X_blocks = np.stack(X_blocks_list, axis=0).astype(np.float32)   # (Nblk, L, m, 2)\n",
    "    y_blocks = np.array(y_blocks_list, dtype=np.int64)\n",
    "\n",
    "    print(f\"[INFO] blocks={X_blocks.shape[0]} | X_blocks={X_blocks.shape} | y_blocks={y_blocks.shape}\")\n",
    "    return X_blocks, y_blocks, label_to_idx\n",
    "\n",
    "# ================= 1D ResNet18（与你原脚本一致） =================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, m, 2)  —— 注意这里序列长度是 m (=group_size)\n",
    "        x = x.permute(0, 2, 1)  # (B, 2, m)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ================= block-level row-fusion 评估（mean logits） =================\n",
    "@torch.no_grad()\n",
    "def evaluate_row_fusion(model, X_blocks, y_blocks, device, num_classes, S=None, block_batch_size=8):\n",
    "    \"\"\"\n",
    "    X_blocks: torch.FloatTensor (Nblk, L, m, 2)\n",
    "    y_blocks: torch.LongTensor  (Nblk,)\n",
    "    S: None=all rows; else select S rows (equally spaced indices)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Nblk, L, m, C = X_blocks.shape\n",
    "\n",
    "    if S is None or S >= L:\n",
    "        row_idx = None\n",
    "    else:\n",
    "        row_idx = np.linspace(0, L - 1, num=S, dtype=int)\n",
    "        row_idx = np.unique(row_idx)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    # 简单按 block 分 batch\n",
    "    for start in range(0, Nblk, block_batch_size):\n",
    "        end = min(Nblk, start + block_batch_size)\n",
    "        blocks = X_blocks[start:end].to(device)      # (B, L, m, 2)\n",
    "        labels = y_blocks[start:end].to(device)      # (B,)\n",
    "        B = blocks.shape[0]\n",
    "\n",
    "        if row_idx is not None:\n",
    "            blocks = blocks[:, row_idx, :, :]        # (B, S, m, 2)\n",
    "            L_eff = blocks.shape[1]\n",
    "        else:\n",
    "            L_eff = blocks.shape[1]\n",
    "\n",
    "        flat = blocks.reshape(B * L_eff, m, C)       # (B*L_eff, m, 2)\n",
    "        logits = model(flat)                         # (B*L_eff, K)\n",
    "        logits = logits.reshape(B, L_eff, num_classes)\n",
    "        fused_logits = logits.mean(dim=1)            # mean logits over rows\n",
    "        preds = torch.argmax(fused_logits, dim=1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = 100.0 * correct / max(total, 1)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "    return acc, cm\n",
    "\n",
    "# ================= row-level（单行样本）评估（可选参考） =================\n",
    "@torch.no_grad()\n",
    "def evaluate_row_level(model, X_blocks, y_blocks, device, num_classes, batch_size=256):\n",
    "    \"\"\"\n",
    "    把 (Nblk, L, m, 2) 展开成 (Nblk*L, m, 2) 做 row-level accuracy（仅作参考，不作为主指标）\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    Nblk, L, m, C = X_blocks.shape\n",
    "    X = X_blocks.reshape(Nblk * L, m, C)\n",
    "    y = y_blocks.repeat_interleave(L)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    for start in range(0, X.shape[0], batch_size):\n",
    "        end = min(X.shape[0], start + batch_size)\n",
    "        xb = X[start:end].to(device)\n",
    "        yb = y[start:end].to(device)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "        all_labels.extend(yb.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = 100.0 * correct / max(total, 1)\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path=None, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Reference')\n",
    "    plt.xlabel('Predicted')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# ================= 主训练（按 block 划分；早停依据 fused val acc） =================\n",
    "def train_for_snr(SNR_dB, save_folder, results_file, group_size=288, fusion_S=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] device={device}\")\n",
    "\n",
    "    # 1) 加载 blocks: (Nblk, L, m, 2)\n",
    "    X_blocks_np, y_blocks_np, label_to_idx = load_and_preprocess_with_grouping(\n",
    "        data_path,\n",
    "        group_size=group_size,\n",
    "        apply_doppler=apply_doppler,\n",
    "        target_velocity_kmh=v_kmh,\n",
    "        apply_awgn=apply_awgn,\n",
    "        snr_db=SNR_dB,\n",
    "        fs=fs,\n",
    "        fc=fc\n",
    "    )\n",
    "\n",
    "    X_blocks = torch.from_numpy(np.ascontiguousarray(X_blocks_np)).float()\n",
    "    y_blocks = torch.from_numpy(np.ascontiguousarray(y_blocks_np)).long()\n",
    "\n",
    "    num_blocks, L, m, C = X_blocks.shape\n",
    "    num_classes = len(label_to_idx)\n",
    "    print(f\"[INFO] blocks={num_blocks} | L={L} | m={m} | classes={num_classes}\")\n",
    "\n",
    "    # 2) block-level train/test split\n",
    "    block_idx = np.arange(num_blocks)\n",
    "    train_blocks, test_blocks = train_test_split(\n",
    "        block_idx, test_size=0.25, random_state=seed, stratify=y_blocks_np\n",
    "    )\n",
    "\n",
    "    X_test_blk = X_blocks[test_blocks]\n",
    "    y_test_blk = y_blocks[test_blocks]\n",
    "\n",
    "    # 3) StratifiedKFold on train blocks\n",
    "    y_train_lbl = y_blocks_np[train_blocks]\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_test_fused = []\n",
    "    fold_test_row = []\n",
    "\n",
    "    for fold, (tr_i, va_i) in enumerate(skf.split(train_blocks, y_train_lbl), start=1):\n",
    "        print(f\"\\n====== Fold {fold}/{n_splits} ======\")\n",
    "        tr_blocks = train_blocks[tr_i]\n",
    "        va_blocks = train_blocks[va_i]\n",
    "\n",
    "        # 构造 row-level 训练数据（展开 tr_blocks）\n",
    "        X_tr = X_blocks[tr_blocks].reshape(-1, m, 2)                 # (Ntr*L, m, 2)\n",
    "        y_tr = y_blocks[tr_blocks].repeat_interleave(L)              # (Ntr*L,)\n",
    "        X_va_row = X_blocks[va_blocks].reshape(-1, m, 2)\n",
    "        y_va_row = y_blocks[va_blocks].repeat_interleave(L)\n",
    "\n",
    "        train_ds = TensorDataset(X_tr, y_tr)\n",
    "        val_row_ds = TensorDataset(X_va_row, y_va_row)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_row_loader = DataLoader(val_row_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        best_val_fused = -1.0\n",
    "        best_state = None\n",
    "        patience_cnt = 0\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # ---- train row-level ----\n",
    "            model.train()\n",
    "            tr_loss = 0.0\n",
    "            tr_correct, tr_total = 0, 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                tr_correct += (preds == yb).sum().item()\n",
    "                tr_total += yb.size(0)\n",
    "\n",
    "            tr_loss /= max(len(train_loader), 1)\n",
    "            tr_acc = 100.0 * tr_correct / max(tr_total, 1)\n",
    "\n",
    "            # ---- val row-level (optional) ----\n",
    "            model.eval()\n",
    "            va_loss = 0.0\n",
    "            va_correct, va_total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_row_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    va_loss += loss.item()\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                    va_correct += (preds == yb).sum().item()\n",
    "                    va_total += yb.size(0)\n",
    "            va_loss /= max(len(val_row_loader), 1)\n",
    "            va_acc_row = 100.0 * va_correct / max(va_total, 1)\n",
    "\n",
    "            # ---- val fused (primary early stopping metric) ----\n",
    "            X_va_blk = X_blocks[va_blocks]\n",
    "            y_va_blk = y_blocks[va_blocks]\n",
    "            va_acc_fused, _ = evaluate_row_fusion(\n",
    "                model, X_va_blk, y_va_blk, device, num_classes, S=fusion_S, block_batch_size=8\n",
    "            )\n",
    "\n",
    "            log = (f\"Fold{fold} Ep{epoch:03d} | \"\n",
    "                   f\"TrainLoss {tr_loss:.4f} TrainRowAcc {tr_acc:.2f}% | \"\n",
    "                   f\"ValLoss {va_loss:.4f} ValRowAcc {va_acc_row:.2f}% | \"\n",
    "                   f\"ValFusedAcc(S={fusion_S if fusion_S is not None else 'all'}) {va_acc_fused:.2f}%\")\n",
    "            print(log)\n",
    "            with open(results_file, \"a\") as f:\n",
    "                f.write(log + \"\\n\")\n",
    "\n",
    "            if va_acc_fused > best_val_fused + 1e-6:\n",
    "                best_val_fused = va_acc_fused\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_cnt = 0\n",
    "            else:\n",
    "                patience_cnt += 1\n",
    "                if patience_cnt >= patience:\n",
    "                    print(f\"[INFO] Early stop: {patience} epochs no improvement on fused val acc.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # restore best\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "\n",
    "        # ---- test fused ----\n",
    "        test_acc_fused, test_cm_fused = evaluate_row_fusion(\n",
    "            model, X_test_blk, y_test_blk, device, num_classes, S=fusion_S, block_batch_size=8\n",
    "        )\n",
    "\n",
    "        # ---- test row-level (reference) ----\n",
    "        test_acc_row, _ = evaluate_row_level(model, X_test_blk, y_test_blk, device, num_classes, batch_size=256)\n",
    "\n",
    "        fold_test_fused.append(test_acc_fused)\n",
    "        fold_test_row.append(test_acc_row)\n",
    "\n",
    "        plot_confusion_matrix(\n",
    "            test_cm_fused,\n",
    "            save_path=os.path.join(save_folder, f\"cm_test_fused_fold{fold}.png\"),\n",
    "            title=f\"Test CM (Fused, S={fusion_S if fusion_S is not None else 'all'})\"\n",
    "        )\n",
    "\n",
    "        ckpt_path = os.path.join(save_folder, f\"best_model_fold{fold}.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "        msg = (f\"[RESULT] Fold {fold} | TestFusedAcc={test_acc_fused:.2f}% \"\n",
    "               f\"| TestRowAcc(ref)={test_acc_row:.2f}% | ckpt={ckpt_path}\")\n",
    "        print(msg)\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(msg + \"\\n\")\n",
    "\n",
    "    mean_fused = float(np.mean(fold_test_fused))\n",
    "    std_fused = float(np.std(fold_test_fused))\n",
    "    mean_row = float(np.mean(fold_test_row))\n",
    "    std_row = float(np.std(fold_test_row))\n",
    "\n",
    "    summary = (f\"\\n[SUMMARY] SNR={SNR_dB} dB | group_size(m)={group_size} | \"\n",
    "               f\"FusedAcc mean±std={mean_fused:.2f}%±{std_fused:.2f}% | \"\n",
    "               f\"RowAcc(ref) mean±std={mean_row:.2f}%±{std_row:.2f}%\\n\")\n",
    "    print(summary)\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    return mean_fused\n",
    "\n",
    "# ================= SNR 循环训练 + 绘制曲线（block-level fused acc） =================\n",
    "if __name__ == \"__main__\":\n",
    "    snr_list = list(range(20, -45, -5))\n",
    "    snr_accs = []\n",
    "\n",
    "    # 建议：group_size=288 对齐 RAW IQ 的 m=288 query\n",
    "    group_size = 288\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    script_name = \"LTEV_XFR_RowFusion\"\n",
    "    out_root = os.path.join(os.getcwd(), \"training_results\",\n",
    "                            f\"{timestamp}_{script_name}_m{group_size}_S{fusion_S if fusion_S is not None else 'all'}\")\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    for snr_db in snr_list:\n",
    "        print(f\"\\n\\n================== 当前实验 SNR={snr_db} dB ==================\\n\")\n",
    "        folder_name = f\"SNR{snr_db}dB_fd{int(compute_doppler_shift(v_kmh,fc))}\"\n",
    "        save_folder = os.path.join(out_root, folder_name)\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "        results_file = os.path.join(save_folder, \"results.txt\")\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(f\"\\n================ SNR={snr_db} dB =================\\n\")\n",
    "\n",
    "        test_acc_fused = train_for_snr(\n",
    "            snr_db, save_folder, results_file,\n",
    "            group_size=group_size,\n",
    "            fusion_S=fusion_S\n",
    "        )\n",
    "        snr_accs.append(test_acc_fused)\n",
    "        print(f\"[INFO] SNR {snr_db:>3} dB → results in: {save_folder}\")\n",
    "\n",
    "    # plot SNR vs fused acc\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(snr_list, snr_accs, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"SNR (dB)\")\n",
    "    plt.ylabel(\"Test Acc (Block-level Row-Fusion, %)\")  # 主指标：block-level\n",
    "    plt.title(f\"LTE-V XFR Row-Fusion Accuracy (m={group_size}, S={fusion_S if fusion_S is not None else 'all'})\")\n",
    "    plt.grid(True)\n",
    "    snr_curve_path = os.path.join(out_root, f\"SNR_vs_fused_accuracy_{timestamp}.png\")\n",
    "    plt.savefig(snr_curve_path)\n",
    "    plt.show()\n",
    "    print(f\"[INFO] 曲线已保存到: {snr_curve_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84d50d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================== 当前实验 SNR=20 dB ==================\n",
      "\n",
      "[INFO] device=cuda\n",
      "[INFO] 共找到 72 个 .mat 文件\n",
      "[INFO] v=120 km/h，多普勒 fd=655.56 Hz | SNR=20 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:09<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 类别数=9 | label_to_idx={'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] blocks=747 | X_blocks=(747, 288, 288, 2) | y_blocks=(747,)\n",
      "[INFO] blocks=747 | L=288 | m=288 | classes=9\n",
      "Fold1 Ep001 | TrainLoss 1.4698 TrainRowAcc 45.96% | ValLoss 0.7464 ValRowAcc 74.69% | ValFused(all) 97.32%\n",
      "Fold1 Ep002 | TrainLoss 0.5422 TrainRowAcc 81.87% | ValLoss 0.3172 ValRowAcc 89.22% | ValFused(all) 100.00%\n",
      "Fold1 Ep003 | TrainLoss 0.3096 TrainRowAcc 89.82% | ValLoss 0.2144 ValRowAcc 92.78% | ValFused(all) 100.00%\n",
      "Fold1 Ep004 | TrainLoss 0.2156 TrainRowAcc 93.03% | ValLoss 0.1675 ValRowAcc 94.51% | ValFused(all) 100.00%\n",
      "Fold1 Ep005 | TrainLoss 0.1645 TrainRowAcc 94.70% | ValLoss 0.1508 ValRowAcc 95.18% | ValFused(all) 100.00%\n",
      "Fold1 Ep006 | TrainLoss 0.1301 TrainRowAcc 95.96% | ValLoss 0.1292 ValRowAcc 95.91% | ValFused(all) 100.00%\n",
      "Fold1 Ep007 | TrainLoss 0.1062 TrainRowAcc 96.68% | ValLoss 0.1103 ValRowAcc 96.49% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 1 | TestRowAcc(ref)=87.46% | TestFusedAcc@S=all=98.40% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\\fold_1\\best_state.pth\n",
      "Fold2 Ep001 | TrainLoss 1.4678 TrainRowAcc 46.11% | ValLoss 0.8674 ValRowAcc 70.90% | ValFused(all) 95.54%\n",
      "Fold2 Ep002 | TrainLoss 0.5551 TrainRowAcc 81.49% | ValLoss 0.3681 ValRowAcc 87.62% | ValFused(all) 99.11%\n",
      "Fold2 Ep003 | TrainLoss 0.3186 TrainRowAcc 89.55% | ValLoss 0.2274 ValRowAcc 92.49% | ValFused(all) 100.00%\n",
      "Fold2 Ep004 | TrainLoss 0.2178 TrainRowAcc 92.92% | ValLoss 0.1893 ValRowAcc 94.07% | ValFused(all) 100.00%\n",
      "Fold2 Ep005 | TrainLoss 0.1652 TrainRowAcc 94.70% | ValLoss 0.1517 ValRowAcc 95.31% | ValFused(all) 100.00%\n",
      "Fold2 Ep006 | TrainLoss 0.1316 TrainRowAcc 95.85% | ValLoss 0.1328 ValRowAcc 95.86% | ValFused(all) 100.00%\n",
      "Fold2 Ep007 | TrainLoss 0.1086 TrainRowAcc 96.65% | ValLoss 0.1270 ValRowAcc 96.10% | ValFused(all) 100.00%\n",
      "Fold2 Ep008 | TrainLoss 0.0900 TrainRowAcc 97.27% | ValLoss 0.1094 ValRowAcc 96.57% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 2 | TestRowAcc(ref)=91.23% | TestFusedAcc@S=all=97.86% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\\fold_2\\best_state.pth\n",
      "Fold3 Ep001 | TrainLoss 1.4214 TrainRowAcc 48.03% | ValLoss 0.8354 ValRowAcc 71.69% | ValFused(all) 94.64%\n",
      "Fold3 Ep002 | TrainLoss 0.5491 TrainRowAcc 81.70% | ValLoss 0.3624 ValRowAcc 87.73% | ValFused(all) 100.00%\n",
      "Fold3 Ep003 | TrainLoss 0.3170 TrainRowAcc 89.56% | ValLoss 0.2343 ValRowAcc 92.18% | ValFused(all) 100.00%\n",
      "Fold3 Ep004 | TrainLoss 0.2269 TrainRowAcc 92.61% | ValLoss 0.1892 ValRowAcc 93.87% | ValFused(all) 100.00%\n",
      "Fold3 Ep005 | TrainLoss 0.1745 TrainRowAcc 94.36% | ValLoss 0.1612 ValRowAcc 94.71% | ValFused(all) 100.00%\n",
      "Fold3 Ep006 | TrainLoss 0.1369 TrainRowAcc 95.64% | ValLoss 0.1319 ValRowAcc 95.73% | ValFused(all) 100.00%\n",
      "Fold3 Ep007 | TrainLoss 0.1128 TrainRowAcc 96.42% | ValLoss 0.1357 ValRowAcc 95.65% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 3 | TestRowAcc(ref)=87.01% | TestFusedAcc@S=all=98.40% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\\fold_3\\best_state.pth\n",
      "Fold4 Ep001 | TrainLoss 1.4500 TrainRowAcc 46.98% | ValLoss 0.7658 ValRowAcc 74.00% | ValFused(all) 95.54%\n",
      "Fold4 Ep002 | TrainLoss 0.5296 TrainRowAcc 82.44% | ValLoss 0.3077 ValRowAcc 89.52% | ValFused(all) 100.00%\n",
      "Fold4 Ep003 | TrainLoss 0.3060 TrainRowAcc 89.91% | ValLoss 0.2003 ValRowAcc 93.37% | ValFused(all) 100.00%\n",
      "Fold4 Ep004 | TrainLoss 0.2221 TrainRowAcc 92.78% | ValLoss 0.1571 ValRowAcc 94.74% | ValFused(all) 100.00%\n",
      "Fold4 Ep005 | TrainLoss 0.1718 TrainRowAcc 94.47% | ValLoss 0.1318 ValRowAcc 95.66% | ValFused(all) 100.00%\n",
      "Fold4 Ep006 | TrainLoss 0.1372 TrainRowAcc 95.68% | ValLoss 0.1085 ValRowAcc 96.36% | ValFused(all) 100.00%\n",
      "Fold4 Ep007 | TrainLoss 0.1132 TrainRowAcc 96.49% | ValLoss 0.0971 ValRowAcc 96.77% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 4 | TestRowAcc(ref)=88.14% | TestFusedAcc@S=all=97.86% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\\fold_4\\best_state.pth\n",
      "Fold5 Ep001 | TrainLoss 1.4861 TrainRowAcc 45.43% | ValLoss 0.7647 ValRowAcc 73.47% | ValFused(all) 96.43%\n",
      "Fold5 Ep002 | TrainLoss 0.5862 TrainRowAcc 80.25% | ValLoss 0.3213 ValRowAcc 89.25% | ValFused(all) 100.00%\n",
      "Fold5 Ep003 | TrainLoss 0.3328 TrainRowAcc 88.95% | ValLoss 0.1867 ValRowAcc 93.73% | ValFused(all) 100.00%\n",
      "Fold5 Ep004 | TrainLoss 0.2331 TrainRowAcc 92.35% | ValLoss 0.1333 ValRowAcc 95.80% | ValFused(all) 100.00%\n",
      "Fold5 Ep005 | TrainLoss 0.1773 TrainRowAcc 94.26% | ValLoss 0.1162 ValRowAcc 96.29% | ValFused(all) 100.00%\n",
      "Fold5 Ep006 | TrainLoss 0.1406 TrainRowAcc 95.52% | ValLoss 0.0909 ValRowAcc 97.04% | ValFused(all) 100.00%\n",
      "Fold5 Ep007 | TrainLoss 0.1155 TrainRowAcc 96.43% | ValLoss 0.0834 ValRowAcc 97.42% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 5 | TestRowAcc(ref)=86.42% | TestFusedAcc@S=all=98.40% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\\fold_5\\best_state.pth\n",
      "[INFO] SNR  20 dB → results in: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR20dB_fd655\n",
      "\n",
      "\n",
      "================== 当前实验 SNR=-5 dB ==================\n",
      "\n",
      "[INFO] device=cuda\n",
      "[INFO] 共找到 72 个 .mat 文件\n",
      "[INFO] v=120 km/h，多普勒 fd=655.56 Hz | SNR=-5 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:09<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 类别数=9 | label_to_idx={'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] blocks=747 | X_blocks=(747, 288, 288, 2) | y_blocks=(747,)\n",
      "[INFO] blocks=747 | L=288 | m=288 | classes=9\n",
      "Fold1 Ep001 | TrainLoss 2.2109 TrainRowAcc 12.06% | ValLoss 2.6033 ValRowAcc 11.55% | ValFused(all) 11.61%\n",
      "Fold1 Ep002 | TrainLoss 2.1769 TrainRowAcc 14.40% | ValLoss 2.4123 ValRowAcc 14.29% | ValFused(all) 13.39%\n",
      "Fold1 Ep003 | TrainLoss 2.0757 TrainRowAcc 21.82% | ValLoss 2.0401 ValRowAcc 24.98% | ValFused(all) 42.86%\n",
      "Fold1 Ep004 | TrainLoss 1.9466 TrainRowAcc 28.26% | ValLoss 1.8888 ValRowAcc 30.09% | ValFused(all) 54.46%\n",
      "Fold1 Ep005 | TrainLoss 1.8573 TrainRowAcc 32.37% | ValLoss 1.8297 ValRowAcc 33.63% | ValFused(all) 76.79%\n",
      "Fold1 Ep006 | TrainLoss 1.8026 TrainRowAcc 34.90% | ValLoss 1.7520 ValRowAcc 37.02% | ValFused(all) 77.68%\n",
      "Fold1 Ep007 | TrainLoss 1.7627 TrainRowAcc 36.68% | ValLoss 1.7306 ValRowAcc 37.37% | ValFused(all) 65.18%\n",
      "Fold1 Ep008 | TrainLoss 1.7286 TrainRowAcc 38.14% | ValLoss 1.6895 ValRowAcc 39.61% | ValFused(all) 94.64%\n",
      "Fold1 Ep009 | TrainLoss 1.6973 TrainRowAcc 39.48% | ValLoss 1.6707 ValRowAcc 40.40% | ValFused(all) 97.32%\n",
      "Fold1 Ep010 | TrainLoss 1.6715 TrainRowAcc 40.59% | ValLoss 1.6634 ValRowAcc 40.60% | ValFused(all) 93.75%\n",
      "Fold1 Ep011 | TrainLoss 1.6259 TrainRowAcc 42.29% | ValLoss 1.6308 ValRowAcc 41.82% | ValFused(all) 99.11%\n",
      "Fold1 Ep012 | TrainLoss 1.6040 TrainRowAcc 43.17% | ValLoss 1.6189 ValRowAcc 42.36% | ValFused(all) 99.11%\n",
      "Fold1 Ep013 | TrainLoss 1.5868 TrainRowAcc 43.89% | ValLoss 1.6137 ValRowAcc 42.59% | ValFused(all) 100.00%\n",
      "Fold1 Ep014 | TrainLoss 1.5695 TrainRowAcc 44.59% | ValLoss 1.6098 ValRowAcc 42.57% | ValFused(all) 99.11%\n",
      "Fold1 Ep015 | TrainLoss 1.5548 TrainRowAcc 45.07% | ValLoss 1.6038 ValRowAcc 42.97% | ValFused(all) 100.00%\n",
      "Fold1 Ep016 | TrainLoss 1.5386 TrainRowAcc 45.80% | ValLoss 1.5980 ValRowAcc 43.19% | ValFused(all) 100.00%\n",
      "Fold1 Ep017 | TrainLoss 1.5225 TrainRowAcc 46.61% | ValLoss 1.5999 ValRowAcc 43.19% | ValFused(all) 99.11%\n",
      "Fold1 Ep018 | TrainLoss 1.5095 TrainRowAcc 46.86% | ValLoss 1.5993 ValRowAcc 43.16% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 1 | TestRowAcc(ref)=41.96% | TestFusedAcc@S=all=99.47% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\\fold_1\\best_state.pth\n",
      "Fold2 Ep001 | TrainLoss 2.2100 TrainRowAcc 12.10% | ValLoss 2.6345 ValRowAcc 10.81% | ValFused(all) 10.71%\n",
      "Fold2 Ep002 | TrainLoss 2.1592 TrainRowAcc 16.09% | ValLoss 2.3245 ValRowAcc 14.36% | ValFused(all) 14.29%\n",
      "Fold2 Ep003 | TrainLoss 2.0429 TrainRowAcc 23.56% | ValLoss 1.9970 ValRowAcc 26.31% | ValFused(all) 58.04%\n",
      "Fold2 Ep004 | TrainLoss 1.9371 TrainRowAcc 28.75% | ValLoss 1.8809 ValRowAcc 30.81% | ValFused(all) 75.89%\n",
      "Fold2 Ep005 | TrainLoss 1.8746 TrainRowAcc 31.76% | ValLoss 1.8691 ValRowAcc 31.95% | ValFused(all) 69.64%\n",
      "Fold2 Ep006 | TrainLoss 1.8206 TrainRowAcc 34.15% | ValLoss 1.7622 ValRowAcc 36.64% | ValFused(all) 79.46%\n",
      "Fold2 Ep007 | TrainLoss 1.7759 TrainRowAcc 35.98% | ValLoss 1.7176 ValRowAcc 38.37% | ValFused(all) 90.18%\n",
      "Fold2 Ep008 | TrainLoss 1.7384 TrainRowAcc 37.88% | ValLoss 1.7104 ValRowAcc 38.51% | ValFused(all) 78.57%\n",
      "Fold2 Ep009 | TrainLoss 1.7098 TrainRowAcc 39.01% | ValLoss 1.6984 ValRowAcc 39.32% | ValFused(all) 88.39%\n",
      "Fold2 Ep010 | TrainLoss 1.6855 TrainRowAcc 40.02% | ValLoss 1.6600 ValRowAcc 40.85% | ValFused(all) 98.21%\n",
      "Fold2 Ep011 | TrainLoss 1.6392 TrainRowAcc 41.97% | ValLoss 1.6375 ValRowAcc 41.74% | ValFused(all) 98.21%\n",
      "Fold2 Ep012 | TrainLoss 1.6170 TrainRowAcc 42.88% | ValLoss 1.6183 ValRowAcc 42.22% | ValFused(all) 100.00%\n",
      "Fold2 Ep013 | TrainLoss 1.6012 TrainRowAcc 43.47% | ValLoss 1.6233 ValRowAcc 42.18% | ValFused(all) 97.32%\n",
      "Fold2 Ep014 | TrainLoss 1.5848 TrainRowAcc 44.14% | ValLoss 1.6163 ValRowAcc 42.16% | ValFused(all) 100.00%\n",
      "Fold2 Ep015 | TrainLoss 1.5662 TrainRowAcc 44.70% | ValLoss 1.6132 ValRowAcc 42.34% | ValFused(all) 98.21%\n",
      "Fold2 Ep016 | TrainLoss 1.5541 TrainRowAcc 45.31% | ValLoss 1.6080 ValRowAcc 42.80% | ValFused(all) 98.21%\n",
      "Fold2 Ep017 | TrainLoss 1.5379 TrainRowAcc 45.95% | ValLoss 1.5939 ValRowAcc 43.31% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 2 | TestRowAcc(ref)=41.61% | TestFusedAcc@S=all=98.40% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\\fold_2\\best_state.pth\n",
      "Fold3 Ep001 | TrainLoss 2.2097 TrainRowAcc 12.00% | ValLoss 2.6630 ValRowAcc 10.77% | ValFused(all) 10.71%\n",
      "Fold3 Ep002 | TrainLoss 2.1699 TrainRowAcc 15.12% | ValLoss 2.2647 ValRowAcc 14.32% | ValFused(all) 16.96%\n",
      "Fold3 Ep003 | TrainLoss 2.0444 TrainRowAcc 23.65% | ValLoss 2.0235 ValRowAcc 24.16% | ValFused(all) 29.46%\n",
      "Fold3 Ep004 | TrainLoss 1.9362 TrainRowAcc 28.90% | ValLoss 1.9028 ValRowAcc 29.23% | ValFused(all) 52.68%\n",
      "Fold3 Ep005 | TrainLoss 1.8748 TrainRowAcc 31.55% | ValLoss 1.8258 ValRowAcc 33.72% | ValFused(all) 75.00%\n",
      "Fold3 Ep006 | TrainLoss 1.8144 TrainRowAcc 34.49% | ValLoss 1.7604 ValRowAcc 36.28% | ValFused(all) 84.82%\n",
      "Fold3 Ep007 | TrainLoss 1.7639 TrainRowAcc 36.70% | ValLoss 1.7351 ValRowAcc 37.62% | ValFused(all) 83.93%\n",
      "Fold3 Ep008 | TrainLoss 1.7288 TrainRowAcc 38.08% | ValLoss 1.6997 ValRowAcc 39.03% | ValFused(all) 83.93%\n",
      "Fold3 Ep009 | TrainLoss 1.6990 TrainRowAcc 39.42% | ValLoss 1.6724 ValRowAcc 40.30% | ValFused(all) 94.64%\n",
      "Fold3 Ep010 | TrainLoss 1.6754 TrainRowAcc 40.24% | ValLoss 1.6638 ValRowAcc 40.58% | ValFused(all) 88.39%\n",
      "Fold3 Ep011 | TrainLoss 1.6305 TrainRowAcc 42.17% | ValLoss 1.6409 ValRowAcc 41.49% | ValFused(all) 86.61%\n",
      "Fold3 Ep012 | TrainLoss 1.6077 TrainRowAcc 43.05% | ValLoss 1.6273 ValRowAcc 42.01% | ValFused(all) 89.29%\n",
      "Fold3 Ep013 | TrainLoss 1.5916 TrainRowAcc 43.74% | ValLoss 1.6145 ValRowAcc 42.62% | ValFused(all) 95.54%\n",
      "Fold3 Ep014 | TrainLoss 1.5783 TrainRowAcc 44.24% | ValLoss 1.6095 ValRowAcc 42.86% | ValFused(all) 98.21%\n",
      "Fold3 Ep015 | TrainLoss 1.5619 TrainRowAcc 44.95% | ValLoss 1.6094 ValRowAcc 42.88% | ValFused(all) 94.64%\n",
      "Fold3 Ep016 | TrainLoss 1.5480 TrainRowAcc 45.47% | ValLoss 1.5921 ValRowAcc 43.51% | ValFused(all) 97.32%\n",
      "Fold3 Ep017 | TrainLoss 1.5296 TrainRowAcc 46.29% | ValLoss 1.5971 ValRowAcc 43.43% | ValFused(all) 96.43%\n",
      "Fold3 Ep018 | TrainLoss 1.5171 TrainRowAcc 46.62% | ValLoss 1.5899 ValRowAcc 43.76% | ValFused(all) 97.32%\n",
      "Fold3 Ep019 | TrainLoss 1.5008 TrainRowAcc 47.34% | ValLoss 1.5799 ValRowAcc 44.11% | ValFused(all) 96.43%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 3 | TestRowAcc(ref)=41.91% | TestFusedAcc@S=all=98.93% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\\fold_3\\best_state.pth\n",
      "Fold4 Ep001 | TrainLoss 2.2075 TrainRowAcc 12.28% | ValLoss 2.3839 ValRowAcc 11.64% | ValFused(all) 11.61%\n",
      "Fold4 Ep002 | TrainLoss 2.1563 TrainRowAcc 16.39% | ValLoss 2.1773 ValRowAcc 18.18% | ValFused(all) 25.89%\n",
      "Fold4 Ep003 | TrainLoss 2.0349 TrainRowAcc 23.86% | ValLoss 1.9768 ValRowAcc 26.72% | ValFused(all) 57.14%\n",
      "Fold4 Ep004 | TrainLoss 1.9293 TrainRowAcc 29.09% | ValLoss 1.8824 ValRowAcc 30.86% | ValFused(all) 65.18%\n",
      "Fold4 Ep005 | TrainLoss 1.8642 TrainRowAcc 32.23% | ValLoss 1.7898 ValRowAcc 35.08% | ValFused(all) 79.46%\n",
      "Fold4 Ep006 | TrainLoss 1.8108 TrainRowAcc 34.51% | ValLoss 1.7446 ValRowAcc 36.99% | ValFused(all) 85.71%\n",
      "Fold4 Ep007 | TrainLoss 1.7661 TrainRowAcc 36.75% | ValLoss 1.6952 ValRowAcc 39.17% | ValFused(all) 84.82%\n",
      "Fold4 Ep008 | TrainLoss 1.7306 TrainRowAcc 38.11% | ValLoss 1.6696 ValRowAcc 40.50% | ValFused(all) 97.32%\n",
      "Fold4 Ep009 | TrainLoss 1.7050 TrainRowAcc 39.33% | ValLoss 1.6592 ValRowAcc 40.48% | ValFused(all) 87.50%\n",
      "Fold4 Ep010 | TrainLoss 1.6810 TrainRowAcc 40.30% | ValLoss 1.6282 ValRowAcc 41.87% | ValFused(all) 99.11%\n",
      "Fold4 Ep011 | TrainLoss 1.6383 TrainRowAcc 41.95% | ValLoss 1.6108 ValRowAcc 42.50% | ValFused(all) 99.11%\n",
      "Fold4 Ep012 | TrainLoss 1.6145 TrainRowAcc 42.74% | ValLoss 1.5985 ValRowAcc 42.78% | ValFused(all) 99.11%\n",
      "Fold4 Ep013 | TrainLoss 1.6002 TrainRowAcc 43.41% | ValLoss 1.5963 ValRowAcc 43.35% | ValFused(all) 100.00%\n",
      "Fold4 Ep014 | TrainLoss 1.5830 TrainRowAcc 44.16% | ValLoss 1.5895 ValRowAcc 43.48% | ValFused(all) 100.00%\n",
      "Fold4 Ep015 | TrainLoss 1.5678 TrainRowAcc 44.78% | ValLoss 1.5817 ValRowAcc 43.85% | ValFused(all) 100.00%\n",
      "Fold4 Ep016 | TrainLoss 1.5529 TrainRowAcc 45.34% | ValLoss 1.5796 ValRowAcc 43.85% | ValFused(all) 100.00%\n",
      "Fold4 Ep017 | TrainLoss 1.5378 TrainRowAcc 45.98% | ValLoss 1.5686 ValRowAcc 44.34% | ValFused(all) 100.00%\n",
      "Fold4 Ep018 | TrainLoss 1.5210 TrainRowAcc 46.58% | ValLoss 1.5703 ValRowAcc 44.34% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 4 | TestRowAcc(ref)=41.65% | TestFusedAcc@S=all=98.93% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\\fold_4\\best_state.pth\n",
      "Fold5 Ep001 | TrainLoss 2.2079 TrainRowAcc 12.10% | ValLoss 2.4398 ValRowAcc 11.74% | ValFused(all) 11.61%\n",
      "Fold5 Ep002 | TrainLoss 2.1568 TrainRowAcc 16.06% | ValLoss 2.2168 ValRowAcc 15.58% | ValFused(all) 17.86%\n",
      "Fold5 Ep003 | TrainLoss 2.0450 TrainRowAcc 23.51% | ValLoss 1.9672 ValRowAcc 26.50% | ValFused(all) 56.25%\n",
      "Fold5 Ep004 | TrainLoss 1.9208 TrainRowAcc 29.57% | ValLoss 1.8465 ValRowAcc 32.47% | ValFused(all) 73.21%\n",
      "Fold5 Ep005 | TrainLoss 1.8391 TrainRowAcc 33.20% | ValLoss 1.7675 ValRowAcc 35.76% | ValFused(all) 88.39%\n",
      "Fold5 Ep006 | TrainLoss 1.7861 TrainRowAcc 35.66% | ValLoss 1.7372 ValRowAcc 37.50% | ValFused(all) 87.50%\n",
      "Fold5 Ep007 | TrainLoss 1.7486 TrainRowAcc 37.22% | ValLoss 1.7081 ValRowAcc 38.56% | ValFused(all) 82.14%\n",
      "Fold5 Ep008 | TrainLoss 1.7197 TrainRowAcc 38.61% | ValLoss 1.6856 ValRowAcc 39.69% | ValFused(all) 97.32%\n",
      "Fold5 Ep009 | TrainLoss 1.6975 TrainRowAcc 39.39% | ValLoss 1.6562 ValRowAcc 41.05% | ValFused(all) 100.00%\n",
      "Fold5 Ep010 | TrainLoss 1.6740 TrainRowAcc 40.37% | ValLoss 1.6365 ValRowAcc 41.85% | ValFused(all) 100.00%\n",
      "Fold5 Ep011 | TrainLoss 1.6300 TrainRowAcc 42.21% | ValLoss 1.6130 ValRowAcc 42.67% | ValFused(all) 100.00%\n",
      "Fold5 Ep012 | TrainLoss 1.6080 TrainRowAcc 43.06% | ValLoss 1.6115 ValRowAcc 42.63% | ValFused(all) 100.00%\n",
      "Fold5 Ep013 | TrainLoss 1.5915 TrainRowAcc 43.88% | ValLoss 1.5954 ValRowAcc 43.13% | ValFused(all) 100.00%\n",
      "Fold5 Ep014 | TrainLoss 1.5775 TrainRowAcc 44.23% | ValLoss 1.5937 ValRowAcc 43.18% | ValFused(all) 100.00%\n",
      "[INFO] Early stop: 5 epochs no improvement on fused val acc@S=all.\n",
      "[RESULT] Fold 5 | TestRowAcc(ref)=40.28% | TestFusedAcc@S=all=98.40% | ckpt=d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\\fold_5\\best_state.pth\n",
      "[INFO] SNR  -5 dB → results in: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR-5dB_fd655\n",
      "[INFO] 汇总 CSV 已保存: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\snr_summary.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SNR 曲线已保存: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-21_19-02-30_LTEV_XFR_RowFusion_SaveAll_m288_EarlySall\\SNR_vs_fusedAcc_multiS_2026-01-21_19-02-30.png\n"
     ]
    }
   ],
   "source": [
    "# LTE-V XFR (row-level training) + block-level row-fusion (mean logits)\n",
    "# - Training: row samples from XFR blocks\n",
    "# - Evaluation: block-level row-fusion over selected rows S in {1,4,8,16,32,'all'}\n",
    "# - Save EVERYTHING needed for paper/repro: config/meta/splits/per-epoch logs/preds/CMs\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import platform\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# ================= 参数设置 =================\n",
    "data_path = \"E:/rf_datasets/\"  # 数据文件夹（*.mat）\n",
    "\n",
    "fs = 5e6\n",
    "fc = 5.9e9\n",
    "v_kmh = 120\n",
    "apply_doppler = True\n",
    "apply_awgn = True\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "in_planes = 64\n",
    "dropout = 0.5\n",
    "patience = 5\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "\n",
    "# XFR: group_size = m（每行长度）\n",
    "group_size = 288\n",
    "\n",
    "# 评估：S 列表（推理预算）\n",
    "S_LIST = [1, 4, 8, 16, 32, \"all\"]\n",
    "\n",
    "# Early-stopping 依据：用哪个 S 的 fused val acc 来选 best epoch\n",
    "EARLY_STOP_S = \"all\"   # 你也可改成 1（部署模式）或 32 等\n",
    "\n",
    "# 混淆矩阵保存：PNG 图片只画少数 S，避免文件爆炸；npy 数值会全保存\n",
    "PLOT_CM_S = [1, \"all\"]\n",
    "\n",
    "# 是否保存 X_blocks（很大，单 SNR ~0.5GB，慎用）\n",
    "SAVE_BLOCKS = False\n",
    "\n",
    "# block-level evaluation batch size\n",
    "block_batch_size = 8\n",
    "\n",
    "# ================= 工具函数：保存 =================\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def to_py(obj):\n",
    "    # 把 numpy / torch 标量转 python 原生，方便 json\n",
    "    if isinstance(obj, (np.integer,)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.floating,)):\n",
    "        return float(obj)\n",
    "    if torch.is_tensor(obj) and obj.numel() == 1:\n",
    "        return float(obj.item())\n",
    "    return obj\n",
    "\n",
    "# ================= 随机种子 =================\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(seed)\n",
    "\n",
    "# ================= 多普勒和AWGN处理函数 =================\n",
    "def compute_doppler_shift(v_kmh, fc_hz):\n",
    "    c = 3e8\n",
    "    v_ms = v_kmh / 3.6\n",
    "    return (v_ms / c) * fc_hz\n",
    "\n",
    "def apply_doppler_shift(signal_c, fd, fs):\n",
    "    t = np.arange(signal_c.shape[-1]) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal_c * doppler_phase\n",
    "\n",
    "def add_awgn(signal_c, snr_db):\n",
    "    signal_power = np.mean(np.abs(signal_c)**2)\n",
    "    noise_power = signal_power / (10**(snr_db/10))\n",
    "    noise_real = np.random.randn(*signal_c.shape)\n",
    "    noise_imag = np.random.randn(*signal_c.shape)\n",
    "    noise = np.sqrt(noise_power/2) * (noise_real + 1j*noise_imag)\n",
    "    return signal_c + noise\n",
    "\n",
    "def power_normalize(signal_c, eps=1e-12):\n",
    "    return signal_c / (np.sqrt(np.mean(np.abs(signal_c)**2)) + eps)\n",
    "\n",
    "# ================= 兼容读取 v7.3 HDF5 dmrs 与 txID =================\n",
    "def read_tx_id_str(rfDataset):\n",
    "    txID_uint16 = rfDataset['txID'][:].flatten()\n",
    "    tx_id = ''.join(chr(int(c)) for c in txID_uint16 if int(c) != 0)\n",
    "    return tx_id\n",
    "\n",
    "def read_dmrs_complex(rfDataset):\n",
    "    dmrs = rfDataset['dmrs']\n",
    "    if isinstance(dmrs, h5py.Group):\n",
    "        real = dmrs['real'][:]\n",
    "        imag = dmrs['imag'][:]\n",
    "        return real + 1j * imag\n",
    "    arr = dmrs[:]\n",
    "    if hasattr(arr, \"dtype\") and arr.dtype.fields is not None and ('real' in arr.dtype.fields) and ('imag' in arr.dtype.fields):\n",
    "        return arr['real'] + 1j * arr['imag']\n",
    "    return arr\n",
    "\n",
    "# ================= 数据加载（按 TX 聚合成 block，并做 XFR 转置） =================\n",
    "def load_and_preprocess_with_grouping(\n",
    "    mat_folder,\n",
    "    group_size=288,\n",
    "    apply_doppler=False,\n",
    "    target_velocity_kmh=120,\n",
    "    apply_awgn=False,\n",
    "    snr_db=20,\n",
    "    fs=5e6,\n",
    "    fc=5.9e9\n",
    "):\n",
    "    mat_files = glob.glob(os.path.join(mat_folder, '*.mat'))\n",
    "    if len(mat_files) == 0:\n",
    "        raise RuntimeError(f\"在 {mat_folder} 未找到 .mat 文件\")\n",
    "\n",
    "    print(f\"[INFO] 共找到 {len(mat_files)} 个 .mat 文件\")\n",
    "    fd = compute_doppler_shift(target_velocity_kmh, fc)\n",
    "    print(f\"[INFO] v={target_velocity_kmh} km/h，多普勒 fd={fd:.2f} Hz | SNR={snr_db} dB\")\n",
    "\n",
    "    X_files, y_files, label_set = [], [], set()\n",
    "\n",
    "    for file in tqdm(mat_files, desc='读取数据'):\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            rfDataset = f['rfDataset']\n",
    "            dmrs_complex = read_dmrs_complex(rfDataset)      # (N, L) complex\n",
    "            tx_id = read_tx_id_str(rfDataset)\n",
    "\n",
    "        if dmrs_complex.ndim != 2:\n",
    "            raise RuntimeError(f\"dmrs维度异常: {dmrs_complex.shape} | file={file}\")\n",
    "\n",
    "        N, seg_len = dmrs_complex.shape\n",
    "\n",
    "        processed = np.empty((N, seg_len, 2), dtype=np.float32)\n",
    "        for i in range(N):\n",
    "            sig = dmrs_complex[i, :]\n",
    "\n",
    "            sig = power_normalize(sig)\n",
    "\n",
    "            if apply_doppler:\n",
    "                sig = apply_doppler_shift(sig, fd, fs)\n",
    "\n",
    "            if apply_awgn:\n",
    "                sig = add_awgn(sig, snr_db)\n",
    "\n",
    "            processed[i, :, 0] = sig.real.astype(np.float32)\n",
    "            processed[i, :, 1] = sig.imag.astype(np.float32)\n",
    "\n",
    "        X_files.append(processed)     # (N, L, 2)\n",
    "        y_files.append(tx_id)\n",
    "        label_set.add(tx_id)\n",
    "\n",
    "    label_list = sorted(list(label_set))\n",
    "    label_to_idx = {label: i for i, label in enumerate(label_list)}\n",
    "    print(f\"[INFO] 类别数={len(label_to_idx)} | label_to_idx={label_to_idx}\")\n",
    "\n",
    "    X_blocks_list = []\n",
    "    y_blocks_list = []\n",
    "\n",
    "    for label in label_list:\n",
    "        files_idx = [i for i, y in enumerate(y_files) if y == label]\n",
    "        num_files = len(files_idx)\n",
    "        if num_files == 0:\n",
    "            continue\n",
    "\n",
    "        samples_per_file = group_size // num_files\n",
    "        if samples_per_file == 0:\n",
    "            print(f\"[WARN] TX {label} 文件过多({num_files})，导致 samples_per_file=0，跳过\")\n",
    "            continue\n",
    "\n",
    "        min_samples = min([X_files[i].shape[0] for i in files_idx])\n",
    "        max_groups = min_samples // samples_per_file\n",
    "        if max_groups == 0:\n",
    "            print(f\"[WARN] TX {label} 样本不足，跳过\")\n",
    "            continue\n",
    "\n",
    "        for g in range(max_groups):\n",
    "            pieces = []\n",
    "            for fi in files_idx:\n",
    "                start = g * samples_per_file\n",
    "                end = start + samples_per_file\n",
    "                piece = X_files[fi][start:end]      # (samples_per_file, L, 2)\n",
    "                pieces.append(piece)\n",
    "\n",
    "            big_block = np.concatenate(pieces, axis=0)       # (m, L, 2)\n",
    "\n",
    "            # XFR: (m, L, 2) -> (L, m, 2)\n",
    "            big_block = np.transpose(big_block, (1, 0, 2))   # (L, m, 2)\n",
    "\n",
    "            X_blocks_list.append(big_block)\n",
    "            y_blocks_list.append(label_to_idx[label])\n",
    "\n",
    "    if len(X_blocks_list) == 0:\n",
    "        raise RuntimeError(\"没有生成任何 block，请检查 group_size 和数据文件。\")\n",
    "\n",
    "    X_blocks = np.stack(X_blocks_list, axis=0).astype(np.float32)   # (Nblk, L, m, 2)\n",
    "    y_blocks = np.array(y_blocks_list, dtype=np.int64)\n",
    "\n",
    "    print(f\"[INFO] blocks={X_blocks.shape[0]} | X_blocks={X_blocks.shape} | y_blocks={y_blocks.shape}\")\n",
    "    return X_blocks, y_blocks, label_to_idx\n",
    "\n",
    "# ================= 1D ResNet18 =================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, m, 2)\n",
    "        x = x.permute(0, 2, 1)  # (B, 2, m)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ================= Dataset：row-level from blocks（避免巨大 reshape 占内存） =================\n",
    "class RowFromBlocksDataset(Dataset):\n",
    "    def __init__(self, X_blocks_t, y_blocks_t, block_ids):\n",
    "        \"\"\"\n",
    "        X_blocks_t: (Nblk, L, m, 2)\n",
    "        y_blocks_t: (Nblk,)\n",
    "        block_ids:  1D array of global block indices\n",
    "        \"\"\"\n",
    "        self.X = X_blocks_t\n",
    "        self.y = y_blocks_t\n",
    "        self.block_ids = np.asarray(block_ids, dtype=np.int64)\n",
    "        self.L = int(X_blocks_t.shape[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.block_ids) * self.L\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        b = idx // self.L\n",
    "        r = idx % self.L\n",
    "        blk_id = int(self.block_ids[b])\n",
    "        x = self.X[blk_id, r]    # (m,2)\n",
    "        y = self.y[blk_id]       # scalar\n",
    "        return x, y\n",
    "\n",
    "class BlockDatasetWithID(Dataset):\n",
    "    def __init__(self, X_blocks_t, y_blocks_t, block_ids):\n",
    "        self.X = X_blocks_t\n",
    "        self.y = y_blocks_t\n",
    "        self.block_ids = np.asarray(block_ids, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.block_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        blk_id = int(self.block_ids[idx])\n",
    "        return self.X[blk_id], self.y[blk_id], blk_id   # (L,m,2), y, global_id\n",
    "\n",
    "# ================= 评估：multi-S row-fusion（一次 forward 复用 logits） =================\n",
    "@torch.no_grad()\n",
    "def evaluate_row_fusion_multiS(model, block_loader, device, num_classes, row_perm_np, S_list):\n",
    "    \"\"\"\n",
    "    row_perm_np: (Nblk, L) 固定随机排列，用于嵌套抽样\n",
    "    返回：\n",
    "      acc_dict: {S: acc%}\n",
    "      cm_dict:  {S: cm ndarray}\n",
    "      pred_dict:{S: preds ndarray (Nblocks,)}\n",
    "      gt:       ndarray (Nblocks,)\n",
    "      blk_ids:  ndarray (Nblocks,)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    acc_correct = {str(S): 0 for S in S_list}\n",
    "    acc_total = 0\n",
    "\n",
    "    all_gt = []\n",
    "    all_blk = []\n",
    "    all_pred = {str(S): [] for S in S_list}\n",
    "\n",
    "    for blocks, labels, blk_ids in block_loader:\n",
    "        blocks = blocks.to(device)     # (B, L, m, 2)\n",
    "        labels = labels.to(device)     # (B,)\n",
    "        blk_ids_np = np.asarray(blk_ids, dtype=np.int64)\n",
    "\n",
    "        B, L, m, C = blocks.shape\n",
    "        flat = blocks.reshape(B * L, m, C)                  # (B*L, m,2)\n",
    "        logits = model(flat).reshape(B, L, num_classes)     # (B,L,K)\n",
    "\n",
    "        for S in S_list:\n",
    "            key = str(S)\n",
    "            if S == \"all\" or S is None or (isinstance(S, int) and S >= L):\n",
    "                fused = logits.mean(dim=1)                  # (B,K)\n",
    "            else:\n",
    "                S_int = int(S)\n",
    "                sel = row_perm_np[blk_ids_np, :S_int]       # (B,S)\n",
    "                sel_t = torch.from_numpy(sel).to(device).long()  # (B,S)\n",
    "                idx = sel_t.unsqueeze(-1).expand(-1, -1, num_classes)  # (B,S,K)\n",
    "                sel_logits = torch.gather(logits, dim=1, index=idx)    # (B,S,K)\n",
    "                fused = sel_logits.mean(dim=1)              # (B,K)\n",
    "\n",
    "            preds = torch.argmax(fused, dim=1)              # (B,)\n",
    "            acc_correct[key] += (preds == labels).sum().item()\n",
    "            all_pred[key].extend(preds.detach().cpu().numpy().tolist())\n",
    "\n",
    "        acc_total += labels.size(0)\n",
    "        all_gt.extend(labels.detach().cpu().numpy().tolist())\n",
    "        all_blk.extend(blk_ids_np.tolist())\n",
    "\n",
    "    gt = np.asarray(all_gt, dtype=np.int64)\n",
    "    blk = np.asarray(all_blk, dtype=np.int64)\n",
    "\n",
    "    acc_dict = {k: 100.0 * acc_correct[k] / max(acc_total, 1) for k in acc_correct.keys()}\n",
    "\n",
    "    cm_dict = {}\n",
    "    for S in S_list:\n",
    "        key = str(S)\n",
    "        preds = np.asarray(all_pred[key], dtype=np.int64)\n",
    "        cm = confusion_matrix(gt, preds, labels=list(range(num_classes)))\n",
    "        cm_dict[key] = cm\n",
    "\n",
    "    pred_dict = {str(S): np.asarray(all_pred[str(S)], dtype=np.int64) for S in S_list}\n",
    "    return acc_dict, cm_dict, pred_dict, gt, blk\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_row_level_acc(model, row_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for xb, yb in row_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    return 100.0 * correct / max(total, 1)\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Reference')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# ================= 主训练（按 block 划分；早停依据 fused val acc@EARLY_STOP_S） =================\n",
    "def train_for_snr(SNR_dB, snr_folder):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] device={device}\")\n",
    "\n",
    "    # ---- 保存 config/meta（每个 SNR 一份）----\n",
    "    cfg = {\n",
    "        \"data_path\": data_path,\n",
    "        \"fs\": fs,\n",
    "        \"fc\": fc,\n",
    "        \"v_kmh\": v_kmh,\n",
    "        \"apply_doppler\": apply_doppler,\n",
    "        \"apply_awgn\": apply_awgn,\n",
    "        \"SNR_dB\": SNR_dB,\n",
    "        \"group_size_m\": group_size,\n",
    "        \"S_LIST\": S_LIST,\n",
    "        \"EARLY_STOP_S\": EARLY_STOP_S,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"in_planes\": in_planes,\n",
    "        \"dropout\": dropout,\n",
    "        \"patience\": patience,\n",
    "        \"n_splits\": n_splits,\n",
    "        \"seed\": seed,\n",
    "        \"block_batch_size\": block_batch_size,\n",
    "        \"SAVE_BLOCKS\": SAVE_BLOCKS,\n",
    "        \"env\": {\n",
    "            \"python\": platform.python_version(),\n",
    "            \"torch\": torch.__version__,\n",
    "            \"cuda_available\": torch.cuda.is_available(),\n",
    "            \"device\": str(device),\n",
    "            \"numpy\": np.__version__,\n",
    "        }\n",
    "    }\n",
    "    save_json(cfg, os.path.join(snr_folder, \"config.json\"))\n",
    "\n",
    "    # 1) load blocks\n",
    "    t0 = time.time()\n",
    "    X_blocks_np, y_blocks_np, label_to_idx = load_and_preprocess_with_grouping(\n",
    "        data_path,\n",
    "        group_size=group_size,\n",
    "        apply_doppler=apply_doppler,\n",
    "        target_velocity_kmh=v_kmh,\n",
    "        apply_awgn=apply_awgn,\n",
    "        snr_db=SNR_dB,\n",
    "        fs=fs,\n",
    "        fc=fc\n",
    "    )\n",
    "    t_load = time.time() - t0\n",
    "\n",
    "    # save label map\n",
    "    save_json(label_to_idx, os.path.join(snr_folder, \"label_to_idx.json\"))\n",
    "\n",
    "    # tensorize\n",
    "    X_blocks = torch.from_numpy(np.ascontiguousarray(X_blocks_np)).float()\n",
    "    y_blocks = torch.from_numpy(np.ascontiguousarray(y_blocks_np)).long()\n",
    "\n",
    "    Nblk, L, m, C = X_blocks.shape\n",
    "    num_classes = len(label_to_idx)\n",
    "    print(f\"[INFO] blocks={Nblk} | L={L} | m={m} | classes={num_classes}\")\n",
    "\n",
    "    # dataset meta\n",
    "    counts = {}\n",
    "    for k, v in label_to_idx.items():\n",
    "        counts[k] = int(np.sum(y_blocks_np == v))\n",
    "    meta = {\n",
    "        \"num_blocks\": int(Nblk),\n",
    "        \"L\": int(L),\n",
    "        \"m\": int(m),\n",
    "        \"C\": int(C),\n",
    "        \"num_classes\": int(num_classes),\n",
    "        \"blocks_per_class\": counts,\n",
    "        \"load_time_sec\": float(t_load),\n",
    "    }\n",
    "    save_json(meta, os.path.join(snr_folder, \"dataset_meta.json\"))\n",
    "\n",
    "    # optionally save blocks (VERY LARGE)\n",
    "    if SAVE_BLOCKS:\n",
    "        np.savez_compressed(\n",
    "            os.path.join(snr_folder, \"Xy_blocks.npz\"),\n",
    "            X_blocks=X_blocks_np.astype(np.float32),\n",
    "            y_blocks=y_blocks_np.astype(np.int64)\n",
    "        )\n",
    "\n",
    "    # 2) fixed row permutation per block for nested S\n",
    "    rng = np.random.default_rng(seed)\n",
    "    row_perm = np.empty((Nblk, L), dtype=np.uint16)\n",
    "    for i in range(Nblk):\n",
    "        row_perm[i] = rng.permutation(L).astype(np.uint16)\n",
    "    np.save(os.path.join(snr_folder, \"row_perm.npy\"), row_perm)\n",
    "\n",
    "    # 3) block-level split train/test\n",
    "    block_idx = np.arange(Nblk, dtype=np.int64)\n",
    "    train_blocks, test_blocks = train_test_split(\n",
    "        block_idx, test_size=0.25, random_state=seed, stratify=y_blocks_np\n",
    "    )\n",
    "    np.savez(\n",
    "        os.path.join(snr_folder, \"split_blocks.npz\"),\n",
    "        train_blocks=train_blocks.astype(np.int64),\n",
    "        test_blocks=test_blocks.astype(np.int64)\n",
    "    )\n",
    "\n",
    "    # fixed test loader (block-level)\n",
    "    test_ds = BlockDatasetWithID(X_blocks, y_blocks, test_blocks)\n",
    "    test_loader = DataLoader(test_ds, batch_size=block_batch_size, shuffle=False)\n",
    "\n",
    "    # for reference row-level acc on test (optional)\n",
    "    test_row_ds = RowFromBlocksDataset(X_blocks, y_blocks, test_blocks)\n",
    "    test_row_loader = DataLoader(test_row_ds, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "    # 4) StratifiedKFold on train blocks\n",
    "    y_train_lbl = y_blocks_np[train_blocks]\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    # aggregate per-S across folds\n",
    "    fold_results = []  # list of dicts\n",
    "\n",
    "    # create summary CSV header later\n",
    "    for fold, (tr_i, va_i) in enumerate(skf.split(train_blocks, y_train_lbl), start=1):\n",
    "        fold_dir = ensure_dir(os.path.join(snr_folder, f\"fold_{fold}\"))\n",
    "        tr_blocks = train_blocks[tr_i]\n",
    "        va_blocks = train_blocks[va_i]\n",
    "\n",
    "        # save fold split\n",
    "        np.savez(\n",
    "            os.path.join(fold_dir, \"fold_blocks.npz\"),\n",
    "            tr_blocks=tr_blocks.astype(np.int64),\n",
    "            va_blocks=va_blocks.astype(np.int64),\n",
    "            test_blocks=test_blocks.astype(np.int64)\n",
    "        )\n",
    "\n",
    "        # row-level dataset loaders\n",
    "        tr_row_ds = RowFromBlocksDataset(X_blocks, y_blocks, tr_blocks)\n",
    "        va_row_ds = RowFromBlocksDataset(X_blocks, y_blocks, va_blocks)\n",
    "\n",
    "        tr_loader = DataLoader(tr_row_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        va_row_loader = DataLoader(va_row_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        # block-level val loader for fusion\n",
    "        va_blk_ds = BlockDatasetWithID(X_blocks, y_blocks, va_blocks)\n",
    "        va_blk_loader = DataLoader(va_blk_ds, batch_size=block_batch_size, shuffle=False)\n",
    "\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        # early stop tracking\n",
    "        best_metric = -1.0\n",
    "        best_epoch = -1\n",
    "        best_state = None\n",
    "        patience_cnt = 0\n",
    "\n",
    "        # epoch logs\n",
    "        # columns: epoch, train_loss, train_row_acc, val_loss, val_row_acc, val_fused_acc_S=...\n",
    "        log_path = os.path.join(fold_dir, \"epoch_log.csv\")\n",
    "        with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            header = [\"epoch\", \"train_loss\", \"train_row_acc\", \"val_loss\", \"val_row_acc\"]\n",
    "            for S in S_LIST:\n",
    "                header.append(f\"val_fused_acc_S={S}\")\n",
    "            f.write(\",\".join(header) + \"\\n\")\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # ---- train ----\n",
    "            model.train()\n",
    "            tr_loss_sum = 0.0\n",
    "            tr_correct, tr_total = 0, 0\n",
    "            for xb, yb in tr_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                tr_loss_sum += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                tr_correct += (preds == yb).sum().item()\n",
    "                tr_total += yb.size(0)\n",
    "\n",
    "            train_loss = tr_loss_sum / max(len(tr_loader), 1)\n",
    "            train_row_acc = 100.0 * tr_correct / max(tr_total, 1)\n",
    "\n",
    "            # ---- val row-level ----\n",
    "            model.eval()\n",
    "            va_loss_sum = 0.0\n",
    "            va_correct, va_total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in va_row_loader:\n",
    "                    xb = xb.to(device)\n",
    "                    yb = yb.to(device)\n",
    "                    logits = model(xb)\n",
    "                    loss = criterion(logits, yb)\n",
    "                    va_loss_sum += loss.item()\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                    va_correct += (preds == yb).sum().item()\n",
    "                    va_total += yb.size(0)\n",
    "\n",
    "            val_loss = va_loss_sum / max(len(va_row_loader), 1)\n",
    "            val_row_acc = 100.0 * va_correct / max(va_total, 1)\n",
    "\n",
    "            # ---- val fused (multi-S) ----\n",
    "            val_fused_acc_dict, _, _, _, _ = evaluate_row_fusion_multiS(\n",
    "                model, va_blk_loader, device, num_classes, row_perm, S_LIST\n",
    "            )\n",
    "\n",
    "            # choose early stop metric\n",
    "            key_es = str(EARLY_STOP_S)\n",
    "            metric = float(val_fused_acc_dict[key_es])\n",
    "\n",
    "            # log to csv\n",
    "            row = [epoch, train_loss, train_row_acc, val_loss, val_row_acc]\n",
    "            for S in S_LIST:\n",
    "                row.append(float(val_fused_acc_dict[str(S)]))\n",
    "            with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(\",\".join([f\"{x:.6f}\" if isinstance(x, float) else str(x) for x in row]) + \"\\n\")\n",
    "\n",
    "            print(f\"Fold{fold} Ep{epoch:03d} | \"\n",
    "                  f\"TrainLoss {train_loss:.4f} TrainRowAcc {train_row_acc:.2f}% | \"\n",
    "                  f\"ValLoss {val_loss:.4f} ValRowAcc {val_row_acc:.2f}% | \"\n",
    "                  f\"ValFused({EARLY_STOP_S}) {metric:.2f}%\")\n",
    "\n",
    "            # early stop update\n",
    "            if metric > best_metric + 1e-6:\n",
    "                best_metric = metric\n",
    "                best_epoch = epoch\n",
    "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "                patience_cnt = 0\n",
    "            else:\n",
    "                patience_cnt += 1\n",
    "                if patience_cnt >= patience:\n",
    "                    print(f\"[INFO] Early stop: {patience} epochs no improvement on fused val acc@S={EARLY_STOP_S}.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # restore best\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "        ckpt_path = os.path.join(fold_dir, \"best_state.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "\n",
    "        # ---- test fused (multi-S) ----\n",
    "        test_fused_acc_dict, test_cm_dict, test_pred_dict, gt_blk, blk_ids = evaluate_row_fusion_multiS(\n",
    "            model, test_loader, device, num_classes, row_perm, S_LIST\n",
    "        )\n",
    "\n",
    "        # test row-level reference\n",
    "        test_row_acc = evaluate_row_level_acc(model, test_row_loader, device)\n",
    "\n",
    "        # save test metrics\n",
    "        test_metrics = {\n",
    "            \"fold\": fold,\n",
    "            \"best_epoch\": best_epoch,\n",
    "            \"best_val_fused_acc_at_early_S\": float(best_metric),\n",
    "            \"test_row_acc_ref\": float(test_row_acc),\n",
    "            \"test_fused_acc\": {k: float(v) for k, v in test_fused_acc_dict.items()},\n",
    "            \"ckpt_path\": ckpt_path\n",
    "        }\n",
    "        save_json(test_metrics, os.path.join(fold_dir, \"test_metrics.json\"))\n",
    "\n",
    "        # save preds/cms per S\n",
    "        for S in S_LIST:\n",
    "            key = str(S)\n",
    "            np.savez(\n",
    "                os.path.join(fold_dir, f\"test_preds_S{key}.npz\"),\n",
    "                block_ids=blk_ids.astype(np.int64),\n",
    "                y_true=gt_blk.astype(np.int64),\n",
    "                y_pred=test_pred_dict[key].astype(np.int64)\n",
    "            )\n",
    "            np.save(os.path.join(fold_dir, f\"cm_test_S{key}.npy\"), test_cm_dict[key].astype(np.int64))\n",
    "\n",
    "            if S in PLOT_CM_S:\n",
    "                plot_confusion_matrix(\n",
    "                    test_cm_dict[key],\n",
    "                    save_path=os.path.join(fold_dir, f\"cm_test_S{key}.png\"),\n",
    "                    title=f\"Test CM (Fused, S={key})\"\n",
    "                )\n",
    "\n",
    "        fold_results.append(test_metrics)\n",
    "\n",
    "        print(f\"[RESULT] Fold {fold} | TestRowAcc(ref)={test_row_acc:.2f}% | \"\n",
    "              f\"TestFusedAcc@S={EARLY_STOP_S}={test_fused_acc_dict[str(EARLY_STOP_S)]:.2f}% | ckpt={ckpt_path}\")\n",
    "\n",
    "    # ---- aggregate across folds for this SNR ----\n",
    "    agg = {\"SNR_dB\": int(SNR_dB), \"folds\": fold_results}\n",
    "    # mean/std per S\n",
    "    fused_means = {}\n",
    "    fused_stds = {}\n",
    "    for S in S_LIST:\n",
    "        key = str(S)\n",
    "        vals = [fr[\"test_fused_acc\"][key] for fr in fold_results]\n",
    "        fused_means[key] = float(np.mean(vals))\n",
    "        fused_stds[key] = float(np.std(vals))\n",
    "    row_vals = [fr[\"test_row_acc_ref\"] for fr in fold_results]\n",
    "    agg[\"test_row_acc_ref_mean\"] = float(np.mean(row_vals))\n",
    "    agg[\"test_row_acc_ref_std\"] = float(np.std(row_vals))\n",
    "    agg[\"test_fused_acc_mean\"] = fused_means\n",
    "    agg[\"test_fused_acc_std\"] = fused_stds\n",
    "\n",
    "    save_json(agg, os.path.join(snr_folder, \"summary.json\"))\n",
    "\n",
    "    # also save a simple CSV for quick plotting\n",
    "    csv_path = os.path.join(snr_folder, \"summary_by_S.csv\")\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        cols = [\"S\", \"mean_acc\", \"std_acc\"]\n",
    "        f.write(\",\".join(cols) + \"\\n\")\n",
    "        for S in S_LIST:\n",
    "            key = str(S)\n",
    "            f.write(f\"{key},{fused_means[key]:.6f},{fused_stds[key]:.6f}\\n\")\n",
    "\n",
    "    return agg\n",
    "\n",
    "# ================= SNR 循环训练 + 汇总保存 =================\n",
    "if __name__ == \"__main__\":\n",
    "    snr_list = [20,-5]\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    script_name = \"LTEV_XFR_RowFusion_SaveAll\"\n",
    "    out_root = ensure_dir(os.path.join(\n",
    "        os.getcwd(),\n",
    "        \"training_results\",\n",
    "        f\"{timestamp}_{script_name}_m{group_size}_EarlyS{EARLY_STOP_S}\"\n",
    "    ))\n",
    "\n",
    "    # 保存全局 config（跨 SNR）\n",
    "    global_cfg = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"snr_list\": snr_list,\n",
    "        \"group_size_m\": group_size,\n",
    "        \"S_LIST\": S_LIST,\n",
    "        \"EARLY_STOP_S\": EARLY_STOP_S,\n",
    "        \"seed\": seed,\n",
    "        \"out_root\": out_root\n",
    "    }\n",
    "    save_json(global_cfg, os.path.join(out_root, \"global_config.json\"))\n",
    "\n",
    "    all_summaries = []\n",
    "\n",
    "    for snr_db in snr_list:\n",
    "        print(f\"\\n\\n================== 当前实验 SNR={snr_db} dB ==================\\n\")\n",
    "        fd_int = int(compute_doppler_shift(v_kmh, fc))\n",
    "        snr_folder = ensure_dir(os.path.join(out_root, f\"SNR{snr_db}dB_fd{fd_int}\"))\n",
    "\n",
    "        summ = train_for_snr(snr_db, snr_folder)\n",
    "        all_summaries.append(summ)\n",
    "        print(f\"[INFO] SNR {snr_db:>3} dB → results in: {snr_folder}\")\n",
    "\n",
    "    # 汇总成一张总表（每个 S 一列）\n",
    "    # 保存为: out_root/snr_summary.csv\n",
    "    summary_csv = os.path.join(out_root, \"snr_summary.csv\")\n",
    "    with open(summary_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        cols = [\"SNR_dB\"]\n",
    "        cols += [f\"mean_S={S}\" for S in S_LIST]\n",
    "        cols += [f\"std_S={S}\" for S in S_LIST]\n",
    "        cols += [\"row_ref_mean\", \"row_ref_std\"]\n",
    "        f.write(\",\".join(cols) + \"\\n\")\n",
    "\n",
    "        for summ in all_summaries:\n",
    "            row = [str(summ[\"SNR_dB\"])]\n",
    "            for S in S_LIST:\n",
    "                row.append(f\"{summ['test_fused_acc_mean'][str(S)]:.6f}\")\n",
    "            for S in S_LIST:\n",
    "                row.append(f\"{summ['test_fused_acc_std'][str(S)]:.6f}\")\n",
    "            row.append(f\"{summ['test_row_acc_ref_mean']:.6f}\")\n",
    "            row.append(f\"{summ['test_row_acc_ref_std']:.6f}\")\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "\n",
    "    print(f\"[INFO] 汇总 CSV 已保存: {summary_csv}\")\n",
    "\n",
    "    # 可选：画 SNR vs Acc 曲线（每个 S 一条）\n",
    "    # 注意：不指定颜色，交给 matplotlib 默认配色\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    for S in S_LIST:\n",
    "        ys = [summ[\"test_fused_acc_mean\"][str(S)] for summ in all_summaries]\n",
    "        plt.plot(snr_list, ys, marker='o', linestyle='-', label=f\"S={S}\")\n",
    "    plt.xlabel(\"SNR (dB)\")\n",
    "    plt.ylabel(\"Test Acc (Block-level Row-Fusion, %)\")\n",
    "    plt.title(f\"LTE-V XFR Row-Fusion (m={group_size})\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    fig_path = os.path.join(out_root, f\"SNR_vs_fusedAcc_multiS_{timestamp}.png\")\n",
    "    plt.savefig(fig_path)\n",
    "    plt.show()\n",
    "    print(f\"[INFO] SNR 曲线已保存: {fig_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
