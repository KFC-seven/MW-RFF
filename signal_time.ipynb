{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38d64943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个文件（dev0.mat）的数据 shape (转置后): (7014, 320),信号数量*采样点数量\n",
      "第1个文件（dev1.mat）的数据 shape (转置后): (6632, 320),信号数量*采样点数量\n",
      "第2个文件（dev10.mat）的数据 shape (转置后): (8935, 320),信号数量*采样点数量\n",
      "第3个文件（dev11.mat）的数据 shape (转置后): (7776, 320),信号数量*采样点数量\n",
      "第4个文件（dev13.mat）的数据 shape (转置后): (7410, 320),信号数量*采样点数量\n",
      "第5个文件（dev14.mat）的数据 shape (转置后): (6274, 320),信号数量*采样点数量\n",
      "第6个文件（dev15.mat）的数据 shape (转置后): (5706, 320),信号数量*采样点数量\n",
      "第7个文件（dev16.mat）的数据 shape (转置后): (12968, 320),信号数量*采样点数量\n",
      "第8个文件（dev17.mat）的数据 shape (转置后): (9508, 320),信号数量*采样点数量\n",
      "第9个文件（dev18.mat）的数据 shape (转置后): (3343, 320),信号数量*采样点数量\n",
      "第10个文件（dev19.mat）的数据 shape (转置后): (4756, 320),信号数量*采样点数量\n",
      "第11个文件（dev2.mat）的数据 shape (转置后): (6316, 320),信号数量*采样点数量\n",
      "第12个文件（dev20.mat）的数据 shape (转置后): (5592, 320),信号数量*采样点数量\n",
      "第13个文件（dev3.mat）的数据 shape (转置后): (5536, 320),信号数量*采样点数量\n",
      "第14个文件（dev4.mat）的数据 shape (转置后): (6669, 320),信号数量*采样点数量\n",
      "第15个文件（dev5.mat）的数据 shape (转置后): (5237, 320),信号数量*采样点数量\n",
      "第16个文件（dev6.mat）的数据 shape (转置后): (5460, 320),信号数量*采样点数量\n",
      "第17个文件（dev7.mat）的数据 shape (转置后): (8926, 320),信号数量*采样点数量\n",
      "第18个文件（dev8.mat）的数据 shape (转置后): (7614, 320),信号数量*采样点数量\n",
      "第19个文件（dev9.mat）的数据 shape (转置后): (7232, 320),信号数量*采样点数量\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "folder_path = r\"..\\los_data\"  # 你的文件夹路径\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.mat')]  # 找到所有mat文件\n",
    "file_list = sorted(file_list)  # 按文件名排序，比如 dev0.mat, dev1.mat, dev2.mat\n",
    "\n",
    "data = []  # 用来存储每个mat文件中的 'data_Ineed'（转置后的）\n",
    "\n",
    "for i, file_name in enumerate(file_list):\n",
    "    full_path = os.path.join(folder_path, file_name)\n",
    "    mat_contents = loadmat(full_path)\n",
    "    if 'data_Ineed' in mat_contents:\n",
    "        data_ineed = mat_contents['data_Ineed'].T  # 加上 .T 转置！\n",
    "        data.append(data_ineed)\n",
    "    else:\n",
    "        print(f\"Warning: {file_name} 里没有 'data_Ineed' 变量！\")\n",
    "\n",
    "# 打印检查\n",
    "for i, d in enumerate(data):\n",
    "    print(f\"第{i}个文件（{file_list[i]}）的数据 shape (转置后): {d.shape},信号数量*采样点数量\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b09b00e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据和加噪声数据示例：\n",
      "原始信号样本（第一个信号）：[-0.01318091-0.00598181j -0.01379628-0.00492906j -0.017992  +0.00138218j\n",
      " -0.185444  +0.24452379j -0.6173177 +0.97452922j -0.15240179+0.98618152j\n",
      "  0.87295696-0.30563645j  0.19726927-0.65624198j  0.0687799 +0.41792528j\n",
      "  0.95404651+0.17878775j]\n",
      "加噪声信号样本（第一个信号）：[-0.53046114-0.00598181j  1.21993253-0.00492906j -0.91074475+0.00138218j\n",
      "  0.53230997+0.24452379j -1.25492826+0.97452922j  0.46152464+0.98618152j\n",
      "  0.51176481-0.30563645j -0.2559005 -0.65624198j  1.76641164+0.41792528j\n",
      "  1.1242514 +0.17878775j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设data是从之前的加载代码中获取的\n",
    "# data = <从前一部分代码中加载的数据>\n",
    "\n",
    "SNR_dB = 0  # 设定信噪比（dB）\n",
    "\n",
    "noisy_data = []  # 用来存储加噪声后的数据\n",
    "\n",
    "for d in data:\n",
    "    # 计算信号的标准差\n",
    "    signal_std = np.std(d)\n",
    "    \n",
    "    # 计算噪声的标准差，根据信噪比（SNR）\n",
    "    noise_std = signal_std / (10 ** (SNR_dB / 20))  # 根据 SNR(dB) 计算噪声标准差\n",
    "    \n",
    "    # 生成高斯噪声并加到原信号上\n",
    "    noise = np.random.normal(0, noise_std, d.shape)  # 均值为0，标准差为噪声标准差\n",
    "    noisy_signal = d + noise  # 添加噪声\n",
    "    \n",
    "    noisy_data.append(noisy_signal)  # 保存加噪声后的信号\n",
    "\n",
    "# 打印检查加噪声后的数据\n",
    "print(\"原始数据和加噪声数据示例：\")\n",
    "print(f\"原始信号样本（第一个信号）：{data[0][0][:10]}\")  # 打印前10个采样点\n",
    "print(f\"加噪声信号样本（第一个信号）：{noisy_data[0][0][:10]}\")  # 打印前10个采样点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b23f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算得到的多普勒频移 fd = 960.00 Hz\n",
      "添加多普勒频移后的信号：\n",
      "[array([[-1.31809103e-02-5.98180779e-03j, -1.37947949e-02-4.93321758e-03j,\n",
      "        -1.79928297e-02+1.37133193e-03j, ...,\n",
      "        -6.89619956e-01+5.50042694e-01j, -9.99839876e-01-8.32659396e-01j,\n",
      "        -1.11560021e+00-9.34665285e-02j],\n",
      "       [-8.56644948e-03-6.65819948e-03j, -8.91658798e-03-5.59493963e-03j,\n",
      "        -2.69344990e-02+1.38531539e-04j, ...,\n",
      "        -8.31800495e-01-1.83720636e-01j, -2.58598388e-01-1.30271445e+00j,\n",
      "        -9.84373209e-01-4.87990085e-01j],\n",
      "       [-1.29356950e-02+3.14398823e-03j, -1.27657228e-02+1.49757215e-03j,\n",
      "         2.21325838e-02-2.62012427e-03j, ...,\n",
      "         6.64212255e-01+5.85842682e-01j, -4.03250557e-02+1.34218788e+00j,\n",
      "         1.01261034e+00+5.58445320e-01j],\n",
      "       ...,\n",
      "       [-2.10301175e-03+1.49593753e-03j, -6.33281110e-04+8.61391858e-04j,\n",
      "         1.06096591e-01+2.45092412e-02j, ...,\n",
      "        -7.49636238e-03+1.04918940e+00j, -1.76456235e-01+1.20591366e+00j,\n",
      "         1.17074818e+00+4.66082017e-01j],\n",
      "       [-1.85324861e-03-2.77106919e-03j, -1.66374474e-03-3.46579472e-03j,\n",
      "        -6.11287197e-02+5.08780575e-02j, ...,\n",
      "        -9.07422101e-01-4.20766158e-01j, -9.31513891e-01-8.94866821e-01j,\n",
      "        -1.12863566e+00+5.53315258e-01j],\n",
      "       [ 9.25959253e-03-1.99484085e-03j,  9.34988327e-03-1.93531879e-03j,\n",
      "         1.05527766e-02+7.04718312e-04j, ...,\n",
      "         2.32000620e-01+9.04963750e-01j, -1.14553903e+00+2.11938317e-01j,\n",
      "        -1.13294755e+00+3.71192788e-01j]]), array([[-5.59588546e-02-1.68155786e-02j, -5.25215163e-02-1.76965885e-02j,\n",
      "        -1.36212372e-02-2.43180793e-02j, ...,\n",
      "         7.19797842e-01+3.00630656e-01j,  5.36621802e-01+1.13105656e+00j,\n",
      "         1.29314902e+00-2.81181535e-02j],\n",
      "       [-4.19027409e-02-1.37979496e-02j, -3.98913264e-02-1.41179423e-02j,\n",
      "        -5.44292390e-02-4.62112411e-02j, ...,\n",
      "         4.98385052e-02-8.24869592e-01j,  1.01815339e+00-8.83032641e-01j,\n",
      "        -3.04829021e-01-1.25929111e+00j],\n",
      "       [-2.81729693e-02-1.11077528e-03j, -2.67796799e-02-2.89294608e-04j,\n",
      "        -2.51994162e-02+4.08634273e-02j, ...,\n",
      "        -3.71355950e-01+7.04693984e-01j, -1.26133191e+00+5.27732219e-01j,\n",
      "        -5.86610837e-02+1.24658227e+00j],\n",
      "       ...,\n",
      "       [-3.97484557e-03+5.40354334e-03j, -4.86061740e-03+7.29608470e-03j,\n",
      "        -1.51882965e-02+2.21145200e-02j, ...,\n",
      "        -5.42163572e-01+5.76931171e-01j, -1.33053708e+00-3.25563091e-01j,\n",
      "        -9.92435245e-01+7.48652206e-01j],\n",
      "       [ 2.51005089e-03+9.16804797e-03j,  2.82735633e-03+6.97821222e-03j,\n",
      "         2.37630162e-02+4.15825857e-02j, ...,\n",
      "        -1.10766604e-01+8.17254120e-01j, -9.75657276e-01+8.91027322e-01j,\n",
      "         4.23656812e-01+1.20332030e+00j],\n",
      "       [-3.39932072e-04-6.60294798e-03j,  1.64765334e-03-7.90920157e-03j,\n",
      "         2.25942716e-02-8.21185899e-02j, ...,\n",
      "         9.12473889e-01-2.42483658e-01j,  1.31533664e+00+1.89454738e-02j,\n",
      "         4.43403748e-01-1.21884333e+00j]]), array([[-0.07714929-0.02866302j, -0.07591815-0.03038013j,\n",
      "        -0.0684509 -0.04619091j, ...,  0.02642813-0.94010268j,\n",
      "         1.07757874-0.17573538j,  1.1341896 -0.14398232j],\n",
      "       [-0.07859567-0.01964287j, -0.08548744-0.01478904j,\n",
      "        -0.21399659+0.12203296j, ..., -0.85091164-0.09005363j,\n",
      "        -0.8815516 -0.51551376j, -0.8806757 +0.77846938j],\n",
      "       [-0.07749676-0.0211156j , -0.08656932-0.02011675j,\n",
      "        -0.25171234+0.04728737j, ..., -0.64041349+0.01015581j,\n",
      "        -0.93590886-0.7577622j , -1.2815881 +0.44374267j],\n",
      "       ...,\n",
      "       [-0.00910293+0.00498973j, -0.01747873+0.00783371j,\n",
      "        -0.17859898+0.08056912j, ..., -0.81684283-0.4038269j ,\n",
      "        -0.68878131-0.88209569j, -1.19133857+0.31214222j],\n",
      "       [-0.00466391-0.00540016j, -0.00442751-0.01237894j,\n",
      "        -0.0343615 -0.11789181j, ...,  0.22597644-0.83222791j,\n",
      "         1.03184431-0.62273245j,  0.08217748-1.1971323j ],\n",
      "       [-0.00583229+0.00236253j, -0.01516299+0.0066073j ,\n",
      "        -0.11606758+0.05867709j, ..., -0.85369518-0.01261527j,\n",
      "        -0.76975397-0.86605895j, -1.15901242+0.21927274j]]), array([[ 1.71212724e-03+6.04403166e-03j, -2.62145795e-03+1.37919500e-02j,\n",
      "        -8.27836884e-02+1.83919766e-01j, ...,\n",
      "        -1.24282759e+00-5.15264001e-02j, -1.20739267e+00-2.55085722e-01j,\n",
      "        -7.18213662e-01+1.11537313e+00j],\n",
      "       [-9.08998346e-05+1.62000500e-02j, -1.22692566e-03+1.73430039e-02j,\n",
      "        -4.35060152e-02+3.14028432e-02j, ...,\n",
      "        -1.02337067e+00-1.46234457e-01j, -4.30793007e-01-1.29876353e+00j,\n",
      "        -9.79894115e-01-5.79089472e-01j],\n",
      "       [-2.51134976e-02-1.23921413e-03j, -2.24056985e-02-2.41686468e-03j,\n",
      "        -3.58108182e-02-8.88550845e-02j, ...,\n",
      "         5.49898887e-01-8.87543777e-01j,  1.35195578e+00-3.39399940e-01j,\n",
      "         3.40911139e-01-1.12724197e+00j],\n",
      "       ...,\n",
      "       [-9.67067526e-03-1.25821438e-02j, -7.15847685e-04-2.09851744e-02j,\n",
      "         1.47755612e-01-1.75579750e-01j, ...,\n",
      "         1.09120749e+00+6.78816232e-01j,  1.00069218e+00+6.81303919e-01j,\n",
      "         1.06836265e+00-7.80294757e-01j],\n",
      "       [ 1.93193525e-02+2.13484864e-03j,  1.83851370e-02+3.97228138e-03j,\n",
      "         2.98794142e-02+9.02847464e-02j, ...,\n",
      "        -4.77428050e-01+9.36356394e-01j, -1.27273969e+00+4.43636209e-01j,\n",
      "        -1.64061369e-01+1.20072194e+00j],\n",
      "       [ 8.71388642e-04-1.39238324e-02j,  5.07118426e-03-1.47905832e-02j,\n",
      "         8.97681333e-02-2.94278218e-02j, ...,\n",
      "         8.33422845e-01+6.67355398e-01j,  1.82014217e-01+1.35558419e+00j,\n",
      "         1.11513958e+00+5.33596642e-01j]]), array([[-2.35110677e-02-5.58918821e-03j, -2.51838114e-02-5.22741030e-03j,\n",
      "        -1.83265461e-02-2.65106043e-03j, ...,\n",
      "         8.46442555e-01+8.71957563e-02j, -1.38343150e-01+1.26121911e+00j,\n",
      "         2.07896425e-01+1.13122649e+00j],\n",
      "       [-9.26490038e-03-1.07341297e-02j, -8.61009318e-03-1.11738422e-02j,\n",
      "        -3.41521433e-02-3.39540235e-02j, ...,\n",
      "        -2.19521250e-01-8.14989948e-01j,  8.21212716e-01-1.17136499e+00j,\n",
      "        -4.03123286e-01-1.01736064e+00j],\n",
      "       [-1.41252801e-02-9.14526096e-03j, -1.46864894e-02-7.48661390e-03j,\n",
      "        -2.76454784e-02+1.52033415e-02j, ...,\n",
      "        -6.28869841e-01+5.54339284e-01j, -1.40031015e+00-3.07745561e-01j,\n",
      "        -9.29875218e-01+6.69455913e-01j],\n",
      "       ...,\n",
      "       [-1.31027962e-03+3.08435656e-03j, -1.74589655e-03+3.57056407e-03j,\n",
      "         7.17102890e-03+1.46925715e-03j, ...,\n",
      "         7.84967631e-01-2.93260457e-01j,  7.30470356e-01+1.12478079e+00j,\n",
      "         1.02426752e+00+5.45111757e-01j],\n",
      "       [ 3.62138305e-03+9.31707491e-05j,  2.98763306e-03+7.42859729e-04j,\n",
      "         3.34965240e-03-2.40553024e-03j, ...,\n",
      "        -8.69714616e-01-2.41181777e-01j,  3.84432508e-01-1.12199165e+00j,\n",
      "         2.61188317e-01-1.18117945e+00j],\n",
      "       [ 3.40165155e-03+2.11910878e-03j,  2.80957173e-03+2.90666797e-03j,\n",
      "         2.55527146e-03+8.69029730e-05j, ...,\n",
      "        -5.64314653e-01-6.80725657e-01j,  9.86773644e-01-7.39841213e-01j,\n",
      "         8.63341573e-01-8.70808418e-01j]]), array([[ 0.41253131+0.17627416j,  0.15981896+0.82145895j,\n",
      "        -0.78031699-0.09896854j, ..., -0.39937906-0.73063082j,\n",
      "         1.03541839-0.92600163j,  0.93888058-0.91994721j],\n",
      "       [ 0.2342232 +0.34427072j, -0.29913246+0.81984885j,\n",
      "        -0.60570004-0.37465277j, ..., -0.01452899-0.84028537j,\n",
      "         1.29484683-0.17841283j,  1.16134893-0.13276927j],\n",
      "       [-0.36166071+0.15586186j, -0.71561761-0.44285941j,\n",
      "         0.39170306-0.50188722j, ...,  0.82702506+0.07173905j,\n",
      "        -0.05830121+1.31481976j, -0.29558426+1.4109625j ],\n",
      "       ...,\n",
      "       [ 0.51728563-0.11107594j,  0.63297848+0.54467827j,\n",
      "        -0.76619616+0.35033917j, ..., -0.7326101 -0.37177652j,\n",
      "         0.24232415-1.38314599j,  0.32497005-0.64919691j],\n",
      "       [-0.31515804-0.42538272j,  0.24531094-0.81461002j,\n",
      "         0.64434802+0.5468524j , ..., -0.14252165+0.79033744j,\n",
      "        -1.35181904+0.29508482j, -1.06548956+0.42345687j],\n",
      "       [ 0.33832472+0.20158519j,  0.03708671+0.85324981j,\n",
      "        -0.64553911-0.03386615j, ..., -0.32440301-0.78482064j,\n",
      "         1.14761572-0.60706581j,  1.18018664-0.43162932j]]), array([[-0.75523841+0.17676383j, -0.78768582-0.32435142j,\n",
      "         0.78355756-0.66150725j, ...,  0.85564704+0.32505974j,\n",
      "         0.51285728+1.22066054j,  0.8270244 +0.92905912j],\n",
      "       [-0.30789476+0.54702624j, -0.81824119+0.33480991j,\n",
      "        -0.06684453-0.96667196j, ...,  0.76297999-0.50266297j,\n",
      "         1.30719924+0.44911184j,  1.07729535-0.02145433j],\n",
      "       [ 0.32670117+0.07917728j,  0.64082338+0.73419542j,\n",
      "        -0.56554706+0.35162715j, ..., -0.74581909-0.45633854j,\n",
      "         0.38845501-1.10323439j,  0.36626718-1.02937357j],\n",
      "       ...,\n",
      "       [-0.09666824-0.96306959j,  0.55956843-0.1937232j ,\n",
      "         0.65787973+1.1426683j , ..., -0.81544856+0.71813739j,\n",
      "        -1.20372654+0.60592176j, -0.62108978+0.90736087j],\n",
      "       [ 0.5810601 -0.79776804j,  0.5749451 +0.15998697j,\n",
      "        -0.29928962+1.28687617j, ..., -1.08497335-0.0736465j ,\n",
      "        -1.28638022-0.46857377j, -1.14788058+0.14472748j],\n",
      "       [-0.65539952+0.6097643j , -0.60123129-0.24411417j,\n",
      "         0.48901684-1.17077534j, ...,  1.054499  +0.10884429j,\n",
      "         1.15636169+0.5993138j ,  1.04242992-0.01453023j]]), array([[ 0.43206902+0.06840523j,  0.61666433+0.64626758j,\n",
      "        -0.72095856+0.37612754j, ..., -0.86407652-0.34012149j,\n",
      "         0.05991121-1.24469911j, -0.12957583-1.07415102j],\n",
      "       [-0.34614252+0.2747257j , -0.85051974-0.08658627j,\n",
      "         0.31713816-0.79583157j, ...,  1.01008685-0.21929665j,\n",
      "         0.69622751+1.06934313j,  0.7748027 +1.11120868j],\n",
      "       [-0.25646164+0.36397322j, -0.90606171+0.32872243j,\n",
      "        -0.07683365-0.7661273j , ...,  0.77886291-0.50605818j,\n",
      "         0.98429859+0.73858448j,  0.96216008+0.52311217j],\n",
      "       ...,\n",
      "       [ 0.15057813-0.50048191j,  0.73869724-0.54804753j,\n",
      "         0.26061307+0.8064951j , ..., -0.50400175+0.74164023j,\n",
      "        -1.30117897-0.17642594j, -1.10715783+0.11888908j],\n",
      "       [ 0.37450278-0.30832252j,  0.82570483+0.09123062j,\n",
      "        -0.36954957+0.84150972j, ..., -1.03025723+0.19233029j,\n",
      "        -0.78111228-1.06177973j, -0.75324122-0.61027618j],\n",
      "       [-0.08945784-0.48783719j,  0.41622347-0.81779522j,\n",
      "         0.60354387+0.56310701j, ..., -0.101332  +0.88442839j,\n",
      "        -1.25070517+0.3833972j , -0.96649552+0.5465927j ]]), array([[ 0.72436952-0.19821906j,  0.59517343+0.41971676j,\n",
      "        -1.0310708 +0.58980261j, ..., -0.60442764-0.33385088j,\n",
      "        -0.06541004-1.1458309j , -0.70070211-0.83920919j],\n",
      "       [-0.00179727-0.82174j   ,  0.59256558-0.53485709j,\n",
      "         0.24740705+1.11226857j, ..., -0.78630811+0.58516278j,\n",
      "        -1.4245668 -0.10723322j, -0.94842323+0.45388821j],\n",
      "       [ 0.6401512 -0.466624j  ,  0.79010847+0.1585057j ,\n",
      "        -0.74192016+0.93102725j, ..., -0.96108815-0.15101101j,\n",
      "        -0.78151621-1.11423709j, -0.93767472-0.39793989j],\n",
      "       ...,\n",
      "       [ 0.57238921-0.13938279j,  0.87119865+0.44648295j,\n",
      "        -0.76297352+0.53114953j, ..., -0.86358213-0.2089017j ,\n",
      "        -0.1706402 -1.33133718j, -0.43448097-0.86822403j],\n",
      "       [ 0.15106823+0.46359171j, -0.43425988+0.93558579j,\n",
      "        -0.55886039-0.58500898j, ...,  0.1576728 -0.84656109j,\n",
      "         1.32600958-0.12671963j,  1.32940872-0.2537445j ],\n",
      "       [ 0.22917164-0.43668965j,  0.98176813-0.37101675j,\n",
      "        -0.04921137+0.81564826j, ..., -0.72080438+0.50914424j,\n",
      "        -1.06313572-0.83674553j, -0.92945549-0.45846126j]]), array([[ 0.07326945+0.40289134j, -0.338221  +0.30998466j,\n",
      "        -0.7396414 -0.66388709j, ...,  0.0792024 -1.05744025j,\n",
      "         1.02496258-1.0021347j , -0.21291959-1.16924631j],\n",
      "       [ 0.18065997+0.1174917j ,  0.27441112+0.44015259j,\n",
      "        -0.68989905+0.18471306j, ..., -0.99890325-0.38400766j,\n",
      "         0.13409698-1.40362071j, -0.30553874-1.21984425j],\n",
      "       [ 0.25627887-0.38004509j,  0.44522813+0.06657376j,\n",
      "        -0.01332067+1.01344613j, ..., -0.89427986+0.58750806j,\n",
      "        -1.41770241-0.05137827j, -0.57897892+1.00791434j],\n",
      "       ...,\n",
      "       [ 0.13068288+0.42532171j, -0.33721127+0.29091674j,\n",
      "        -0.790246  -0.64353172j, ...,  0.0772871 -1.08755521j,\n",
      "         0.86551875-1.13957366j, -0.43966007-1.12045329j],\n",
      "       [-0.16080344-0.09738405j, -0.33976438-0.4078528j ,\n",
      "         0.58943863-0.2660878j , ...,  1.03413178+0.25420776j,\n",
      "        -0.08546912+1.35997616j,  0.1768667 +1.27960052j],\n",
      "       [-0.06701458+0.14463491j, -0.38161942+0.39090041j,\n",
      "        -0.33836479-0.47149085j, ...,  0.08052578-1.13261819j,\n",
      "         1.27256797-0.1084598j ,  1.2384551 -0.21135379j]]), array([[ 0.        +0.j        ,  0.        +0.j        ,\n",
      "         0.        +0.j        , ...,  0.        +0.j        ,\n",
      "         0.        +0.j        ,  0.        +0.j        ],\n",
      "       [ 0.        +0.j        ,  0.        +0.j        ,\n",
      "         0.        +0.j        , ...,  0.        +0.j        ,\n",
      "         0.        +0.j        ,  0.        +0.j        ],\n",
      "       [-0.26164098-0.1168667j , -0.10791867-0.35437308j,\n",
      "         0.65035551-0.16083181j, ...,  0.27999267+0.25189498j,\n",
      "         0.62398869+1.18648089j,  0.95476307-0.23684071j],\n",
      "       ...,\n",
      "       [ 0.03173402-0.06864551j,  0.35025003-0.01318029j,\n",
      "         0.54328249+0.84836534j, ..., -0.54259702+0.67860237j,\n",
      "        -1.08625124+1.04945662j,  0.55320909+1.07169761j],\n",
      "       [ 0.01692375-0.04112009j,  0.15706403-0.04184453j,\n",
      "         0.35709851+0.41443926j, ...,  0.45653715+0.43081647j,\n",
      "        -1.3877568 +0.33964117j, -1.01661482+0.85273349j],\n",
      "       [ 0.00285897+0.03455358j, -0.11618153+0.11193853j,\n",
      "        -0.50303664-0.17841921j, ..., -0.66395364-0.20730913j,\n",
      "         1.12957421-0.72593281j,  0.76762247-1.09547432j]]), array([[-8.87014201e-03-8.27848820e-03j, -9.55248171e-03-9.68410979e-03j,\n",
      "        -5.73631707e-02+7.20796820e-02j, ...,\n",
      "        -9.90559151e-01-1.41358044e-01j, -1.13353205e+00-4.68267573e-01j,\n",
      "        -7.16764315e-01+9.88939220e-01j],\n",
      "       [-1.26744599e-02-7.27186684e-04j, -1.34422879e-02+1.06154991e-03j,\n",
      "         4.05100718e-02-1.44454159e-02j, ...,\n",
      "         7.75938663e-01+4.51319262e-01j,  5.70348205e-01+1.19740417e+00j,\n",
      "         1.14531138e+00-1.89155821e-01j],\n",
      "       [-1.26621658e-02+3.47028408e-03j, -1.27648244e-02+1.71240495e-03j,\n",
      "         2.96049253e-02-2.67174577e-02j, ...,\n",
      "         8.84983882e-01+9.53789781e-02j,  9.49922102e-01+9.22137984e-01j,\n",
      "         1.03140396e+00-5.40852837e-01j],\n",
      "       ...,\n",
      "       [-4.78046111e-04-5.01316521e-03j, -2.08274415e-03-5.60265681e-03j,\n",
      "        -1.92102378e-02+1.14867622e-01j, ...,\n",
      "        -1.04942981e+00+2.55514113e-01j, -1.20049715e+00+2.34889087e-01j,\n",
      "        -7.97002539e-02+1.23629667e+00j],\n",
      "       [ 1.99852688e-03-2.47533782e-03j,  8.00496409e-05-1.60431008e-03j,\n",
      "        -2.42867553e-03-6.67767792e-04j, ...,\n",
      "        -8.10991396e-01+4.90500614e-01j, -4.48962016e-01-1.01945494e+00j,\n",
      "        -5.12344820e-01-1.06340421e+00j],\n",
      "       [-9.83310657e-03-3.74025965e-03j, -1.25392688e-02-2.35974727e-03j,\n",
      "         4.40396287e-03+1.56804780e-02j, ...,\n",
      "         1.30229043e-01+7.91232221e-01j, -1.07670612e+00+8.90547713e-01j,\n",
      "         5.56296954e-02+1.11169141e+00j]]), array([[ 0.28002897-0.2938319j ,  1.32027745+0.15883343j,\n",
      "        -0.2133143 +0.7971675j , ..., -0.7893826 +0.30346516j,\n",
      "        -0.50189367-1.08244195j, -0.44645922-1.32754446j],\n",
      "       [ 0.21062443+0.31766863j, -0.4137863 +1.28909425j,\n",
      "        -0.82567402-0.2526418j , ..., -0.19063336-0.87249335j,\n",
      "         1.17528965-0.38454887j,  1.00028021-0.31160732j],\n",
      "       [-0.36139997+0.22062231j, -1.32226538-0.3969678j ,\n",
      "         0.23663021-0.7763728j , ...,  0.89725562-0.22298707j,\n",
      "         0.33419892+1.16855548j,  0.23073064+1.10807964j],\n",
      "       ...,\n",
      "       [ 0.49643222+0.29590076j,  0.3480508 +1.25767011j,\n",
      "        -0.97114528-0.03777461j, ..., -0.47829904-0.70384092j,\n",
      "         0.85234424-0.97628765j,  0.84231131-1.08537966j],\n",
      "       [-0.2116234 -0.49164613j,  0.52065164-1.24896636j,\n",
      "         0.74656693+0.54835872j, ..., -0.02259851+0.8668233j ,\n",
      "        -1.21573651+0.27086643j, -1.30584659+0.32084641j],\n",
      "       [ 0.18185471+0.49089523j, -0.58303049+1.22755745j,\n",
      "        -0.72295376-0.56061275j, ..., -0.01316938-0.8792674j ,\n",
      "         1.26820927-0.2713918j ,  1.00556403-0.33026129j]]), array([[-0.01873567-1.68964096e-02j, -0.01785824-1.85049313e-02j,\n",
      "        -0.06505039-1.15034475e-02j, ..., -0.7042105 -5.44294289e-01j,\n",
      "        -0.34126366-1.28802912e+00j, -1.18878212-1.30133992e-01j],\n",
      "       [-0.02890113-4.49824260e-03j, -0.02962655-3.34052589e-03j,\n",
      "        -0.02598405-1.12566532e-03j, ...,  0.89664372+3.61989433e-02j,\n",
      "        -0.02426684+1.26233320e+00j,  0.35070241+1.10153108e+00j],\n",
      "       [-0.01535944-3.60087412e-03j, -0.01545937-4.53240131e-03j,\n",
      "         0.06833032+3.47489718e-02j, ...,  0.0231521 +1.03643687e+00j,\n",
      "        -0.24184647+1.21415538e+00j,  1.15145034+5.32004951e-01j],\n",
      "       ...,\n",
      "       [-0.00199685+1.27114355e-02j, -0.00388151+1.35521560e-02j,\n",
      "        -0.00344402+1.21872541e-02j, ..., -0.16835079-9.45309118e-01j,\n",
      "         1.14100729-6.83818263e-02j,  1.12822315-1.96106688e-01j],\n",
      "       [ 0.0104336 -9.04050199e-03j,  0.01029753-8.80281792e-03j,\n",
      "         0.00652457-7.09128761e-03j, ..., -0.58420591+6.67299200e-01j,\n",
      "        -0.91240036-8.80367010e-01j, -1.03086934-4.22516091e-01j],\n",
      "       [ 0.0143337 -4.88898222e-03j,  0.013365  -4.60090682e-03j,\n",
      "         0.01107318-4.22332370e-03j, ..., -0.85547659+3.24224436e-01j,\n",
      "        -0.35368437-1.18051652e+00j, -0.58786169-1.01223717e+00j]]), array([[-2.88928858e-02-5.17339126e-03j, -2.83192732e-02-3.66376910e-03j,\n",
      "        -3.57990588e-02+1.88573992e-03j, ...,\n",
      "        -7.42443288e-01+4.03774664e-01j, -9.94225246e-01-9.74574981e-01j,\n",
      "        -1.18836147e+00-2.90137301e-01j],\n",
      "       [-1.83775745e-02-8.97961416e-04j, -1.92149580e-02-2.53228864e-03j,\n",
      "        -4.70916040e-02+3.60172053e-02j, ...,\n",
      "        -9.19796874e-01+1.37517018e-01j, -1.30749594e+00-6.16211703e-01j,\n",
      "        -9.74897446e-01+6.61071492e-01j],\n",
      "       [-2.86881138e-02-2.01487227e-03j, -2.71468822e-02-2.20798776e-03j,\n",
      "        -6.00856209e-02-1.50106739e-03j, ...,\n",
      "        -7.28584326e-01-5.03437873e-01j, -2.28469903e-01-1.37649373e+00j,\n",
      "        -1.08173794e+00-4.99723451e-01j],\n",
      "       ...,\n",
      "       [-4.91383631e-05+1.26645303e-02j,  1.43996178e-03+1.06703094e-02j,\n",
      "        -8.24127729e-03+1.53749795e-02j, ...,\n",
      "        -7.57528488e-01+3.44211529e-01j, -8.29677489e-01-1.07396056e+00j,\n",
      "        -1.10488791e+00-4.65407484e-01j],\n",
      "       [-1.11914979e-02+3.62666977e-03j, -1.15668410e-02+3.71053323e-03j,\n",
      "        -1.21996059e-02+3.91471163e-03j, ...,\n",
      "        -9.00084431e-01-2.49200980e-01j,  3.41461345e-01-1.07715383e+00j,\n",
      "         3.48228162e-01-1.18774806e+00j],\n",
      "       [ 9.88516083e-03+7.80560509e-04j,  1.17568557e-02+8.87977256e-04j,\n",
      "         1.75186988e-02+1.40813968e-02j, ...,\n",
      "         1.43634590e-01+8.01483153e-01j, -1.20723239e+00+6.75280142e-01j,\n",
      "        -3.58187465e-01+1.06539910e+00j]]), array([[-0.00688618-0.04157866j, -0.00918768-0.04768463j,\n",
      "        -0.08824999-0.13450358j, ..., -0.11354481-0.81299319j,\n",
      "         0.60366122-0.95291878j, -0.58659414-1.06660932j],\n",
      "       [-0.03823901-0.02562551j, -0.04078731-0.02753485j,\n",
      "        -0.13058822-0.00395185j, ..., -0.73642398-0.2448173j ,\n",
      "        -0.39439142-1.11850457j, -1.1040489 -0.33509074j],\n",
      "       [-0.02999431+0.02119722j, -0.0303085 +0.02466255j,\n",
      "        -0.00149333+0.11085122j, ..., -0.14390072+0.74575598j,\n",
      "        -1.05360044+0.45464962j, -0.15562121+1.13652359j],\n",
      "       ...,\n",
      "       [-0.01834729-0.03138001j, -0.02144642-0.03095422j,\n",
      "        -0.12407636-0.04300882j, ..., -0.53018165-0.59050629j,\n",
      "         0.07489867-1.18572745j, -0.95539021-0.71499397j],\n",
      "       [ 0.96040743+0.61098652j,  1.17116876+0.38313445j,\n",
      "        -0.15826115-0.52212625j, ...,  0.8033    -0.62101678j,\n",
      "         0.71289665-0.14463777j,  0.13679871+0.50880519j],\n",
      "       [ 0.02034645+0.02764757j,  0.03394741+0.02949632j,\n",
      "         0.23188538+0.03995189j, ...,  0.34312166+0.85698966j,\n",
      "         0.20930329+1.11685053j,  1.16576557+0.32495441j]]), array([[ 0.00139658-0.00781024j,  0.00200918-0.00971543j,\n",
      "         0.01734857-0.04416434j, ...,  0.30816632-0.77111493j,\n",
      "         1.08075625+0.27681451j,  0.95642625-0.36012017j],\n",
      "       [-0.02151178+0.00369563j, -0.02043235+0.01085218j,\n",
      "         0.01579344+0.13590064j, ..., -0.45855813+0.76588038j,\n",
      "        -0.94821392+0.51986248j,  0.13560365+1.27422109j],\n",
      "       [-0.01038959+0.01678896j, -0.00873418+0.01730254j,\n",
      "         0.01723205+0.05399946j, ...,  0.39492242+0.77096804j,\n",
      "        -0.80002676+0.77135729j, -0.12306185+1.05734254j],\n",
      "       ...,\n",
      "       [ 0.00706329-0.01380172j,  0.00702352-0.01513683j,\n",
      "        -0.001838  -0.04372248j, ..., -0.32275579-0.83194508j,\n",
      "         0.91924538-0.53652684j,  0.57020842-0.83240655j],\n",
      "       [ 0.01038435+0.01035644j,  0.00981743+0.0117645j ,\n",
      "         0.03421796+0.01632577j, ...,  0.86084964-0.15639793j,\n",
      "         0.3179083 +1.07314452j,  0.63119376+0.91437949j],\n",
      "       [ 0.0066178 +0.01312824j,  0.00777239+0.01417806j,\n",
      "         0.02330508+0.02134603j, ...,  0.88667453+0.13738944j,\n",
      "        -0.07619876+1.03503972j,  0.03389392+1.07003935j]]), array([[-3.61402326e-02-1.60398363e-02j, -3.69526632e-02-1.69016480e-02j,\n",
      "        -6.76882700e-02-5.78445108e-02j, ...,\n",
      "        -3.80318390e-01-4.92617196e-01j,  7.22058228e-01-1.15780280e+00j,\n",
      "        -2.68703301e-01-9.52346756e-01j],\n",
      "       [-3.49243843e-02+4.54155886e-03j, -3.57317961e-02+5.46738419e-03j,\n",
      "         2.68907030e-04+1.19527769e-02j, ...,\n",
      "         6.32050018e-01-4.47133990e-02j,  4.88567601e-01+1.35595085e+00j,\n",
      "         8.55003280e-01+6.86929135e-01j],\n",
      "       [-2.47585252e-03+8.38097556e-03j, -5.32173307e-03+9.72367230e-03j,\n",
      "         5.87676166e-03+1.53832533e-02j, ...,\n",
      "         6.09581852e-01-4.33992929e-01j,  4.75825482e-01+1.05236570e+00j,\n",
      "         4.74023123e-01+1.20512994e+00j],\n",
      "       ...,\n",
      "       [-2.49676002e-02+1.27326199e-02j, -8.79753631e-03+1.74372192e-02j,\n",
      "         7.23281502e-02+1.52265952e-01j, ...,\n",
      "        -5.06639088e-01+8.95103436e-01j, -8.17629532e-01+1.02928231e+00j,\n",
      "         9.03567207e-01+9.30593808e-01j],\n",
      "       [ 7.79699003e-03-1.26691524e-03j,  5.60818685e-03-9.67780267e-03j,\n",
      "         4.66091975e-03-1.44897302e-01j, ...,\n",
      "         7.86834084e-01-5.15938841e-01j,  1.25260968e+00-3.97807806e-01j,\n",
      "        -2.77422574e-01-1.21411944e+00j],\n",
      "       [ 1.38511852e-03-1.05043188e-02j,  5.07516176e-06-7.66799412e-03j,\n",
      "        -4.12989870e-02-3.18552725e-02j, ...,\n",
      "        -5.23713112e-01-3.50798555e-01j,  2.29459548e-01-1.40655314e+00j,\n",
      "        -5.92939334e-01-8.71965398e-01j]]), array([[-1.33181266e-02-1.43382042e-02j, -1.09038877e-02-1.78230095e-02j,\n",
      "        -1.91781196e-02-5.66886929e-02j, ...,\n",
      "        -5.89106550e-03-8.06312268e-01j,  1.39148631e+00-7.34658964e-01j,\n",
      "         4.55587828e-01-1.06486805e+00j],\n",
      "       [-7.39303774e-03-1.06725591e-03j, -7.66629812e-03+3.91856782e-04j,\n",
      "         2.23842672e-02+2.31876635e-03j, ...,\n",
      "         7.16161053e-01-7.00916150e-03j,  3.15038900e-01+1.40346953e+00j,\n",
      "         6.28728980e-01+9.39314129e-01j],\n",
      "       [-1.78893396e-02+4.40387420e-03j, -1.83278996e-02+6.02007183e-03j,\n",
      "        -1.90744019e-02+8.85176627e-02j, ...,\n",
      "        -4.69340047e-01+7.09683847e-01j, -1.37715505e+00+4.12504597e-01j,\n",
      "        -1.62798307e-01+1.07829246e+00j],\n",
      "       ...,\n",
      "       [-7.94746052e-04-8.69412245e-03j, -2.11221369e-03-1.27638681e-02j,\n",
      "        -4.57570255e-03-1.31639434e-01j, ...,\n",
      "         7.34901499e-01-6.94993370e-01j,  1.30876267e+00-4.50843384e-01j,\n",
      "        -9.21394333e-02-1.15187900e+00j],\n",
      "       [ 4.79206130e-03+5.20007096e-03j,  5.30755172e-03+9.84461527e-03j,\n",
      "         3.75104910e-02+6.38288865e-02j, ...,\n",
      "         7.04107970e-02+8.21911145e-01j, -1.02825438e+00+1.08216759e+00j,\n",
      "         1.50031480e-01+1.02315601e+00j],\n",
      "       [ 1.79996772e-03+4.24815400e-03j,  4.99426734e-03+1.20822747e-02j,\n",
      "         9.64257512e-02+1.22739495e-01j, ...,\n",
      "        -4.06213639e-01+1.04894009e+00j, -8.18201250e-01+1.10678571e+00j,\n",
      "         7.98866126e-01+8.70599199e-01j]]), array([[-5.39145933e-02-0.00585862j, -5.76570676e-02-0.00195868j,\n",
      "        -1.47371774e-01+0.15099781j, ..., -9.96658441e-01+0.05281914j,\n",
      "        -1.23905572e+00-0.42583023j, -7.48347083e-01+0.9339976j ],\n",
      "       [-4.17582984e-02-0.01431051j, -3.87471345e-02-0.02006326j,\n",
      "        -1.08223727e-03-0.15867736j, ...,  8.89219519e-01-0.50259591j,\n",
      "         1.38719950e+00+0.01106594j,  6.35883322e-01-1.10504128j],\n",
      "       [-3.87996989e-02-0.01820837j, -4.01056492e-02-0.02244441j,\n",
      "         6.08389400e-02-0.12087037j, ...,  9.90942110e-01-0.0993597j ,\n",
      "         1.24357048e+00+0.61993015j,  1.02408665e+00-0.72272527j],\n",
      "       ...,\n",
      "       [ 2.14039749e-03-0.00880126j,  5.22664824e-03-0.01334383j,\n",
      "         1.94764970e-02-0.10185444j, ...,  5.16746443e-01-0.74278269j,\n",
      "         1.39315021e+00-0.16820981j,  7.05995721e-01-0.98418251j],\n",
      "       [-1.10936891e-03-0.00895245j, -2.03224348e-03-0.01305272j,\n",
      "        -1.68864713e-04-0.08781456j, ...,  2.80144386e-01-0.84930822j,\n",
      "         1.35118580e+00-0.47900468j,  6.02936691e-01-1.07393434j],\n",
      "       [-1.15392049e-02-0.00492866j, -1.25953102e-02-0.00632884j,\n",
      "        -7.27927039e-02-0.03380803j, ..., -6.54269044e-01-0.51772479j,\n",
      "         1.86486134e-01-1.42996762j, -5.91603645e-01-1.02297461j]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_doppler_shift(v, fc):\n",
    "    \"\"\"\n",
    "    根据移动速度 v (m/s) 和载波频率 fc (Hz) 计算多普勒频移\n",
    "    \"\"\"\n",
    "    c = 3e8  # 光速 m/s\n",
    "    return (v / c) * fc\n",
    "\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    \"\"\"\n",
    "    给IQ信号加多普勒频移\n",
    "    signal: shape (num_channels, num_samples)，复数IQ信号\n",
    "    fd: 多普勒频移 (Hz)\n",
    "    fs: 采样率 (Hz)\n",
    "    \"\"\"\n",
    "    num_channels, num_samples = signal.shape\n",
    "    t = np.arange(num_samples) / fs  # 时间轴\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)  # 复指数\n",
    "    return signal * doppler_phase\n",
    "\n",
    "# 例子\n",
    "fs = 20e6  # 采样率，比如1 MHz\n",
    "fc = 2.4e9  # 载波频率，比如2.4 GHz Wi-Fi\n",
    "v = 120  # 移动速度，比如30 m/s (~108 km/h)\n",
    "\n",
    "fd = compute_doppler_shift(v, fc)  # 先计算多普勒频移\n",
    "print(f\"计算得到的多普勒频移 fd = {fd:.2f} Hz\")\n",
    "\n",
    "# 假设 data 是你之前读出来的list，每个是 shape (信号数量, 采样点数)\n",
    "data_with_doppler = []\n",
    "for sig in data:\n",
    "    shifted_sig = add_doppler_shift(sig, fd, fs)\n",
    "    data_with_doppler.append(shifted_sig)\n",
    "\n",
    "print(\"添加多普勒频移后的信号：\")\n",
    "print(data_with_doppler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01de1c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终数据 shape: torch.Size([138904, 320])\n",
      "最终标签 shape: torch.Size([138904])\n",
      "训练集大小: 111123\n",
      "验证集大小: 27780\n",
      "测试集大小: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 假设 noisy_data 已经是你处理好的数据列表，每个元素 shape = (总信号数量, 320)\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for device_idx, device_signals in enumerate(noisy_data):\n",
    "    device_labels = np.full((device_signals.shape[0],), device_idx)  # 每条信号的标签就是设备编号\n",
    "    all_data.append(torch.tensor(device_signals, dtype=torch.float32))\n",
    "    all_labels.append(torch.tensor(device_labels, dtype=torch.long))\n",
    "\n",
    "# 拼接成完整数据\n",
    "all_data = torch.cat(all_data, dim=0)  # (总样本数, 320)\n",
    "all_labels = torch.cat(all_labels, dim=0)  # (总样本数, )\n",
    "\n",
    "print(f\"最终数据 shape: {all_data.shape}\")\n",
    "print(f\"最终标签 shape: {all_labels.shape}\")\n",
    "\n",
    "# 构建 PyTorch Dataset\n",
    "full_dataset = TensorDataset(all_data, all_labels)\n",
    "\n",
    "# 划分训练集、验证集、测试集 (8:2:0)\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size  # 剩下的作为测试集\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 打印数据集大小\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6dd3f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  23%|██▎       | 99/435 [00:24<01:22,  4.07batch/s, train_accuracy=6.86, train_loss=3.06]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# 计算损失\u001b[39;00m\n\u001b[0;32m    140\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[38], line 86\u001b[0m, in \u001b[0;36mSignalTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Transformer输入要求的格式是 (batch_size, seq_len, input_dim)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)  \u001b[38;5;66;03m# 变为 (batch_size, seq_len, input_dim)\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_len, input_dim)\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# 确认x的维度\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:274\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    269\u001b[0m     src,\n\u001b[0;32m    270\u001b[0m     mask\u001b[38;5;241m=\u001b[39msrc_mask,\n\u001b[0;32m    271\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[0;32m    272\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal,\n\u001b[0;32m    273\u001b[0m )\n\u001b[1;32m--> 274\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:598\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    595\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 598\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    610\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1087\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1082\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m   1083\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[0;32m   1084\u001b[0m     )\n\u001b[0;32m   1085\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[0;32m   1086\u001b[0m         x\n\u001b[1;32m-> 1087\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m     )\n\u001b[0;32m   1091\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:1123\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mha_block\u001b[39m(\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1117\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1123\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\nn\\functional.py:6405\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6402\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m   6403\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m-> 6405\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[0;32m   6407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6408\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   6409\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[0;32m   6410\u001b[0m )\n\u001b[0;32m   6412\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # 导入tqdm库来显示进度条\n",
    "\n",
    "# 假设 SNR_dB 和 fd 已经在之前定义\n",
    "# SNR_dB = 0  # 设定信噪比（dB）\n",
    "# fd = 5  # 多普勒频移参数，这里只是举例\n",
    "\n",
    "\n",
    "# 初始化模型参数\n",
    "input_dim = 320  # 每个信号有320个采样点\n",
    "num_heads = 4  # 注意力头数\n",
    "num_layers = 2  # Transformer编码器层数\n",
    "num_classes = 20  # 有20个设备\n",
    "dropout = 0.4  # Dropout率\n",
    "\n",
    "# 训练参数\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-5\n",
    "patience = 5  # Early stopping 的容忍期（最多允许多少个epoch验证集性能没有改善）\n",
    "\n",
    "# 训练过程的时间戳和文件夹名\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# 检查 SNR_dB 和 fd 是否已经定义，如果没有，则设置为 \"no\"\n",
    "SNR_dB = globals().get('SNR_dB', 'no')\n",
    "fd = globals().get('fd', 'no')\n",
    "\n",
    "# 手动设置 script_name（例如使用固定的文件名）\n",
    "script_name = \"time\"\n",
    "\n",
    "\n",
    "# 构造文件夹名\n",
    "folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{fd}_classes_{num_classes}_Transformer\"\n",
    "save_folder = os.path.join(os.getcwd(), \"training_results\", folder_name)\n",
    "\n",
    "# 创建保存结果的文件夹\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# 创建保存结果的文件夹\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# 打开结果文件，保存训练的总结\n",
    "results_file = os.path.join(save_folder, \"results.txt\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    f.write(f\"=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Feature Folder: trajectory_plots\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "\n",
    "# 定义SignalTransformer模型\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        \n",
    "        # 输入数据的嵌入层\n",
    "        self.embedding = nn.Linear(input_dim, input_dim)  # 将输入信号的维度转换为适合Transformer的维度\n",
    "        \n",
    "        # Transformer编码器层\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=input_dim,  # 输入特征维度\n",
    "            nhead=num_heads,  # 多头注意力机制的头数\n",
    "            num_encoder_layers=num_layers,  # 编码器层数\n",
    "            dropout=dropout,  # Dropout率\n",
    "            batch_first=True  # 设置为True以支持(batch_size, seq_len, input_dim)输入\n",
    "        )\n",
    "        \n",
    "        # 最后的分类层，将Transformer的输出映射到类别\n",
    "        self.fc = nn.Linear(input_dim, num_classes)  # 分类输出层\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Transformer输入要求的格式是 (batch_size, seq_len, input_dim)\n",
    "        x = self.embedding(x)  # 变为 (batch_size, seq_len, input_dim)\n",
    "        x = self.transformer(x, x)  # (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        # 确认x的维度\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, -1, :]  # 取序列最后一个时间步的输出 (batch_size, input_dim)\n",
    "        elif len(x.shape) == 2:\n",
    "            # 如果是二维的，则直接使用输出 (batch_size, input_dim)\n",
    "            pass\n",
    "            \n",
    "        x = self.fc(x)  # (batch_size, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) \n",
    "\n",
    "# 初始化模型\n",
    "model = SignalTransformer(input_dim=input_dim, num_heads=num_heads, num_layers=num_layers, num_classes=num_classes, dropout=dropout)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# 用来记录训练过程的损失和准确度\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Early stopping 变量\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# 训练过程\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # 使用 tqdm 显示训练进度条\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for batch_idx, (inputs, labels) in enumerate(tepoch):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            \n",
    "            # 计算训练准确度\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # 计算训练集准确率\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            # 更新进度条，显示训练损失和准确率\n",
    "            tepoch.set_postfix(train_loss=running_train_loss / (batch_idx + 1), train_accuracy=train_accuracy)\n",
    "\n",
    "    # 计算训练集每个epoch的损失和准确度\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    epoch_train_acc = 100 * correct_train / total_train\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "    # 验证过程\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 显示验证进度条\n",
    "        with tqdm(val_loader, desc=\"Validation\", unit=\"batch\") as vepoch:\n",
    "            for val_inputs, val_labels in vepoch:\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "                # 计算验证集准确率\n",
    "                val_accuracy = 100 * correct_val / total_val\n",
    "                # 更新验证集进度条，显示验证损失和准确率\n",
    "                vepoch.set_postfix(val_loss=running_val_loss / (len(val_loader) + 1), val_accuracy=val_accuracy)\n",
    "\n",
    "    # 计算验证集每个epoch的损失和准确度\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    epoch_val_acc = 100 * correct_val / total_val\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(epoch_val_acc)\n",
    "\n",
    "    # 打印每个epoch的训练和验证结果\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {epoch_train_loss:.4f}, Train Accuracy: {epoch_train_acc:.2f}%\")\n",
    "    print(f\"  Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.2f}%\")\n",
    "\n",
    "    # 保存训练信息\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch+1} | Train Loss: {epoch_train_loss:.4f} | Train Accuracy: {epoch_train_acc:.2f}% | Validation Loss: {epoch_val_loss:.4f} | Validation Accuracy: {epoch_val_acc:.2f}%\\n\")\n",
    "\n",
    "    # Early Stopping 检查\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        patience_counter = 0  # 重置计数器\n",
    "    else:\n",
    "        patience_counter += 1  # 验证损失没有改善，增加计数器\n",
    "\n",
    "    # 如果验证损失在连续patience个epoch中没有改善，停止训练\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1} due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "\n",
    "# 绘制训练和验证损失曲线\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curve')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder, \"loss_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# 绘制训练和验证准确度曲线\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Curve')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_folder, \"accuracy_curve.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ===== 生成并保存混淆矩阵 =====\n",
    "\n",
    "# 再次在验证集上跑一次，收集所有预测和标签\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for val_inputs, val_labels in val_loader:\n",
    "        val_outputs = model(val_inputs)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        all_preds.extend(val_predicted.cpu().numpy())\n",
    "        all_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存混淆矩阵图片\n",
    "confusion_matrix_path = os.path.join(save_folder, \"confusion_matrix.png\")\n",
    "plt.savefig(confusion_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "# 也可以保存混淆矩阵原始数据（比如保存成txt）\n",
    "np.savetxt(os.path.join(save_folder, \"confusion_matrix.txt\"), cm, fmt='%d')\n",
    "\n",
    "print(f\"Confusion matrix saved to {confusion_matrix_path}\")\n",
    "\n",
    "# 打印训练总结\n",
    "with open(results_file, \"a\") as f:\n",
    "    f.write(\"\\n=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Feature Folder: losdata\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "    f.write(f\"Best Train Accuracy: {max(train_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Best Val Accuracy: {max(val_accuracies):.4f}\\n\")\n",
    "    f.write(f\"Final Train Accuracy: {train_accuracies[-1]:.4f}\\n\")\n",
    "    f.write(f\"Final Val Accuracy: {val_accuracies[-1]:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MW-RFF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
