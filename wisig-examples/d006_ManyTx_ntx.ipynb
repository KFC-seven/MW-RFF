{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import scipy,scipy.spatial\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "\n",
    "from  data_utilities import *\n",
    "# from definitions import *\n",
    "# from run_train_eval_net import run_train_eval_net,run_eval_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 18\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'ManyTx'\n",
    "dataset_path='../ManyTx.pkl/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "\n",
    "equalized = 0\n",
    "\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "print(n_tx,n_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">405</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m25,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m8,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m405\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,697</span> (155.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,697\u001b[0m (155.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,697</span> (155.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,697\u001b[0m (155.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " def create_net(ntx_i):\n",
    "\n",
    "    inputs = Input(shape=(256,2))\n",
    "    x = Reshape((256,2,1))(inputs)\n",
    "    x = Conv2D(8,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,2),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    x = Conv2D(32,(3,1),activation='relu',padding = 'same')(x)\n",
    "    x = MaxPool2D((2,1))(x)\n",
    "    x = Conv2D(16,(3,1),activation='relu',padding = 'same')(x)\n",
    "    #x = resnet(x,64,(3,2),'6')\n",
    "    #x = MaxPool2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "    x = Dense(100, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "    x = Dense(80, activation='relu',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(ntx_i, activation='softmax',kernel_regularizer = keras.regularizers.l2(0.0001))(x)\n",
    "    ops = x\n",
    "\n",
    "    classifier = Model(inputs,ops)\n",
    "    classifier.compile(loss='categorical_crossentropy',metrics=['categorical_accuracy'],optimizer=keras.optimizers.Adam(0.0005))\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "classifier = create_net(5)\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(classifier):\n",
    "    pred = classifier.predict(sig_dfTest)\n",
    "    acc = np.mean(np.argmax(pred,1)==txidNum_dfTest)\n",
    "\n",
    "    test_indx = ()\n",
    "    for indx in range(len(tx_list)):\n",
    "        cls_indx = np.where(txidNum_dfTest == indx)\n",
    "        test_indx = test_indx + (cls_indx[0][:n_test_samples],)\n",
    "    test_indx = np.concatenate(test_indx) \n",
    "    acc_bal = np.mean(np.argmax(pred[test_indx,:],1)==txidNum_dfTest[test_indx])\n",
    "    return acc,acc_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 45, 80, 115, 150]\n",
      "\n",
      "\n",
      "ntx_i: 10  \n",
      "Epoch 1/100\n",
      "\u001b[1m823/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - categorical_accuracy: 0.1123 - loss: 2.5785\n",
      "Epoch 1: val_loss improved from inf to 2.13419, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - categorical_accuracy: 0.1127 - loss: 2.5777 - val_categorical_accuracy: 0.2009 - val_loss: 2.1342\n",
      "Epoch 2/100\n",
      "\u001b[1m823/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2039 - loss: 2.3317\n",
      "Epoch 2: val_loss improved from 2.13419 to 1.93972, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.2042 - loss: 2.3308 - val_categorical_accuracy: 0.2837 - val_loss: 1.9397\n",
      "Epoch 3/100\n",
      "\u001b[1m827/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2664 - loss: 2.1458\n",
      "Epoch 3: val_loss improved from 1.93972 to 1.84355, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.2666 - loss: 2.1454 - val_categorical_accuracy: 0.3226 - val_loss: 1.8436\n",
      "Epoch 4/100\n",
      "\u001b[1m824/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3341 - loss: 1.9924\n",
      "Epoch 4: val_loss improved from 1.84355 to 1.62879, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.3343 - loss: 1.9918 - val_categorical_accuracy: 0.4141 - val_loss: 1.6288\n",
      "Epoch 5/100\n",
      "\u001b[1m836/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4201 - loss: 1.7783\n",
      "Epoch 5: val_loss improved from 1.62879 to 1.33021, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.4202 - loss: 1.7781 - val_categorical_accuracy: 0.5339 - val_loss: 1.3302\n",
      "Epoch 6/100\n",
      "\u001b[1m828/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5223 - loss: 1.4731\n",
      "Epoch 6: val_loss improved from 1.33021 to 1.05650, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.5226 - loss: 1.4724 - val_categorical_accuracy: 0.6487 - val_loss: 1.0565\n",
      "Epoch 7/100\n",
      "\u001b[1m827/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6128 - loss: 1.2374\n",
      "Epoch 7: val_loss improved from 1.05650 to 0.88707, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.6130 - loss: 1.2369 - val_categorical_accuracy: 0.7013 - val_loss: 0.8871\n",
      "Epoch 8/100\n",
      "\u001b[1m824/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6681 - loss: 1.0803\n",
      "Epoch 8: val_loss improved from 0.88707 to 0.82760, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.6683 - loss: 1.0799 - val_categorical_accuracy: 0.7250 - val_loss: 0.8276\n",
      "Epoch 9/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7084 - loss: 0.9735\n",
      "Epoch 9: val_loss improved from 0.82760 to 0.73926, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.7084 - loss: 0.9733 - val_categorical_accuracy: 0.7549 - val_loss: 0.7393\n",
      "Epoch 10/100\n",
      "\u001b[1m833/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7405 - loss: 0.8748\n",
      "Epoch 10: val_loss improved from 0.73926 to 0.68699, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7405 - loss: 0.8749 - val_categorical_accuracy: 0.7722 - val_loss: 0.6870\n",
      "Epoch 11/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7505 - loss: 0.8235\n",
      "Epoch 11: val_loss improved from 0.68699 to 0.63004, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7506 - loss: 0.8234 - val_categorical_accuracy: 0.7979 - val_loss: 0.6300\n",
      "Epoch 12/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7668 - loss: 0.7882\n",
      "Epoch 12: val_loss improved from 0.63004 to 0.60952, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7667 - loss: 0.7882 - val_categorical_accuracy: 0.8018 - val_loss: 0.6095\n",
      "Epoch 13/100\n",
      "\u001b[1m825/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7748 - loss: 0.7376\n",
      "Epoch 13: val_loss improved from 0.60952 to 0.59240, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7748 - loss: 0.7377 - val_categorical_accuracy: 0.8075 - val_loss: 0.5924\n",
      "Epoch 14/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7801 - loss: 0.7239\n",
      "Epoch 14: val_loss improved from 0.59240 to 0.58487, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.7801 - loss: 0.7240 - val_categorical_accuracy: 0.8096 - val_loss: 0.5849\n",
      "Epoch 15/100\n",
      "\u001b[1m834/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7863 - loss: 0.7005\n",
      "Epoch 15: val_loss did not improve from 0.58487\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7863 - loss: 0.7005 - val_categorical_accuracy: 0.8015 - val_loss: 0.5924\n",
      "Epoch 16/100\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7889 - loss: 0.6839\n",
      "Epoch 16: val_loss did not improve from 0.58487\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7889 - loss: 0.6839 - val_categorical_accuracy: 0.8042 - val_loss: 0.5930\n",
      "Epoch 17/100\n",
      "\u001b[1m831/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7964 - loss: 0.6672\n",
      "Epoch 17: val_loss improved from 0.58487 to 0.56737, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.7964 - loss: 0.6672 - val_categorical_accuracy: 0.8141 - val_loss: 0.5674\n",
      "Epoch 18/100\n",
      "\u001b[1m834/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.7990 - loss: 0.6563\n",
      "Epoch 18: val_loss improved from 0.56737 to 0.55699, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.7990 - loss: 0.6564 - val_categorical_accuracy: 0.8179 - val_loss: 0.5570\n",
      "Epoch 19/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8063 - loss: 0.6346\n",
      "Epoch 19: val_loss did not improve from 0.55699\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.8063 - loss: 0.6347 - val_categorical_accuracy: 0.8057 - val_loss: 0.5883\n",
      "Epoch 20/100\n",
      "\u001b[1m824/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8058 - loss: 0.6316\n",
      "Epoch 20: val_loss did not improve from 0.55699\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.8059 - loss: 0.6315 - val_categorical_accuracy: 0.8158 - val_loss: 0.5628\n",
      "Epoch 21/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8130 - loss: 0.6089\n",
      "Epoch 21: val_loss did not improve from 0.55699\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.8130 - loss: 0.6090 - val_categorical_accuracy: 0.8135 - val_loss: 0.5616\n",
      "Epoch 22/100\n",
      "\u001b[1m835/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8128 - loss: 0.6091\n",
      "Epoch 22: val_loss improved from 0.55699 to 0.53793, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - categorical_accuracy: 0.8128 - loss: 0.6091 - val_categorical_accuracy: 0.8227 - val_loss: 0.5379\n",
      "Epoch 23/100\n",
      "\u001b[1m828/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8221 - loss: 0.5842\n",
      "Epoch 23: val_loss did not improve from 0.53793\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.8221 - loss: 0.5844 - val_categorical_accuracy: 0.8009 - val_loss: 0.6159\n",
      "Epoch 24/100\n",
      "\u001b[1m826/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8203 - loss: 0.5795\n",
      "Epoch 24: val_loss improved from 0.53793 to 0.53602, saving model to t_weights_1.keras\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.8203 - loss: 0.5797 - val_categorical_accuracy: 0.8260 - val_loss: 0.5360\n",
      "Epoch 25/100\n",
      "\u001b[1m830/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8217 - loss: 0.5762\n",
      "Epoch 25: val_loss did not improve from 0.53602\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.8217 - loss: 0.5763 - val_categorical_accuracy: 0.8242 - val_loss: 0.5633\n",
      "Epoch 26/100\n",
      "\u001b[1m832/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8226 - loss: 0.5653\n",
      "Epoch 26: val_loss did not improve from 0.53602\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - categorical_accuracy: 0.8226 - loss: 0.5654 - val_categorical_accuracy: 0.8203 - val_loss: 0.5621\n",
      "Epoch 27/100\n",
      "\u001b[1m832/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.8240 - loss: 0.5709\n",
      "Epoch 27: val_loss did not improve from 0.53602\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - categorical_accuracy: 0.8240 - loss: 0.5709 - val_categorical_accuracy: 0.8236 - val_loss: 0.5508\n",
      "Epoch 28/100\n",
      "\u001b[1m836/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.8295 - loss: 0.5439\n",
      "Epoch 28: val_loss did not improve from 0.53602\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - categorical_accuracy: 0.8295 - loss: 0.5439 - val_categorical_accuracy: 0.8182 - val_loss: 0.5775\n",
      "Epoch 29/100\n",
      "\u001b[1m827/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.8324 - loss: 0.5439\n",
      "Epoch 29: val_loss did not improve from 0.53602\n",
      "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - categorical_accuracy: 0.8324 - loss: 0.5440 - val_categorical_accuracy: 0.8233 - val_loss: 0.5539\n",
      "0.8134528994560242\n",
      "WARNING:tensorflow:From C:\\Users\\zy_seven\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\n",
      "\n",
      "ntx_i: 45  \n",
      "Epoch 1/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.0408 - loss: 4.1860\n",
      "Epoch 1: val_loss improved from inf to 2.78427, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - categorical_accuracy: 0.0408 - loss: 4.1852 - val_categorical_accuracy: 0.2001 - val_loss: 2.7843\n",
      "Epoch 2/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.2037 - loss: 3.1264\n",
      "Epoch 2: val_loss improved from 2.78427 to 2.27706, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - categorical_accuracy: 0.2038 - loss: 3.1260 - val_categorical_accuracy: 0.3427 - val_loss: 2.2771\n",
      "Epoch 3/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3058 - loss: 2.6929\n",
      "Epoch 3: val_loss improved from 2.27706 to 1.93734, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - categorical_accuracy: 0.3058 - loss: 2.6927 - val_categorical_accuracy: 0.4386 - val_loss: 1.9373\n",
      "Epoch 4/100\n",
      "\u001b[1m3795/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3869 - loss: 2.3801\n",
      "Epoch 4: val_loss improved from 1.93734 to 1.78190, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - categorical_accuracy: 0.3869 - loss: 2.3801 - val_categorical_accuracy: 0.4765 - val_loss: 1.7819\n",
      "Epoch 5/100\n",
      "\u001b[1m3797/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4333 - loss: 2.1929\n",
      "Epoch 5: val_loss improved from 1.78190 to 1.65351, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.4333 - loss: 2.1928 - val_categorical_accuracy: 0.5200 - val_loss: 1.6535\n",
      "Epoch 6/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4712 - loss: 2.0612\n",
      "Epoch 6: val_loss improved from 1.65351 to 1.52657, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.4712 - loss: 2.0612 - val_categorical_accuracy: 0.5508 - val_loss: 1.5266\n",
      "Epoch 7/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4917 - loss: 1.9662\n",
      "Epoch 7: val_loss improved from 1.52657 to 1.47308, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.4917 - loss: 1.9661 - val_categorical_accuracy: 0.5730 - val_loss: 1.4731\n",
      "Epoch 8/100\n",
      "\u001b[1m3794/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5144 - loss: 1.8882\n",
      "Epoch 8: val_loss improved from 1.47308 to 1.42257, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5144 - loss: 1.8881 - val_categorical_accuracy: 0.5921 - val_loss: 1.4226\n",
      "Epoch 9/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5267 - loss: 1.8395\n",
      "Epoch 9: val_loss improved from 1.42257 to 1.40174, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5267 - loss: 1.8395 - val_categorical_accuracy: 0.5958 - val_loss: 1.4017\n",
      "Epoch 10/100\n",
      "\u001b[1m3796/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5412 - loss: 1.7870\n",
      "Epoch 10: val_loss improved from 1.40174 to 1.33712, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.5412 - loss: 1.7870 - val_categorical_accuracy: 0.6150 - val_loss: 1.3371\n",
      "Epoch 11/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5494 - loss: 1.7450\n",
      "Epoch 11: val_loss improved from 1.33712 to 1.33533, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5495 - loss: 1.7450 - val_categorical_accuracy: 0.6137 - val_loss: 1.3353\n",
      "Epoch 12/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5553 - loss: 1.7258\n",
      "Epoch 12: val_loss improved from 1.33533 to 1.30221, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5553 - loss: 1.7258 - val_categorical_accuracy: 0.6276 - val_loss: 1.3022\n",
      "Epoch 13/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5679 - loss: 1.6889\n",
      "Epoch 13: val_loss did not improve from 1.30221\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5679 - loss: 1.6889 - val_categorical_accuracy: 0.6098 - val_loss: 1.3320\n",
      "Epoch 14/100\n",
      "\u001b[1m3797/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5740 - loss: 1.6720\n",
      "Epoch 14: val_loss improved from 1.30221 to 1.25791, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.5740 - loss: 1.6720 - val_categorical_accuracy: 0.6394 - val_loss: 1.2579\n",
      "Epoch 15/100\n",
      "\u001b[1m3795/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5843 - loss: 1.6277\n",
      "Epoch 15: val_loss improved from 1.25791 to 1.25385, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.5843 - loss: 1.6277 - val_categorical_accuracy: 0.6302 - val_loss: 1.2539\n",
      "Epoch 16/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5856 - loss: 1.6218\n",
      "Epoch 16: val_loss did not improve from 1.25385\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.5855 - loss: 1.6218 - val_categorical_accuracy: 0.6201 - val_loss: 1.2899\n",
      "Epoch 17/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5883 - loss: 1.6112\n",
      "Epoch 17: val_loss improved from 1.25385 to 1.22117, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.5883 - loss: 1.6112 - val_categorical_accuracy: 0.6513 - val_loss: 1.2212\n",
      "Epoch 18/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5927 - loss: 1.5942\n",
      "Epoch 18: val_loss did not improve from 1.22117\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5927 - loss: 1.5942 - val_categorical_accuracy: 0.6339 - val_loss: 1.2532\n",
      "Epoch 19/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5977 - loss: 1.5785\n",
      "Epoch 19: val_loss improved from 1.22117 to 1.21064, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.5977 - loss: 1.5785 - val_categorical_accuracy: 0.6574 - val_loss: 1.2106\n",
      "Epoch 20/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6001 - loss: 1.5639\n",
      "Epoch 20: val_loss did not improve from 1.21064\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6001 - loss: 1.5639 - val_categorical_accuracy: 0.6484 - val_loss: 1.2251\n",
      "Epoch 21/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6002 - loss: 1.5642\n",
      "Epoch 21: val_loss did not improve from 1.21064\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6002 - loss: 1.5642 - val_categorical_accuracy: 0.6358 - val_loss: 1.2696\n",
      "Epoch 22/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6071 - loss: 1.5516\n",
      "Epoch 22: val_loss did not improve from 1.21064\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6071 - loss: 1.5516 - val_categorical_accuracy: 0.6514 - val_loss: 1.2176\n",
      "Epoch 23/100\n",
      "\u001b[1m3790/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6094 - loss: 1.5374\n",
      "Epoch 23: val_loss improved from 1.21064 to 1.18253, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6094 - loss: 1.5374 - val_categorical_accuracy: 0.6638 - val_loss: 1.1825\n",
      "Epoch 24/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6126 - loss: 1.5206\n",
      "Epoch 24: val_loss improved from 1.18253 to 1.17920, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6126 - loss: 1.5206 - val_categorical_accuracy: 0.6584 - val_loss: 1.1792\n",
      "Epoch 25/100\n",
      "\u001b[1m3793/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6158 - loss: 1.5215\n",
      "Epoch 25: val_loss improved from 1.17920 to 1.15744, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6158 - loss: 1.5215 - val_categorical_accuracy: 0.6691 - val_loss: 1.1574\n",
      "Epoch 26/100\n",
      "\u001b[1m3797/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6177 - loss: 1.5100\n",
      "Epoch 26: val_loss did not improve from 1.15744\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6177 - loss: 1.5100 - val_categorical_accuracy: 0.6480 - val_loss: 1.2173\n",
      "Epoch 27/100\n",
      "\u001b[1m3794/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6197 - loss: 1.5008\n",
      "Epoch 27: val_loss improved from 1.15744 to 1.13914, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6197 - loss: 1.5008 - val_categorical_accuracy: 0.6767 - val_loss: 1.1391\n",
      "Epoch 28/100\n",
      "\u001b[1m3794/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6238 - loss: 1.4894\n",
      "Epoch 28: val_loss improved from 1.13914 to 1.13248, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - categorical_accuracy: 0.6238 - loss: 1.4894 - val_categorical_accuracy: 0.6826 - val_loss: 1.1325\n",
      "Epoch 29/100\n",
      "\u001b[1m3791/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6254 - loss: 1.4854\n",
      "Epoch 29: val_loss did not improve from 1.13248\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6254 - loss: 1.4854 - val_categorical_accuracy: 0.6765 - val_loss: 1.1444\n",
      "Epoch 30/100\n",
      "\u001b[1m3796/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6305 - loss: 1.4643\n",
      "Epoch 30: val_loss did not improve from 1.13248\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6305 - loss: 1.4643 - val_categorical_accuracy: 0.6664 - val_loss: 1.1798\n",
      "Epoch 31/100\n",
      "\u001b[1m3793/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.6308 - loss: 1.4616\n",
      "Epoch 31: val_loss did not improve from 1.13248\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - categorical_accuracy: 0.6308 - loss: 1.4616 - val_categorical_accuracy: 0.6821 - val_loss: 1.1388\n",
      "Epoch 32/100\n",
      "\u001b[1m3796/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6288 - loss: 1.4606\n",
      "Epoch 32: val_loss did not improve from 1.13248\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6288 - loss: 1.4606 - val_categorical_accuracy: 0.6741 - val_loss: 1.1567\n",
      "Epoch 33/100\n",
      "\u001b[1m3793/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6353 - loss: 1.4525\n",
      "Epoch 33: val_loss improved from 1.13248 to 1.12354, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6353 - loss: 1.4525 - val_categorical_accuracy: 0.6839 - val_loss: 1.1235\n",
      "Epoch 34/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6309 - loss: 1.4590\n",
      "Epoch 34: val_loss improved from 1.12354 to 1.11999, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6309 - loss: 1.4590 - val_categorical_accuracy: 0.6909 - val_loss: 1.1200\n",
      "Epoch 35/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6369 - loss: 1.4377\n",
      "Epoch 35: val_loss improved from 1.11999 to 1.11669, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6369 - loss: 1.4377 - val_categorical_accuracy: 0.6914 - val_loss: 1.1167\n",
      "Epoch 36/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6410 - loss: 1.4305\n",
      "Epoch 36: val_loss did not improve from 1.11669\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6410 - loss: 1.4305 - val_categorical_accuracy: 0.6728 - val_loss: 1.1581\n",
      "Epoch 37/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6369 - loss: 1.4335\n",
      "Epoch 37: val_loss did not improve from 1.11669\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6369 - loss: 1.4335 - val_categorical_accuracy: 0.6865 - val_loss: 1.1191\n",
      "Epoch 38/100\n",
      "\u001b[1m3796/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6415 - loss: 1.4260\n",
      "Epoch 38: val_loss improved from 1.11669 to 1.09872, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6415 - loss: 1.4260 - val_categorical_accuracy: 0.6954 - val_loss: 1.0987\n",
      "Epoch 39/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6436 - loss: 1.4222\n",
      "Epoch 39: val_loss did not improve from 1.09872\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6436 - loss: 1.4223 - val_categorical_accuracy: 0.6897 - val_loss: 1.1141\n",
      "Epoch 40/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6432 - loss: 1.4225\n",
      "Epoch 40: val_loss improved from 1.09872 to 1.09334, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6432 - loss: 1.4225 - val_categorical_accuracy: 0.6976 - val_loss: 1.0933\n",
      "Epoch 41/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6468 - loss: 1.4040\n",
      "Epoch 41: val_loss improved from 1.09334 to 1.08664, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6468 - loss: 1.4041 - val_categorical_accuracy: 0.6981 - val_loss: 1.0866\n",
      "Epoch 42/100\n",
      "\u001b[1m3784/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6441 - loss: 1.4167\n",
      "Epoch 42: val_loss did not improve from 1.08664\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6441 - loss: 1.4167 - val_categorical_accuracy: 0.6882 - val_loss: 1.1080\n",
      "Epoch 43/100\n",
      "\u001b[1m3794/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6484 - loss: 1.4024\n",
      "Epoch 43: val_loss improved from 1.08664 to 1.08239, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6484 - loss: 1.4024 - val_categorical_accuracy: 0.7018 - val_loss: 1.0824\n",
      "Epoch 44/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6450 - loss: 1.4095\n",
      "Epoch 44: val_loss did not improve from 1.08239\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6450 - loss: 1.4095 - val_categorical_accuracy: 0.6912 - val_loss: 1.1150\n",
      "Epoch 45/100\n",
      "\u001b[1m3796/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6483 - loss: 1.4039\n",
      "Epoch 45: val_loss did not improve from 1.08239\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - categorical_accuracy: 0.6483 - loss: 1.4039 - val_categorical_accuracy: 0.6872 - val_loss: 1.1259\n",
      "Epoch 46/100\n",
      "\u001b[1m3788/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6546 - loss: 1.3847\n",
      "Epoch 46: val_loss did not improve from 1.08239\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6546 - loss: 1.3847 - val_categorical_accuracy: 0.6985 - val_loss: 1.0921\n",
      "Epoch 47/100\n",
      "\u001b[1m3786/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6527 - loss: 1.3881\n",
      "Epoch 47: val_loss improved from 1.08239 to 1.08205, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6527 - loss: 1.3882 - val_categorical_accuracy: 0.7028 - val_loss: 1.0820\n",
      "Epoch 48/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6553 - loss: 1.3808\n",
      "Epoch 48: val_loss did not improve from 1.08205\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6553 - loss: 1.3808 - val_categorical_accuracy: 0.6866 - val_loss: 1.1292\n",
      "Epoch 49/100\n",
      "\u001b[1m3795/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6584 - loss: 1.3763\n",
      "Epoch 49: val_loss improved from 1.08205 to 1.07519, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6584 - loss: 1.3764 - val_categorical_accuracy: 0.7055 - val_loss: 1.0752\n",
      "Epoch 50/100\n",
      "\u001b[1m3787/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6570 - loss: 1.3752\n",
      "Epoch 50: val_loss did not improve from 1.07519\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6570 - loss: 1.3752 - val_categorical_accuracy: 0.6958 - val_loss: 1.1072\n",
      "Epoch 51/100\n",
      "\u001b[1m3790/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6577 - loss: 1.3767\n",
      "Epoch 51: val_loss did not improve from 1.07519\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6577 - loss: 1.3767 - val_categorical_accuracy: 0.7026 - val_loss: 1.0804\n",
      "Epoch 52/100\n",
      "\u001b[1m3785/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6588 - loss: 1.3655\n",
      "Epoch 52: val_loss improved from 1.07519 to 1.07344, saving model to t_weights_1.keras\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6588 - loss: 1.3656 - val_categorical_accuracy: 0.7021 - val_loss: 1.0734\n",
      "Epoch 53/100\n",
      "\u001b[1m3791/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6578 - loss: 1.3704\n",
      "Epoch 53: val_loss did not improve from 1.07344\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - categorical_accuracy: 0.6578 - loss: 1.3704 - val_categorical_accuracy: 0.6956 - val_loss: 1.1142\n",
      "Epoch 54/100\n",
      "\u001b[1m3790/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6563 - loss: 1.3695\n",
      "Epoch 54: val_loss did not improve from 1.07344\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6563 - loss: 1.3695 - val_categorical_accuracy: 0.7009 - val_loss: 1.0870\n",
      "Epoch 55/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.6631 - loss: 1.3591\n",
      "Epoch 55: val_loss did not improve from 1.07344\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - categorical_accuracy: 0.6631 - loss: 1.3592 - val_categorical_accuracy: 0.6931 - val_loss: 1.1144\n",
      "Epoch 56/100\n",
      "\u001b[1m3792/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6631 - loss: 1.3578\n",
      "Epoch 56: val_loss did not improve from 1.07344\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - categorical_accuracy: 0.6631 - loss: 1.3578 - val_categorical_accuracy: 0.6969 - val_loss: 1.0973\n",
      "Epoch 57/100\n",
      "\u001b[1m3789/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.6619 - loss: 1.3610\n",
      "Epoch 57: val_loss did not improve from 1.07344\n",
      "\u001b[1m3798/3798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - categorical_accuracy: 0.6619 - loss: 1.3610 - val_categorical_accuracy: 0.7043 - val_loss: 1.0870\n",
      "0.7085390686988831\n",
      "\n",
      "\n",
      "ntx_i: 80  \n",
      "Epoch 1/100\n",
      "\u001b[1m6802/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.0328 - loss: 4.8452\n",
      "Epoch 1: val_loss improved from inf to 3.24938, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.0329 - loss: 4.8447 - val_categorical_accuracy: 0.1660 - val_loss: 3.2494\n",
      "Epoch 2/100\n",
      "\u001b[1m6809/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.1732 - loss: 3.7042\n",
      "Epoch 2: val_loss improved from 3.24938 to 2.47292, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.1732 - loss: 3.7041 - val_categorical_accuracy: 0.3355 - val_loss: 2.4729\n",
      "Epoch 3/100\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2902 - loss: 3.0667\n",
      "Epoch 3: val_loss improved from 2.47292 to 2.20048, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.2902 - loss: 3.0667 - val_categorical_accuracy: 0.3974 - val_loss: 2.2005\n",
      "Epoch 4/100\n",
      "\u001b[1m6810/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3331 - loss: 2.8274\n",
      "Epoch 4: val_loss improved from 2.20048 to 2.06733, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.3331 - loss: 2.8274 - val_categorical_accuracy: 0.4229 - val_loss: 2.0673\n",
      "Epoch 5/100\n",
      "\u001b[1m6806/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3608 - loss: 2.6779\n",
      "Epoch 5: val_loss improved from 2.06733 to 1.96234, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - categorical_accuracy: 0.3608 - loss: 2.6779 - val_categorical_accuracy: 0.4551 - val_loss: 1.9623\n",
      "Epoch 6/100\n",
      "\u001b[1m6804/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3818 - loss: 2.5690\n",
      "Epoch 6: val_loss improved from 1.96234 to 1.92532, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.3818 - loss: 2.5690 - val_categorical_accuracy: 0.4564 - val_loss: 1.9253\n",
      "Epoch 7/100\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3953 - loss: 2.5083\n",
      "Epoch 7: val_loss improved from 1.92532 to 1.86878, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - categorical_accuracy: 0.3953 - loss: 2.5083 - val_categorical_accuracy: 0.4745 - val_loss: 1.8688\n",
      "Epoch 8/100\n",
      "\u001b[1m6802/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4038 - loss: 2.4652\n",
      "Epoch 8: val_loss improved from 1.86878 to 1.83101, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - categorical_accuracy: 0.4038 - loss: 2.4652 - val_categorical_accuracy: 0.4807 - val_loss: 1.8310\n",
      "Epoch 9/100\n",
      "\u001b[1m6808/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4119 - loss: 2.4237\n",
      "Epoch 9: val_loss improved from 1.83101 to 1.77979, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - categorical_accuracy: 0.4119 - loss: 2.4237 - val_categorical_accuracy: 0.5012 - val_loss: 1.7798\n",
      "Epoch 10/100\n",
      "\u001b[1m6804/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4193 - loss: 2.3915\n",
      "Epoch 10: val_loss improved from 1.77979 to 1.75045, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4193 - loss: 2.3915 - val_categorical_accuracy: 0.5081 - val_loss: 1.7504\n",
      "Epoch 11/100\n",
      "\u001b[1m6803/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4286 - loss: 2.3592\n",
      "Epoch 11: val_loss did not improve from 1.75045\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4286 - loss: 2.3592 - val_categorical_accuracy: 0.5036 - val_loss: 1.7624\n",
      "Epoch 12/100\n",
      "\u001b[1m6801/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4331 - loss: 2.3346\n",
      "Epoch 12: val_loss improved from 1.75045 to 1.72175, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4331 - loss: 2.3346 - val_categorical_accuracy: 0.5136 - val_loss: 1.7217\n",
      "Epoch 13/100\n",
      "\u001b[1m6804/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4390 - loss: 2.3145\n",
      "Epoch 13: val_loss did not improve from 1.72175\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.4390 - loss: 2.3145 - val_categorical_accuracy: 0.5091 - val_loss: 1.7499\n",
      "Epoch 14/100\n",
      "\u001b[1m6801/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4430 - loss: 2.2922\n",
      "Epoch 14: val_loss improved from 1.72175 to 1.70667, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4430 - loss: 2.2922 - val_categorical_accuracy: 0.5202 - val_loss: 1.7067\n",
      "Epoch 15/100\n",
      "\u001b[1m6800/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4464 - loss: 2.2729\n",
      "Epoch 15: val_loss did not improve from 1.70667\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.4464 - loss: 2.2729 - val_categorical_accuracy: 0.5036 - val_loss: 1.7428\n",
      "Epoch 16/100\n",
      "\u001b[1m6801/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4511 - loss: 2.2606\n",
      "Epoch 16: val_loss improved from 1.70667 to 1.65656, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4511 - loss: 2.2606 - val_categorical_accuracy: 0.5397 - val_loss: 1.6566\n",
      "Epoch 17/100\n",
      "\u001b[1m6798/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4544 - loss: 2.2513\n",
      "Epoch 17: val_loss improved from 1.65656 to 1.63064, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - categorical_accuracy: 0.4544 - loss: 2.2513 - val_categorical_accuracy: 0.5440 - val_loss: 1.6306\n",
      "Epoch 18/100\n",
      "\u001b[1m6806/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4580 - loss: 2.2258\n",
      "Epoch 18: val_loss did not improve from 1.63064\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.4580 - loss: 2.2258 - val_categorical_accuracy: 0.5260 - val_loss: 1.6740\n",
      "Epoch 19/100\n",
      "\u001b[1m6807/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4612 - loss: 2.2220\n",
      "Epoch 19: val_loss did not improve from 1.63064\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.4612 - loss: 2.2220 - val_categorical_accuracy: 0.5389 - val_loss: 1.6529\n",
      "Epoch 20/100\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4640 - loss: 2.2115\n",
      "Epoch 20: val_loss did not improve from 1.63064\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4640 - loss: 2.2115 - val_categorical_accuracy: 0.5447 - val_loss: 1.6397\n",
      "Epoch 21/100\n",
      "\u001b[1m6805/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4645 - loss: 2.2023\n",
      "Epoch 21: val_loss improved from 1.63064 to 1.62898, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - categorical_accuracy: 0.4645 - loss: 2.2023 - val_categorical_accuracy: 0.5484 - val_loss: 1.6290\n",
      "Epoch 22/100\n",
      "\u001b[1m6800/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4709 - loss: 2.1867\n",
      "Epoch 22: val_loss did not improve from 1.62898\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - categorical_accuracy: 0.4709 - loss: 2.1867 - val_categorical_accuracy: 0.5380 - val_loss: 1.6387\n",
      "Epoch 23/100\n",
      "\u001b[1m6799/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4745 - loss: 2.1680\n",
      "Epoch 23: val_loss improved from 1.62898 to 1.60686, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - categorical_accuracy: 0.4745 - loss: 2.1680 - val_categorical_accuracy: 0.5501 - val_loss: 1.6069\n",
      "Epoch 24/100\n",
      "\u001b[1m6807/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4788 - loss: 2.1529\n",
      "Epoch 24: val_loss improved from 1.60686 to 1.59080, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - categorical_accuracy: 0.4788 - loss: 2.1529 - val_categorical_accuracy: 0.5652 - val_loss: 1.5908\n",
      "Epoch 25/100\n",
      "\u001b[1m6806/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4776 - loss: 2.1510\n",
      "Epoch 25: val_loss did not improve from 1.59080\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - categorical_accuracy: 0.4776 - loss: 2.1510 - val_categorical_accuracy: 0.5524 - val_loss: 1.6103\n",
      "Epoch 26/100\n",
      "\u001b[1m6810/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4803 - loss: 2.1455\n",
      "Epoch 26: val_loss did not improve from 1.59080\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - categorical_accuracy: 0.4803 - loss: 2.1455 - val_categorical_accuracy: 0.5488 - val_loss: 1.6110\n",
      "Epoch 27/100\n",
      "\u001b[1m6806/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4816 - loss: 2.1349\n",
      "Epoch 27: val_loss improved from 1.59080 to 1.58581, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - categorical_accuracy: 0.4816 - loss: 2.1349 - val_categorical_accuracy: 0.5626 - val_loss: 1.5858\n",
      "Epoch 28/100\n",
      "\u001b[1m6805/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4842 - loss: 2.1231\n",
      "Epoch 28: val_loss improved from 1.58581 to 1.55289, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - categorical_accuracy: 0.4842 - loss: 2.1231 - val_categorical_accuracy: 0.5771 - val_loss: 1.5529\n",
      "Epoch 29/100\n",
      "\u001b[1m6810/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4867 - loss: 2.1167\n",
      "Epoch 29: val_loss did not improve from 1.55289\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - categorical_accuracy: 0.4867 - loss: 2.1167 - val_categorical_accuracy: 0.5613 - val_loss: 1.5810\n",
      "Epoch 30/100\n",
      "\u001b[1m6804/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4884 - loss: 2.1097\n",
      "Epoch 30: val_loss improved from 1.55289 to 1.54773, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 4ms/step - categorical_accuracy: 0.4884 - loss: 2.1097 - val_categorical_accuracy: 0.5763 - val_loss: 1.5477\n",
      "Epoch 31/100\n",
      "\u001b[1m6805/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4880 - loss: 2.1099\n",
      "Epoch 31: val_loss improved from 1.54773 to 1.53814, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - categorical_accuracy: 0.4880 - loss: 2.1099 - val_categorical_accuracy: 0.5759 - val_loss: 1.5381\n",
      "Epoch 32/100\n",
      "\u001b[1m6805/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4892 - loss: 2.0963\n",
      "Epoch 32: val_loss did not improve from 1.53814\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - categorical_accuracy: 0.4892 - loss: 2.0963 - val_categorical_accuracy: 0.5711 - val_loss: 1.5523\n",
      "Epoch 33/100\n",
      "\u001b[1m6804/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4938 - loss: 2.0942\n",
      "Epoch 33: val_loss improved from 1.53814 to 1.50955, saving model to t_weights_1.keras\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - categorical_accuracy: 0.4938 - loss: 2.0942 - val_categorical_accuracy: 0.5806 - val_loss: 1.5095\n",
      "Epoch 34/100\n",
      "\u001b[1m6800/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4974 - loss: 2.0778\n",
      "Epoch 34: val_loss did not improve from 1.50955\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - categorical_accuracy: 0.4974 - loss: 2.0778 - val_categorical_accuracy: 0.5802 - val_loss: 1.5235\n",
      "Epoch 35/100\n",
      "\u001b[1m6801/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4946 - loss: 2.0844\n",
      "Epoch 35: val_loss did not improve from 1.50955\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - categorical_accuracy: 0.4946 - loss: 2.0844 - val_categorical_accuracy: 0.5661 - val_loss: 1.5621\n",
      "Epoch 36/100\n",
      "\u001b[1m6798/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4967 - loss: 2.0668\n",
      "Epoch 36: val_loss did not improve from 1.50955\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - categorical_accuracy: 0.4967 - loss: 2.0668 - val_categorical_accuracy: 0.5561 - val_loss: 1.5916\n",
      "Epoch 37/100\n",
      "\u001b[1m6807/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4994 - loss: 2.0648\n",
      "Epoch 37: val_loss did not improve from 1.50955\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.4994 - loss: 2.0648 - val_categorical_accuracy: 0.5791 - val_loss: 1.5153\n",
      "Epoch 38/100\n",
      "\u001b[1m6802/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.5004 - loss: 2.0558\n",
      "Epoch 38: val_loss did not improve from 1.50955\n",
      "\u001b[1m6811/6811\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4ms/step - categorical_accuracy: 0.5004 - loss: 2.0558 - val_categorical_accuracy: 0.5579 - val_loss: 1.5929\n",
      "0.577674150466919\n",
      "\n",
      "\n",
      "ntx_i: 115  \n",
      "Epoch 1/100\n",
      "\u001b[1m9808/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.0363 - loss: 5.1924\n",
      "Epoch 1: val_loss improved from inf to 3.14973, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - categorical_accuracy: 0.0363 - loss: 5.1921 - val_categorical_accuracy: 0.2089 - val_loss: 3.1497\n",
      "Epoch 2/100\n",
      "\u001b[1m9806/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.1878 - loss: 3.7512\n",
      "Epoch 2: val_loss improved from 3.14973 to 2.63957, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - categorical_accuracy: 0.1879 - loss: 3.7511 - val_categorical_accuracy: 0.3045 - val_loss: 2.6396\n",
      "Epoch 3/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2567 - loss: 3.3193\n",
      "Epoch 3: val_loss improved from 2.63957 to 2.40181, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - categorical_accuracy: 0.2567 - loss: 3.3193 - val_categorical_accuracy: 0.3536 - val_loss: 2.4018\n",
      "Epoch 4/100\n",
      "\u001b[1m9813/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2978 - loss: 3.0968\n",
      "Epoch 4: val_loss improved from 2.40181 to 2.31473, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - categorical_accuracy: 0.2978 - loss: 3.0968 - val_categorical_accuracy: 0.3805 - val_loss: 2.3147\n",
      "Epoch 5/100\n",
      "\u001b[1m9812/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3217 - loss: 2.9706\n",
      "Epoch 5: val_loss improved from 2.31473 to 2.21000, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - categorical_accuracy: 0.3217 - loss: 2.9706 - val_categorical_accuracy: 0.4050 - val_loss: 2.2100\n",
      "Epoch 6/100\n",
      "\u001b[1m9801/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3386 - loss: 2.8827\n",
      "Epoch 6: val_loss improved from 2.21000 to 2.19883, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.3386 - loss: 2.8827 - val_categorical_accuracy: 0.4036 - val_loss: 2.1988\n",
      "Epoch 7/100\n",
      "\u001b[1m9813/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3552 - loss: 2.8043\n",
      "Epoch 7: val_loss improved from 2.19883 to 2.11950, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - categorical_accuracy: 0.3552 - loss: 2.8043 - val_categorical_accuracy: 0.4315 - val_loss: 2.1195\n",
      "Epoch 8/100\n",
      "\u001b[1m9811/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3673 - loss: 2.7474\n",
      "Epoch 8: val_loss improved from 2.11950 to 2.06841, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.3673 - loss: 2.7474 - val_categorical_accuracy: 0.4427 - val_loss: 2.0684\n",
      "Epoch 9/100\n",
      "\u001b[1m9808/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3771 - loss: 2.7080\n",
      "Epoch 9: val_loss did not improve from 2.06841\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.3771 - loss: 2.7080 - val_categorical_accuracy: 0.4336 - val_loss: 2.0872\n",
      "Epoch 10/100\n",
      "\u001b[1m9810/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3839 - loss: 2.6733\n",
      "Epoch 10: val_loss improved from 2.06841 to 2.01139, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - categorical_accuracy: 0.3839 - loss: 2.6733 - val_categorical_accuracy: 0.4616 - val_loss: 2.0114\n",
      "Epoch 11/100\n",
      "\u001b[1m9813/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3923 - loss: 2.6435\n",
      "Epoch 11: val_loss improved from 2.01139 to 1.98021, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.3923 - loss: 2.6435 - val_categorical_accuracy: 0.4676 - val_loss: 1.9802\n",
      "Epoch 12/100\n",
      "\u001b[1m9804/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3950 - loss: 2.6167\n",
      "Epoch 12: val_loss improved from 1.98021 to 1.94541, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.3950 - loss: 2.6167 - val_categorical_accuracy: 0.4786 - val_loss: 1.9454\n",
      "Epoch 13/100\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4017 - loss: 2.5931\n",
      "Epoch 13: val_loss did not improve from 1.94541\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4017 - loss: 2.5931 - val_categorical_accuracy: 0.4757 - val_loss: 1.9510\n",
      "Epoch 14/100\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4064 - loss: 2.5761\n",
      "Epoch 14: val_loss did not improve from 1.94541\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4ms/step - categorical_accuracy: 0.4064 - loss: 2.5761 - val_categorical_accuracy: 0.4590 - val_loss: 2.0031\n",
      "Epoch 15/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4099 - loss: 2.5596\n",
      "Epoch 15: val_loss improved from 1.94541 to 1.89714, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - categorical_accuracy: 0.4099 - loss: 2.5596 - val_categorical_accuracy: 0.4961 - val_loss: 1.8971\n",
      "Epoch 16/100\n",
      "\u001b[1m9808/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4150 - loss: 2.5395\n",
      "Epoch 16: val_loss improved from 1.89714 to 1.86644, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - categorical_accuracy: 0.4150 - loss: 2.5395 - val_categorical_accuracy: 0.5035 - val_loss: 1.8664\n",
      "Epoch 17/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4174 - loss: 2.5328\n",
      "Epoch 17: val_loss improved from 1.86644 to 1.85039, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - categorical_accuracy: 0.4174 - loss: 2.5328 - val_categorical_accuracy: 0.5087 - val_loss: 1.8504\n",
      "Epoch 18/100\n",
      "\u001b[1m9803/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4215 - loss: 2.5101\n",
      "Epoch 18: val_loss did not improve from 1.85039\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - categorical_accuracy: 0.4215 - loss: 2.5101 - val_categorical_accuracy: 0.4872 - val_loss: 1.8974\n",
      "Epoch 19/100\n",
      "\u001b[1m9801/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4252 - loss: 2.4975\n",
      "Epoch 19: val_loss did not improve from 1.85039\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4ms/step - categorical_accuracy: 0.4252 - loss: 2.4976 - val_categorical_accuracy: 0.5028 - val_loss: 1.8593\n",
      "Epoch 20/100\n",
      "\u001b[1m9809/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4272 - loss: 2.4856\n",
      "Epoch 20: val_loss improved from 1.85039 to 1.84689, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.4272 - loss: 2.4856 - val_categorical_accuracy: 0.5106 - val_loss: 1.8469\n",
      "Epoch 21/100\n",
      "\u001b[1m9811/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4293 - loss: 2.4765\n",
      "Epoch 21: val_loss improved from 1.84689 to 1.82635, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.4293 - loss: 2.4766 - val_categorical_accuracy: 0.5148 - val_loss: 1.8264\n",
      "Epoch 22/100\n",
      "\u001b[1m9801/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4320 - loss: 2.4713\n",
      "Epoch 22: val_loss did not improve from 1.82635\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.4320 - loss: 2.4713 - val_categorical_accuracy: 0.5112 - val_loss: 1.8373\n",
      "Epoch 23/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4339 - loss: 2.4594\n",
      "Epoch 23: val_loss improved from 1.82635 to 1.81843, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.4339 - loss: 2.4594 - val_categorical_accuracy: 0.5173 - val_loss: 1.8184\n",
      "Epoch 24/100\n",
      "\u001b[1m9810/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4336 - loss: 2.4613\n",
      "Epoch 24: val_loss did not improve from 1.81843\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - categorical_accuracy: 0.4336 - loss: 2.4613 - val_categorical_accuracy: 0.5153 - val_loss: 1.8225\n",
      "Epoch 25/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4361 - loss: 2.4447\n",
      "Epoch 25: val_loss improved from 1.81843 to 1.79459, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - categorical_accuracy: 0.4361 - loss: 2.4447 - val_categorical_accuracy: 0.5225 - val_loss: 1.7946\n",
      "Epoch 26/100\n",
      "\u001b[1m9810/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4361 - loss: 2.4483\n",
      "Epoch 26: val_loss did not improve from 1.79459\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - categorical_accuracy: 0.4361 - loss: 2.4483 - val_categorical_accuracy: 0.5306 - val_loss: 1.7952\n",
      "Epoch 27/100\n",
      "\u001b[1m9804/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4385 - loss: 2.4343\n",
      "Epoch 27: val_loss improved from 1.79459 to 1.78531, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4ms/step - categorical_accuracy: 0.4385 - loss: 2.4343 - val_categorical_accuracy: 0.5249 - val_loss: 1.7853\n",
      "Epoch 28/100\n",
      "\u001b[1m9806/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4399 - loss: 2.4275\n",
      "Epoch 28: val_loss improved from 1.78531 to 1.77160, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - categorical_accuracy: 0.4399 - loss: 2.4275 - val_categorical_accuracy: 0.5305 - val_loss: 1.7716\n",
      "Epoch 29/100\n",
      "\u001b[1m9805/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4431 - loss: 2.4183\n",
      "Epoch 29: val_loss did not improve from 1.77160\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - categorical_accuracy: 0.4431 - loss: 2.4183 - val_categorical_accuracy: 0.5048 - val_loss: 1.8335\n",
      "Epoch 30/100\n",
      "\u001b[1m9813/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.4439 - loss: 2.4207\n",
      "Epoch 30: val_loss did not improve from 1.77160\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5ms/step - categorical_accuracy: 0.4439 - loss: 2.4207 - val_categorical_accuracy: 0.5223 - val_loss: 1.8067\n",
      "Epoch 31/100\n",
      "\u001b[1m9808/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4477 - loss: 2.4046\n",
      "Epoch 31: val_loss did not improve from 1.77160\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.4477 - loss: 2.4046 - val_categorical_accuracy: 0.5294 - val_loss: 1.7720\n",
      "Epoch 32/100\n",
      "\u001b[1m9813/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4481 - loss: 2.4023\n",
      "Epoch 32: val_loss improved from 1.77160 to 1.77013, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - categorical_accuracy: 0.4481 - loss: 2.4023 - val_categorical_accuracy: 0.5336 - val_loss: 1.7701\n",
      "Epoch 33/100\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4481 - loss: 2.3897\n",
      "Epoch 33: val_loss did not improve from 1.77013\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4481 - loss: 2.3897 - val_categorical_accuracy: 0.5184 - val_loss: 1.8071\n",
      "Epoch 34/100\n",
      "\u001b[1m9810/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4487 - loss: 2.3967\n",
      "Epoch 34: val_loss improved from 1.77013 to 1.75934, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.4487 - loss: 2.3967 - val_categorical_accuracy: 0.5367 - val_loss: 1.7593\n",
      "Epoch 35/100\n",
      "\u001b[1m9804/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4485 - loss: 2.3944\n",
      "Epoch 35: val_loss improved from 1.75934 to 1.75178, saving model to t_weights_1.keras\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4485 - loss: 2.3944 - val_categorical_accuracy: 0.5358 - val_loss: 1.7518\n",
      "Epoch 36/100\n",
      "\u001b[1m9810/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4510 - loss: 2.3838\n",
      "Epoch 36: val_loss did not improve from 1.75178\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4510 - loss: 2.3838 - val_categorical_accuracy: 0.5338 - val_loss: 1.7634\n",
      "Epoch 37/100\n",
      "\u001b[1m9805/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4514 - loss: 2.3753\n",
      "Epoch 37: val_loss did not improve from 1.75178\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4514 - loss: 2.3753 - val_categorical_accuracy: 0.5131 - val_loss: 1.8152\n",
      "Epoch 38/100\n",
      "\u001b[1m9811/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4542 - loss: 2.3708\n",
      "Epoch 38: val_loss did not improve from 1.75178\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5ms/step - categorical_accuracy: 0.4542 - loss: 2.3708 - val_categorical_accuracy: 0.5296 - val_loss: 1.7690\n",
      "Epoch 39/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4557 - loss: 2.3634\n",
      "Epoch 39: val_loss did not improve from 1.75178\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - categorical_accuracy: 0.4557 - loss: 2.3634 - val_categorical_accuracy: 0.5341 - val_loss: 1.7622\n",
      "Epoch 40/100\n",
      "\u001b[1m9807/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.4533 - loss: 2.3689\n",
      "Epoch 40: val_loss did not improve from 1.75178\n",
      "\u001b[1m9814/9814\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - categorical_accuracy: 0.4533 - loss: 2.3689 - val_categorical_accuracy: 0.5344 - val_loss: 1.7613\n",
      "0.5350282788276672\n",
      "\n",
      "\n",
      "ntx_i: 150  \n",
      "Epoch 1/100\n",
      "\u001b[1m12779/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.0192 - loss: 5.5673\n",
      "Epoch 1: val_loss improved from inf to 4.06485, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.0192 - loss: 5.5671 - val_categorical_accuracy: 0.0721 - val_loss: 4.0648\n",
      "Epoch 2/100\n",
      "\u001b[1m12785/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.0781 - loss: 4.7227\n",
      "Epoch 2: val_loss improved from 4.06485 to 3.44242, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - categorical_accuracy: 0.0781 - loss: 4.7226 - val_categorical_accuracy: 0.1679 - val_loss: 3.4424\n",
      "Epoch 3/100\n",
      "\u001b[1m12781/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1424 - loss: 4.2026\n",
      "Epoch 3: val_loss improved from 3.44242 to 3.20934, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.1424 - loss: 4.2025 - val_categorical_accuracy: 0.2169 - val_loss: 3.2093\n",
      "Epoch 4/100\n",
      "\u001b[1m12786/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.1713 - loss: 3.9959\n",
      "Epoch 4: val_loss improved from 3.20934 to 3.08800, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 5ms/step - categorical_accuracy: 0.1713 - loss: 3.9959 - val_categorical_accuracy: 0.2385 - val_loss: 3.0880\n",
      "Epoch 5/100\n",
      "\u001b[1m12776/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.1926 - loss: 3.8618\n",
      "Epoch 5: val_loss improved from 3.08800 to 2.92806, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 4ms/step - categorical_accuracy: 0.1926 - loss: 3.8617 - val_categorical_accuracy: 0.2652 - val_loss: 2.9281\n",
      "Epoch 6/100\n",
      "\u001b[1m12780/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2200 - loss: 3.6740\n",
      "Epoch 6: val_loss improved from 2.92806 to 2.78751, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - categorical_accuracy: 0.2200 - loss: 3.6740 - val_categorical_accuracy: 0.2958 - val_loss: 2.7875\n",
      "Epoch 7/100\n",
      "\u001b[1m12777/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2469 - loss: 3.5144\n",
      "Epoch 7: val_loss improved from 2.78751 to 2.62125, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - categorical_accuracy: 0.2469 - loss: 3.5144 - val_categorical_accuracy: 0.3356 - val_loss: 2.6212\n",
      "Epoch 8/100\n",
      "\u001b[1m12779/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2668 - loss: 3.3909\n",
      "Epoch 8: val_loss improved from 2.62125 to 2.55149, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 5ms/step - categorical_accuracy: 0.2668 - loss: 3.3908 - val_categorical_accuracy: 0.3468 - val_loss: 2.5515\n",
      "Epoch 9/100\n",
      "\u001b[1m12787/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2813 - loss: 3.2983\n",
      "Epoch 9: val_loss improved from 2.55149 to 2.46903, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - categorical_accuracy: 0.2813 - loss: 3.2983 - val_categorical_accuracy: 0.3614 - val_loss: 2.4690\n",
      "Epoch 10/100\n",
      "\u001b[1m12774/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.2934 - loss: 3.2210\n",
      "Epoch 10: val_loss improved from 2.46903 to 2.45161, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4ms/step - categorical_accuracy: 0.2934 - loss: 3.2210 - val_categorical_accuracy: 0.3645 - val_loss: 2.4516\n",
      "Epoch 11/100\n",
      "\u001b[1m12780/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3020 - loss: 3.1677\n",
      "Epoch 11: val_loss improved from 2.45161 to 2.39666, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - categorical_accuracy: 0.3020 - loss: 3.1677 - val_categorical_accuracy: 0.3775 - val_loss: 2.3967\n",
      "Epoch 12/100\n",
      "\u001b[1m12785/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3079 - loss: 3.1205\n",
      "Epoch 12: val_loss did not improve from 2.39666\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - categorical_accuracy: 0.3079 - loss: 3.1205 - val_categorical_accuracy: 0.3712 - val_loss: 2.4021\n",
      "Epoch 13/100\n",
      "\u001b[1m12782/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3164 - loss: 3.0865\n",
      "Epoch 13: val_loss improved from 2.39666 to 2.29159, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - categorical_accuracy: 0.3164 - loss: 3.0865 - val_categorical_accuracy: 0.4089 - val_loss: 2.2916\n",
      "Epoch 14/100\n",
      "\u001b[1m12784/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3220 - loss: 3.0507\n",
      "Epoch 14: val_loss improved from 2.29159 to 2.28840, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - categorical_accuracy: 0.3220 - loss: 3.0507 - val_categorical_accuracy: 0.4010 - val_loss: 2.2884\n",
      "Epoch 15/100\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3263 - loss: 3.0347\n",
      "Epoch 15: val_loss improved from 2.28840 to 2.24956, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.3263 - loss: 3.0347 - val_categorical_accuracy: 0.4179 - val_loss: 2.2496\n",
      "Epoch 16/100\n",
      "\u001b[1m12778/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3318 - loss: 3.0050\n",
      "Epoch 16: val_loss did not improve from 2.24956\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.3318 - loss: 3.0050 - val_categorical_accuracy: 0.4029 - val_loss: 2.2887\n",
      "Epoch 17/100\n",
      "\u001b[1m12778/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3342 - loss: 2.9936\n",
      "Epoch 17: val_loss improved from 2.24956 to 2.23746, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.3342 - loss: 2.9936 - val_categorical_accuracy: 0.4149 - val_loss: 2.2375\n",
      "Epoch 18/100\n",
      "\u001b[1m12778/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3375 - loss: 2.9772\n",
      "Epoch 18: val_loss improved from 2.23746 to 2.23368, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - categorical_accuracy: 0.3375 - loss: 2.9772 - val_categorical_accuracy: 0.4201 - val_loss: 2.2337\n",
      "Epoch 19/100\n",
      "\u001b[1m12780/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3418 - loss: 2.9586\n",
      "Epoch 19: val_loss improved from 2.23368 to 2.21687, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - categorical_accuracy: 0.3418 - loss: 2.9586 - val_categorical_accuracy: 0.4212 - val_loss: 2.2169\n",
      "Epoch 20/100\n",
      "\u001b[1m12784/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3435 - loss: 2.9453\n",
      "Epoch 20: val_loss did not improve from 2.21687\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - categorical_accuracy: 0.3435 - loss: 2.9453 - val_categorical_accuracy: 0.3966 - val_loss: 2.2939\n",
      "Epoch 21/100\n",
      "\u001b[1m12785/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3443 - loss: 2.9399\n",
      "Epoch 21: val_loss improved from 2.21687 to 2.17218, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - categorical_accuracy: 0.3443 - loss: 2.9399 - val_categorical_accuracy: 0.4366 - val_loss: 2.1722\n",
      "Epoch 22/100\n",
      "\u001b[1m12782/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3481 - loss: 2.9302\n",
      "Epoch 22: val_loss did not improve from 2.17218\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - categorical_accuracy: 0.3481 - loss: 2.9302 - val_categorical_accuracy: 0.4327 - val_loss: 2.1809\n",
      "Epoch 23/100\n",
      "\u001b[1m12784/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3510 - loss: 2.9181\n",
      "Epoch 23: val_loss did not improve from 2.17218\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 5ms/step - categorical_accuracy: 0.3510 - loss: 2.9181 - val_categorical_accuracy: 0.4327 - val_loss: 2.1954\n",
      "Epoch 24/100\n",
      "\u001b[1m12778/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3512 - loss: 2.9089\n",
      "Epoch 24: val_loss did not improve from 2.17218\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 5ms/step - categorical_accuracy: 0.3512 - loss: 2.9089 - val_categorical_accuracy: 0.4288 - val_loss: 2.1952\n",
      "Epoch 25/100\n",
      "\u001b[1m12778/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3543 - loss: 2.8986\n",
      "Epoch 25: val_loss did not improve from 2.17218\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - categorical_accuracy: 0.3543 - loss: 2.8986 - val_categorical_accuracy: 0.4259 - val_loss: 2.1907\n",
      "Epoch 26/100\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3579 - loss: 2.8781\n",
      "Epoch 26: val_loss improved from 2.17218 to 2.15237, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 5ms/step - categorical_accuracy: 0.3579 - loss: 2.8781 - val_categorical_accuracy: 0.4401 - val_loss: 2.1524\n",
      "Epoch 27/100\n",
      "\u001b[1m12785/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - categorical_accuracy: 0.3572 - loss: 2.8838\n",
      "Epoch 27: val_loss did not improve from 2.15237\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 5ms/step - categorical_accuracy: 0.3572 - loss: 2.8838 - val_categorical_accuracy: 0.4370 - val_loss: 2.1591\n",
      "Epoch 28/100\n",
      "\u001b[1m12777/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3568 - loss: 2.8822\n",
      "Epoch 28: val_loss did not improve from 2.15237\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 5ms/step - categorical_accuracy: 0.3568 - loss: 2.8822 - val_categorical_accuracy: 0.4383 - val_loss: 2.1582\n",
      "Epoch 29/100\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3592 - loss: 2.8734\n",
      "Epoch 29: val_loss improved from 2.15237 to 2.13281, saving model to t_weights_1.keras\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 5ms/step - categorical_accuracy: 0.3592 - loss: 2.8734 - val_categorical_accuracy: 0.4450 - val_loss: 2.1328\n",
      "Epoch 30/100\n",
      "\u001b[1m12787/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3618 - loss: 2.8641\n",
      "Epoch 30: val_loss did not improve from 2.13281\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 5ms/step - categorical_accuracy: 0.3618 - loss: 2.8641 - val_categorical_accuracy: 0.4470 - val_loss: 2.1386\n",
      "Epoch 31/100\n",
      "\u001b[1m12779/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3641 - loss: 2.8553\n",
      "Epoch 31: val_loss did not improve from 2.13281\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4ms/step - categorical_accuracy: 0.3641 - loss: 2.8553 - val_categorical_accuracy: 0.4342 - val_loss: 2.1600\n",
      "Epoch 32/100\n",
      "\u001b[1m12783/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3637 - loss: 2.8571\n",
      "Epoch 32: val_loss did not improve from 2.13281\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4ms/step - categorical_accuracy: 0.3637 - loss: 2.8571 - val_categorical_accuracy: 0.4457 - val_loss: 2.1464\n",
      "Epoch 33/100\n",
      "\u001b[1m12784/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3664 - loss: 2.8407\n",
      "Epoch 33: val_loss did not improve from 2.13281\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4ms/step - categorical_accuracy: 0.3664 - loss: 2.8407 - val_categorical_accuracy: 0.4467 - val_loss: 2.1406\n",
      "Epoch 34/100\n",
      "\u001b[1m12784/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - categorical_accuracy: 0.3681 - loss: 2.8378\n",
      "Epoch 34: val_loss did not improve from 2.13281\n",
      "\u001b[1m12788/12788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4ms/step - categorical_accuracy: 0.3681 - loss: 2.8378 - val_categorical_accuracy: 0.4383 - val_loss: 2.1652\n",
      "0.444996178150177\n"
     ]
    }
   ],
   "source": [
    "TRAIN = True\n",
    "continue_training = True\n",
    "nreal = 5\n",
    "\n",
    "real_list = list(range(nreal))\n",
    "\n",
    "ntx_list = [10, 45, 80, 115,150]\n",
    "print(ntx_list)\n",
    "\n",
    "patience = 5\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "smTest_results_real = []\n",
    "dfTest_results_real = []\n",
    "dfTestBal_results_real = []\n",
    "\n",
    "for ntx_i in ntx_list:\n",
    "    print(\"\");print(\"\")\n",
    "    print(\"ntx_i: {}  \".format(ntx_i))\n",
    "    fname_w = 'd006_{:04d}.weights.h5'.format(ntx_i)\n",
    "    tx_train_list= tx_list[0:ntx_i]\n",
    "\n",
    "    dataset = merge_compact_dataset(compact_dataset,capture_date_list,tx_train_list,rx_list, equalized=equalized)\n",
    "    \n",
    "    train_augset,val_augset,test_augset_smRx =  prepare_dataset(dataset,tx_train_list,\n",
    "                                                        val_frac=0.1, test_frac=0.1)\n",
    "    [sig_train,txidNum_train,txid_train,cls_weights] = train_augset\n",
    "    [sig_valid,txidNum_valid,txid_valid,_] = val_augset\n",
    "    [sig_smTest,txidNum_smTest,txid_smTest,cls_weights] = test_augset_smRx\n",
    "\n",
    "    if continue_training:\n",
    "        skip = os.path.isfile(fname_w)\n",
    "    else:\n",
    "        skip = False\n",
    "    classifier = create_net(ntx_i)\n",
    "    if TRAIN and not skip:\n",
    "        filepath = f't_weights_{GPU}_{:04d}.keras'.format(ntx_i)\n",
    "        c=[ keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "          keras.callbacks.EarlyStopping(monitor='val_loss',  patience=patience)]\n",
    "        if isinstance(cls_weights, list):\n",
    "            cls_weights = {i: w for i, w in enumerate(cls_weights)}\n",
    "        history = classifier.fit(sig_train,txid_train,class_weight=cls_weights,\n",
    "                                 validation_data=(sig_valid , txid_valid),callbacks=c, epochs=n_epochs)\n",
    "        classifier.load_weights(filepath)\n",
    "        classifier.save_weights(fname_w)\n",
    "    else:\n",
    "        classifier.load_weights(fname_w)\n",
    "\n",
    "    smTest_r = classifier.evaluate(sig_smTest,txid_smTest,verbose=0)[1]\n",
    "\n",
    "\n",
    "    print(smTest_r)\n",
    "    smTest_results_real.append(smTest_r)\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 45, 80, 115, 150]\n",
      "[0.8134528994560242, 0.7085390686988831, 0.577674150466919, 0.5350282788276672, 0.444996178150177]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ntx_list,smTest_results_real)\n",
    "plt.plot(ntx_list,1/np.array(ntx_list),'--')\n",
    "plt.xlabel('Number of Tx')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Result','Random'])\n",
    "print(ntx_list)\n",
    "print(smTest_results_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MW-RFF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
