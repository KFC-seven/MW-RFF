{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 72 个 .mat 文件\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取与处理数据: 100%|██████████| 72/72 [00:03<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据维度: X=(215928, 288, 2), y=(215928,)\n",
      "类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "\n",
      "===== 随机搜索 1/50 参数: {'model_dim': 32, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 256, 'learning_rate': 0.0005, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 19.62% | 验证集: 19.57% | 测试集: 19.17%\n",
      "[INFO] 新最佳模型已保存到: search_results\\2025-08-20_19-52-56_LTE-V_time_random_SNR10_fd960.00\\best_model.pth\n",
      "\n",
      "===== 随机搜索 2/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 26.56% | 验证集: 26.31% | 测试集: 26.08%\n",
      "[INFO] 新最佳模型已保存到: search_results\\2025-08-20_19-52-56_LTE-V_time_random_SNR10_fd960.00\\best_model.pth\n",
      "\n",
      "===== 随机搜索 3/50 参数: {'model_dim': 32, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 256, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 21.43% | 验证集: 21.15% | 测试集: 20.82%\n",
      "\n",
      "===== 随机搜索 4/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 256, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 19.80% | 验证集: 19.77% | 测试集: 19.39%\n",
      "\n",
      "===== 随机搜索 5/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 16.09% | 验证集: 16.08% | 测试集: 15.95%\n",
      "\n",
      "===== 随机搜索 6/50 参数: {'model_dim': 64, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 21.81% | 验证集: 21.63% | 测试集: 21.14%\n",
      "\n",
      "===== 随机搜索 7/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.73% | 验证集: 12.97% | 测试集: 12.68%\n",
      "\n",
      "===== 随机搜索 8/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.59% | 验证集: 15.54% | 测试集: 15.33%\n",
      "\n",
      "===== 随机搜索 9/50 参数: {'model_dim': 64, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 21.21% | 验证集: 21.25% | 测试集: 20.85%\n",
      "\n",
      "===== 随机搜索 10/50 参数: {'model_dim': 256, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 16.30% | 验证集: 16.43% | 测试集: 16.13%\n",
      "\n",
      "===== 随机搜索 11/50 参数: {'model_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 17.97% | 验证集: 18.05% | 测试集: 17.78%\n",
      "\n",
      "===== 随机搜索 12/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.10% | 验证集: 12.35% | 测试集: 12.09%\n",
      "\n",
      "===== 随机搜索 13/50 参数: {'model_dim': 256, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.33% | 验证集: 15.38% | 测试集: 15.11%\n",
      "\n",
      "===== 随机搜索 14/50 参数: {'model_dim': 64, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.78% | 验证集: 15.61% | 测试集: 15.47%\n",
      "\n",
      "===== 随机搜索 15/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 18.73% | 验证集: 18.78% | 测试集: 18.31%\n",
      "\n",
      "===== 随机搜索 16/50 参数: {'model_dim': 32, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 22.11% | 验证集: 22.06% | 测试集: 21.69%\n",
      "\n",
      "===== 随机搜索 17/50 参数: {'model_dim': 32, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 256, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.51% | 验证集: 12.69% | 测试集: 12.66%\n",
      "\n",
      "===== 随机搜索 18/50 参数: {'model_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 256, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 18.32% | 验证集: 18.31% | 测试集: 18.08%\n",
      "\n",
      "===== 随机搜索 19/50 参数: {'model_dim': 128, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 16.18% | 验证集: 16.06% | 测试集: 15.64%\n",
      "\n",
      "===== 随机搜索 20/50 参数: {'model_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 19.17% | 验证集: 19.19% | 测试集: 18.78%\n",
      "\n",
      "===== 随机搜索 21/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 13.07% | 验证集: 13.19% | 测试集: 13.25%\n",
      "\n",
      "===== 随机搜索 22/50 参数: {'model_dim': 32, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 256, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.93% | 验证集: 13.19% | 测试集: 13.07%\n",
      "\n",
      "===== 随机搜索 23/50 参数: {'model_dim': 64, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 14.80% | 验证集: 14.81% | 测试集: 14.59%\n",
      "\n",
      "===== 随机搜索 24/50 参数: {'model_dim': 64, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 256, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.78% | 验证集: 15.82% | 测试集: 15.66%\n",
      "\n",
      "===== 随机搜索 25/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 256, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 20.24% | 验证集: 20.05% | 测试集: 20.20%\n",
      "\n",
      "===== 随机搜索 26/50 参数: {'model_dim': 32, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 21.57% | 验证集: 21.42% | 测试集: 20.96%\n",
      "\n",
      "===== 随机搜索 27/50 参数: {'model_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 256, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 11.71% | 验证集: 11.71% | 测试集: 11.63%\n",
      "\n",
      "===== 随机搜索 28/50 参数: {'model_dim': 256, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.45% | 验证集: 12.60% | 测试集: 12.41%\n",
      "\n",
      "===== 随机搜索 29/50 参数: {'model_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.3, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 14.92% | 验证集: 14.98% | 测试集: 14.69%\n",
      "\n",
      "===== 随机搜索 30/50 参数: {'model_dim': 256, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 14.93% | 验证集: 14.86% | 测试集: 14.70%\n",
      "\n",
      "===== 随机搜索 31/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.41% | 验证集: 15.44% | 测试集: 15.28%\n",
      "\n",
      "===== 随机搜索 32/50 参数: {'model_dim': 256, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 256, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 13.00% | 验证集: 13.34% | 测试集: 12.88%\n",
      "\n",
      "===== 随机搜索 33/50 参数: {'model_dim': 128, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 14.79% | 验证集: 14.97% | 测试集: 14.58%\n",
      "\n",
      "===== 随机搜索 34/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.1, 'batch_size': 256, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.96% | 验证集: 15.85% | 测试集: 15.65%\n",
      "\n",
      "===== 随机搜索 35/50 参数: {'model_dim': 256, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.97% | 验证集: 15.87% | 测试集: 15.79%\n",
      "\n",
      "===== 随机搜索 36/50 参数: {'model_dim': 64, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 13.60% | 验证集: 13.55% | 测试集: 13.33%\n",
      "\n",
      "===== 随机搜索 37/50 参数: {'model_dim': 32, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 17.70% | 验证集: 17.67% | 测试集: 17.44%\n",
      "\n",
      "===== 随机搜索 38/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 128, 'learning_rate': 0.0001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 25.78% | 验证集: 25.35% | 测试集: 25.12%\n",
      "\n",
      "===== 随机搜索 39/50 参数: {'model_dim': 256, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 256, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.07% | 验证集: 14.97% | 测试集: 14.83%\n",
      "\n",
      "===== 随机搜索 40/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 24.59% | 验证集: 24.05% | 测试集: 24.00%\n",
      "\n",
      "===== 随机搜索 41/50 参数: {'model_dim': 32, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 15.74% | 验证集: 15.59% | 测试集: 15.41%\n",
      "\n",
      "===== 随机搜索 42/50 参数: {'model_dim': 64, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.24% | 验证集: 12.51% | 测试集: 12.45%\n",
      "\n",
      "===== 随机搜索 43/50 参数: {'model_dim': 64, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.67% | 验证集: 12.74% | 测试集: 12.59%\n",
      "\n",
      "===== 随机搜索 44/50 参数: {'model_dim': 256, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.5, 'batch_size': 64, 'learning_rate': 0.0005, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.95% | 验证集: 12.96% | 测试集: 12.68%\n",
      "\n",
      "===== 随机搜索 45/50 参数: {'model_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 128, 'learning_rate': 0.0005, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 23.99% | 验证集: 23.91% | 测试集: 23.48%\n",
      "\n",
      "===== 随机搜索 46/50 参数: {'model_dim': 32, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.57% | 验证集: 12.78% | 测试集: 12.49%\n",
      "\n",
      "===== 随机搜索 47/50 参数: {'model_dim': 32, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 24.76% | 验证集: 24.61% | 测试集: 23.97%\n",
      "\n",
      "===== 随机搜索 48/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 19.28% | 验证集: 19.09% | 测试集: 19.07%\n",
      "\n",
      "===== 随机搜索 49/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.3, 'batch_size': 256, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 12.47% | 验证集: 12.74% | 测试集: 12.55%\n",
      "\n",
      "===== 随机搜索 50/50 参数: {'model_dim': 128, 'num_heads': 2, 'num_layers': 2, 'dropout': 0.5, 'batch_size': 128, 'learning_rate': 0.0005, 'weight_decay': 0.0001, 'num_epochs': 200, 'patience': 5} =====\n",
      "早停触发: 连续 5 轮无提升\n",
      "训练集: 18.53% | 验证集: 18.31% | 测试集: 18.23%\n",
      "[INFO] 所有结果已保存到: search_results\\2025-08-20_19-52-56_LTE-V_time_random_SNR10_fd960.00\\results.txt\n",
      "[INFO] 混淆矩阵已保存到: search_results\\2025-08-20_19-52-56_LTE-V_time_random_SNR10_fd960.00\\best_confusion_matrix.png\n",
      "[INFO] 最佳模型已保存到: search_results\\2025-08-20_19-52-56_LTE-V_time_random_SNR10_fd960.00\\best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "# ================= 数据路径和信号参数 =================\n",
    "data_path = \"E:/rf_datasets/\"\n",
    "SNR_dB = 10\n",
    "fs = 5e6\n",
    "fc = 5.9e9\n",
    "v = 120\n",
    "apply_doppler = False\n",
    "apply_awgn = False\n",
    "\n",
    "# ================= 训练参数 =================\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "batch_size = 256\n",
    "weight_decay = 5e-4\n",
    "\n",
    "# ================= 数据处理函数 =================\n",
    "def compute_doppler_shift(v, fc):\n",
    "    c = 3e8\n",
    "    v = v/3.6 # 转换为m/s\n",
    "    return (v / c) * fc\n",
    "\n",
    "def apply_doppler_shift(signal, fd, fs):\n",
    "    t = np.arange(signal.shape[-1]) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "def add_awgn(signal, snr_db):\n",
    "    signal_power = np.mean(np.abs(signal)**2)\n",
    "    noise_power = signal_power / (10**(snr_db/10))\n",
    "    noise = np.sqrt(noise_power/2) * (np.random.randn(*signal.shape) + 1j*np.random.randn(*signal.shape))\n",
    "    return signal + noise\n",
    "\n",
    "def load_and_preprocess(mat_folder, apply_doppler=False, target_velocity=30, apply_awgn=False, snr_db=20, fs=20e6, fc=2.4e9):\n",
    "    mat_files = glob.glob(os.path.join(mat_folder, '*.mat'))\n",
    "    print(f\"共找到 {len(mat_files)} 个 .mat 文件\")\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    fd = compute_doppler_shift(target_velocity, fc)\n",
    "\n",
    "    for file in tqdm(mat_files, desc='读取与处理数据'):\n",
    "        with h5py.File(file, 'r') as f:\n",
    "            rfDataset = f['rfDataset']\n",
    "            dmrs_struct = rfDataset['dmrs'][:]\n",
    "            dmrs_complex = dmrs_struct['real'] + 1j * dmrs_struct['imag']\n",
    "            txID_uint16 = rfDataset['txID'][:].flatten()\n",
    "            tx_id = ''.join(chr(c) for c in txID_uint16 if c != 0)\n",
    "\n",
    "        processed_signals = []\n",
    "        for sig in dmrs_complex:\n",
    "            if apply_doppler:\n",
    "                sig = apply_doppler_shift(sig, fd, fs)\n",
    "            if apply_awgn:\n",
    "                sig = add_awgn(sig, snr_db)\n",
    "            iq = np.stack((sig.real, sig.imag), axis=-1)\n",
    "            processed_signals.append(iq)\n",
    "\n",
    "        processed_signals = np.array(processed_signals)\n",
    "        X_list.append(processed_signals)\n",
    "        y_list.append(tx_id)\n",
    "\n",
    "    unique_labels = sorted(list(set(y_list)))\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    y_idx = np.array([label_to_idx[lab] for lab in y_list])\n",
    "\n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.repeat(y_idx, dmrs_complex.shape[0])\n",
    "\n",
    "    print(f\"数据维度: X={X_all.shape}, y={y_all.shape}\")\n",
    "    print(f\"类别映射: {label_to_idx}\")\n",
    "    return X_all, y_all, label_to_idx\n",
    "\n",
    "# ================= 模型 =================\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.4):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(raw_input_dim, model_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# ================= 工具函数 =================\n",
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=range(num_classes))\n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def random_search_train(X_all, y_all, label_to_idx, param_grid, n_iter=10, save_dir=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X_tensor = torch.tensor(X_all, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_all, dtype=torch.long)\n",
    "    full_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "    indices = np.arange(len(full_dataset))\n",
    "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
    "        indices, y_all, test_size=0.3, stratify=y_all, random_state=42\n",
    "    )\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx, test_size=0.5, stratify=y_temp, random_state=42\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_params = None\n",
    "    best_model_state = None\n",
    "    best_test_acc = 0\n",
    "    best_cm = None\n",
    "\n",
    "    results_file = os.path.join(save_dir, \"results.txt\")\n",
    "    with open(results_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"数据集路径: {data_path}\\n\")\n",
    "        f.write(\"===== 随机搜索结果 =====\\n\")\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "        print(f\"\\n===== 随机搜索 {i+1}/{n_iter} 参数: {params} =====\")\n",
    "\n",
    "        train_loader = DataLoader(Subset(full_dataset, train_idx), batch_size=params[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(Subset(full_dataset, val_idx), batch_size=params[\"batch_size\"], shuffle=False)\n",
    "        test_loader = DataLoader(Subset(full_dataset, test_idx), batch_size=params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "        model = SignalTransformer(\n",
    "            raw_input_dim=2,\n",
    "            model_dim=params[\"model_dim\"],\n",
    "            num_heads=params[\"num_heads\"],\n",
    "            num_layers=params[\"num_layers\"],\n",
    "            num_classes=len(label_to_idx),\n",
    "            dropout=params[\"dropout\"]\n",
    "        ).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=params[\"weight_decay\"])\n",
    "\n",
    "        best_epoch_val_acc = 0\n",
    "        patience_counter = 0\n",
    "        model_state = None\n",
    "\n",
    "        for epoch in range(params[\"num_epochs\"]):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            val_acc, _ = evaluate_model(model, val_loader, device, len(label_to_idx))\n",
    "            if val_acc > best_epoch_val_acc:\n",
    "                best_epoch_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                model_state = model.state_dict()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= params[\"patience\"]:\n",
    "                    print(f\"早停触发: 连续 {params['patience']} 轮无提升\")\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(model_state)\n",
    "\n",
    "        # 计算训练、验证、测试集准确率\n",
    "        train_acc, _ = evaluate_model(model, train_loader, device, len(label_to_idx))\n",
    "        val_acc, _ = evaluate_model(model, val_loader, device, len(label_to_idx))\n",
    "        test_acc, cm = evaluate_model(model, test_loader, device, len(label_to_idx))\n",
    "\n",
    "        print(f\"训练集: {train_acc:.2f}% | 验证集: {val_acc:.2f}% | 测试集: {test_acc:.2f}%\")\n",
    "\n",
    "        # 保存每轮结果到文件\n",
    "        with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"[组合 {i+1}] {params} | Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Test: {test_acc:.2f}%\\n\")\n",
    "\n",
    "        # 如果是最佳模型，保存状态和混淆矩阵\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params = params\n",
    "            best_model_state = model_state\n",
    "            best_test_acc = test_acc\n",
    "            best_cm = cm\n",
    "\n",
    "            best_model_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "            torch.save(best_model_state, best_model_path)\n",
    "            print(f\"[INFO] 新最佳模型已保存到: {best_model_path}\")\n",
    "\n",
    "    # 保存最佳结果总结\n",
    "    with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n===== 最佳结果 =====\\n\")\n",
    "        f.write(f\"最佳参数: {best_params}\\n\")\n",
    "        f.write(f\"验证集准确率: {best_val_acc:.2f}%\\n\")\n",
    "        f.write(f\"测试集准确率: {best_test_acc:.2f}%\\n\")\n",
    "        f.write(f\"最佳模型路径: {os.path.join(save_dir, 'best_model.pth')}\\n\")\n",
    "\n",
    "    # 保存混淆矩阵\n",
    "    cm_path = os.path.join(save_dir, \"best_confusion_matrix.png\")\n",
    "    plot_confusion_matrix(best_cm, cm_path)\n",
    "\n",
    "    print(f\"[INFO] 所有结果已保存到: {results_file}\")\n",
    "    print(f\"[INFO] 混淆矩阵已保存到: {cm_path}\")\n",
    "    print(f\"[INFO] 最佳模型已保存到: {os.path.join(save_dir, 'best_model.pth')}\")\n",
    "\n",
    "# ================= 主函数 =================\n",
    "if __name__ == \"__main__\":\n",
    "    X_all, y_all, label_to_idx = load_and_preprocess(\n",
    "        data_path,\n",
    "        apply_doppler=apply_doppler,\n",
    "        target_velocity=v,\n",
    "        apply_awgn=apply_awgn,\n",
    "        snr_db=SNR_dB,\n",
    "        fs=fs,\n",
    "        fc=fc\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'model_dim': [32, 64, 128, 256],\n",
    "        'num_heads': [2, 4, 8],\n",
    "        'num_layers': [1, 2],\n",
    "        'dropout': [0.1, 0.3, 0.5],\n",
    "        'batch_size': [64, 128, 256],\n",
    "        'learning_rate': [1e-4, 5e-4, 1e-3],\n",
    "        'weight_decay': [1e-4, 5e-4],\n",
    "        'num_epochs': [200],\n",
    "        'patience': [5]\n",
    "    }\n",
    "\n",
    "    fd = compute_doppler_shift(v, fc)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    script_name = \"LTE-V_time_random\"\n",
    "    folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}_fd{fd:.2f}\"\n",
    "    save_dir = os.path.join(\"search_results\", folder_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    random_search_train(X_all, y_all, label_to_idx, param_grid, n_iter=50, save_dir=save_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
