{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9927a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "开始训练：SNR = 20 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.1235, Train Acc=18.73%, Val Loss=2.4917, Val Acc=20.18%, Grad Norm=6.8947, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=1.7359, Train Acc=35.61%, Val Loss=1.8134, Val Acc=35.43%, Grad Norm=5.9770, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=1.4103, Train Acc=48.25%, Val Loss=1.5063, Val Acc=46.56%, Grad Norm=5.0710, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=1.2311, Train Acc=55.15%, Val Loss=1.3764, Val Acc=51.05%, Grad Norm=4.6532, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=1.1141, Train Acc=59.49%, Val Loss=1.3104, Val Acc=54.31%, Grad Norm=4.3843, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.0447, Train Acc=62.33%, Val Loss=1.3161, Val Acc=56.01%, Grad Norm=4.2066, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=0.9935, Train Acc=64.53%, Val Loss=1.2164, Val Acc=57.81%, Grad Norm=4.1652, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=0.9489, Train Acc=65.99%, Val Loss=1.1793, Val Acc=58.61%, Grad Norm=4.1342, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=0.9145, Train Acc=67.53%, Val Loss=1.1538, Val Acc=59.66%, Grad Norm=4.2915, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=0.8835, Train Acc=68.72%, Val Loss=1.1439, Val Acc=60.06%, Grad Norm=4.3543, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=0.8244, Train Acc=70.99%, Val Loss=1.1367, Val Acc=61.05%, Grad Norm=4.4429, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=0.8009, Train Acc=71.95%, Val Loss=1.1503, Val Acc=61.41%, Grad Norm=4.7434, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=0.7806, Train Acc=72.64%, Val Loss=1.0971, Val Acc=62.25%, Grad Norm=4.9598, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=0.7611, Train Acc=73.44%, Val Loss=1.1424, Val Acc=61.27%, Grad Norm=5.1574, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=0.7383, Train Acc=74.24%, Val Loss=1.1104, Val Acc=62.33%, Grad Norm=5.3588, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=0.7227, Train Acc=74.82%, Val Loss=1.0863, Val Acc=63.48%, Grad Norm=5.5774, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=0.7119, Train Acc=75.30%, Val Loss=1.1067, Val Acc=63.29%, Grad Norm=5.7038, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=0.6884, Train Acc=76.33%, Val Loss=1.0761, Val Acc=63.97%, Grad Norm=5.8775, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=0.6759, Train Acc=76.90%, Val Loss=1.1166, Val Acc=63.77%, Grad Norm=6.0814, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=0.6615, Train Acc=77.11%, Val Loss=1.1095, Val Acc=63.68%, Grad Norm=6.2316, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=0.6243, Train Acc=78.59%, Val Loss=1.0859, Val Acc=64.79%, Grad Norm=6.4533, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=0.6096, Train Acc=79.25%, Val Loss=1.1186, Val Acc=64.61%, Grad Norm=6.7336, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=0.5925, Train Acc=80.01%, Val Loss=1.1191, Val Acc=65.08%, Grad Norm=6.9437, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=0.5817, Train Acc=80.13%, Val Loss=1.1099, Val Acc=64.37%, Grad Norm=7.1446, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=0.5701, Train Acc=80.82%, Val Loss=1.0944, Val Acc=65.24%, Grad Norm=7.3114, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=0.5608, Train Acc=80.92%, Val Loss=1.1105, Val Acc=65.02%, Grad Norm=7.5265, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=0.5516, Train Acc=81.49%, Val Loss=1.0951, Val Acc=65.60%, Grad Norm=7.7182, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=0.5388, Train Acc=81.93%, Val Loss=1.0992, Val Acc=65.60%, Grad Norm=7.9780, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=0.5341, Train Acc=82.07%, Val Loss=1.1011, Val Acc=66.26%, Grad Norm=8.0638, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=0.5198, Train Acc=82.65%, Val Loss=1.1101, Val Acc=65.79%, Grad Norm=8.2814, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=0.4989, Train Acc=83.33%, Val Loss=1.0844, Val Acc=66.29%, Grad Norm=8.3988, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=0.4892, Train Acc=83.54%, Val Loss=1.0983, Val Acc=65.83%, Grad Norm=8.6299, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=0.4793, Train Acc=84.07%, Val Loss=1.1330, Val Acc=65.72%, Grad Norm=8.8319, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=0.4764, Train Acc=84.07%, Val Loss=1.1089, Val Acc=66.27%, Grad Norm=8.9371, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=0.4652, Train Acc=84.55%, Val Loss=1.1281, Val Acc=66.10%, Grad Norm=9.0229, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=0.4686, Train Acc=84.27%, Val Loss=1.1169, Val Acc=65.99%, Grad Norm=9.2050, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=0.4581, Train Acc=84.81%, Val Loss=1.1024, Val Acc=66.15%, Grad Norm=9.2783, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=0.4533, Train Acc=84.82%, Val Loss=1.1154, Val Acc=66.08%, Grad Norm=9.5085, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=0.4474, Train Acc=85.05%, Val Loss=1.1078, Val Acc=66.04%, Grad Norm=9.5581, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=0.4423, Train Acc=85.46%, Val Loss=1.1541, Val Acc=65.71%, Grad Norm=9.7199, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=0.4268, Train Acc=85.89%, Val Loss=1.1288, Val Acc=66.05%, Grad Norm=9.7259, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=0.4250, Train Acc=86.01%, Val Loss=1.1114, Val Acc=66.55%, Grad Norm=9.9487, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=0.4193, Train Acc=86.15%, Val Loss=1.1253, Val Acc=66.66%, Grad Norm=10.0001, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=0.4173, Train Acc=86.05%, Val Loss=1.1320, Val Acc=66.37%, Grad Norm=10.1789, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=0.4174, Train Acc=86.07%, Val Loss=1.1175, Val Acc=66.52%, Grad Norm=10.3203, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=0.4081, Train Acc=86.64%, Val Loss=1.1257, Val Acc=66.70%, Grad Norm=10.3200, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=0.4029, Train Acc=86.94%, Val Loss=1.1327, Val Acc=66.37%, Grad Norm=10.3693, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=0.4058, Train Acc=86.71%, Val Loss=1.1410, Val Acc=66.60%, Grad Norm=10.5361, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=0.3972, Train Acc=87.00%, Val Loss=1.1198, Val Acc=66.55%, Grad Norm=10.5471, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=0.3944, Train Acc=86.98%, Val Loss=1.1307, Val Acc=66.60%, Grad Norm=10.6626, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=0.3865, Train Acc=87.33%, Val Loss=1.1359, Val Acc=66.56%, Grad Norm=10.6790, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=0.3917, Train Acc=87.14%, Val Loss=1.1414, Val Acc=66.29%, Grad Norm=10.8296, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=0.3848, Train Acc=87.37%, Val Loss=1.1277, Val Acc=66.58%, Grad Norm=10.7084, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=0.3821, Train Acc=87.44%, Val Loss=1.1387, Val Acc=66.75%, Grad Norm=10.8652, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=0.3789, Train Acc=87.60%, Val Loss=1.1434, Val Acc=66.56%, Grad Norm=10.8760, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=0.3817, Train Acc=87.46%, Val Loss=1.1383, Val Acc=66.83%, Grad Norm=10.9776, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=0.3768, Train Acc=87.70%, Val Loss=1.1338, Val Acc=66.64%, Grad Norm=11.0676, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=0.3779, Train Acc=87.54%, Val Loss=1.1354, Val Acc=66.54%, Grad Norm=11.1493, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=0.3714, Train Acc=87.90%, Val Loss=1.1506, Val Acc=66.83%, Grad Norm=11.0962, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=0.3724, Train Acc=87.74%, Val Loss=1.1270, Val Acc=66.61%, Grad Norm=11.1570, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=0.3683, Train Acc=88.07%, Val Loss=1.1355, Val Acc=66.70%, Grad Norm=11.1699, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=0.3723, Train Acc=87.87%, Val Loss=1.1405, Val Acc=66.66%, Grad Norm=11.3019, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=0.3695, Train Acc=87.93%, Val Loss=1.1273, Val Acc=66.65%, Grad Norm=11.3057, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=0.3671, Train Acc=87.94%, Val Loss=1.1389, Val Acc=66.83%, Grad Norm=11.2844, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=0.3661, Train Acc=88.05%, Val Loss=1.1360, Val Acc=66.89%, Grad Norm=11.3062, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=0.3601, Train Acc=88.38%, Val Loss=1.1348, Val Acc=66.80%, Grad Norm=11.2479, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=0.3661, Train Acc=87.98%, Val Loss=1.1408, Val Acc=66.52%, Grad Norm=11.4354, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=0.3662, Train Acc=88.03%, Val Loss=1.1457, Val Acc=66.71%, Grad Norm=11.4700, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=0.3613, Train Acc=88.32%, Val Loss=1.1438, Val Acc=66.63%, Grad Norm=11.4045, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=0.3545, Train Acc=88.56%, Val Loss=1.1419, Val Acc=66.56%, Grad Norm=11.3726, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=0.3596, Train Acc=88.32%, Val Loss=1.1389, Val Acc=66.72%, Grad Norm=11.4661, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=0.3621, Train Acc=88.18%, Val Loss=1.1375, Val Acc=66.91%, Grad Norm=11.5334, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=0.3553, Train Acc=88.52%, Val Loss=1.1375, Val Acc=66.67%, Grad Norm=11.4040, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=0.3570, Train Acc=88.25%, Val Loss=1.1418, Val Acc=66.69%, Grad Norm=11.4856, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=0.3497, Train Acc=88.73%, Val Loss=1.1327, Val Acc=66.97%, Grad Norm=11.3294, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=0.3581, Train Acc=88.30%, Val Loss=1.1329, Val Acc=66.86%, Grad Norm=11.5634, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=0.3521, Train Acc=88.62%, Val Loss=1.1345, Val Acc=66.76%, Grad Norm=11.4914, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=0.3583, Train Acc=88.41%, Val Loss=1.1403, Val Acc=66.78%, Grad Norm=11.6174, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=0.3615, Train Acc=88.09%, Val Loss=1.1438, Val Acc=66.81%, Grad Norm=11.6978, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=0.3576, Train Acc=88.28%, Val Loss=1.1453, Val Acc=66.83%, Grad Norm=11.6487, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=0.3486, Train Acc=88.81%, Val Loss=1.1392, Val Acc=66.77%, Grad Norm=11.4999, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=0.3539, Train Acc=88.47%, Val Loss=1.1379, Val Acc=66.79%, Grad Norm=11.5753, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=0.3543, Train Acc=88.39%, Val Loss=1.1340, Val Acc=66.93%, Grad Norm=11.6297, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=0.3529, Train Acc=88.53%, Val Loss=1.1397, Val Acc=66.86%, Grad Norm=11.6434, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=0.3527, Train Acc=88.54%, Val Loss=1.1304, Val Acc=66.94%, Grad Norm=11.5816, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=0.3518, Train Acc=88.67%, Val Loss=1.1401, Val Acc=66.79%, Grad Norm=11.6004, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=0.3542, Train Acc=88.47%, Val Loss=1.1422, Val Acc=66.76%, Grad Norm=11.6907, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=0.3543, Train Acc=88.61%, Val Loss=1.1440, Val Acc=66.86%, Grad Norm=11.6298, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=0.3517, Train Acc=88.61%, Val Loss=1.1464, Val Acc=66.72%, Grad Norm=11.6453, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=0.3477, Train Acc=88.68%, Val Loss=1.1417, Val Acc=66.80%, Grad Norm=11.5749, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=0.3483, Train Acc=88.71%, Val Loss=1.1395, Val Acc=66.90%, Grad Norm=11.5745, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=0.3501, Train Acc=88.66%, Val Loss=1.1461, Val Acc=66.99%, Grad Norm=11.6624, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=0.3504, Train Acc=88.55%, Val Loss=1.1505, Val Acc=66.92%, Grad Norm=11.6638, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=0.3520, Train Acc=88.50%, Val Loss=1.1470, Val Acc=66.63%, Grad Norm=11.6582, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=0.3520, Train Acc=88.46%, Val Loss=1.1443, Val Acc=66.70%, Grad Norm=11.6909, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=0.3539, Train Acc=88.67%, Val Loss=1.1462, Val Acc=66.88%, Grad Norm=11.6474, LR=1.95313e-07\n",
      "Fold 1, Epoch 97: Train Loss=0.3506, Train Acc=88.63%, Val Loss=1.1370, Val Acc=66.90%, Grad Norm=11.6861, LR=1.95313e-07\n",
      "Fold 1, Epoch 98: Train Loss=0.3494, Train Acc=88.58%, Val Loss=1.1525, Val Acc=66.82%, Grad Norm=11.6238, LR=1.95313e-07\n",
      "Fold 1, Epoch 99: Train Loss=0.3498, Train Acc=88.50%, Val Loss=1.1462, Val Acc=66.75%, Grad Norm=11.6929, LR=1.95313e-07\n",
      "Fold 1, Epoch 100: Train Loss=0.3518, Train Acc=88.52%, Val Loss=1.1393, Val Acc=66.68%, Grad Norm=11.6675, LR=1.95313e-07\n",
      "Fold 1, Epoch 101: Train Loss=0.3500, Train Acc=88.65%, Val Loss=1.1405, Val Acc=66.72%, Grad Norm=11.7032, LR=9.76563e-08\n",
      "Fold 1, Epoch 102: Train Loss=0.3523, Train Acc=88.54%, Val Loss=1.1403, Val Acc=66.93%, Grad Norm=11.7380, LR=9.76563e-08\n",
      "Fold 1, Epoch 103: Train Loss=0.3539, Train Acc=88.45%, Val Loss=1.1327, Val Acc=66.93%, Grad Norm=11.7768, LR=9.76563e-08\n",
      "Fold 1, Epoch 104: Train Loss=0.3479, Train Acc=88.78%, Val Loss=1.1421, Val Acc=66.69%, Grad Norm=11.6842, LR=9.76563e-08\n",
      "Fold 1, Epoch 105: Train Loss=0.3472, Train Acc=88.70%, Val Loss=1.1413, Val Acc=66.79%, Grad Norm=11.5760, LR=9.76563e-08\n",
      "Fold 1, Epoch 106: Train Loss=0.3509, Train Acc=88.58%, Val Loss=1.1328, Val Acc=66.94%, Grad Norm=11.7258, LR=9.76563e-08\n",
      "Fold 1, Epoch 107: Train Loss=0.3509, Train Acc=88.65%, Val Loss=1.1421, Val Acc=66.76%, Grad Norm=11.7115, LR=9.76563e-08\n",
      "Fold 1, Epoch 108: Train Loss=0.3502, Train Acc=88.52%, Val Loss=1.1432, Val Acc=67.02%, Grad Norm=11.7506, LR=9.76563e-08\n",
      "Fold 1, Epoch 109: Train Loss=0.3502, Train Acc=88.69%, Val Loss=1.1427, Val Acc=66.79%, Grad Norm=11.6709, LR=9.76563e-08\n",
      "Fold 1, Epoch 110: Train Loss=0.3461, Train Acc=88.79%, Val Loss=1.1435, Val Acc=66.83%, Grad Norm=11.6152, LR=9.76563e-08\n",
      "Fold 1, Epoch 111: Train Loss=0.3489, Train Acc=88.69%, Val Loss=1.1390, Val Acc=66.85%, Grad Norm=11.6700, LR=4.88281e-08\n",
      "Fold 1, Epoch 112: Train Loss=0.3445, Train Acc=88.82%, Val Loss=1.1437, Val Acc=66.70%, Grad Norm=11.6326, LR=4.88281e-08\n",
      "Fold 1, Epoch 113: Train Loss=0.3490, Train Acc=88.75%, Val Loss=1.1432, Val Acc=66.84%, Grad Norm=11.6455, LR=4.88281e-08\n",
      "Fold 1, Epoch 114: Train Loss=0.3509, Train Acc=88.57%, Val Loss=1.1360, Val Acc=66.74%, Grad Norm=11.7749, LR=4.88281e-08\n",
      "Fold 1, Epoch 115: Train Loss=0.3497, Train Acc=88.49%, Val Loss=1.1348, Val Acc=67.05%, Grad Norm=11.6735, LR=4.88281e-08\n",
      "Fold 1, Epoch 116: Train Loss=0.3420, Train Acc=89.03%, Val Loss=1.1460, Val Acc=66.96%, Grad Norm=11.5311, LR=4.88281e-08\n",
      "Fold 1, Epoch 117: Train Loss=0.3459, Train Acc=88.79%, Val Loss=1.1339, Val Acc=66.92%, Grad Norm=11.6863, LR=4.88281e-08\n",
      "Fold 1, Epoch 118: Train Loss=0.3537, Train Acc=88.45%, Val Loss=1.1470, Val Acc=66.77%, Grad Norm=11.8459, LR=4.88281e-08\n",
      "Fold 1, Epoch 119: Train Loss=0.3488, Train Acc=88.69%, Val Loss=1.1358, Val Acc=66.92%, Grad Norm=11.6838, LR=4.88281e-08\n",
      "Fold 1, Epoch 120: Train Loss=0.3489, Train Acc=88.69%, Val Loss=1.1570, Val Acc=66.46%, Grad Norm=11.7005, LR=4.88281e-08\n",
      "Fold 1, Epoch 121: Train Loss=0.3518, Train Acc=88.51%, Val Loss=1.1394, Val Acc=66.96%, Grad Norm=11.7664, LR=2.44141e-08\n",
      "Fold 1, Epoch 122: Train Loss=0.3499, Train Acc=88.54%, Val Loss=1.1516, Val Acc=66.71%, Grad Norm=11.7268, LR=2.44141e-08\n",
      "Fold 1, Epoch 123: Train Loss=0.3475, Train Acc=88.72%, Val Loss=1.1423, Val Acc=66.83%, Grad Norm=11.6073, LR=2.44141e-08\n",
      "Fold 1, Epoch 124: Train Loss=0.3546, Train Acc=88.43%, Val Loss=1.1461, Val Acc=66.77%, Grad Norm=11.8091, LR=2.44141e-08\n",
      "Fold 1, Epoch 125: Train Loss=0.3517, Train Acc=88.51%, Val Loss=1.1418, Val Acc=66.81%, Grad Norm=11.7440, LR=2.44141e-08\n",
      "Fold 1, Epoch 126: Train Loss=0.3529, Train Acc=88.48%, Val Loss=1.1434, Val Acc=66.78%, Grad Norm=11.7673, LR=2.44141e-08\n",
      "Fold 1, Epoch 127: Train Loss=0.3430, Train Acc=88.90%, Val Loss=1.1332, Val Acc=66.88%, Grad Norm=11.5661, LR=2.44141e-08\n",
      "Fold 1, Epoch 128: Train Loss=0.3467, Train Acc=88.78%, Val Loss=1.1455, Val Acc=66.83%, Grad Norm=11.6933, LR=2.44141e-08\n",
      "Fold 1, Epoch 129: Train Loss=0.3495, Train Acc=88.64%, Val Loss=1.1297, Val Acc=66.88%, Grad Norm=11.6904, LR=2.44141e-08\n",
      "Fold 1, Epoch 130: Train Loss=0.3512, Train Acc=88.60%, Val Loss=1.1407, Val Acc=66.88%, Grad Norm=11.7431, LR=2.44141e-08\n",
      "Fold 1, Epoch 131: Train Loss=0.3500, Train Acc=88.56%, Val Loss=1.1464, Val Acc=66.82%, Grad Norm=11.7110, LR=1.2207e-08\n",
      "Fold 1, Epoch 132: Train Loss=0.3490, Train Acc=88.83%, Val Loss=1.1451, Val Acc=66.89%, Grad Norm=11.7179, LR=1.2207e-08\n",
      "Fold 1, Epoch 133: Train Loss=0.3506, Train Acc=88.55%, Val Loss=1.1396, Val Acc=66.90%, Grad Norm=11.7510, LR=1.2207e-08\n",
      "Fold 1, Epoch 134: Train Loss=0.3457, Train Acc=88.73%, Val Loss=1.1409, Val Acc=66.73%, Grad Norm=11.6563, LR=1.2207e-08\n",
      "Fold 1, Epoch 135: Train Loss=0.3475, Train Acc=88.80%, Val Loss=1.1427, Val Acc=66.67%, Grad Norm=11.6662, LR=1.2207e-08\n",
      "Fold 1, Epoch 136: Train Loss=0.3417, Train Acc=88.81%, Val Loss=1.1408, Val Acc=66.88%, Grad Norm=11.5892, LR=1.2207e-08\n",
      "Fold 1, Epoch 137: Train Loss=0.3471, Train Acc=88.61%, Val Loss=1.1402, Val Acc=66.66%, Grad Norm=11.6503, LR=1.2207e-08\n",
      "Fold 1, Epoch 138: Train Loss=0.3470, Train Acc=88.84%, Val Loss=1.1449, Val Acc=66.78%, Grad Norm=11.7174, LR=1.2207e-08\n",
      "Fold 1, Epoch 139: Train Loss=0.3445, Train Acc=88.65%, Val Loss=1.1458, Val Acc=66.77%, Grad Norm=11.6909, LR=1.2207e-08\n",
      "Fold 1, Epoch 140: Train Loss=0.3497, Train Acc=88.55%, Val Loss=1.1402, Val Acc=66.93%, Grad Norm=11.7579, LR=1.2207e-08\n",
      "Fold 1, Epoch 141: Train Loss=0.3476, Train Acc=88.61%, Val Loss=1.1481, Val Acc=66.73%, Grad Norm=11.7236, LR=6.10352e-09\n",
      "Fold 1, Epoch 142: Train Loss=0.3443, Train Acc=88.86%, Val Loss=1.1423, Val Acc=67.09%, Grad Norm=11.6208, LR=6.10352e-09\n",
      "Fold 1, Epoch 143: Train Loss=0.3439, Train Acc=88.94%, Val Loss=1.1375, Val Acc=67.04%, Grad Norm=11.5954, LR=6.10352e-09\n",
      "Fold 1, Epoch 144: Train Loss=0.3473, Train Acc=88.82%, Val Loss=1.1375, Val Acc=66.89%, Grad Norm=11.6820, LR=6.10352e-09\n",
      "Fold 1, Epoch 145: Train Loss=0.3501, Train Acc=88.49%, Val Loss=1.1384, Val Acc=66.85%, Grad Norm=11.7052, LR=6.10352e-09\n",
      "Fold 1, Epoch 146: Train Loss=0.3464, Train Acc=88.84%, Val Loss=1.1482, Val Acc=66.87%, Grad Norm=11.6535, LR=6.10352e-09\n",
      "Fold 1, Epoch 147: Train Loss=0.3524, Train Acc=88.59%, Val Loss=1.1458, Val Acc=67.01%, Grad Norm=11.7518, LR=6.10352e-09\n",
      "Fold 1, Epoch 148: Train Loss=0.3510, Train Acc=88.51%, Val Loss=1.1453, Val Acc=66.89%, Grad Norm=11.7910, LR=6.10352e-09\n",
      "Fold 1, Epoch 149: Train Loss=0.3475, Train Acc=88.76%, Val Loss=1.1468, Val Acc=66.92%, Grad Norm=11.6863, LR=6.10352e-09\n",
      "Fold 1, Epoch 150: Train Loss=0.3462, Train Acc=88.65%, Val Loss=1.1402, Val Acc=66.89%, Grad Norm=11.6923, LR=6.10352e-09\n",
      "Fold 1, Epoch 151: Train Loss=0.3492, Train Acc=88.82%, Val Loss=1.1468, Val Acc=66.69%, Grad Norm=11.7082, LR=3.05176e-09\n",
      "Fold 1, Epoch 152: Train Loss=0.3479, Train Acc=88.61%, Val Loss=1.1434, Val Acc=66.86%, Grad Norm=11.7157, LR=3.05176e-09\n",
      "Fold 1, Epoch 153: Train Loss=0.3481, Train Acc=88.63%, Val Loss=1.1354, Val Acc=66.92%, Grad Norm=11.6916, LR=3.05176e-09\n",
      "Fold 1, Epoch 154: Train Loss=0.3477, Train Acc=88.77%, Val Loss=1.1475, Val Acc=66.64%, Grad Norm=11.6807, LR=3.05176e-09\n",
      "Fold 1, Epoch 155: Train Loss=0.3463, Train Acc=88.72%, Val Loss=1.1463, Val Acc=66.69%, Grad Norm=11.6497, LR=3.05176e-09\n",
      "Fold 1, Epoch 156: Train Loss=0.3469, Train Acc=88.78%, Val Loss=1.1417, Val Acc=66.77%, Grad Norm=11.6723, LR=3.05176e-09\n",
      "Fold 1, Epoch 157: Train Loss=0.3477, Train Acc=88.68%, Val Loss=1.1390, Val Acc=66.98%, Grad Norm=11.7178, LR=3.05176e-09\n",
      "Fold 1, Epoch 158: Train Loss=0.3473, Train Acc=88.73%, Val Loss=1.1451, Val Acc=66.80%, Grad Norm=11.7063, LR=3.05176e-09\n",
      "Fold 1, Epoch 159: Train Loss=0.3486, Train Acc=88.75%, Val Loss=1.1425, Val Acc=66.66%, Grad Norm=11.7059, LR=3.05176e-09\n",
      "Fold 1, Epoch 160: Train Loss=0.3444, Train Acc=88.87%, Val Loss=1.1361, Val Acc=66.94%, Grad Norm=11.6080, LR=3.05176e-09\n",
      "Fold 1, Epoch 161: Train Loss=0.3497, Train Acc=88.66%, Val Loss=1.1530, Val Acc=66.53%, Grad Norm=11.7043, LR=1.52588e-09\n",
      "Fold 1, Epoch 162: Train Loss=0.3482, Train Acc=88.66%, Val Loss=1.1454, Val Acc=66.68%, Grad Norm=11.7237, LR=1.52588e-09\n",
      "Fold 1, Epoch 163: Train Loss=0.3508, Train Acc=88.53%, Val Loss=1.1384, Val Acc=66.68%, Grad Norm=11.7384, LR=1.52588e-09\n",
      "Fold 1, Epoch 164: Train Loss=0.3476, Train Acc=88.83%, Val Loss=1.1417, Val Acc=66.73%, Grad Norm=11.7062, LR=1.52588e-09\n",
      "Fold 1, Epoch 165: Train Loss=0.3511, Train Acc=88.55%, Val Loss=1.1359, Val Acc=66.79%, Grad Norm=11.7215, LR=1.52588e-09\n",
      "Fold 1, Epoch 166: Train Loss=0.3496, Train Acc=88.58%, Val Loss=1.1421, Val Acc=66.90%, Grad Norm=11.7114, LR=1.52588e-09\n",
      "Fold 1, Epoch 167: Train Loss=0.3490, Train Acc=88.62%, Val Loss=1.1410, Val Acc=66.76%, Grad Norm=11.7145, LR=1.52588e-09\n",
      "Fold 1, Epoch 168: Train Loss=0.3480, Train Acc=88.67%, Val Loss=1.1409, Val Acc=66.90%, Grad Norm=11.7134, LR=1.52588e-09\n",
      "Fold 1, Epoch 169: Train Loss=0.3481, Train Acc=88.75%, Val Loss=1.1488, Val Acc=66.72%, Grad Norm=11.6928, LR=1.52588e-09\n",
      "Fold 1, Epoch 170: Train Loss=0.3504, Train Acc=88.70%, Val Loss=1.1446, Val Acc=66.80%, Grad Norm=11.7185, LR=1.52588e-09\n",
      "Fold 1, Epoch 171: Train Loss=0.3515, Train Acc=88.58%, Val Loss=1.1408, Val Acc=66.92%, Grad Norm=11.7856, LR=7.62939e-10\n",
      "Fold 1, Epoch 172: Train Loss=0.3511, Train Acc=88.55%, Val Loss=1.1362, Val Acc=66.95%, Grad Norm=11.7393, LR=7.62939e-10\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=67.09%）\n",
      "Fold 1 DONE | Best Val Acc≈67.09% | Final Val Acc=67.09% | Test Acc=65.35%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.1085, Train Acc=19.03%, Val Loss=3.1727, Val Acc=17.43%, Grad Norm=7.0398, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=1.7138, Train Acc=36.72%, Val Loss=1.9363, Val Acc=38.04%, Grad Norm=5.9251, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=1.3680, Train Acc=49.90%, Val Loss=1.5526, Val Acc=46.57%, Grad Norm=4.9497, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=1.2075, Train Acc=55.83%, Val Loss=1.5655, Val Acc=48.94%, Grad Norm=4.3507, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.1112, Train Acc=59.51%, Val Loss=1.4798, Val Acc=51.64%, Grad Norm=4.2260, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.0486, Train Acc=61.98%, Val Loss=1.3979, Val Acc=53.14%, Grad Norm=4.0997, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=0.9957, Train Acc=64.32%, Val Loss=1.3229, Val Acc=54.55%, Grad Norm=4.0548, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=0.9497, Train Acc=65.89%, Val Loss=1.3964, Val Acc=54.19%, Grad Norm=4.1060, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=0.9156, Train Acc=67.43%, Val Loss=1.3239, Val Acc=56.44%, Grad Norm=4.1748, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=0.8834, Train Acc=68.47%, Val Loss=1.3422, Val Acc=55.95%, Grad Norm=4.2550, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=0.8279, Train Acc=71.08%, Val Loss=1.2708, Val Acc=58.81%, Grad Norm=4.3830, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=0.8124, Train Acc=71.54%, Val Loss=1.2243, Val Acc=59.39%, Grad Norm=4.6601, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=0.7868, Train Acc=72.55%, Val Loss=1.2350, Val Acc=59.30%, Grad Norm=4.8309, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=0.7683, Train Acc=72.99%, Val Loss=1.2324, Val Acc=59.00%, Grad Norm=5.0321, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=0.7592, Train Acc=73.56%, Val Loss=1.2302, Val Acc=58.88%, Grad Norm=5.2729, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=0.7386, Train Acc=74.21%, Val Loss=1.1919, Val Acc=60.55%, Grad Norm=5.4814, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=0.7219, Train Acc=75.18%, Val Loss=1.2215, Val Acc=59.59%, Grad Norm=5.6358, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=0.7017, Train Acc=75.64%, Val Loss=1.1879, Val Acc=60.49%, Grad Norm=5.8605, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=0.6923, Train Acc=76.21%, Val Loss=1.2003, Val Acc=61.04%, Grad Norm=6.0250, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=0.6742, Train Acc=76.88%, Val Loss=1.1479, Val Acc=61.75%, Grad Norm=6.1512, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=0.6359, Train Acc=78.31%, Val Loss=1.1387, Val Acc=62.05%, Grad Norm=6.4622, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=0.6233, Train Acc=78.67%, Val Loss=1.1448, Val Acc=61.97%, Grad Norm=6.7003, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=0.6104, Train Acc=79.28%, Val Loss=1.1570, Val Acc=61.81%, Grad Norm=6.9092, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=0.5977, Train Acc=79.72%, Val Loss=1.1188, Val Acc=62.88%, Grad Norm=7.1477, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=0.5887, Train Acc=79.96%, Val Loss=1.1377, Val Acc=62.71%, Grad Norm=7.3732, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=0.5780, Train Acc=80.37%, Val Loss=1.1430, Val Acc=62.18%, Grad Norm=7.5755, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=0.5666, Train Acc=80.75%, Val Loss=1.1074, Val Acc=63.32%, Grad Norm=7.7917, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=0.5579, Train Acc=81.30%, Val Loss=1.1368, Val Acc=62.47%, Grad Norm=7.9905, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=0.5462, Train Acc=81.60%, Val Loss=1.1304, Val Acc=63.83%, Grad Norm=8.1969, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=0.5378, Train Acc=81.95%, Val Loss=1.1335, Val Acc=62.83%, Grad Norm=8.3354, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=0.5169, Train Acc=82.58%, Val Loss=1.1525, Val Acc=63.17%, Grad Norm=8.5644, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=0.5095, Train Acc=82.75%, Val Loss=1.1222, Val Acc=63.60%, Grad Norm=8.7824, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=0.4911, Train Acc=83.62%, Val Loss=1.1365, Val Acc=63.58%, Grad Norm=8.8990, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=0.4861, Train Acc=83.72%, Val Loss=1.1501, Val Acc=63.88%, Grad Norm=9.0943, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=0.4808, Train Acc=84.09%, Val Loss=1.1244, Val Acc=64.16%, Grad Norm=9.2378, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=0.4768, Train Acc=84.08%, Val Loss=1.1431, Val Acc=63.48%, Grad Norm=9.4521, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=0.4759, Train Acc=84.02%, Val Loss=1.1533, Val Acc=63.45%, Grad Norm=9.5931, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=0.4663, Train Acc=84.59%, Val Loss=1.1179, Val Acc=64.23%, Grad Norm=9.7080, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=0.4599, Train Acc=84.93%, Val Loss=1.1392, Val Acc=64.12%, Grad Norm=9.7708, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=0.4504, Train Acc=85.00%, Val Loss=1.1372, Val Acc=64.28%, Grad Norm=9.9272, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=0.4372, Train Acc=85.59%, Val Loss=1.1576, Val Acc=64.02%, Grad Norm=9.9902, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=0.4360, Train Acc=85.59%, Val Loss=1.1452, Val Acc=63.96%, Grad Norm=10.1528, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=0.4316, Train Acc=85.54%, Val Loss=1.1452, Val Acc=64.15%, Grad Norm=10.2425, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=0.4301, Train Acc=85.77%, Val Loss=1.1510, Val Acc=63.91%, Grad Norm=10.3709, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=0.4263, Train Acc=85.86%, Val Loss=1.1321, Val Acc=64.61%, Grad Norm=10.4438, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=0.4222, Train Acc=86.10%, Val Loss=1.1539, Val Acc=63.96%, Grad Norm=10.5627, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=0.4166, Train Acc=86.27%, Val Loss=1.1211, Val Acc=64.71%, Grad Norm=10.6545, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=0.4146, Train Acc=86.47%, Val Loss=1.1462, Val Acc=64.30%, Grad Norm=10.7779, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=0.4104, Train Acc=86.55%, Val Loss=1.1482, Val Acc=64.44%, Grad Norm=10.8249, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=0.4085, Train Acc=86.66%, Val Loss=1.1542, Val Acc=64.35%, Grad Norm=10.9742, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=0.4033, Train Acc=86.76%, Val Loss=1.1450, Val Acc=64.31%, Grad Norm=10.9571, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=0.3977, Train Acc=86.94%, Val Loss=1.1477, Val Acc=64.28%, Grad Norm=11.0674, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=0.3943, Train Acc=87.06%, Val Loss=1.1438, Val Acc=64.42%, Grad Norm=11.0915, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=0.3924, Train Acc=87.22%, Val Loss=1.1420, Val Acc=64.40%, Grad Norm=11.1134, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=0.3927, Train Acc=87.18%, Val Loss=1.1361, Val Acc=64.46%, Grad Norm=11.2425, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=0.3930, Train Acc=87.21%, Val Loss=1.1373, Val Acc=64.42%, Grad Norm=11.3071, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=0.3879, Train Acc=87.36%, Val Loss=1.1479, Val Acc=64.24%, Grad Norm=11.2558, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=0.3835, Train Acc=87.47%, Val Loss=1.1478, Val Acc=64.26%, Grad Norm=11.3282, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=0.3884, Train Acc=87.35%, Val Loss=1.1528, Val Acc=64.21%, Grad Norm=11.4365, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=0.3819, Train Acc=87.60%, Val Loss=1.1493, Val Acc=64.29%, Grad Norm=11.4618, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=0.3744, Train Acc=87.84%, Val Loss=1.1500, Val Acc=64.31%, Grad Norm=11.4086, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=0.3775, Train Acc=87.66%, Val Loss=1.1548, Val Acc=64.32%, Grad Norm=11.4926, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=0.3809, Train Acc=87.78%, Val Loss=1.1580, Val Acc=64.15%, Grad Norm=11.6002, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=0.3755, Train Acc=87.84%, Val Loss=1.1468, Val Acc=64.48%, Grad Norm=11.5403, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=0.3768, Train Acc=87.92%, Val Loss=1.1519, Val Acc=64.45%, Grad Norm=11.5910, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=0.3770, Train Acc=87.68%, Val Loss=1.1620, Val Acc=64.21%, Grad Norm=11.6481, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=0.3684, Train Acc=88.01%, Val Loss=1.1561, Val Acc=64.33%, Grad Norm=11.5276, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=0.3740, Train Acc=88.07%, Val Loss=1.1511, Val Acc=64.41%, Grad Norm=11.6442, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=0.3730, Train Acc=87.78%, Val Loss=1.1519, Val Acc=64.42%, Grad Norm=11.7255, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=0.3745, Train Acc=87.90%, Val Loss=1.1533, Val Acc=64.34%, Grad Norm=11.8368, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=0.3668, Train Acc=88.15%, Val Loss=1.1545, Val Acc=64.38%, Grad Norm=11.7187, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=0.3712, Train Acc=87.97%, Val Loss=1.1472, Val Acc=64.44%, Grad Norm=11.8109, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=0.3679, Train Acc=88.12%, Val Loss=1.1521, Val Acc=64.23%, Grad Norm=11.7973, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=0.3643, Train Acc=88.04%, Val Loss=1.1583, Val Acc=64.25%, Grad Norm=11.7852, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=0.3659, Train Acc=88.13%, Val Loss=1.1571, Val Acc=64.26%, Grad Norm=11.8418, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=0.3671, Train Acc=88.06%, Val Loss=1.1472, Val Acc=64.54%, Grad Norm=11.8651, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=0.3623, Train Acc=88.20%, Val Loss=1.1599, Val Acc=64.18%, Grad Norm=11.7673, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=64.71%）\n",
      "Fold 2 DONE | Best Val Acc≈64.71% | Final Val Acc=64.71% | Test Acc=62.03%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.1080, Train Acc=18.91%, Val Loss=3.0383, Val Acc=21.20%, Grad Norm=6.8513, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=1.7107, Train Acc=36.02%, Val Loss=1.8941, Val Acc=36.49%, Grad Norm=5.8870, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=1.4140, Train Acc=48.61%, Val Loss=1.5317, Val Acc=46.95%, Grad Norm=5.1579, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=1.2315, Train Acc=55.39%, Val Loss=1.4008, Val Acc=51.56%, Grad Norm=4.5896, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.1219, Train Acc=59.73%, Val Loss=1.3146, Val Acc=53.98%, Grad Norm=4.3121, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.0495, Train Acc=62.52%, Val Loss=1.2726, Val Acc=55.66%, Grad Norm=4.1860, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=0.9993, Train Acc=64.47%, Val Loss=1.2582, Val Acc=55.67%, Grad Norm=4.1531, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=0.9520, Train Acc=66.17%, Val Loss=1.2483, Val Acc=57.17%, Grad Norm=4.1697, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=0.9216, Train Acc=67.39%, Val Loss=1.1870, Val Acc=58.87%, Grad Norm=4.2443, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=0.8879, Train Acc=68.52%, Val Loss=1.2120, Val Acc=58.58%, Grad Norm=4.3584, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=0.8324, Train Acc=70.76%, Val Loss=1.1304, Val Acc=60.28%, Grad Norm=4.4950, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=0.8019, Train Acc=71.94%, Val Loss=1.1509, Val Acc=60.10%, Grad Norm=4.6979, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=0.7826, Train Acc=72.52%, Val Loss=1.1661, Val Acc=60.41%, Grad Norm=4.9786, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=0.7625, Train Acc=73.37%, Val Loss=1.1399, Val Acc=61.46%, Grad Norm=5.1793, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=0.7474, Train Acc=74.05%, Val Loss=1.1472, Val Acc=60.91%, Grad Norm=5.3457, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=0.7270, Train Acc=74.85%, Val Loss=1.1621, Val Acc=61.08%, Grad Norm=5.5647, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=0.7158, Train Acc=75.07%, Val Loss=1.1479, Val Acc=62.08%, Grad Norm=5.8050, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=0.6984, Train Acc=75.79%, Val Loss=1.1439, Val Acc=61.46%, Grad Norm=5.8914, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=0.6819, Train Acc=76.54%, Val Loss=1.1497, Val Acc=61.76%, Grad Norm=6.0937, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=0.6670, Train Acc=77.16%, Val Loss=1.1236, Val Acc=62.92%, Grad Norm=6.2200, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=0.6281, Train Acc=78.29%, Val Loss=1.1075, Val Acc=63.49%, Grad Norm=6.4280, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=0.6126, Train Acc=79.04%, Val Loss=1.1201, Val Acc=63.49%, Grad Norm=6.6929, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=0.5969, Train Acc=79.81%, Val Loss=1.1542, Val Acc=62.79%, Grad Norm=6.9430, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=0.5834, Train Acc=80.20%, Val Loss=1.1247, Val Acc=63.09%, Grad Norm=7.1774, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=0.5743, Train Acc=80.57%, Val Loss=1.1213, Val Acc=63.83%, Grad Norm=7.3867, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=0.5608, Train Acc=80.91%, Val Loss=1.1232, Val Acc=63.35%, Grad Norm=7.5851, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=0.5548, Train Acc=81.10%, Val Loss=1.1235, Val Acc=64.00%, Grad Norm=7.8328, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=0.5411, Train Acc=81.71%, Val Loss=1.1784, Val Acc=62.32%, Grad Norm=7.9679, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=0.5333, Train Acc=81.97%, Val Loss=1.1375, Val Acc=63.56%, Grad Norm=8.2192, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=0.5252, Train Acc=82.27%, Val Loss=1.1388, Val Acc=63.67%, Grad Norm=8.4202, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=0.5065, Train Acc=82.82%, Val Loss=1.1435, Val Acc=64.04%, Grad Norm=8.5310, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=0.4948, Train Acc=83.40%, Val Loss=1.1381, Val Acc=63.71%, Grad Norm=8.6508, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=0.4887, Train Acc=83.65%, Val Loss=1.1380, Val Acc=64.51%, Grad Norm=8.8567, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=0.4764, Train Acc=84.21%, Val Loss=1.1617, Val Acc=64.18%, Grad Norm=9.0867, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=0.4745, Train Acc=84.14%, Val Loss=1.1272, Val Acc=64.59%, Grad Norm=9.2793, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=0.4664, Train Acc=84.30%, Val Loss=1.1604, Val Acc=64.06%, Grad Norm=9.3414, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=0.4632, Train Acc=84.57%, Val Loss=1.1608, Val Acc=64.13%, Grad Norm=9.5549, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=0.4556, Train Acc=84.79%, Val Loss=1.1520, Val Acc=64.21%, Grad Norm=9.6577, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=0.4493, Train Acc=84.96%, Val Loss=1.1683, Val Acc=63.75%, Grad Norm=9.8658, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=0.4434, Train Acc=85.30%, Val Loss=1.1615, Val Acc=64.21%, Grad Norm=9.9548, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=0.4342, Train Acc=85.71%, Val Loss=1.1408, Val Acc=64.83%, Grad Norm=10.0709, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=0.4226, Train Acc=86.05%, Val Loss=1.1744, Val Acc=64.14%, Grad Norm=10.0435, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=0.4209, Train Acc=86.01%, Val Loss=1.1653, Val Acc=63.85%, Grad Norm=10.1639, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=0.4235, Train Acc=86.05%, Val Loss=1.1768, Val Acc=64.04%, Grad Norm=10.3412, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=0.4175, Train Acc=85.97%, Val Loss=1.1625, Val Acc=64.51%, Grad Norm=10.4506, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=0.4070, Train Acc=86.60%, Val Loss=1.1769, Val Acc=63.92%, Grad Norm=10.4104, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=0.4070, Train Acc=86.70%, Val Loss=1.1760, Val Acc=64.27%, Grad Norm=10.6052, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=0.4021, Train Acc=86.85%, Val Loss=1.1653, Val Acc=64.35%, Grad Norm=10.6474, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=0.3989, Train Acc=87.00%, Val Loss=1.1740, Val Acc=64.41%, Grad Norm=10.7513, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=0.3965, Train Acc=86.98%, Val Loss=1.1806, Val Acc=64.32%, Grad Norm=10.8477, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=0.3898, Train Acc=87.24%, Val Loss=1.1577, Val Acc=64.76%, Grad Norm=10.9159, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=0.3840, Train Acc=87.46%, Val Loss=1.1536, Val Acc=64.77%, Grad Norm=10.9157, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=0.3873, Train Acc=87.30%, Val Loss=1.1645, Val Acc=64.94%, Grad Norm=11.0044, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=0.3852, Train Acc=87.12%, Val Loss=1.1682, Val Acc=64.56%, Grad Norm=11.0661, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=0.3811, Train Acc=87.56%, Val Loss=1.1513, Val Acc=64.80%, Grad Norm=11.1212, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=0.3766, Train Acc=87.58%, Val Loss=1.1739, Val Acc=64.51%, Grad Norm=11.1361, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=0.3777, Train Acc=87.74%, Val Loss=1.1730, Val Acc=64.55%, Grad Norm=11.2027, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=0.3753, Train Acc=87.84%, Val Loss=1.1588, Val Acc=64.74%, Grad Norm=11.3172, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=0.3679, Train Acc=87.88%, Val Loss=1.1780, Val Acc=64.55%, Grad Norm=11.3543, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=0.3708, Train Acc=87.99%, Val Loss=1.1591, Val Acc=64.74%, Grad Norm=11.4176, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=0.3700, Train Acc=87.77%, Val Loss=1.1593, Val Acc=64.81%, Grad Norm=11.4417, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=0.3688, Train Acc=87.96%, Val Loss=1.1699, Val Acc=64.57%, Grad Norm=11.4643, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=0.3687, Train Acc=87.89%, Val Loss=1.1715, Val Acc=64.49%, Grad Norm=11.4863, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=0.3675, Train Acc=87.99%, Val Loss=1.1657, Val Acc=64.88%, Grad Norm=11.5406, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=0.3617, Train Acc=88.26%, Val Loss=1.1604, Val Acc=64.89%, Grad Norm=11.4908, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=0.3607, Train Acc=88.31%, Val Loss=1.1814, Val Acc=64.33%, Grad Norm=11.5260, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=0.3642, Train Acc=88.06%, Val Loss=1.1601, Val Acc=64.79%, Grad Norm=11.6360, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=0.3622, Train Acc=88.25%, Val Loss=1.1704, Val Acc=64.65%, Grad Norm=11.6096, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=0.3630, Train Acc=88.13%, Val Loss=1.1797, Val Acc=64.48%, Grad Norm=11.6280, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=0.3643, Train Acc=88.10%, Val Loss=1.1709, Val Acc=64.72%, Grad Norm=11.6970, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=0.3569, Train Acc=88.42%, Val Loss=1.1689, Val Acc=64.77%, Grad Norm=11.5859, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=0.3624, Train Acc=88.19%, Val Loss=1.1661, Val Acc=64.85%, Grad Norm=11.7187, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=0.3599, Train Acc=88.34%, Val Loss=1.1744, Val Acc=64.59%, Grad Norm=11.6618, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=0.3566, Train Acc=88.44%, Val Loss=1.1733, Val Acc=64.73%, Grad Norm=11.6596, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=0.3584, Train Acc=88.26%, Val Loss=1.1750, Val Acc=64.75%, Grad Norm=11.7187, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=0.3548, Train Acc=88.37%, Val Loss=1.1741, Val Acc=64.62%, Grad Norm=11.6742, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=0.3532, Train Acc=88.57%, Val Loss=1.1615, Val Acc=64.83%, Grad Norm=11.6503, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=0.3525, Train Acc=88.65%, Val Loss=1.1811, Val Acc=64.53%, Grad Norm=11.6835, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=0.3567, Train Acc=88.46%, Val Loss=1.1736, Val Acc=64.90%, Grad Norm=11.7547, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=0.3521, Train Acc=88.59%, Val Loss=1.1817, Val Acc=64.53%, Grad Norm=11.7386, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=0.3543, Train Acc=88.72%, Val Loss=1.1723, Val Acc=64.66%, Grad Norm=11.7679, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=0.3530, Train Acc=88.68%, Val Loss=1.1827, Val Acc=64.48%, Grad Norm=11.7370, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=0.3540, Train Acc=88.55%, Val Loss=1.1902, Val Acc=64.48%, Grad Norm=11.7937, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=64.94%）\n",
      "Fold 3 DONE | Best Val Acc≈64.94% | Final Val Acc=64.94% | Test Acc=62.75%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.0941, Train Acc=20.09%, Val Loss=2.2837, Val Acc=23.88%, Grad Norm=6.6886, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=1.6630, Train Acc=38.24%, Val Loss=1.7382, Val Acc=39.65%, Grad Norm=5.6151, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=1.3425, Train Acc=50.91%, Val Loss=1.4453, Val Acc=50.36%, Grad Norm=4.6644, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.1817, Train Acc=57.07%, Val Loss=1.3547, Val Acc=53.65%, Grad Norm=4.3037, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.0939, Train Acc=60.51%, Val Loss=1.2145, Val Acc=57.74%, Grad Norm=4.1296, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.0273, Train Acc=63.29%, Val Loss=1.2196, Val Acc=58.21%, Grad Norm=4.0760, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=0.9706, Train Acc=65.52%, Val Loss=1.1885, Val Acc=59.65%, Grad Norm=4.0723, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=0.9305, Train Acc=67.06%, Val Loss=1.1710, Val Acc=60.05%, Grad Norm=4.1023, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=0.9008, Train Acc=68.19%, Val Loss=1.1183, Val Acc=61.46%, Grad Norm=4.2280, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=0.8686, Train Acc=69.55%, Val Loss=1.1149, Val Acc=63.54%, Grad Norm=4.3201, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=0.8052, Train Acc=71.82%, Val Loss=1.0766, Val Acc=62.90%, Grad Norm=4.5383, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=0.7826, Train Acc=72.69%, Val Loss=1.0763, Val Acc=62.56%, Grad Norm=4.8310, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=0.7630, Train Acc=73.27%, Val Loss=1.0586, Val Acc=63.92%, Grad Norm=5.0336, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=0.7401, Train Acc=74.32%, Val Loss=1.0460, Val Acc=63.48%, Grad Norm=5.3048, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=0.7238, Train Acc=75.14%, Val Loss=1.0563, Val Acc=63.44%, Grad Norm=5.6034, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=0.7084, Train Acc=75.45%, Val Loss=1.0614, Val Acc=64.14%, Grad Norm=5.8658, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=0.6906, Train Acc=76.12%, Val Loss=1.0461, Val Acc=64.54%, Grad Norm=6.0042, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=0.6736, Train Acc=76.79%, Val Loss=1.0359, Val Acc=64.89%, Grad Norm=6.2526, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=0.6583, Train Acc=77.36%, Val Loss=1.0409, Val Acc=64.68%, Grad Norm=6.5107, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=0.6407, Train Acc=78.23%, Val Loss=1.0861, Val Acc=64.52%, Grad Norm=6.6490, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=0.6000, Train Acc=79.69%, Val Loss=0.9839, Val Acc=67.15%, Grad Norm=6.8400, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=0.5848, Train Acc=80.13%, Val Loss=1.0031, Val Acc=66.46%, Grad Norm=7.2550, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=0.5686, Train Acc=80.81%, Val Loss=0.9882, Val Acc=66.92%, Grad Norm=7.4692, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=0.5611, Train Acc=80.95%, Val Loss=1.0360, Val Acc=66.29%, Grad Norm=7.7237, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=0.5477, Train Acc=81.54%, Val Loss=1.0262, Val Acc=65.89%, Grad Norm=8.0119, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=0.5360, Train Acc=81.94%, Val Loss=1.0194, Val Acc=66.53%, Grad Norm=8.2217, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=0.5291, Train Acc=82.14%, Val Loss=1.0303, Val Acc=67.00%, Grad Norm=8.3914, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=0.5197, Train Acc=82.43%, Val Loss=1.0474, Val Acc=66.66%, Grad Norm=8.5912, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=0.5038, Train Acc=83.18%, Val Loss=0.9932, Val Acc=67.12%, Grad Norm=8.8327, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=0.5023, Train Acc=83.21%, Val Loss=1.0280, Val Acc=67.49%, Grad Norm=9.0379, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=0.4735, Train Acc=84.21%, Val Loss=1.0061, Val Acc=68.20%, Grad Norm=9.1416, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=0.4647, Train Acc=84.65%, Val Loss=1.0285, Val Acc=67.78%, Grad Norm=9.3401, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=0.4502, Train Acc=85.00%, Val Loss=1.0089, Val Acc=67.74%, Grad Norm=9.5218, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=0.4492, Train Acc=85.06%, Val Loss=1.0082, Val Acc=67.25%, Grad Norm=9.7221, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=0.4459, Train Acc=85.25%, Val Loss=1.0159, Val Acc=68.03%, Grad Norm=9.9380, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=0.4381, Train Acc=85.53%, Val Loss=1.0187, Val Acc=67.88%, Grad Norm=10.1083, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=0.4289, Train Acc=85.73%, Val Loss=1.0387, Val Acc=67.12%, Grad Norm=10.2561, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=0.4208, Train Acc=86.09%, Val Loss=1.0334, Val Acc=67.78%, Grad Norm=10.4020, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=0.4157, Train Acc=86.32%, Val Loss=1.0415, Val Acc=67.81%, Grad Norm=10.5545, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=0.4160, Train Acc=86.24%, Val Loss=1.0281, Val Acc=67.70%, Grad Norm=10.7066, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=0.3973, Train Acc=86.87%, Val Loss=1.0222, Val Acc=67.94%, Grad Norm=10.7564, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=0.3909, Train Acc=87.14%, Val Loss=1.0316, Val Acc=68.15%, Grad Norm=10.8769, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=0.3888, Train Acc=87.34%, Val Loss=1.0314, Val Acc=67.62%, Grad Norm=10.9510, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=0.3818, Train Acc=87.54%, Val Loss=1.0546, Val Acc=67.40%, Grad Norm=11.0561, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=0.3840, Train Acc=87.39%, Val Loss=1.0347, Val Acc=68.22%, Grad Norm=11.1926, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=0.3796, Train Acc=87.71%, Val Loss=1.0654, Val Acc=67.76%, Grad Norm=11.2583, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=0.3713, Train Acc=87.93%, Val Loss=1.0589, Val Acc=67.82%, Grad Norm=11.3230, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=0.3683, Train Acc=88.12%, Val Loss=1.0450, Val Acc=67.88%, Grad Norm=11.4387, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=0.3681, Train Acc=88.01%, Val Loss=1.0454, Val Acc=67.87%, Grad Norm=11.5617, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=0.3601, Train Acc=88.25%, Val Loss=1.0505, Val Acc=68.06%, Grad Norm=11.6482, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=0.3535, Train Acc=88.49%, Val Loss=1.0591, Val Acc=68.11%, Grad Norm=11.6680, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=0.3538, Train Acc=88.47%, Val Loss=1.0599, Val Acc=67.60%, Grad Norm=11.7729, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=0.3509, Train Acc=88.63%, Val Loss=1.0625, Val Acc=67.68%, Grad Norm=11.7942, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=0.3485, Train Acc=88.73%, Val Loss=1.0509, Val Acc=67.99%, Grad Norm=11.8129, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=0.3524, Train Acc=88.42%, Val Loss=1.0619, Val Acc=67.95%, Grad Norm=11.9786, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=0.3472, Train Acc=88.83%, Val Loss=1.0630, Val Acc=67.90%, Grad Norm=12.0162, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=0.3452, Train Acc=88.74%, Val Loss=1.0683, Val Acc=67.73%, Grad Norm=12.0404, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=0.3432, Train Acc=88.91%, Val Loss=1.0667, Val Acc=68.00%, Grad Norm=12.1531, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=0.3405, Train Acc=89.01%, Val Loss=1.0665, Val Acc=67.82%, Grad Norm=12.1695, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=0.3394, Train Acc=89.01%, Val Loss=1.0785, Val Acc=67.77%, Grad Norm=12.1661, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=0.3334, Train Acc=89.14%, Val Loss=1.0653, Val Acc=67.92%, Grad Norm=12.1813, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=0.3331, Train Acc=89.19%, Val Loss=1.0649, Val Acc=67.89%, Grad Norm=12.2299, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=0.3346, Train Acc=89.13%, Val Loss=1.0560, Val Acc=68.16%, Grad Norm=12.3417, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=0.3359, Train Acc=89.08%, Val Loss=1.0804, Val Acc=67.59%, Grad Norm=12.3869, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=0.3321, Train Acc=89.18%, Val Loss=1.0599, Val Acc=68.00%, Grad Norm=12.3640, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=0.3315, Train Acc=89.37%, Val Loss=1.0716, Val Acc=67.93%, Grad Norm=12.3795, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=0.3309, Train Acc=89.29%, Val Loss=1.0724, Val Acc=67.90%, Grad Norm=12.4716, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=0.3274, Train Acc=89.36%, Val Loss=1.0660, Val Acc=67.95%, Grad Norm=12.3532, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=0.3289, Train Acc=89.31%, Val Loss=1.0596, Val Acc=68.25%, Grad Norm=12.4817, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=0.3288, Train Acc=89.28%, Val Loss=1.0649, Val Acc=67.87%, Grad Norm=12.4879, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=0.3306, Train Acc=89.32%, Val Loss=1.0733, Val Acc=67.74%, Grad Norm=12.6133, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=0.3277, Train Acc=89.49%, Val Loss=1.0722, Val Acc=67.82%, Grad Norm=12.5909, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=0.3203, Train Acc=89.65%, Val Loss=1.0721, Val Acc=67.89%, Grad Norm=12.4970, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=0.3214, Train Acc=89.84%, Val Loss=1.0721, Val Acc=67.91%, Grad Norm=12.4855, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=0.3202, Train Acc=89.78%, Val Loss=1.0759, Val Acc=67.89%, Grad Norm=12.4955, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=0.3234, Train Acc=89.53%, Val Loss=1.0621, Val Acc=67.78%, Grad Norm=12.5673, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=0.3220, Train Acc=89.65%, Val Loss=1.0672, Val Acc=68.07%, Grad Norm=12.6049, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=0.3240, Train Acc=89.55%, Val Loss=1.0701, Val Acc=67.76%, Grad Norm=12.6362, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=0.3177, Train Acc=89.88%, Val Loss=1.0712, Val Acc=67.82%, Grad Norm=12.5522, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=0.3176, Train Acc=89.90%, Val Loss=1.0680, Val Acc=68.03%, Grad Norm=12.5391, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=0.3240, Train Acc=89.46%, Val Loss=1.0665, Val Acc=67.83%, Grad Norm=12.7369, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=0.3166, Train Acc=89.96%, Val Loss=1.0688, Val Acc=67.85%, Grad Norm=12.6020, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=0.3198, Train Acc=89.71%, Val Loss=1.0628, Val Acc=68.07%, Grad Norm=12.6463, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=0.3174, Train Acc=89.78%, Val Loss=1.0728, Val Acc=67.52%, Grad Norm=12.6348, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=0.3158, Train Acc=90.01%, Val Loss=1.0742, Val Acc=67.89%, Grad Norm=12.6143, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=0.3140, Train Acc=89.96%, Val Loss=1.0735, Val Acc=67.88%, Grad Norm=12.5611, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=0.3169, Train Acc=89.87%, Val Loss=1.0722, Val Acc=67.96%, Grad Norm=12.7115, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=0.3188, Train Acc=89.76%, Val Loss=1.0740, Val Acc=67.91%, Grad Norm=12.7357, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=0.3204, Train Acc=89.70%, Val Loss=1.0691, Val Acc=67.87%, Grad Norm=12.7690, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=0.3194, Train Acc=89.68%, Val Loss=1.0713, Val Acc=68.10%, Grad Norm=12.7480, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=0.3175, Train Acc=89.66%, Val Loss=1.0670, Val Acc=67.94%, Grad Norm=12.7197, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=0.3157, Train Acc=89.74%, Val Loss=1.0680, Val Acc=67.98%, Grad Norm=12.6947, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=0.3150, Train Acc=89.81%, Val Loss=1.0723, Val Acc=67.70%, Grad Norm=12.6804, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=0.3162, Train Acc=89.83%, Val Loss=1.0802, Val Acc=67.77%, Grad Norm=12.7085, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=0.3153, Train Acc=89.85%, Val Loss=1.0732, Val Acc=68.01%, Grad Norm=12.7013, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=0.3144, Train Acc=89.92%, Val Loss=1.0720, Val Acc=67.77%, Grad Norm=12.7074, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=0.3141, Train Acc=89.98%, Val Loss=1.0700, Val Acc=67.91%, Grad Norm=12.7199, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=0.3142, Train Acc=90.04%, Val Loss=1.0823, Val Acc=67.81%, Grad Norm=12.6869, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=0.3149, Train Acc=89.89%, Val Loss=1.0684, Val Acc=67.82%, Grad Norm=12.7337, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=68.25%）\n",
      "Fold 4 DONE | Best Val Acc≈68.25% | Final Val Acc=68.25% | Test Acc=65.75%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.0845, Train Acc=20.79%, Val Loss=2.8558, Val Acc=21.91%, Grad Norm=7.1048, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=1.6282, Train Acc=39.58%, Val Loss=1.9696, Val Acc=36.15%, Grad Norm=5.5227, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=1.3164, Train Acc=51.90%, Val Loss=1.6840, Val Acc=44.88%, Grad Norm=4.6223, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=1.1586, Train Acc=58.01%, Val Loss=1.6451, Val Acc=50.24%, Grad Norm=4.3419, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.0679, Train Acc=61.68%, Val Loss=1.5711, Val Acc=51.71%, Grad Norm=4.0893, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.0107, Train Acc=63.97%, Val Loss=1.5720, Val Acc=53.18%, Grad Norm=4.0829, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=0.9573, Train Acc=65.79%, Val Loss=1.4417, Val Acc=55.34%, Grad Norm=4.0523, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=0.9191, Train Acc=67.34%, Val Loss=1.5531, Val Acc=53.01%, Grad Norm=4.1022, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=0.8916, Train Acc=68.36%, Val Loss=1.3540, Val Acc=55.35%, Grad Norm=4.1540, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=0.8597, Train Acc=69.65%, Val Loss=1.3781, Val Acc=56.03%, Grad Norm=4.2898, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=0.7937, Train Acc=72.05%, Val Loss=1.3384, Val Acc=57.22%, Grad Norm=4.4895, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=0.7700, Train Acc=73.17%, Val Loss=1.3430, Val Acc=57.12%, Grad Norm=4.8344, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=0.7478, Train Acc=73.96%, Val Loss=1.3142, Val Acc=57.24%, Grad Norm=5.0541, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=0.7312, Train Acc=74.64%, Val Loss=1.3116, Val Acc=57.78%, Grad Norm=5.4184, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=0.7149, Train Acc=75.13%, Val Loss=1.3178, Val Acc=56.78%, Grad Norm=5.5712, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=0.6937, Train Acc=76.11%, Val Loss=1.3013, Val Acc=58.28%, Grad Norm=5.8050, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=0.6818, Train Acc=76.61%, Val Loss=1.3026, Val Acc=59.08%, Grad Norm=6.0080, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=0.6627, Train Acc=77.23%, Val Loss=1.3276, Val Acc=59.46%, Grad Norm=6.1472, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=0.6491, Train Acc=77.81%, Val Loss=1.2766, Val Acc=58.56%, Grad Norm=6.4518, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=0.6281, Train Acc=78.47%, Val Loss=1.2641, Val Acc=59.97%, Grad Norm=6.6278, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=0.5890, Train Acc=80.00%, Val Loss=1.2581, Val Acc=60.15%, Grad Norm=6.9004, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=0.5732, Train Acc=80.66%, Val Loss=1.2562, Val Acc=59.96%, Grad Norm=7.0810, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=0.5564, Train Acc=81.16%, Val Loss=1.2325, Val Acc=61.46%, Grad Norm=7.3846, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=0.5441, Train Acc=81.49%, Val Loss=1.2420, Val Acc=60.90%, Grad Norm=7.5335, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=0.5381, Train Acc=81.89%, Val Loss=1.2438, Val Acc=60.99%, Grad Norm=7.7632, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=0.5336, Train Acc=82.07%, Val Loss=1.2372, Val Acc=60.93%, Grad Norm=7.9965, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=0.5161, Train Acc=82.69%, Val Loss=1.2487, Val Acc=60.46%, Grad Norm=8.2001, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=0.5085, Train Acc=82.84%, Val Loss=1.2510, Val Acc=60.81%, Grad Norm=8.3999, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=0.5024, Train Acc=83.12%, Val Loss=1.2855, Val Acc=61.09%, Grad Norm=8.5860, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=0.4931, Train Acc=83.36%, Val Loss=1.2965, Val Acc=60.33%, Grad Norm=8.7958, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=0.4700, Train Acc=84.28%, Val Loss=1.2296, Val Acc=61.87%, Grad Norm=8.9286, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=0.4589, Train Acc=84.69%, Val Loss=1.2202, Val Acc=62.41%, Grad Norm=9.0741, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=0.4477, Train Acc=85.09%, Val Loss=1.2478, Val Acc=62.13%, Grad Norm=9.3068, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=0.4444, Train Acc=85.21%, Val Loss=1.2720, Val Acc=61.51%, Grad Norm=9.5204, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=0.4412, Train Acc=85.29%, Val Loss=1.2326, Val Acc=62.37%, Grad Norm=9.6643, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=0.4299, Train Acc=85.74%, Val Loss=1.2295, Val Acc=61.93%, Grad Norm=9.8230, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=0.4252, Train Acc=85.81%, Val Loss=1.2295, Val Acc=62.54%, Grad Norm=9.9866, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=0.4179, Train Acc=86.18%, Val Loss=1.2497, Val Acc=61.76%, Grad Norm=10.0912, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=0.4159, Train Acc=86.30%, Val Loss=1.2373, Val Acc=62.43%, Grad Norm=10.2397, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=0.4096, Train Acc=86.55%, Val Loss=1.2627, Val Acc=61.45%, Grad Norm=10.3858, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=0.3964, Train Acc=86.88%, Val Loss=1.2487, Val Acc=62.17%, Grad Norm=10.5086, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=0.3931, Train Acc=87.08%, Val Loss=1.2387, Val Acc=62.47%, Grad Norm=10.6344, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=0.3856, Train Acc=87.17%, Val Loss=1.2313, Val Acc=62.94%, Grad Norm=10.7117, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=0.3873, Train Acc=87.24%, Val Loss=1.2330, Val Acc=62.65%, Grad Norm=10.8127, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=0.3812, Train Acc=87.47%, Val Loss=1.2233, Val Acc=63.28%, Grad Norm=10.9167, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=0.3775, Train Acc=87.47%, Val Loss=1.2145, Val Acc=63.01%, Grad Norm=10.9920, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=0.3737, Train Acc=87.58%, Val Loss=1.2351, Val Acc=62.53%, Grad Norm=11.1752, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=0.3716, Train Acc=88.01%, Val Loss=1.2366, Val Acc=63.02%, Grad Norm=11.2662, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=0.3654, Train Acc=87.94%, Val Loss=1.2342, Val Acc=62.80%, Grad Norm=11.3024, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=0.3657, Train Acc=87.80%, Val Loss=1.2495, Val Acc=62.46%, Grad Norm=11.4571, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=0.3596, Train Acc=88.27%, Val Loss=1.2370, Val Acc=62.65%, Grad Norm=11.4837, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=0.3527, Train Acc=88.44%, Val Loss=1.2386, Val Acc=62.78%, Grad Norm=11.4439, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=0.3503, Train Acc=88.56%, Val Loss=1.2502, Val Acc=62.85%, Grad Norm=11.5096, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=0.3514, Train Acc=88.51%, Val Loss=1.2235, Val Acc=63.15%, Grad Norm=11.6895, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=0.3508, Train Acc=88.51%, Val Loss=1.2529, Val Acc=62.86%, Grad Norm=11.6806, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=0.3474, Train Acc=88.63%, Val Loss=1.2399, Val Acc=62.64%, Grad Norm=11.7016, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=0.3461, Train Acc=88.66%, Val Loss=1.2516, Val Acc=62.82%, Grad Norm=11.7960, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=0.3453, Train Acc=88.77%, Val Loss=1.2379, Val Acc=63.20%, Grad Norm=11.8684, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=0.3441, Train Acc=88.71%, Val Loss=1.2610, Val Acc=62.85%, Grad Norm=11.8903, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=0.3416, Train Acc=88.90%, Val Loss=1.2369, Val Acc=62.96%, Grad Norm=11.9869, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=0.3402, Train Acc=88.99%, Val Loss=1.2482, Val Acc=62.77%, Grad Norm=11.9846, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=0.3379, Train Acc=88.94%, Val Loss=1.2289, Val Acc=62.97%, Grad Norm=12.0202, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=0.3349, Train Acc=89.02%, Val Loss=1.2416, Val Acc=62.84%, Grad Norm=12.0708, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=0.3324, Train Acc=89.27%, Val Loss=1.2408, Val Acc=63.31%, Grad Norm=12.0147, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=0.3339, Train Acc=89.17%, Val Loss=1.2432, Val Acc=62.80%, Grad Norm=12.0754, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=0.3335, Train Acc=89.25%, Val Loss=1.2403, Val Acc=63.05%, Grad Norm=12.0837, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=0.3265, Train Acc=89.40%, Val Loss=1.2417, Val Acc=63.02%, Grad Norm=12.0302, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=0.3323, Train Acc=89.14%, Val Loss=1.2420, Val Acc=63.15%, Grad Norm=12.2547, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=0.3280, Train Acc=89.36%, Val Loss=1.2461, Val Acc=62.92%, Grad Norm=12.1787, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=0.3263, Train Acc=89.41%, Val Loss=1.2388, Val Acc=63.22%, Grad Norm=12.1468, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=0.3265, Train Acc=89.42%, Val Loss=1.2465, Val Acc=63.05%, Grad Norm=12.2972, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=0.3244, Train Acc=89.45%, Val Loss=1.2525, Val Acc=63.02%, Grad Norm=12.2640, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=0.3286, Train Acc=89.22%, Val Loss=1.2505, Val Acc=62.87%, Grad Norm=12.3505, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=0.3214, Train Acc=89.47%, Val Loss=1.2313, Val Acc=63.08%, Grad Norm=12.2453, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=0.3263, Train Acc=89.42%, Val Loss=1.2468, Val Acc=62.81%, Grad Norm=12.3925, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=0.3271, Train Acc=89.39%, Val Loss=1.2388, Val Acc=62.94%, Grad Norm=12.3894, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=0.3208, Train Acc=89.59%, Val Loss=1.2499, Val Acc=63.02%, Grad Norm=12.2920, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=0.3222, Train Acc=89.65%, Val Loss=1.2390, Val Acc=63.21%, Grad Norm=12.3518, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=0.3185, Train Acc=89.72%, Val Loss=1.2485, Val Acc=62.90%, Grad Norm=12.3440, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=0.3255, Train Acc=89.45%, Val Loss=1.2427, Val Acc=63.05%, Grad Norm=12.4337, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=0.3192, Train Acc=89.64%, Val Loss=1.2428, Val Acc=63.02%, Grad Norm=12.3843, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=0.3204, Train Acc=89.77%, Val Loss=1.2352, Val Acc=63.31%, Grad Norm=12.3558, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=0.3192, Train Acc=89.78%, Val Loss=1.2299, Val Acc=63.58%, Grad Norm=12.3239, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=0.3195, Train Acc=89.70%, Val Loss=1.2439, Val Acc=62.83%, Grad Norm=12.3736, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=0.3209, Train Acc=89.71%, Val Loss=1.2450, Val Acc=63.08%, Grad Norm=12.4439, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=0.3209, Train Acc=89.49%, Val Loss=1.2408, Val Acc=63.02%, Grad Norm=12.4701, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=0.3202, Train Acc=89.69%, Val Loss=1.2370, Val Acc=63.14%, Grad Norm=12.4791, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=0.3202, Train Acc=89.62%, Val Loss=1.2609, Val Acc=62.97%, Grad Norm=12.4521, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=0.3159, Train Acc=89.76%, Val Loss=1.2547, Val Acc=62.78%, Grad Norm=12.3914, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=0.3224, Train Acc=89.60%, Val Loss=1.2227, Val Acc=63.32%, Grad Norm=12.5292, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=0.3174, Train Acc=89.88%, Val Loss=1.2385, Val Acc=63.45%, Grad Norm=12.4197, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=0.3200, Train Acc=89.70%, Val Loss=1.2373, Val Acc=63.21%, Grad Norm=12.4906, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=0.3161, Train Acc=89.87%, Val Loss=1.2283, Val Acc=63.43%, Grad Norm=12.4349, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=0.3200, Train Acc=89.66%, Val Loss=1.2324, Val Acc=63.34%, Grad Norm=12.5035, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=0.3167, Train Acc=89.77%, Val Loss=1.2344, Val Acc=63.43%, Grad Norm=12.4291, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=0.3193, Train Acc=89.79%, Val Loss=1.2397, Val Acc=63.08%, Grad Norm=12.4635, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=0.3161, Train Acc=89.85%, Val Loss=1.2534, Val Acc=63.09%, Grad Norm=12.4749, LR=1.95313e-07\n",
      "Fold 5, Epoch 98: Train Loss=0.3160, Train Acc=89.79%, Val Loss=1.2540, Val Acc=63.09%, Grad Norm=12.4401, LR=1.95313e-07\n",
      "Fold 5, Epoch 99: Train Loss=0.3177, Train Acc=89.80%, Val Loss=1.2457, Val Acc=62.99%, Grad Norm=12.4711, LR=1.95313e-07\n",
      "Fold 5, Epoch 100: Train Loss=0.3153, Train Acc=89.90%, Val Loss=1.2448, Val Acc=63.04%, Grad Norm=12.4370, LR=1.95313e-07\n",
      "Fold 5, Epoch 101: Train Loss=0.3185, Train Acc=89.82%, Val Loss=1.2458, Val Acc=63.00%, Grad Norm=12.5127, LR=9.76563e-08\n",
      "Fold 5, Epoch 102: Train Loss=0.3168, Train Acc=89.75%, Val Loss=1.2344, Val Acc=63.40%, Grad Norm=12.5024, LR=9.76563e-08\n",
      "Fold 5, Epoch 103: Train Loss=0.3146, Train Acc=89.98%, Val Loss=1.2381, Val Acc=63.19%, Grad Norm=12.4954, LR=9.76563e-08\n",
      "Fold 5, Epoch 104: Train Loss=0.3173, Train Acc=89.73%, Val Loss=1.2421, Val Acc=63.34%, Grad Norm=12.4970, LR=9.76563e-08\n",
      "Fold 5, Epoch 105: Train Loss=0.3171, Train Acc=89.72%, Val Loss=1.2536, Val Acc=63.06%, Grad Norm=12.5258, LR=9.76563e-08\n",
      "Fold 5, Epoch 106: Train Loss=0.3169, Train Acc=89.68%, Val Loss=1.2379, Val Acc=63.34%, Grad Norm=12.5192, LR=9.76563e-08\n",
      "Fold 5, Epoch 107: Train Loss=0.3164, Train Acc=89.85%, Val Loss=1.2332, Val Acc=63.36%, Grad Norm=12.5165, LR=9.76563e-08\n",
      "Fold 5, Epoch 108: Train Loss=0.3169, Train Acc=89.82%, Val Loss=1.2516, Val Acc=63.09%, Grad Norm=12.5553, LR=9.76563e-08\n",
      "Fold 5, Epoch 109: Train Loss=0.3168, Train Acc=89.79%, Val Loss=1.2320, Val Acc=63.29%, Grad Norm=12.5446, LR=9.76563e-08\n",
      "Fold 5, Epoch 110: Train Loss=0.3152, Train Acc=89.72%, Val Loss=1.2523, Val Acc=62.81%, Grad Norm=12.5199, LR=9.76563e-08\n",
      "Fold 5, Epoch 111: Train Loss=0.3152, Train Acc=89.84%, Val Loss=1.2364, Val Acc=63.24%, Grad Norm=12.4440, LR=4.88281e-08\n",
      "Fold 5, Epoch 112: Train Loss=0.3141, Train Acc=89.90%, Val Loss=1.2500, Val Acc=63.19%, Grad Norm=12.4685, LR=4.88281e-08\n",
      "Fold 5, Epoch 113: Train Loss=0.3132, Train Acc=89.89%, Val Loss=1.2409, Val Acc=63.11%, Grad Norm=12.4924, LR=4.88281e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=63.58%）\n",
      "Fold 5 DONE | Best Val Acc≈63.58% | Final Val Acc=63.58% | Test Acc=66.53%\n",
      "[INFO] SNR=20 dB | Mean Test Acc: 64.48% ± 1.76%\n",
      "[INFO] SNR  20 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR20dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = 15 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.1311, Train Acc=18.04%, Val Loss=2.4696, Val Acc=17.68%, Grad Norm=6.7704, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=1.7578, Train Acc=34.51%, Val Loss=1.9204, Val Acc=33.59%, Grad Norm=5.9461, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=1.4086, Train Acc=48.70%, Val Loss=1.4889, Val Acc=45.87%, Grad Norm=5.0475, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=1.2175, Train Acc=55.72%, Val Loss=1.3608, Val Acc=51.64%, Grad Norm=4.4797, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=1.1204, Train Acc=59.57%, Val Loss=1.2933, Val Acc=53.77%, Grad Norm=4.2591, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.0522, Train Acc=62.31%, Val Loss=1.2685, Val Acc=55.62%, Grad Norm=4.1724, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=0.9936, Train Acc=64.55%, Val Loss=1.2344, Val Acc=56.48%, Grad Norm=4.1757, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=0.9521, Train Acc=66.27%, Val Loss=1.2312, Val Acc=57.53%, Grad Norm=4.2046, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=0.9198, Train Acc=67.36%, Val Loss=1.2786, Val Acc=56.78%, Grad Norm=4.2766, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=0.8851, Train Acc=69.12%, Val Loss=1.2532, Val Acc=57.64%, Grad Norm=4.2541, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=0.8310, Train Acc=70.86%, Val Loss=1.1758, Val Acc=59.58%, Grad Norm=4.3754, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=0.8075, Train Acc=71.81%, Val Loss=1.1765, Val Acc=60.13%, Grad Norm=4.6767, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=0.7870, Train Acc=72.49%, Val Loss=1.1651, Val Acc=60.59%, Grad Norm=4.9133, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=0.7756, Train Acc=72.87%, Val Loss=1.1781, Val Acc=59.93%, Grad Norm=5.1004, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=0.7490, Train Acc=73.85%, Val Loss=1.1461, Val Acc=61.50%, Grad Norm=5.2884, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=0.7428, Train Acc=74.16%, Val Loss=1.1163, Val Acc=62.51%, Grad Norm=5.4129, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=0.7245, Train Acc=74.86%, Val Loss=1.1926, Val Acc=61.24%, Grad Norm=5.6108, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=0.7111, Train Acc=75.47%, Val Loss=1.1633, Val Acc=60.98%, Grad Norm=5.7292, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=0.6961, Train Acc=76.09%, Val Loss=1.1522, Val Acc=61.76%, Grad Norm=5.9301, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=0.6793, Train Acc=76.76%, Val Loss=1.1475, Val Acc=62.32%, Grad Norm=6.1729, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=0.6434, Train Acc=77.92%, Val Loss=1.1544, Val Acc=62.75%, Grad Norm=6.3684, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=0.6292, Train Acc=78.51%, Val Loss=1.1406, Val Acc=62.87%, Grad Norm=6.6277, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=0.6193, Train Acc=78.87%, Val Loss=1.1395, Val Acc=62.68%, Grad Norm=6.8647, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=0.6084, Train Acc=79.23%, Val Loss=1.1397, Val Acc=63.27%, Grad Norm=7.0671, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=0.5964, Train Acc=79.69%, Val Loss=1.1218, Val Acc=63.45%, Grad Norm=7.2262, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=0.5870, Train Acc=80.10%, Val Loss=1.1325, Val Acc=63.29%, Grad Norm=7.3988, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=0.5790, Train Acc=80.36%, Val Loss=1.1171, Val Acc=63.70%, Grad Norm=7.6636, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=0.5650, Train Acc=80.82%, Val Loss=1.1531, Val Acc=63.35%, Grad Norm=7.8807, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=0.5549, Train Acc=81.08%, Val Loss=1.1428, Val Acc=63.23%, Grad Norm=8.1240, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=0.5493, Train Acc=81.35%, Val Loss=1.1463, Val Acc=63.92%, Grad Norm=8.2486, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=0.5252, Train Acc=82.36%, Val Loss=1.1221, Val Acc=64.32%, Grad Norm=8.3611, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=0.5174, Train Acc=82.62%, Val Loss=1.1142, Val Acc=64.44%, Grad Norm=8.5964, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=0.5111, Train Acc=82.98%, Val Loss=1.1604, Val Acc=63.93%, Grad Norm=8.7805, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=0.5014, Train Acc=83.33%, Val Loss=1.1310, Val Acc=64.63%, Grad Norm=8.9570, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=0.4984, Train Acc=83.37%, Val Loss=1.1474, Val Acc=64.00%, Grad Norm=9.0694, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=0.4948, Train Acc=83.23%, Val Loss=1.1454, Val Acc=64.06%, Grad Norm=9.2228, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=0.4846, Train Acc=83.76%, Val Loss=1.1580, Val Acc=64.10%, Grad Norm=9.3758, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=0.4797, Train Acc=83.99%, Val Loss=1.1840, Val Acc=64.07%, Grad Norm=9.5364, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=0.4728, Train Acc=84.14%, Val Loss=1.1606, Val Acc=64.08%, Grad Norm=9.7186, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=0.4653, Train Acc=84.38%, Val Loss=1.1746, Val Acc=63.94%, Grad Norm=9.8136, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=0.4618, Train Acc=84.55%, Val Loss=1.1545, Val Acc=64.20%, Grad Norm=9.9526, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=0.4465, Train Acc=85.09%, Val Loss=1.1655, Val Acc=64.50%, Grad Norm=9.9845, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=0.4465, Train Acc=85.24%, Val Loss=1.1547, Val Acc=64.58%, Grad Norm=10.0995, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=0.4416, Train Acc=85.35%, Val Loss=1.1505, Val Acc=64.57%, Grad Norm=10.2668, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=0.4428, Train Acc=85.32%, Val Loss=1.1721, Val Acc=64.45%, Grad Norm=10.4322, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=0.4310, Train Acc=85.87%, Val Loss=1.1767, Val Acc=64.43%, Grad Norm=10.4290, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=0.4343, Train Acc=85.71%, Val Loss=1.1622, Val Acc=64.76%, Grad Norm=10.6055, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=0.4273, Train Acc=85.91%, Val Loss=1.1664, Val Acc=64.41%, Grad Norm=10.6277, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=0.4209, Train Acc=86.25%, Val Loss=1.1631, Val Acc=64.38%, Grad Norm=10.6589, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=0.4250, Train Acc=85.89%, Val Loss=1.1724, Val Acc=64.11%, Grad Norm=10.8651, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=0.4187, Train Acc=86.04%, Val Loss=1.1566, Val Acc=64.86%, Grad Norm=10.8593, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=0.4190, Train Acc=86.22%, Val Loss=1.1610, Val Acc=64.94%, Grad Norm=10.9370, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=0.4096, Train Acc=86.60%, Val Loss=1.1772, Val Acc=64.47%, Grad Norm=10.8966, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=0.4082, Train Acc=86.52%, Val Loss=1.1662, Val Acc=64.64%, Grad Norm=11.0854, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=0.4043, Train Acc=86.78%, Val Loss=1.1812, Val Acc=64.59%, Grad Norm=11.0303, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=0.4085, Train Acc=86.45%, Val Loss=1.1662, Val Acc=64.80%, Grad Norm=11.2165, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=0.4043, Train Acc=86.71%, Val Loss=1.1642, Val Acc=64.62%, Grad Norm=11.2259, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=0.4047, Train Acc=86.68%, Val Loss=1.1705, Val Acc=64.74%, Grad Norm=11.2406, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=0.4025, Train Acc=86.72%, Val Loss=1.1868, Val Acc=64.55%, Grad Norm=11.2780, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=0.3913, Train Acc=87.20%, Val Loss=1.1803, Val Acc=64.57%, Grad Norm=11.2344, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=0.3930, Train Acc=87.11%, Val Loss=1.1726, Val Acc=64.80%, Grad Norm=11.3617, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=0.3903, Train Acc=87.15%, Val Loss=1.1773, Val Acc=64.82%, Grad Norm=11.3553, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=0.3935, Train Acc=87.14%, Val Loss=1.1691, Val Acc=64.75%, Grad Norm=11.4743, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=0.3949, Train Acc=87.03%, Val Loss=1.1802, Val Acc=64.53%, Grad Norm=11.5105, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=0.3891, Train Acc=87.29%, Val Loss=1.1773, Val Acc=64.70%, Grad Norm=11.4614, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=0.3858, Train Acc=87.34%, Val Loss=1.1768, Val Acc=64.84%, Grad Norm=11.4884, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=0.3883, Train Acc=87.29%, Val Loss=1.1821, Val Acc=64.68%, Grad Norm=11.5504, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=0.3856, Train Acc=87.45%, Val Loss=1.1711, Val Acc=64.59%, Grad Norm=11.5533, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=0.3883, Train Acc=87.32%, Val Loss=1.1736, Val Acc=65.05%, Grad Norm=11.6095, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=0.3812, Train Acc=87.37%, Val Loss=1.1753, Val Acc=64.85%, Grad Norm=11.6155, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=0.3903, Train Acc=87.26%, Val Loss=1.1809, Val Acc=64.89%, Grad Norm=11.7917, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=0.3907, Train Acc=87.08%, Val Loss=1.1680, Val Acc=64.84%, Grad Norm=11.8124, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=0.3798, Train Acc=87.53%, Val Loss=1.1732, Val Acc=64.88%, Grad Norm=11.6651, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=0.3796, Train Acc=87.57%, Val Loss=1.1822, Val Acc=64.72%, Grad Norm=11.6833, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=0.3795, Train Acc=87.60%, Val Loss=1.1792, Val Acc=64.75%, Grad Norm=11.6732, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=0.3836, Train Acc=87.33%, Val Loss=1.1841, Val Acc=64.53%, Grad Norm=11.7538, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=0.3827, Train Acc=87.47%, Val Loss=1.1645, Val Acc=65.08%, Grad Norm=11.7812, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=0.3805, Train Acc=87.44%, Val Loss=1.1854, Val Acc=64.91%, Grad Norm=11.7288, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=0.3771, Train Acc=87.73%, Val Loss=1.1715, Val Acc=64.87%, Grad Norm=11.7072, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=0.3784, Train Acc=87.81%, Val Loss=1.1817, Val Acc=64.80%, Grad Norm=11.7278, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=0.3708, Train Acc=87.91%, Val Loss=1.1722, Val Acc=64.93%, Grad Norm=11.6670, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=0.3778, Train Acc=87.70%, Val Loss=1.1796, Val Acc=64.79%, Grad Norm=11.7582, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=0.3764, Train Acc=87.72%, Val Loss=1.1823, Val Acc=64.76%, Grad Norm=11.7948, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=0.3782, Train Acc=87.56%, Val Loss=1.1786, Val Acc=64.73%, Grad Norm=11.8371, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=0.3721, Train Acc=87.86%, Val Loss=1.1815, Val Acc=64.91%, Grad Norm=11.7935, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=0.3773, Train Acc=87.70%, Val Loss=1.1832, Val Acc=64.82%, Grad Norm=11.8907, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=0.3728, Train Acc=87.92%, Val Loss=1.1731, Val Acc=64.88%, Grad Norm=11.7959, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=0.3744, Train Acc=87.78%, Val Loss=1.1747, Val Acc=64.91%, Grad Norm=11.8297, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=0.3789, Train Acc=87.61%, Val Loss=1.1835, Val Acc=64.93%, Grad Norm=11.9144, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=0.3755, Train Acc=87.78%, Val Loss=1.1830, Val Acc=64.92%, Grad Norm=11.8254, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=0.3713, Train Acc=87.91%, Val Loss=1.1779, Val Acc=64.67%, Grad Norm=11.8271, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=0.3793, Train Acc=87.47%, Val Loss=1.1751, Val Acc=64.91%, Grad Norm=11.9464, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=0.3775, Train Acc=87.66%, Val Loss=1.1862, Val Acc=64.66%, Grad Norm=11.9364, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=0.3746, Train Acc=87.78%, Val Loss=1.1768, Val Acc=64.78%, Grad Norm=11.8767, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=0.3778, Train Acc=87.68%, Val Loss=1.1763, Val Acc=64.90%, Grad Norm=11.9268, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=0.3746, Train Acc=87.84%, Val Loss=1.1820, Val Acc=64.79%, Grad Norm=11.8566, LR=1.95313e-07\n",
      "Fold 1, Epoch 97: Train Loss=0.3767, Train Acc=87.70%, Val Loss=1.1881, Val Acc=64.84%, Grad Norm=11.8874, LR=1.95313e-07\n",
      "Fold 1, Epoch 98: Train Loss=0.3747, Train Acc=87.90%, Val Loss=1.1760, Val Acc=65.04%, Grad Norm=11.9097, LR=1.95313e-07\n",
      "Fold 1, Epoch 99: Train Loss=0.3724, Train Acc=87.92%, Val Loss=1.1913, Val Acc=64.79%, Grad Norm=11.8852, LR=1.95313e-07\n",
      "Fold 1, Epoch 100: Train Loss=0.3701, Train Acc=88.15%, Val Loss=1.1802, Val Acc=64.85%, Grad Norm=11.8026, LR=1.95313e-07\n",
      "Fold 1, Epoch 101: Train Loss=0.3756, Train Acc=87.84%, Val Loss=1.1852, Val Acc=64.69%, Grad Norm=11.9699, LR=9.76563e-08\n",
      "Fold 1, Epoch 102: Train Loss=0.3764, Train Acc=87.81%, Val Loss=1.1720, Val Acc=64.87%, Grad Norm=11.9574, LR=9.76563e-08\n",
      "Fold 1, Epoch 103: Train Loss=0.3742, Train Acc=87.74%, Val Loss=1.1750, Val Acc=64.84%, Grad Norm=11.9612, LR=9.76563e-08\n",
      "Fold 1, Epoch 104: Train Loss=0.3700, Train Acc=87.92%, Val Loss=1.1848, Val Acc=64.69%, Grad Norm=11.8725, LR=9.76563e-08\n",
      "Fold 1, Epoch 105: Train Loss=0.3787, Train Acc=87.65%, Val Loss=1.1845, Val Acc=64.72%, Grad Norm=11.9787, LR=9.76563e-08\n",
      "Fold 1, Epoch 106: Train Loss=0.3710, Train Acc=87.85%, Val Loss=1.1845, Val Acc=64.88%, Grad Norm=11.8585, LR=9.76563e-08\n",
      "Fold 1, Epoch 107: Train Loss=0.3730, Train Acc=87.92%, Val Loss=1.1904, Val Acc=64.86%, Grad Norm=11.9317, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=65.08%）\n",
      "Fold 1 DONE | Best Val Acc≈65.08% | Final Val Acc=65.08% | Test Acc=64.09%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.1409, Train Acc=17.50%, Val Loss=2.9224, Val Acc=17.58%, Grad Norm=6.8495, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=1.7798, Train Acc=33.95%, Val Loss=1.9847, Val Acc=32.73%, Grad Norm=6.2334, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=1.4390, Train Acc=47.39%, Val Loss=1.5407, Val Acc=45.75%, Grad Norm=5.3228, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=1.2266, Train Acc=55.27%, Val Loss=1.4659, Val Acc=50.57%, Grad Norm=4.6564, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.1159, Train Acc=59.47%, Val Loss=1.3959, Val Acc=51.50%, Grad Norm=4.3559, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.0450, Train Acc=62.31%, Val Loss=1.3543, Val Acc=54.54%, Grad Norm=4.2034, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=1.0028, Train Acc=64.09%, Val Loss=1.3699, Val Acc=53.36%, Grad Norm=4.1163, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=0.9588, Train Acc=65.62%, Val Loss=1.3557, Val Acc=55.66%, Grad Norm=4.1583, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=0.9270, Train Acc=66.98%, Val Loss=1.3164, Val Acc=56.97%, Grad Norm=4.2367, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=0.8964, Train Acc=68.04%, Val Loss=1.2648, Val Acc=57.29%, Grad Norm=4.2409, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=0.8390, Train Acc=70.47%, Val Loss=1.2462, Val Acc=58.56%, Grad Norm=4.3790, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=0.8130, Train Acc=71.44%, Val Loss=1.2466, Val Acc=58.91%, Grad Norm=4.7219, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=0.7871, Train Acc=72.23%, Val Loss=1.2637, Val Acc=58.55%, Grad Norm=4.9150, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=0.7710, Train Acc=73.04%, Val Loss=1.2109, Val Acc=60.06%, Grad Norm=5.1054, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=0.7592, Train Acc=73.53%, Val Loss=1.2428, Val Acc=58.67%, Grad Norm=5.3180, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=0.7461, Train Acc=73.92%, Val Loss=1.2044, Val Acc=60.52%, Grad Norm=5.4818, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=0.7231, Train Acc=74.92%, Val Loss=1.2475, Val Acc=59.72%, Grad Norm=5.6493, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=0.7061, Train Acc=75.64%, Val Loss=1.2242, Val Acc=59.67%, Grad Norm=5.8777, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=0.6962, Train Acc=75.93%, Val Loss=1.1980, Val Acc=60.20%, Grad Norm=6.0287, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=0.6767, Train Acc=76.75%, Val Loss=1.2098, Val Acc=59.82%, Grad Norm=6.2042, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=0.6462, Train Acc=77.83%, Val Loss=1.1783, Val Acc=61.35%, Grad Norm=6.3920, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=0.6257, Train Acc=78.60%, Val Loss=1.1927, Val Acc=61.00%, Grad Norm=6.6557, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=0.6162, Train Acc=79.09%, Val Loss=1.1888, Val Acc=60.91%, Grad Norm=6.9220, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=0.6104, Train Acc=79.23%, Val Loss=1.1750, Val Acc=61.53%, Grad Norm=7.1042, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=0.5972, Train Acc=79.63%, Val Loss=1.1871, Val Acc=61.64%, Grad Norm=7.3113, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=0.5934, Train Acc=79.61%, Val Loss=1.1767, Val Acc=61.72%, Grad Norm=7.5497, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=0.5806, Train Acc=80.22%, Val Loss=1.1578, Val Acc=62.47%, Grad Norm=7.6829, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=0.5706, Train Acc=80.66%, Val Loss=1.1847, Val Acc=62.34%, Grad Norm=7.8970, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=0.5591, Train Acc=81.23%, Val Loss=1.1586, Val Acc=62.53%, Grad Norm=8.0433, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=0.5499, Train Acc=81.39%, Val Loss=1.1449, Val Acc=62.52%, Grad Norm=8.2321, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=0.5317, Train Acc=82.20%, Val Loss=1.1553, Val Acc=62.84%, Grad Norm=8.3825, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=0.5204, Train Acc=82.61%, Val Loss=1.1841, Val Acc=62.09%, Grad Norm=8.5995, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=0.5077, Train Acc=82.88%, Val Loss=1.1508, Val Acc=62.80%, Grad Norm=8.7282, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=0.5038, Train Acc=83.12%, Val Loss=1.1675, Val Acc=62.67%, Grad Norm=9.0189, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=0.4953, Train Acc=83.46%, Val Loss=1.1550, Val Acc=63.07%, Grad Norm=9.1170, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=0.4901, Train Acc=83.70%, Val Loss=1.1435, Val Acc=63.23%, Grad Norm=9.2833, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=0.4819, Train Acc=84.11%, Val Loss=1.1931, Val Acc=62.49%, Grad Norm=9.4678, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=0.4815, Train Acc=83.75%, Val Loss=1.1553, Val Acc=62.87%, Grad Norm=9.6237, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=0.4723, Train Acc=84.16%, Val Loss=1.1598, Val Acc=63.15%, Grad Norm=9.7335, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=0.4658, Train Acc=84.58%, Val Loss=1.1792, Val Acc=62.98%, Grad Norm=9.9303, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=0.4508, Train Acc=85.11%, Val Loss=1.1668, Val Acc=63.47%, Grad Norm=9.9505, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=0.4432, Train Acc=85.40%, Val Loss=1.1590, Val Acc=63.25%, Grad Norm=10.0487, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=0.4454, Train Acc=85.33%, Val Loss=1.1659, Val Acc=63.08%, Grad Norm=10.1444, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=0.4420, Train Acc=85.45%, Val Loss=1.1630, Val Acc=63.21%, Grad Norm=10.3174, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=0.4386, Train Acc=85.41%, Val Loss=1.1715, Val Acc=63.15%, Grad Norm=10.4207, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=0.4348, Train Acc=85.50%, Val Loss=1.1899, Val Acc=62.77%, Grad Norm=10.5271, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=0.4349, Train Acc=85.58%, Val Loss=1.1607, Val Acc=63.29%, Grad Norm=10.6790, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=0.4262, Train Acc=85.77%, Val Loss=1.1774, Val Acc=63.34%, Grad Norm=10.7035, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=0.4306, Train Acc=85.68%, Val Loss=1.1924, Val Acc=63.13%, Grad Norm=10.8884, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=0.4237, Train Acc=86.02%, Val Loss=1.1536, Val Acc=63.46%, Grad Norm=10.8849, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=0.4138, Train Acc=86.22%, Val Loss=1.1863, Val Acc=63.30%, Grad Norm=10.9028, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=0.4097, Train Acc=86.42%, Val Loss=1.1728, Val Acc=63.36%, Grad Norm=10.9224, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=0.4099, Train Acc=86.57%, Val Loss=1.1732, Val Acc=63.65%, Grad Norm=11.0148, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=0.4060, Train Acc=86.60%, Val Loss=1.1756, Val Acc=63.38%, Grad Norm=11.0439, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=0.4067, Train Acc=86.65%, Val Loss=1.1683, Val Acc=63.48%, Grad Norm=11.2077, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=0.4051, Train Acc=86.73%, Val Loss=1.1797, Val Acc=63.50%, Grad Norm=11.1808, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=0.3973, Train Acc=87.04%, Val Loss=1.1708, Val Acc=63.37%, Grad Norm=11.1626, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=0.3997, Train Acc=86.98%, Val Loss=1.1668, Val Acc=63.55%, Grad Norm=11.3529, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=0.4041, Train Acc=86.78%, Val Loss=1.1921, Val Acc=63.11%, Grad Norm=11.4456, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=0.3980, Train Acc=86.98%, Val Loss=1.1803, Val Acc=63.63%, Grad Norm=11.4241, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=0.3940, Train Acc=87.09%, Val Loss=1.1891, Val Acc=63.68%, Grad Norm=11.4103, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=0.3936, Train Acc=87.15%, Val Loss=1.1816, Val Acc=63.50%, Grad Norm=11.4670, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=0.3891, Train Acc=87.41%, Val Loss=1.1762, Val Acc=63.51%, Grad Norm=11.4285, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=0.3893, Train Acc=87.30%, Val Loss=1.1713, Val Acc=63.47%, Grad Norm=11.5040, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=0.3929, Train Acc=87.06%, Val Loss=1.1731, Val Acc=63.68%, Grad Norm=11.6119, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=0.3921, Train Acc=87.20%, Val Loss=1.1778, Val Acc=63.57%, Grad Norm=11.6018, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=0.3852, Train Acc=87.60%, Val Loss=1.1751, Val Acc=63.91%, Grad Norm=11.5709, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=0.3856, Train Acc=87.46%, Val Loss=1.1709, Val Acc=63.74%, Grad Norm=11.6481, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=0.3842, Train Acc=87.48%, Val Loss=1.1774, Val Acc=63.54%, Grad Norm=11.6424, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=0.3859, Train Acc=87.34%, Val Loss=1.1776, Val Acc=63.47%, Grad Norm=11.7095, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=0.3796, Train Acc=87.71%, Val Loss=1.1688, Val Acc=63.62%, Grad Norm=11.6483, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=0.3815, Train Acc=87.66%, Val Loss=1.1785, Val Acc=63.63%, Grad Norm=11.6856, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=0.3835, Train Acc=87.44%, Val Loss=1.1830, Val Acc=63.63%, Grad Norm=11.7899, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=0.3814, Train Acc=87.62%, Val Loss=1.1844, Val Acc=63.62%, Grad Norm=11.7891, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=0.3837, Train Acc=87.41%, Val Loss=1.1837, Val Acc=63.58%, Grad Norm=11.8403, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=0.3814, Train Acc=87.61%, Val Loss=1.1796, Val Acc=63.60%, Grad Norm=11.8170, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=0.3758, Train Acc=87.91%, Val Loss=1.1822, Val Acc=63.57%, Grad Norm=11.7277, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=0.3800, Train Acc=87.76%, Val Loss=1.1759, Val Acc=63.63%, Grad Norm=11.7883, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=0.3799, Train Acc=87.64%, Val Loss=1.1932, Val Acc=63.52%, Grad Norm=11.8661, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=0.3776, Train Acc=87.81%, Val Loss=1.1771, Val Acc=63.53%, Grad Norm=11.8148, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=0.3794, Train Acc=87.66%, Val Loss=1.1756, Val Acc=63.79%, Grad Norm=11.8737, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=0.3818, Train Acc=87.53%, Val Loss=1.1728, Val Acc=63.64%, Grad Norm=11.9471, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=0.3787, Train Acc=87.75%, Val Loss=1.1830, Val Acc=63.63%, Grad Norm=11.8488, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=0.3815, Train Acc=87.48%, Val Loss=1.1764, Val Acc=63.64%, Grad Norm=11.9775, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=0.3785, Train Acc=87.59%, Val Loss=1.1815, Val Acc=63.77%, Grad Norm=11.8515, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=0.3773, Train Acc=87.60%, Val Loss=1.1729, Val Acc=63.68%, Grad Norm=11.8835, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=0.3737, Train Acc=87.81%, Val Loss=1.1749, Val Acc=63.63%, Grad Norm=11.8327, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=0.3710, Train Acc=88.06%, Val Loss=1.1688, Val Acc=63.46%, Grad Norm=11.7894, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=0.3737, Train Acc=87.98%, Val Loss=1.1693, Val Acc=63.62%, Grad Norm=11.8805, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=0.3772, Train Acc=87.77%, Val Loss=1.1729, Val Acc=63.70%, Grad Norm=11.9298, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=0.3767, Train Acc=87.65%, Val Loss=1.1744, Val Acc=63.53%, Grad Norm=11.9120, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=0.3695, Train Acc=87.99%, Val Loss=1.1788, Val Acc=63.74%, Grad Norm=11.8554, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=0.3798, Train Acc=87.53%, Val Loss=1.1764, Val Acc=63.57%, Grad Norm=11.9916, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=0.3753, Train Acc=87.79%, Val Loss=1.1926, Val Acc=63.55%, Grad Norm=11.9107, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=0.3739, Train Acc=87.82%, Val Loss=1.1750, Val Acc=63.72%, Grad Norm=11.8925, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=0.3708, Train Acc=87.98%, Val Loss=1.1775, Val Acc=63.91%, Grad Norm=11.8598, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=0.3733, Train Acc=87.87%, Val Loss=1.1784, Val Acc=63.54%, Grad Norm=11.9089, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=63.91%）\n",
      "Fold 2 DONE | Best Val Acc≈63.91% | Final Val Acc=63.91% | Test Acc=62.06%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.1223, Train Acc=18.57%, Val Loss=3.0105, Val Acc=18.66%, Grad Norm=6.6299, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=1.7786, Train Acc=34.04%, Val Loss=2.0241, Val Acc=31.97%, Grad Norm=5.7697, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=1.4551, Train Acc=46.99%, Val Loss=1.6299, Val Acc=44.64%, Grad Norm=5.0488, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=1.2549, Train Acc=54.40%, Val Loss=1.4010, Val Acc=49.86%, Grad Norm=4.6343, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.1402, Train Acc=59.11%, Val Loss=1.3734, Val Acc=51.82%, Grad Norm=4.3732, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.0684, Train Acc=61.82%, Val Loss=1.3318, Val Acc=54.61%, Grad Norm=4.1884, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=1.0142, Train Acc=63.71%, Val Loss=1.2888, Val Acc=56.15%, Grad Norm=4.1690, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=0.9652, Train Acc=65.53%, Val Loss=1.2528, Val Acc=56.01%, Grad Norm=4.1653, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=0.9324, Train Acc=67.05%, Val Loss=1.2416, Val Acc=57.64%, Grad Norm=4.2245, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=0.8999, Train Acc=68.18%, Val Loss=1.1912, Val Acc=58.31%, Grad Norm=4.2800, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=0.8404, Train Acc=70.49%, Val Loss=1.1639, Val Acc=59.45%, Grad Norm=4.4290, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=0.8136, Train Acc=71.30%, Val Loss=1.1522, Val Acc=60.61%, Grad Norm=4.6970, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=0.7973, Train Acc=72.03%, Val Loss=1.1808, Val Acc=59.50%, Grad Norm=4.9203, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=0.7787, Train Acc=72.82%, Val Loss=1.1911, Val Acc=59.35%, Grad Norm=5.1312, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=0.7593, Train Acc=73.34%, Val Loss=1.1480, Val Acc=60.10%, Grad Norm=5.3256, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=0.7361, Train Acc=74.46%, Val Loss=1.1534, Val Acc=61.24%, Grad Norm=5.4871, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=0.7274, Train Acc=74.76%, Val Loss=1.1716, Val Acc=60.12%, Grad Norm=5.7528, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=0.7103, Train Acc=75.38%, Val Loss=1.1776, Val Acc=60.60%, Grad Norm=5.8590, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=0.6962, Train Acc=75.94%, Val Loss=1.1803, Val Acc=60.56%, Grad Norm=6.0866, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=0.6786, Train Acc=76.77%, Val Loss=1.1475, Val Acc=61.25%, Grad Norm=6.3094, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=0.6389, Train Acc=78.22%, Val Loss=1.1426, Val Acc=62.05%, Grad Norm=6.4685, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=0.6206, Train Acc=78.65%, Val Loss=1.1975, Val Acc=61.36%, Grad Norm=6.7752, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=0.6120, Train Acc=79.13%, Val Loss=1.1965, Val Acc=61.01%, Grad Norm=7.0360, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=0.5966, Train Acc=79.72%, Val Loss=1.1596, Val Acc=62.26%, Grad Norm=7.2611, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=0.5870, Train Acc=79.96%, Val Loss=1.1233, Val Acc=62.82%, Grad Norm=7.4292, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=0.5753, Train Acc=80.32%, Val Loss=1.1444, Val Acc=62.52%, Grad Norm=7.6425, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=0.5651, Train Acc=80.86%, Val Loss=1.1400, Val Acc=62.75%, Grad Norm=7.8358, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=0.5586, Train Acc=81.18%, Val Loss=1.1494, Val Acc=62.74%, Grad Norm=8.0590, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=0.5477, Train Acc=81.54%, Val Loss=1.1478, Val Acc=62.74%, Grad Norm=8.2231, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=0.5391, Train Acc=81.77%, Val Loss=1.1477, Val Acc=62.83%, Grad Norm=8.4618, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=0.5144, Train Acc=82.67%, Val Loss=1.1536, Val Acc=63.05%, Grad Norm=8.5114, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=0.5069, Train Acc=83.06%, Val Loss=1.1687, Val Acc=63.37%, Grad Norm=8.7883, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=0.4974, Train Acc=83.41%, Val Loss=1.1510, Val Acc=63.16%, Grad Norm=8.9596, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=0.4901, Train Acc=83.43%, Val Loss=1.1925, Val Acc=62.80%, Grad Norm=9.1049, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=0.4881, Train Acc=83.70%, Val Loss=1.1600, Val Acc=63.67%, Grad Norm=9.2666, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=0.4761, Train Acc=84.08%, Val Loss=1.1818, Val Acc=63.51%, Grad Norm=9.3856, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=0.4725, Train Acc=84.21%, Val Loss=1.1544, Val Acc=63.62%, Grad Norm=9.4734, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=0.4694, Train Acc=84.50%, Val Loss=1.1475, Val Acc=63.57%, Grad Norm=9.6215, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=0.4633, Train Acc=84.35%, Val Loss=1.1675, Val Acc=63.05%, Grad Norm=9.8440, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=0.4545, Train Acc=84.83%, Val Loss=1.1694, Val Acc=63.52%, Grad Norm=9.9917, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=0.4488, Train Acc=85.17%, Val Loss=1.1774, Val Acc=63.40%, Grad Norm=10.1108, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=0.4336, Train Acc=85.72%, Val Loss=1.1777, Val Acc=63.31%, Grad Norm=10.1296, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=0.4339, Train Acc=85.61%, Val Loss=1.1881, Val Acc=63.49%, Grad Norm=10.2370, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=0.4239, Train Acc=86.10%, Val Loss=1.1617, Val Acc=64.02%, Grad Norm=10.2373, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=0.4263, Train Acc=85.86%, Val Loss=1.1677, Val Acc=63.66%, Grad Norm=10.4450, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=0.4191, Train Acc=86.23%, Val Loss=1.1800, Val Acc=63.76%, Grad Norm=10.5073, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=0.4154, Train Acc=86.29%, Val Loss=1.1858, Val Acc=63.34%, Grad Norm=10.5785, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=0.4147, Train Acc=86.28%, Val Loss=1.1846, Val Acc=63.70%, Grad Norm=10.7051, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=0.4108, Train Acc=86.43%, Val Loss=1.1831, Val Acc=63.70%, Grad Norm=10.7002, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=0.4079, Train Acc=86.66%, Val Loss=1.1764, Val Acc=63.99%, Grad Norm=10.8277, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=0.4000, Train Acc=86.99%, Val Loss=1.1792, Val Acc=63.69%, Grad Norm=10.8458, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=0.3969, Train Acc=87.10%, Val Loss=1.1836, Val Acc=63.51%, Grad Norm=10.9291, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=0.3960, Train Acc=87.18%, Val Loss=1.1876, Val Acc=63.69%, Grad Norm=11.0061, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=0.3951, Train Acc=87.02%, Val Loss=1.1808, Val Acc=64.09%, Grad Norm=11.1046, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=0.3918, Train Acc=87.19%, Val Loss=1.1815, Val Acc=63.87%, Grad Norm=11.0711, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=0.3954, Train Acc=87.04%, Val Loss=1.1863, Val Acc=63.70%, Grad Norm=11.2653, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=0.3895, Train Acc=87.20%, Val Loss=1.1859, Val Acc=63.91%, Grad Norm=11.2311, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=0.3900, Train Acc=87.30%, Val Loss=1.1863, Val Acc=63.76%, Grad Norm=11.3352, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=0.3847, Train Acc=87.47%, Val Loss=1.1755, Val Acc=64.23%, Grad Norm=11.3112, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=0.3856, Train Acc=87.45%, Val Loss=1.1707, Val Acc=64.30%, Grad Norm=11.3811, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=0.3798, Train Acc=87.59%, Val Loss=1.1815, Val Acc=63.98%, Grad Norm=11.4569, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=0.3806, Train Acc=87.57%, Val Loss=1.1766, Val Acc=64.12%, Grad Norm=11.4796, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=0.3774, Train Acc=87.77%, Val Loss=1.1788, Val Acc=63.89%, Grad Norm=11.4455, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=0.3822, Train Acc=87.33%, Val Loss=1.1839, Val Acc=63.78%, Grad Norm=11.6036, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=0.3750, Train Acc=87.94%, Val Loss=1.1622, Val Acc=64.32%, Grad Norm=11.5017, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=0.3712, Train Acc=87.91%, Val Loss=1.1912, Val Acc=63.95%, Grad Norm=11.4941, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=0.3792, Train Acc=87.68%, Val Loss=1.1776, Val Acc=64.16%, Grad Norm=11.6194, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=0.3752, Train Acc=87.64%, Val Loss=1.1880, Val Acc=63.72%, Grad Norm=11.6503, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=0.3759, Train Acc=87.63%, Val Loss=1.1848, Val Acc=64.07%, Grad Norm=11.6376, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=0.3700, Train Acc=87.94%, Val Loss=1.1869, Val Acc=64.05%, Grad Norm=11.6125, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=0.3740, Train Acc=87.80%, Val Loss=1.1834, Val Acc=63.95%, Grad Norm=11.7364, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=0.3693, Train Acc=87.80%, Val Loss=1.1955, Val Acc=63.72%, Grad Norm=11.6714, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=0.3694, Train Acc=88.14%, Val Loss=1.1891, Val Acc=63.80%, Grad Norm=11.6748, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=0.3672, Train Acc=88.05%, Val Loss=1.2006, Val Acc=63.59%, Grad Norm=11.6672, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=0.3684, Train Acc=88.11%, Val Loss=1.1868, Val Acc=63.72%, Grad Norm=11.7360, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=0.3651, Train Acc=88.25%, Val Loss=1.1864, Val Acc=63.74%, Grad Norm=11.7033, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=0.3661, Train Acc=88.07%, Val Loss=1.1948, Val Acc=63.85%, Grad Norm=11.7479, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=0.3664, Train Acc=88.08%, Val Loss=1.1895, Val Acc=63.92%, Grad Norm=11.7795, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=0.3668, Train Acc=88.09%, Val Loss=1.1798, Val Acc=63.90%, Grad Norm=11.7683, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=0.3686, Train Acc=87.97%, Val Loss=1.1927, Val Acc=63.88%, Grad Norm=11.8775, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=0.3640, Train Acc=88.11%, Val Loss=1.1836, Val Acc=63.67%, Grad Norm=11.7637, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=0.3647, Train Acc=88.07%, Val Loss=1.1798, Val Acc=64.05%, Grad Norm=11.7925, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=0.3616, Train Acc=88.45%, Val Loss=1.1885, Val Acc=63.77%, Grad Norm=11.7078, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=0.3631, Train Acc=88.22%, Val Loss=1.1781, Val Acc=64.09%, Grad Norm=11.8088, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=0.3628, Train Acc=88.15%, Val Loss=1.1888, Val Acc=63.83%, Grad Norm=11.7930, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=0.3637, Train Acc=88.23%, Val Loss=1.1888, Val Acc=63.85%, Grad Norm=11.8396, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=0.3631, Train Acc=88.07%, Val Loss=1.1927, Val Acc=63.77%, Grad Norm=11.8394, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=0.3615, Train Acc=88.31%, Val Loss=1.1834, Val Acc=63.98%, Grad Norm=11.8032, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=0.3605, Train Acc=88.25%, Val Loss=1.1832, Val Acc=64.13%, Grad Norm=11.8016, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=0.3577, Train Acc=88.28%, Val Loss=1.1868, Val Acc=63.96%, Grad Norm=11.7810, LR=3.90625e-07\n",
      "Fold 3, Epoch 91: Train Loss=0.3624, Train Acc=88.12%, Val Loss=1.1917, Val Acc=63.86%, Grad Norm=11.8322, LR=1.95313e-07\n",
      "Fold 3, Epoch 92: Train Loss=0.3589, Train Acc=88.29%, Val Loss=1.1724, Val Acc=64.51%, Grad Norm=11.8125, LR=1.95313e-07\n",
      "Fold 3, Epoch 93: Train Loss=0.3593, Train Acc=88.21%, Val Loss=1.1824, Val Acc=64.13%, Grad Norm=11.7595, LR=1.95313e-07\n",
      "Fold 3, Epoch 94: Train Loss=0.3617, Train Acc=88.21%, Val Loss=1.1895, Val Acc=63.71%, Grad Norm=11.8626, LR=1.95313e-07\n",
      "Fold 3, Epoch 95: Train Loss=0.3607, Train Acc=88.25%, Val Loss=1.1813, Val Acc=63.86%, Grad Norm=11.8363, LR=1.95313e-07\n",
      "Fold 3, Epoch 96: Train Loss=0.3592, Train Acc=88.37%, Val Loss=1.1750, Val Acc=64.33%, Grad Norm=11.8224, LR=1.95313e-07\n",
      "Fold 3, Epoch 97: Train Loss=0.3652, Train Acc=88.12%, Val Loss=1.1888, Val Acc=64.03%, Grad Norm=11.9242, LR=1.95313e-07\n",
      "Fold 3, Epoch 98: Train Loss=0.3660, Train Acc=88.23%, Val Loss=1.1945, Val Acc=63.97%, Grad Norm=11.9387, LR=1.95313e-07\n",
      "Fold 3, Epoch 99: Train Loss=0.3583, Train Acc=88.35%, Val Loss=1.1881, Val Acc=63.82%, Grad Norm=11.8307, LR=1.95313e-07\n",
      "Fold 3, Epoch 100: Train Loss=0.3614, Train Acc=88.24%, Val Loss=1.1879, Val Acc=63.94%, Grad Norm=11.8614, LR=1.95313e-07\n",
      "Fold 3, Epoch 101: Train Loss=0.3633, Train Acc=88.09%, Val Loss=1.1929, Val Acc=63.84%, Grad Norm=11.9732, LR=9.76563e-08\n",
      "Fold 3, Epoch 102: Train Loss=0.3633, Train Acc=88.20%, Val Loss=1.2021, Val Acc=63.76%, Grad Norm=11.8705, LR=9.76563e-08\n",
      "Fold 3, Epoch 103: Train Loss=0.3588, Train Acc=88.33%, Val Loss=1.1915, Val Acc=64.05%, Grad Norm=11.8994, LR=9.76563e-08\n",
      "Fold 3, Epoch 104: Train Loss=0.3637, Train Acc=88.05%, Val Loss=1.1921, Val Acc=63.76%, Grad Norm=11.9776, LR=9.76563e-08\n",
      "Fold 3, Epoch 105: Train Loss=0.3617, Train Acc=88.11%, Val Loss=1.1962, Val Acc=63.72%, Grad Norm=11.9138, LR=9.76563e-08\n",
      "Fold 3, Epoch 106: Train Loss=0.3597, Train Acc=88.20%, Val Loss=1.1787, Val Acc=64.05%, Grad Norm=11.8881, LR=9.76563e-08\n",
      "Fold 3, Epoch 107: Train Loss=0.3569, Train Acc=88.37%, Val Loss=1.1767, Val Acc=64.18%, Grad Norm=11.8424, LR=9.76563e-08\n",
      "Fold 3, Epoch 108: Train Loss=0.3547, Train Acc=88.63%, Val Loss=1.1819, Val Acc=64.01%, Grad Norm=11.7646, LR=9.76563e-08\n",
      "Fold 3, Epoch 109: Train Loss=0.3581, Train Acc=88.33%, Val Loss=1.1884, Val Acc=63.91%, Grad Norm=11.8467, LR=9.76563e-08\n",
      "Fold 3, Epoch 110: Train Loss=0.3603, Train Acc=88.35%, Val Loss=1.1813, Val Acc=64.17%, Grad Norm=11.8794, LR=9.76563e-08\n",
      "Fold 3, Epoch 111: Train Loss=0.3614, Train Acc=88.32%, Val Loss=1.1955, Val Acc=63.87%, Grad Norm=11.8808, LR=4.88281e-08\n",
      "Fold 3, Epoch 112: Train Loss=0.3576, Train Acc=88.38%, Val Loss=1.1889, Val Acc=63.85%, Grad Norm=11.8451, LR=4.88281e-08\n",
      "Fold 3, Epoch 113: Train Loss=0.3557, Train Acc=88.60%, Val Loss=1.1876, Val Acc=64.05%, Grad Norm=11.7691, LR=4.88281e-08\n",
      "Fold 3, Epoch 114: Train Loss=0.3641, Train Acc=88.22%, Val Loss=1.1988, Val Acc=63.60%, Grad Norm=11.9607, LR=4.88281e-08\n",
      "Fold 3, Epoch 115: Train Loss=0.3582, Train Acc=88.37%, Val Loss=1.1859, Val Acc=64.06%, Grad Norm=11.8636, LR=4.88281e-08\n",
      "Fold 3, Epoch 116: Train Loss=0.3567, Train Acc=88.47%, Val Loss=1.1852, Val Acc=64.17%, Grad Norm=11.8456, LR=4.88281e-08\n",
      "Fold 3, Epoch 117: Train Loss=0.3580, Train Acc=88.44%, Val Loss=1.1854, Val Acc=64.22%, Grad Norm=11.8767, LR=4.88281e-08\n",
      "Fold 3, Epoch 118: Train Loss=0.3578, Train Acc=88.42%, Val Loss=1.1908, Val Acc=63.83%, Grad Norm=11.8737, LR=4.88281e-08\n",
      "Fold 3, Epoch 119: Train Loss=0.3587, Train Acc=88.27%, Val Loss=1.1811, Val Acc=63.89%, Grad Norm=11.9082, LR=4.88281e-08\n",
      "Fold 3, Epoch 120: Train Loss=0.3575, Train Acc=88.46%, Val Loss=1.1889, Val Acc=64.10%, Grad Norm=11.8910, LR=4.88281e-08\n",
      "Fold 3, Epoch 121: Train Loss=0.3587, Train Acc=88.47%, Val Loss=1.1771, Val Acc=64.35%, Grad Norm=11.8097, LR=2.44141e-08\n",
      "Fold 3, Epoch 122: Train Loss=0.3604, Train Acc=88.21%, Val Loss=1.1788, Val Acc=64.20%, Grad Norm=11.9074, LR=2.44141e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=64.51%）\n",
      "Fold 3 DONE | Best Val Acc≈64.51% | Final Val Acc=64.51% | Test Acc=62.36%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.1056, Train Acc=19.53%, Val Loss=2.4581, Val Acc=23.37%, Grad Norm=6.8313, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=1.6713, Train Acc=37.32%, Val Loss=1.8845, Val Acc=38.72%, Grad Norm=5.6692, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=1.3589, Train Acc=50.42%, Val Loss=1.4569, Val Acc=49.75%, Grad Norm=4.7572, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.1985, Train Acc=56.35%, Val Loss=1.2605, Val Acc=55.75%, Grad Norm=4.4175, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.0973, Train Acc=60.58%, Val Loss=1.2221, Val Acc=58.10%, Grad Norm=4.1929, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.0289, Train Acc=62.98%, Val Loss=1.2202, Val Acc=57.98%, Grad Norm=4.1718, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=0.9813, Train Acc=65.03%, Val Loss=1.1472, Val Acc=61.57%, Grad Norm=4.1076, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=0.9377, Train Acc=66.69%, Val Loss=1.1075, Val Acc=61.47%, Grad Norm=4.1757, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=0.9045, Train Acc=67.93%, Val Loss=1.0927, Val Acc=62.58%, Grad Norm=4.2275, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=0.8814, Train Acc=68.69%, Val Loss=1.1184, Val Acc=62.91%, Grad Norm=4.3457, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=0.8176, Train Acc=71.22%, Val Loss=1.0886, Val Acc=63.48%, Grad Norm=4.5168, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=0.7994, Train Acc=72.01%, Val Loss=1.0627, Val Acc=64.04%, Grad Norm=4.8771, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=0.7772, Train Acc=72.84%, Val Loss=1.0084, Val Acc=65.00%, Grad Norm=5.0533, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=0.7532, Train Acc=73.91%, Val Loss=1.0806, Val Acc=64.37%, Grad Norm=5.3819, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=0.7423, Train Acc=74.23%, Val Loss=1.0594, Val Acc=63.92%, Grad Norm=5.5992, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=0.7220, Train Acc=74.99%, Val Loss=1.0449, Val Acc=64.56%, Grad Norm=5.7650, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=0.6974, Train Acc=75.98%, Val Loss=1.0784, Val Acc=64.47%, Grad Norm=6.0466, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=0.6867, Train Acc=76.40%, Val Loss=1.0381, Val Acc=64.74%, Grad Norm=6.2401, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=0.6678, Train Acc=77.15%, Val Loss=1.0283, Val Acc=66.09%, Grad Norm=6.4883, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=0.6507, Train Acc=77.65%, Val Loss=1.0323, Val Acc=65.70%, Grad Norm=6.7207, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=0.6158, Train Acc=78.85%, Val Loss=1.0621, Val Acc=65.65%, Grad Norm=6.8636, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=0.5956, Train Acc=79.62%, Val Loss=1.0422, Val Acc=65.94%, Grad Norm=7.2472, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=0.5815, Train Acc=80.24%, Val Loss=1.0392, Val Acc=65.90%, Grad Norm=7.4953, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=0.5731, Train Acc=80.45%, Val Loss=1.0284, Val Acc=66.97%, Grad Norm=7.7251, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=0.5579, Train Acc=81.13%, Val Loss=1.0103, Val Acc=67.13%, Grad Norm=8.0274, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=0.5504, Train Acc=81.43%, Val Loss=1.0091, Val Acc=67.52%, Grad Norm=8.1540, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=0.5349, Train Acc=81.87%, Val Loss=1.0607, Val Acc=66.75%, Grad Norm=8.3506, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=0.5315, Train Acc=82.14%, Val Loss=1.0389, Val Acc=67.12%, Grad Norm=8.6490, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=0.5208, Train Acc=82.43%, Val Loss=1.0318, Val Acc=66.78%, Grad Norm=8.8034, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=0.5116, Train Acc=83.03%, Val Loss=1.0390, Val Acc=67.48%, Grad Norm=8.9668, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=0.4838, Train Acc=83.71%, Val Loss=1.0358, Val Acc=67.01%, Grad Norm=9.1783, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=0.4770, Train Acc=84.01%, Val Loss=1.0641, Val Acc=67.36%, Grad Norm=9.3037, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=0.4684, Train Acc=84.26%, Val Loss=1.0653, Val Acc=66.64%, Grad Norm=9.4979, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=0.4620, Train Acc=84.59%, Val Loss=1.0704, Val Acc=67.11%, Grad Norm=9.6472, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=0.4553, Train Acc=84.82%, Val Loss=1.0605, Val Acc=66.99%, Grad Norm=9.8301, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=0.4427, Train Acc=85.38%, Val Loss=1.0578, Val Acc=67.28%, Grad Norm=9.9318, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=0.4431, Train Acc=85.19%, Val Loss=1.0569, Val Acc=67.30%, Grad Norm=10.1973, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=0.4375, Train Acc=85.35%, Val Loss=1.0287, Val Acc=67.57%, Grad Norm=10.3477, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=0.4282, Train Acc=85.75%, Val Loss=1.0457, Val Acc=67.92%, Grad Norm=10.4943, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=0.4221, Train Acc=86.04%, Val Loss=1.0432, Val Acc=67.69%, Grad Norm=10.5912, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=0.4157, Train Acc=86.10%, Val Loss=1.0486, Val Acc=67.78%, Grad Norm=10.7615, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=0.4067, Train Acc=86.68%, Val Loss=1.0805, Val Acc=67.44%, Grad Norm=10.7716, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=0.4045, Train Acc=86.62%, Val Loss=1.0659, Val Acc=67.70%, Grad Norm=10.9437, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=0.3970, Train Acc=86.93%, Val Loss=1.0637, Val Acc=67.87%, Grad Norm=11.0407, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=0.3955, Train Acc=86.94%, Val Loss=1.0679, Val Acc=67.63%, Grad Norm=11.1706, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=0.3964, Train Acc=86.91%, Val Loss=1.0577, Val Acc=67.59%, Grad Norm=11.3359, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=0.3868, Train Acc=87.28%, Val Loss=1.0699, Val Acc=67.74%, Grad Norm=11.4126, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=0.3829, Train Acc=87.43%, Val Loss=1.0752, Val Acc=67.77%, Grad Norm=11.3901, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=0.3847, Train Acc=87.26%, Val Loss=1.0747, Val Acc=67.85%, Grad Norm=11.5942, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=0.3757, Train Acc=87.69%, Val Loss=1.0634, Val Acc=67.63%, Grad Norm=11.6716, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=0.3733, Train Acc=87.74%, Val Loss=1.0789, Val Acc=67.68%, Grad Norm=11.7387, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=0.3679, Train Acc=87.98%, Val Loss=1.0759, Val Acc=67.71%, Grad Norm=11.6962, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=0.3628, Train Acc=88.28%, Val Loss=1.0700, Val Acc=67.91%, Grad Norm=11.6643, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=0.3695, Train Acc=87.83%, Val Loss=1.0721, Val Acc=67.95%, Grad Norm=11.9276, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=0.3667, Train Acc=87.99%, Val Loss=1.0786, Val Acc=67.69%, Grad Norm=11.9318, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=0.3619, Train Acc=88.21%, Val Loss=1.0654, Val Acc=67.72%, Grad Norm=11.9561, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=0.3565, Train Acc=88.45%, Val Loss=1.0745, Val Acc=67.84%, Grad Norm=11.9525, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=0.3564, Train Acc=88.32%, Val Loss=1.0800, Val Acc=67.63%, Grad Norm=12.1238, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=0.3538, Train Acc=88.51%, Val Loss=1.0718, Val Acc=68.08%, Grad Norm=12.1107, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=0.3518, Train Acc=88.38%, Val Loss=1.0808, Val Acc=67.92%, Grad Norm=12.1644, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=0.3500, Train Acc=88.60%, Val Loss=1.0681, Val Acc=68.06%, Grad Norm=12.2213, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=0.3476, Train Acc=88.69%, Val Loss=1.0704, Val Acc=67.97%, Grad Norm=12.1880, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=0.3502, Train Acc=88.67%, Val Loss=1.0757, Val Acc=67.88%, Grad Norm=12.2800, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=0.3467, Train Acc=88.72%, Val Loss=1.0719, Val Acc=68.17%, Grad Norm=12.3227, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=0.3458, Train Acc=88.94%, Val Loss=1.0749, Val Acc=68.08%, Grad Norm=12.2854, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=0.3461, Train Acc=88.85%, Val Loss=1.0753, Val Acc=67.78%, Grad Norm=12.4006, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=0.3433, Train Acc=88.65%, Val Loss=1.0810, Val Acc=67.95%, Grad Norm=12.3989, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=0.3424, Train Acc=88.93%, Val Loss=1.0794, Val Acc=68.00%, Grad Norm=12.3939, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=0.3428, Train Acc=88.90%, Val Loss=1.0677, Val Acc=68.13%, Grad Norm=12.4888, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=0.3388, Train Acc=89.07%, Val Loss=1.0802, Val Acc=67.95%, Grad Norm=12.4305, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=0.3402, Train Acc=89.03%, Val Loss=1.0704, Val Acc=68.22%, Grad Norm=12.4754, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=0.3391, Train Acc=89.05%, Val Loss=1.0818, Val Acc=67.93%, Grad Norm=12.4779, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=0.3391, Train Acc=88.99%, Val Loss=1.0716, Val Acc=68.13%, Grad Norm=12.5483, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=0.3371, Train Acc=89.04%, Val Loss=1.0833, Val Acc=67.92%, Grad Norm=12.5101, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=0.3365, Train Acc=89.01%, Val Loss=1.0790, Val Acc=68.10%, Grad Norm=12.5662, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=0.3376, Train Acc=89.04%, Val Loss=1.0703, Val Acc=68.15%, Grad Norm=12.5776, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=0.3352, Train Acc=89.19%, Val Loss=1.0756, Val Acc=68.20%, Grad Norm=12.5478, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=0.3379, Train Acc=89.11%, Val Loss=1.0773, Val Acc=67.82%, Grad Norm=12.7096, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=0.3365, Train Acc=88.88%, Val Loss=1.0779, Val Acc=68.09%, Grad Norm=12.6966, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=0.3368, Train Acc=89.12%, Val Loss=1.0754, Val Acc=67.99%, Grad Norm=12.6735, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=0.3323, Train Acc=89.28%, Val Loss=1.0699, Val Acc=68.17%, Grad Norm=12.5891, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=0.3325, Train Acc=89.23%, Val Loss=1.0741, Val Acc=67.94%, Grad Norm=12.6540, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=0.3320, Train Acc=89.27%, Val Loss=1.0748, Val Acc=68.13%, Grad Norm=12.6547, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=0.3312, Train Acc=89.35%, Val Loss=1.0830, Val Acc=67.74%, Grad Norm=12.6043, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=0.3310, Train Acc=89.28%, Val Loss=1.0796, Val Acc=68.07%, Grad Norm=12.6356, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=0.3300, Train Acc=89.30%, Val Loss=1.0822, Val Acc=68.03%, Grad Norm=12.6413, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=0.3312, Train Acc=89.31%, Val Loss=1.0844, Val Acc=67.88%, Grad Norm=12.6580, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=0.3336, Train Acc=89.19%, Val Loss=1.0801, Val Acc=68.08%, Grad Norm=12.7388, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=0.3309, Train Acc=89.29%, Val Loss=1.0774, Val Acc=68.06%, Grad Norm=12.6588, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=0.3361, Train Acc=89.08%, Val Loss=1.0786, Val Acc=67.89%, Grad Norm=12.7843, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=0.3308, Train Acc=89.33%, Val Loss=1.0873, Val Acc=67.99%, Grad Norm=12.6994, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=0.3298, Train Acc=89.39%, Val Loss=1.0855, Val Acc=67.94%, Grad Norm=12.6352, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=0.3308, Train Acc=89.34%, Val Loss=1.0800, Val Acc=68.17%, Grad Norm=12.7001, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=0.3321, Train Acc=89.27%, Val Loss=1.0760, Val Acc=68.21%, Grad Norm=12.7205, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=0.3319, Train Acc=89.20%, Val Loss=1.0869, Val Acc=68.00%, Grad Norm=12.7448, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=0.3280, Train Acc=89.36%, Val Loss=1.0804, Val Acc=68.00%, Grad Norm=12.6798, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=0.3276, Train Acc=89.49%, Val Loss=1.0778, Val Acc=68.12%, Grad Norm=12.6621, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=0.3302, Train Acc=89.33%, Val Loss=1.0843, Val Acc=67.85%, Grad Norm=12.7389, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=0.3319, Train Acc=89.14%, Val Loss=1.0762, Val Acc=68.00%, Grad Norm=12.8036, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=0.3288, Train Acc=89.42%, Val Loss=1.0755, Val Acc=68.11%, Grad Norm=12.7485, LR=1.95313e-07\n",
      "Fold 4, Epoch 101: Train Loss=0.3279, Train Acc=89.44%, Val Loss=1.0855, Val Acc=68.00%, Grad Norm=12.7349, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=68.22%）\n",
      "Fold 4 DONE | Best Val Acc≈68.22% | Final Val Acc=68.22% | Test Acc=65.58%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.0656, Train Acc=21.28%, Val Loss=2.2323, Val Acc=25.06%, Grad Norm=6.6346, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=1.6189, Train Acc=39.87%, Val Loss=1.8171, Val Acc=39.22%, Grad Norm=5.4177, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=1.3290, Train Acc=51.17%, Val Loss=1.7429, Val Acc=46.20%, Grad Norm=4.6622, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=1.1740, Train Acc=57.51%, Val Loss=1.6559, Val Acc=49.24%, Grad Norm=4.3304, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.0765, Train Acc=61.09%, Val Loss=1.5291, Val Acc=52.82%, Grad Norm=4.1423, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.0127, Train Acc=63.57%, Val Loss=1.4583, Val Acc=52.62%, Grad Norm=4.1491, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=0.9623, Train Acc=65.70%, Val Loss=1.4119, Val Acc=54.16%, Grad Norm=4.0719, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=0.9212, Train Acc=67.27%, Val Loss=1.4179, Val Acc=55.87%, Grad Norm=4.1232, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=0.8870, Train Acc=68.51%, Val Loss=1.5384, Val Acc=53.77%, Grad Norm=4.1997, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=0.8576, Train Acc=69.88%, Val Loss=1.3218, Val Acc=56.54%, Grad Norm=4.3086, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=0.8012, Train Acc=71.85%, Val Loss=1.3731, Val Acc=56.26%, Grad Norm=4.4555, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=0.7736, Train Acc=73.13%, Val Loss=1.3391, Val Acc=56.61%, Grad Norm=4.8171, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=0.7546, Train Acc=73.71%, Val Loss=1.3302, Val Acc=57.07%, Grad Norm=5.0220, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=0.7381, Train Acc=74.48%, Val Loss=1.3676, Val Acc=58.18%, Grad Norm=5.3212, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=0.7171, Train Acc=75.05%, Val Loss=1.3814, Val Acc=56.83%, Grad Norm=5.5291, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=0.7009, Train Acc=75.81%, Val Loss=1.3762, Val Acc=57.20%, Grad Norm=5.7703, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=0.6831, Train Acc=76.60%, Val Loss=1.2900, Val Acc=59.16%, Grad Norm=5.9342, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=0.6696, Train Acc=76.76%, Val Loss=1.3587, Val Acc=57.34%, Grad Norm=6.1845, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=0.6541, Train Acc=77.59%, Val Loss=1.3352, Val Acc=58.45%, Grad Norm=6.4329, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=0.6383, Train Acc=78.19%, Val Loss=1.2781, Val Acc=59.31%, Grad Norm=6.6252, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=0.5981, Train Acc=79.70%, Val Loss=1.3036, Val Acc=58.87%, Grad Norm=6.7494, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=0.5828, Train Acc=80.24%, Val Loss=1.2750, Val Acc=60.35%, Grad Norm=7.1275, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=0.5673, Train Acc=80.78%, Val Loss=1.2584, Val Acc=60.17%, Grad Norm=7.3262, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=0.5556, Train Acc=81.25%, Val Loss=1.2630, Val Acc=60.55%, Grad Norm=7.5083, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=0.5465, Train Acc=81.44%, Val Loss=1.3059, Val Acc=58.81%, Grad Norm=7.8087, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=0.5379, Train Acc=81.78%, Val Loss=1.2775, Val Acc=60.06%, Grad Norm=8.0066, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=0.5241, Train Acc=82.24%, Val Loss=1.2889, Val Acc=60.45%, Grad Norm=8.2219, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=0.5180, Train Acc=82.59%, Val Loss=1.2978, Val Acc=60.14%, Grad Norm=8.4050, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=0.5101, Train Acc=82.82%, Val Loss=1.3156, Val Acc=60.10%, Grad Norm=8.5882, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=0.4992, Train Acc=83.14%, Val Loss=1.2497, Val Acc=61.62%, Grad Norm=8.7955, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=0.4808, Train Acc=84.02%, Val Loss=1.2933, Val Acc=61.07%, Grad Norm=8.9692, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=0.4681, Train Acc=84.32%, Val Loss=1.2955, Val Acc=60.30%, Grad Norm=9.2677, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=0.4563, Train Acc=84.81%, Val Loss=1.2961, Val Acc=61.02%, Grad Norm=9.3154, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=0.4533, Train Acc=84.96%, Val Loss=1.2695, Val Acc=61.01%, Grad Norm=9.5423, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=0.4486, Train Acc=85.00%, Val Loss=1.2768, Val Acc=61.37%, Grad Norm=9.7074, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=0.4397, Train Acc=85.32%, Val Loss=1.2473, Val Acc=62.06%, Grad Norm=9.8231, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=0.4299, Train Acc=85.68%, Val Loss=1.2981, Val Acc=61.28%, Grad Norm=9.9588, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=0.4283, Train Acc=85.79%, Val Loss=1.3041, Val Acc=61.30%, Grad Norm=10.0973, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=0.4210, Train Acc=86.12%, Val Loss=1.2672, Val Acc=61.37%, Grad Norm=10.2904, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=0.4157, Train Acc=86.11%, Val Loss=1.2790, Val Acc=61.60%, Grad Norm=10.4438, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=0.4086, Train Acc=86.54%, Val Loss=1.2685, Val Acc=61.80%, Grad Norm=10.5172, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=0.4021, Train Acc=86.64%, Val Loss=1.2847, Val Acc=61.63%, Grad Norm=10.6870, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=0.3960, Train Acc=86.97%, Val Loss=1.2747, Val Acc=62.08%, Grad Norm=10.7355, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=0.3906, Train Acc=87.24%, Val Loss=1.2872, Val Acc=61.76%, Grad Norm=10.7841, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=0.3867, Train Acc=87.33%, Val Loss=1.2790, Val Acc=62.20%, Grad Norm=11.0250, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=0.3793, Train Acc=87.62%, Val Loss=1.2714, Val Acc=62.27%, Grad Norm=11.0549, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=0.3824, Train Acc=87.31%, Val Loss=1.2772, Val Acc=62.08%, Grad Norm=11.1752, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=0.3834, Train Acc=87.34%, Val Loss=1.2808, Val Acc=62.41%, Grad Norm=11.3834, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=0.3749, Train Acc=87.85%, Val Loss=1.2784, Val Acc=61.64%, Grad Norm=11.3827, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=0.3713, Train Acc=87.87%, Val Loss=1.2729, Val Acc=62.20%, Grad Norm=11.4600, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=0.3651, Train Acc=88.14%, Val Loss=1.2558, Val Acc=62.58%, Grad Norm=11.4900, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=0.3589, Train Acc=88.24%, Val Loss=1.2809, Val Acc=62.31%, Grad Norm=11.4927, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=0.3580, Train Acc=88.35%, Val Loss=1.2974, Val Acc=62.31%, Grad Norm=11.5955, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=0.3607, Train Acc=88.20%, Val Loss=1.2775, Val Acc=62.59%, Grad Norm=11.7322, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=0.3610, Train Acc=88.15%, Val Loss=1.2925, Val Acc=62.26%, Grad Norm=11.8200, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=0.3565, Train Acc=88.54%, Val Loss=1.2726, Val Acc=62.49%, Grad Norm=11.8031, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=0.3514, Train Acc=88.52%, Val Loss=1.2759, Val Acc=62.40%, Grad Norm=11.8260, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=0.3534, Train Acc=88.45%, Val Loss=1.2797, Val Acc=61.97%, Grad Norm=11.9261, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=0.3523, Train Acc=88.54%, Val Loss=1.2654, Val Acc=62.43%, Grad Norm=11.9720, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=0.3497, Train Acc=88.43%, Val Loss=1.2863, Val Acc=62.44%, Grad Norm=12.0299, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=0.3488, Train Acc=88.70%, Val Loss=1.2886, Val Acc=62.40%, Grad Norm=12.0659, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=0.3448, Train Acc=88.74%, Val Loss=1.2914, Val Acc=62.31%, Grad Norm=12.0889, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=0.3414, Train Acc=88.97%, Val Loss=1.2782, Val Acc=62.64%, Grad Norm=12.0619, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=0.3455, Train Acc=88.82%, Val Loss=1.2785, Val Acc=62.55%, Grad Norm=12.2264, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=0.3467, Train Acc=88.67%, Val Loss=1.2800, Val Acc=62.62%, Grad Norm=12.2777, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=0.3390, Train Acc=88.90%, Val Loss=1.2975, Val Acc=62.06%, Grad Norm=12.2266, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=0.3337, Train Acc=89.19%, Val Loss=1.2808, Val Acc=62.29%, Grad Norm=12.1915, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=0.3357, Train Acc=89.21%, Val Loss=1.2785, Val Acc=62.51%, Grad Norm=12.2878, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=0.3378, Train Acc=89.05%, Val Loss=1.2721, Val Acc=62.66%, Grad Norm=12.3254, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=0.3355, Train Acc=89.07%, Val Loss=1.2911, Val Acc=62.45%, Grad Norm=12.3281, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=0.3339, Train Acc=88.99%, Val Loss=1.2697, Val Acc=62.87%, Grad Norm=12.3217, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=0.3319, Train Acc=89.19%, Val Loss=1.2713, Val Acc=62.93%, Grad Norm=12.3204, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=0.3356, Train Acc=89.14%, Val Loss=1.2809, Val Acc=62.62%, Grad Norm=12.4051, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=0.3336, Train Acc=89.10%, Val Loss=1.2871, Val Acc=62.64%, Grad Norm=12.4264, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=0.3351, Train Acc=89.09%, Val Loss=1.2885, Val Acc=62.48%, Grad Norm=12.4153, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=0.3326, Train Acc=89.26%, Val Loss=1.2780, Val Acc=62.75%, Grad Norm=12.4239, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=0.3305, Train Acc=89.28%, Val Loss=1.2963, Val Acc=62.53%, Grad Norm=12.3835, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=0.3290, Train Acc=89.56%, Val Loss=1.3026, Val Acc=62.15%, Grad Norm=12.3485, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=0.3343, Train Acc=89.10%, Val Loss=1.2750, Val Acc=62.56%, Grad Norm=12.5364, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=0.3315, Train Acc=89.34%, Val Loss=1.2892, Val Acc=62.60%, Grad Norm=12.5270, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=0.3337, Train Acc=89.28%, Val Loss=1.2874, Val Acc=62.59%, Grad Norm=12.5549, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=0.3280, Train Acc=89.32%, Val Loss=1.2719, Val Acc=62.65%, Grad Norm=12.4297, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=0.3311, Train Acc=89.20%, Val Loss=1.2834, Val Acc=62.86%, Grad Norm=12.4718, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=0.3278, Train Acc=89.56%, Val Loss=1.2864, Val Acc=62.57%, Grad Norm=12.4412, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=0.3270, Train Acc=89.43%, Val Loss=1.2882, Val Acc=62.41%, Grad Norm=12.4733, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=0.3310, Train Acc=89.21%, Val Loss=1.2718, Val Acc=62.90%, Grad Norm=12.5932, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=0.3244, Train Acc=89.43%, Val Loss=1.2927, Val Acc=62.64%, Grad Norm=12.4474, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=0.3257, Train Acc=89.59%, Val Loss=1.2791, Val Acc=62.75%, Grad Norm=12.4956, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=0.3283, Train Acc=89.30%, Val Loss=1.2828, Val Acc=62.75%, Grad Norm=12.5733, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=0.3299, Train Acc=89.33%, Val Loss=1.2871, Val Acc=62.67%, Grad Norm=12.5961, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=0.3236, Train Acc=89.58%, Val Loss=1.2990, Val Acc=62.38%, Grad Norm=12.4586, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=0.3281, Train Acc=89.33%, Val Loss=1.2878, Val Acc=62.42%, Grad Norm=12.5961, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=0.3250, Train Acc=89.53%, Val Loss=1.2841, Val Acc=62.65%, Grad Norm=12.5815, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=0.3271, Train Acc=89.36%, Val Loss=1.2843, Val Acc=62.41%, Grad Norm=12.5675, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=0.3281, Train Acc=89.42%, Val Loss=1.2909, Val Acc=62.32%, Grad Norm=12.5335, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=0.3297, Train Acc=89.27%, Val Loss=1.2796, Val Acc=62.60%, Grad Norm=12.6418, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=0.3264, Train Acc=89.51%, Val Loss=1.2887, Val Acc=62.64%, Grad Norm=12.5507, LR=1.95313e-07\n",
      "Fold 5, Epoch 98: Train Loss=0.3250, Train Acc=89.52%, Val Loss=1.2854, Val Acc=62.70%, Grad Norm=12.5573, LR=1.95313e-07\n",
      "Fold 5, Epoch 99: Train Loss=0.3274, Train Acc=89.53%, Val Loss=1.2862, Val Acc=62.59%, Grad Norm=12.6267, LR=1.95313e-07\n",
      "Fold 5, Epoch 100: Train Loss=0.3277, Train Acc=89.32%, Val Loss=1.2907, Val Acc=62.36%, Grad Norm=12.6274, LR=1.95313e-07\n",
      "Fold 5, Epoch 101: Train Loss=0.3230, Train Acc=89.61%, Val Loss=1.2882, Val Acc=62.72%, Grad Norm=12.5393, LR=9.76563e-08\n",
      "Fold 5, Epoch 102: Train Loss=0.3251, Train Acc=89.46%, Val Loss=1.2794, Val Acc=62.71%, Grad Norm=12.5925, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=62.93%）\n",
      "Fold 5 DONE | Best Val Acc≈62.93% | Final Val Acc=62.93% | Test Acc=64.57%\n",
      "[INFO] SNR=15 dB | Mean Test Acc: 63.73% ± 1.33%\n",
      "[INFO] SNR  15 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR15dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = 10 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:11<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.1577, Train Acc=16.55%, Val Loss=3.1244, Val Acc=13.98%, Grad Norm=6.9637, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=1.8520, Train Acc=30.56%, Val Loss=1.9238, Val Acc=31.65%, Grad Norm=6.1651, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=1.5303, Train Acc=43.16%, Val Loss=1.5740, Val Acc=42.82%, Grad Norm=5.0853, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=1.3113, Train Acc=52.22%, Val Loss=1.4299, Val Acc=48.53%, Grad Norm=4.6503, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=1.1831, Train Acc=56.87%, Val Loss=1.3543, Val Acc=50.90%, Grad Norm=4.4132, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.1071, Train Acc=60.17%, Val Loss=1.2811, Val Acc=54.42%, Grad Norm=4.2893, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=1.0489, Train Acc=62.45%, Val Loss=1.2812, Val Acc=55.44%, Grad Norm=4.2252, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=1.0073, Train Acc=63.88%, Val Loss=1.2502, Val Acc=56.01%, Grad Norm=4.1949, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=0.9665, Train Acc=65.64%, Val Loss=1.2105, Val Acc=56.94%, Grad Norm=4.2452, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=0.9355, Train Acc=67.05%, Val Loss=1.2372, Val Acc=57.63%, Grad Norm=4.2012, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=0.8810, Train Acc=68.96%, Val Loss=1.1994, Val Acc=58.48%, Grad Norm=4.3368, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=0.8574, Train Acc=69.76%, Val Loss=1.1891, Val Acc=59.65%, Grad Norm=4.6406, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=0.8445, Train Acc=70.28%, Val Loss=1.1638, Val Acc=60.13%, Grad Norm=4.8362, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=0.8235, Train Acc=71.17%, Val Loss=1.2128, Val Acc=59.26%, Grad Norm=5.0471, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=0.8042, Train Acc=72.00%, Val Loss=1.1771, Val Acc=60.01%, Grad Norm=5.1976, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=0.7933, Train Acc=72.41%, Val Loss=1.1619, Val Acc=60.40%, Grad Norm=5.4432, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=0.7749, Train Acc=73.00%, Val Loss=1.1644, Val Acc=60.09%, Grad Norm=5.5756, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=0.7616, Train Acc=73.53%, Val Loss=1.1674, Val Acc=61.10%, Grad Norm=5.7780, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=0.7471, Train Acc=74.20%, Val Loss=1.1966, Val Acc=60.54%, Grad Norm=5.9544, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=0.7299, Train Acc=74.89%, Val Loss=1.1688, Val Acc=60.22%, Grad Norm=6.1351, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=0.6946, Train Acc=76.10%, Val Loss=1.1539, Val Acc=61.80%, Grad Norm=6.3903, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=0.6772, Train Acc=76.84%, Val Loss=1.1740, Val Acc=61.84%, Grad Norm=6.6988, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=0.6693, Train Acc=77.17%, Val Loss=1.1762, Val Acc=62.03%, Grad Norm=6.9302, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=0.6496, Train Acc=77.88%, Val Loss=1.1852, Val Acc=61.82%, Grad Norm=7.1516, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=0.6394, Train Acc=78.24%, Val Loss=1.1725, Val Acc=61.95%, Grad Norm=7.4244, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=0.6292, Train Acc=78.63%, Val Loss=1.1269, Val Acc=62.25%, Grad Norm=7.5172, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=0.6229, Train Acc=78.93%, Val Loss=1.1728, Val Acc=61.86%, Grad Norm=7.8329, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=0.6118, Train Acc=79.31%, Val Loss=1.1874, Val Acc=62.07%, Grad Norm=7.9114, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=0.6018, Train Acc=79.70%, Val Loss=1.1648, Val Acc=62.77%, Grad Norm=8.2070, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=0.5988, Train Acc=79.74%, Val Loss=1.1788, Val Acc=62.21%, Grad Norm=8.3914, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=0.5674, Train Acc=81.02%, Val Loss=1.1785, Val Acc=63.22%, Grad Norm=8.5019, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=0.5595, Train Acc=81.21%, Val Loss=1.1753, Val Acc=62.95%, Grad Norm=8.7368, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=0.5510, Train Acc=81.42%, Val Loss=1.1749, Val Acc=62.68%, Grad Norm=8.9081, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=0.5451, Train Acc=81.62%, Val Loss=1.1569, Val Acc=63.51%, Grad Norm=9.1433, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=0.5445, Train Acc=81.70%, Val Loss=1.1551, Val Acc=63.24%, Grad Norm=9.2863, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=0.5336, Train Acc=82.31%, Val Loss=1.1548, Val Acc=63.28%, Grad Norm=9.4100, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=0.5219, Train Acc=82.48%, Val Loss=1.1722, Val Acc=63.33%, Grad Norm=9.5984, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=0.5188, Train Acc=82.64%, Val Loss=1.1710, Val Acc=63.10%, Grad Norm=9.7857, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=0.5135, Train Acc=82.76%, Val Loss=1.1820, Val Acc=63.16%, Grad Norm=9.9606, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=0.5091, Train Acc=82.85%, Val Loss=1.1935, Val Acc=63.50%, Grad Norm=10.0912, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=0.4996, Train Acc=83.52%, Val Loss=1.1663, Val Acc=63.84%, Grad Norm=10.1503, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=0.4881, Train Acc=83.56%, Val Loss=1.1816, Val Acc=63.83%, Grad Norm=10.2263, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=0.4818, Train Acc=84.03%, Val Loss=1.1784, Val Acc=63.99%, Grad Norm=10.3516, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=0.4885, Train Acc=83.75%, Val Loss=1.1950, Val Acc=63.48%, Grad Norm=10.5248, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=0.4782, Train Acc=84.07%, Val Loss=1.1845, Val Acc=63.75%, Grad Norm=10.6175, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=0.4753, Train Acc=84.24%, Val Loss=1.1929, Val Acc=63.80%, Grad Norm=10.6830, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=0.4723, Train Acc=84.41%, Val Loss=1.1869, Val Acc=63.95%, Grad Norm=10.7682, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=0.4716, Train Acc=84.27%, Val Loss=1.1722, Val Acc=63.80%, Grad Norm=10.9279, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=0.4637, Train Acc=84.62%, Val Loss=1.1801, Val Acc=63.94%, Grad Norm=10.9447, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=0.4610, Train Acc=84.80%, Val Loss=1.1839, Val Acc=63.78%, Grad Norm=11.0161, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=0.4572, Train Acc=84.87%, Val Loss=1.1807, Val Acc=64.19%, Grad Norm=11.1145, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=0.4592, Train Acc=84.79%, Val Loss=1.1821, Val Acc=64.01%, Grad Norm=11.2106, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=0.4512, Train Acc=84.99%, Val Loss=1.1930, Val Acc=63.96%, Grad Norm=11.2105, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=0.4532, Train Acc=85.14%, Val Loss=1.2069, Val Acc=63.94%, Grad Norm=11.3714, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=0.4415, Train Acc=85.31%, Val Loss=1.1946, Val Acc=64.07%, Grad Norm=11.3413, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=0.4468, Train Acc=85.34%, Val Loss=1.1920, Val Acc=64.34%, Grad Norm=11.4574, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=0.4441, Train Acc=85.50%, Val Loss=1.1894, Val Acc=64.07%, Grad Norm=11.4605, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=0.4377, Train Acc=85.67%, Val Loss=1.2002, Val Acc=63.83%, Grad Norm=11.4645, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=0.4402, Train Acc=85.43%, Val Loss=1.2029, Val Acc=64.08%, Grad Norm=11.6318, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=0.4327, Train Acc=85.89%, Val Loss=1.1989, Val Acc=64.12%, Grad Norm=11.5523, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=0.4353, Train Acc=85.67%, Val Loss=1.1963, Val Acc=64.10%, Grad Norm=11.6395, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=0.4320, Train Acc=85.62%, Val Loss=1.1993, Val Acc=63.92%, Grad Norm=11.6847, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=0.4339, Train Acc=85.66%, Val Loss=1.2003, Val Acc=63.77%, Grad Norm=11.8018, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=0.4301, Train Acc=85.80%, Val Loss=1.2054, Val Acc=64.08%, Grad Norm=11.7636, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=0.4316, Train Acc=85.71%, Val Loss=1.2006, Val Acc=63.80%, Grad Norm=11.8426, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=0.4316, Train Acc=85.90%, Val Loss=1.1875, Val Acc=64.04%, Grad Norm=11.8392, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=0.4285, Train Acc=86.02%, Val Loss=1.1883, Val Acc=64.10%, Grad Norm=11.8308, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=0.4315, Train Acc=85.79%, Val Loss=1.1991, Val Acc=64.21%, Grad Norm=11.9723, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=0.4245, Train Acc=86.22%, Val Loss=1.1919, Val Acc=64.17%, Grad Norm=11.8487, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=0.4214, Train Acc=86.38%, Val Loss=1.1964, Val Acc=63.81%, Grad Norm=11.8635, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=0.4212, Train Acc=86.17%, Val Loss=1.1980, Val Acc=64.08%, Grad Norm=11.9479, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=0.4225, Train Acc=86.23%, Val Loss=1.1985, Val Acc=63.98%, Grad Norm=11.9893, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=0.4185, Train Acc=86.37%, Val Loss=1.2051, Val Acc=63.87%, Grad Norm=11.9074, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=0.4205, Train Acc=86.25%, Val Loss=1.1946, Val Acc=63.99%, Grad Norm=11.9637, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=0.4158, Train Acc=86.39%, Val Loss=1.1941, Val Acc=64.21%, Grad Norm=11.8810, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=0.4261, Train Acc=85.91%, Val Loss=1.1905, Val Acc=64.01%, Grad Norm=12.0843, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=0.4201, Train Acc=86.16%, Val Loss=1.1878, Val Acc=64.11%, Grad Norm=11.9889, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=0.4217, Train Acc=85.99%, Val Loss=1.1866, Val Acc=64.15%, Grad Norm=12.1147, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=0.4209, Train Acc=86.27%, Val Loss=1.2015, Val Acc=63.94%, Grad Norm=12.0888, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=0.4204, Train Acc=86.18%, Val Loss=1.1892, Val Acc=64.33%, Grad Norm=12.1203, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=0.4172, Train Acc=86.25%, Val Loss=1.1959, Val Acc=64.10%, Grad Norm=12.1134, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=0.4209, Train Acc=86.15%, Val Loss=1.1967, Val Acc=64.04%, Grad Norm=12.1854, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=0.4133, Train Acc=86.70%, Val Loss=1.1982, Val Acc=63.91%, Grad Norm=12.0735, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=0.4175, Train Acc=86.53%, Val Loss=1.1893, Val Acc=64.11%, Grad Norm=12.1539, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=0.4181, Train Acc=86.34%, Val Loss=1.2048, Val Acc=64.12%, Grad Norm=12.1672, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=0.4177, Train Acc=86.35%, Val Loss=1.1836, Val Acc=64.26%, Grad Norm=12.1897, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=64.34%）\n",
      "Fold 1 DONE | Best Val Acc≈64.34% | Final Val Acc=64.34% | Test Acc=62.86%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.1558, Train Acc=17.00%, Val Loss=2.8875, Val Acc=16.60%, Grad Norm=7.0681, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=1.8261, Train Acc=31.63%, Val Loss=2.0991, Val Acc=32.84%, Grad Norm=6.3982, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=1.4816, Train Acc=45.11%, Val Loss=1.5226, Val Acc=45.67%, Grad Norm=5.1498, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=1.2720, Train Acc=53.62%, Val Loss=1.3919, Val Acc=49.92%, Grad Norm=4.5199, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.1596, Train Acc=57.70%, Val Loss=1.3756, Val Acc=50.97%, Grad Norm=4.1376, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.0967, Train Acc=60.26%, Val Loss=1.3572, Val Acc=52.18%, Grad Norm=4.0438, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=1.0403, Train Acc=62.60%, Val Loss=1.2896, Val Acc=54.36%, Grad Norm=4.0146, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=0.9991, Train Acc=63.86%, Val Loss=1.3240, Val Acc=55.36%, Grad Norm=4.0378, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=0.9669, Train Acc=65.19%, Val Loss=1.2965, Val Acc=54.18%, Grad Norm=4.0241, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=0.9395, Train Acc=66.47%, Val Loss=1.2767, Val Acc=57.02%, Grad Norm=4.0650, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=0.8868, Train Acc=68.27%, Val Loss=1.2011, Val Acc=58.19%, Grad Norm=4.2483, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=0.8595, Train Acc=69.36%, Val Loss=1.2436, Val Acc=57.68%, Grad Norm=4.5218, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=0.8395, Train Acc=70.14%, Val Loss=1.2056, Val Acc=59.26%, Grad Norm=4.6658, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=0.8225, Train Acc=70.93%, Val Loss=1.1756, Val Acc=59.56%, Grad Norm=4.9704, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=0.8139, Train Acc=71.54%, Val Loss=1.1827, Val Acc=58.71%, Grad Norm=5.0699, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=0.8014, Train Acc=71.78%, Val Loss=1.2079, Val Acc=58.56%, Grad Norm=5.2541, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=0.7810, Train Acc=72.58%, Val Loss=1.1982, Val Acc=58.98%, Grad Norm=5.4395, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=0.7639, Train Acc=73.28%, Val Loss=1.1874, Val Acc=59.53%, Grad Norm=5.6785, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=0.7514, Train Acc=73.87%, Val Loss=1.1544, Val Acc=60.21%, Grad Norm=5.7913, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=0.7381, Train Acc=74.39%, Val Loss=1.1542, Val Acc=60.21%, Grad Norm=6.0071, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=0.7033, Train Acc=75.69%, Val Loss=1.1422, Val Acc=60.81%, Grad Norm=6.2511, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=0.6905, Train Acc=76.30%, Val Loss=1.1722, Val Acc=61.16%, Grad Norm=6.5370, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=0.6807, Train Acc=76.53%, Val Loss=1.1717, Val Acc=60.97%, Grad Norm=6.7736, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=0.6699, Train Acc=76.98%, Val Loss=1.1631, Val Acc=60.99%, Grad Norm=6.9383, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=0.6583, Train Acc=77.44%, Val Loss=1.1394, Val Acc=61.38%, Grad Norm=7.2117, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=0.6493, Train Acc=77.81%, Val Loss=1.1491, Val Acc=60.93%, Grad Norm=7.4774, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=0.6416, Train Acc=78.15%, Val Loss=1.1398, Val Acc=61.52%, Grad Norm=7.6227, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=0.6305, Train Acc=78.58%, Val Loss=1.1786, Val Acc=60.91%, Grad Norm=7.8300, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=0.6178, Train Acc=78.76%, Val Loss=1.1729, Val Acc=61.33%, Grad Norm=8.1272, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=0.6109, Train Acc=79.17%, Val Loss=1.1447, Val Acc=61.49%, Grad Norm=8.3201, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=0.5935, Train Acc=79.88%, Val Loss=1.1534, Val Acc=61.68%, Grad Norm=8.4523, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=0.5779, Train Acc=80.39%, Val Loss=1.1525, Val Acc=62.23%, Grad Norm=8.6402, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=0.5668, Train Acc=80.97%, Val Loss=1.1513, Val Acc=61.90%, Grad Norm=8.7952, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=0.5633, Train Acc=81.15%, Val Loss=1.1502, Val Acc=62.12%, Grad Norm=9.0774, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=0.5565, Train Acc=81.40%, Val Loss=1.1673, Val Acc=61.82%, Grad Norm=9.1398, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=0.5519, Train Acc=81.45%, Val Loss=1.1694, Val Acc=62.13%, Grad Norm=9.3340, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=0.5411, Train Acc=81.89%, Val Loss=1.1579, Val Acc=62.37%, Grad Norm=9.4988, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=0.5374, Train Acc=81.87%, Val Loss=1.1296, Val Acc=62.67%, Grad Norm=9.7236, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=0.5282, Train Acc=82.34%, Val Loss=1.1681, Val Acc=62.12%, Grad Norm=9.8880, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=0.5244, Train Acc=82.49%, Val Loss=1.1860, Val Acc=62.00%, Grad Norm=10.0889, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=0.5121, Train Acc=82.93%, Val Loss=1.1555, Val Acc=62.37%, Grad Norm=10.0983, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=0.5067, Train Acc=83.08%, Val Loss=1.1570, Val Acc=62.53%, Grad Norm=10.2488, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=0.5048, Train Acc=83.36%, Val Loss=1.1421, Val Acc=62.96%, Grad Norm=10.4069, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=0.5019, Train Acc=83.16%, Val Loss=1.1698, Val Acc=62.36%, Grad Norm=10.5572, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=0.4984, Train Acc=83.52%, Val Loss=1.1598, Val Acc=62.52%, Grad Norm=10.6898, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=0.5009, Train Acc=83.23%, Val Loss=1.1582, Val Acc=62.51%, Grad Norm=10.8340, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=0.4898, Train Acc=83.72%, Val Loss=1.1608, Val Acc=62.79%, Grad Norm=10.9084, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=0.4886, Train Acc=83.38%, Val Loss=1.1846, Val Acc=62.13%, Grad Norm=11.0192, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=0.4841, Train Acc=84.01%, Val Loss=1.1601, Val Acc=62.52%, Grad Norm=11.0246, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=0.4812, Train Acc=84.17%, Val Loss=1.1578, Val Acc=62.58%, Grad Norm=11.1284, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=0.4713, Train Acc=84.41%, Val Loss=1.1548, Val Acc=62.91%, Grad Norm=11.1689, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=0.4686, Train Acc=84.40%, Val Loss=1.1639, Val Acc=62.54%, Grad Norm=11.2896, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=0.4692, Train Acc=84.48%, Val Loss=1.1705, Val Acc=62.43%, Grad Norm=11.4030, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=0.4719, Train Acc=84.22%, Val Loss=1.1617, Val Acc=62.97%, Grad Norm=11.4555, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=0.4644, Train Acc=84.61%, Val Loss=1.1534, Val Acc=62.69%, Grad Norm=11.4388, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=0.4629, Train Acc=84.58%, Val Loss=1.1649, Val Acc=62.37%, Grad Norm=11.5192, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=0.4589, Train Acc=84.93%, Val Loss=1.1588, Val Acc=62.88%, Grad Norm=11.5377, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=0.4567, Train Acc=84.96%, Val Loss=1.1679, Val Acc=62.67%, Grad Norm=11.6397, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=0.4583, Train Acc=84.93%, Val Loss=1.1667, Val Acc=62.86%, Grad Norm=11.7252, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=0.4547, Train Acc=84.87%, Val Loss=1.1593, Val Acc=62.92%, Grad Norm=11.7599, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=0.4536, Train Acc=85.05%, Val Loss=1.1663, Val Acc=62.94%, Grad Norm=11.8190, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=0.4515, Train Acc=85.04%, Val Loss=1.1489, Val Acc=63.07%, Grad Norm=11.8133, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=0.4468, Train Acc=85.28%, Val Loss=1.1583, Val Acc=62.82%, Grad Norm=11.8078, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=0.4453, Train Acc=85.31%, Val Loss=1.1658, Val Acc=62.88%, Grad Norm=11.8758, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=0.4495, Train Acc=85.03%, Val Loss=1.1502, Val Acc=63.29%, Grad Norm=11.9786, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=0.4501, Train Acc=85.05%, Val Loss=1.1566, Val Acc=62.86%, Grad Norm=12.0699, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=0.4477, Train Acc=85.20%, Val Loss=1.1591, Val Acc=62.88%, Grad Norm=12.0618, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=0.4466, Train Acc=85.19%, Val Loss=1.1579, Val Acc=62.90%, Grad Norm=12.1154, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=0.4396, Train Acc=85.49%, Val Loss=1.1703, Val Acc=62.82%, Grad Norm=12.0290, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=0.4418, Train Acc=85.52%, Val Loss=1.1618, Val Acc=62.81%, Grad Norm=12.0956, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=0.4419, Train Acc=85.34%, Val Loss=1.1628, Val Acc=63.07%, Grad Norm=12.2198, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=0.4403, Train Acc=85.58%, Val Loss=1.1456, Val Acc=63.30%, Grad Norm=12.1759, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=0.4413, Train Acc=85.49%, Val Loss=1.1590, Val Acc=62.75%, Grad Norm=12.1757, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=0.4367, Train Acc=85.55%, Val Loss=1.1633, Val Acc=62.96%, Grad Norm=12.1640, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=0.4397, Train Acc=85.46%, Val Loss=1.1617, Val Acc=62.97%, Grad Norm=12.2061, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=0.4361, Train Acc=85.62%, Val Loss=1.1601, Val Acc=63.03%, Grad Norm=12.2153, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=0.4375, Train Acc=85.53%, Val Loss=1.1645, Val Acc=62.95%, Grad Norm=12.2286, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=0.4369, Train Acc=85.70%, Val Loss=1.1569, Val Acc=62.90%, Grad Norm=12.2261, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=0.4347, Train Acc=85.52%, Val Loss=1.1668, Val Acc=62.76%, Grad Norm=12.2611, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=0.4336, Train Acc=85.78%, Val Loss=1.1594, Val Acc=62.81%, Grad Norm=12.2472, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=0.4363, Train Acc=85.75%, Val Loss=1.1657, Val Acc=62.61%, Grad Norm=12.2798, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=0.4348, Train Acc=85.63%, Val Loss=1.1620, Val Acc=62.91%, Grad Norm=12.3122, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=0.4301, Train Acc=86.01%, Val Loss=1.1676, Val Acc=62.81%, Grad Norm=12.1903, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=0.4332, Train Acc=85.55%, Val Loss=1.1557, Val Acc=62.92%, Grad Norm=12.3336, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=0.4318, Train Acc=85.84%, Val Loss=1.1568, Val Acc=62.96%, Grad Norm=12.3296, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=0.4297, Train Acc=85.74%, Val Loss=1.1565, Val Acc=62.97%, Grad Norm=12.3065, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=0.4278, Train Acc=85.87%, Val Loss=1.1615, Val Acc=62.75%, Grad Norm=12.2696, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=0.4299, Train Acc=85.81%, Val Loss=1.1579, Val Acc=62.98%, Grad Norm=12.3513, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=0.4369, Train Acc=85.58%, Val Loss=1.1563, Val Acc=63.03%, Grad Norm=12.4162, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=0.4299, Train Acc=85.90%, Val Loss=1.1514, Val Acc=63.21%, Grad Norm=12.3610, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=0.4304, Train Acc=85.69%, Val Loss=1.1606, Val Acc=62.85%, Grad Norm=12.3720, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=0.4288, Train Acc=85.82%, Val Loss=1.1692, Val Acc=62.86%, Grad Norm=12.3598, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=0.4361, Train Acc=85.58%, Val Loss=1.1669, Val Acc=62.80%, Grad Norm=12.4593, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=0.4315, Train Acc=85.71%, Val Loss=1.1597, Val Acc=62.82%, Grad Norm=12.4348, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=0.4293, Train Acc=86.07%, Val Loss=1.1620, Val Acc=62.91%, Grad Norm=12.4021, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=0.4365, Train Acc=85.55%, Val Loss=1.1686, Val Acc=62.81%, Grad Norm=12.5032, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=0.4315, Train Acc=85.86%, Val Loss=1.1728, Val Acc=62.58%, Grad Norm=12.4012, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=0.4274, Train Acc=86.08%, Val Loss=1.1611, Val Acc=62.93%, Grad Norm=12.3489, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=0.4324, Train Acc=85.75%, Val Loss=1.1625, Val Acc=62.98%, Grad Norm=12.4595, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=0.4315, Train Acc=85.83%, Val Loss=1.1602, Val Acc=62.86%, Grad Norm=12.4264, LR=1.95313e-07\n",
      "Fold 2, Epoch 101: Train Loss=0.4288, Train Acc=85.91%, Val Loss=1.1629, Val Acc=62.83%, Grad Norm=12.3576, LR=9.76563e-08\n",
      "Fold 2, Epoch 102: Train Loss=0.4290, Train Acc=85.92%, Val Loss=1.1523, Val Acc=63.08%, Grad Norm=12.4194, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=63.30%）\n",
      "Fold 2 DONE | Best Val Acc≈63.30% | Final Val Acc=63.30% | Test Acc=60.87%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.1393, Train Acc=17.23%, Val Loss=2.3929, Val Acc=17.36%, Grad Norm=6.9825, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=1.8135, Train Acc=32.66%, Val Loss=1.9825, Val Acc=32.03%, Grad Norm=5.8575, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=1.4845, Train Acc=45.68%, Val Loss=1.6567, Val Acc=42.43%, Grad Norm=5.1585, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=1.2818, Train Acc=53.19%, Val Loss=1.4560, Val Acc=47.98%, Grad Norm=4.5229, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.1746, Train Acc=57.31%, Val Loss=1.3857, Val Acc=50.96%, Grad Norm=4.1806, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.1092, Train Acc=59.86%, Val Loss=1.3161, Val Acc=54.46%, Grad Norm=4.1309, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=1.0535, Train Acc=62.25%, Val Loss=1.2475, Val Acc=56.46%, Grad Norm=4.0685, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=1.0097, Train Acc=64.07%, Val Loss=1.2538, Val Acc=56.15%, Grad Norm=4.0974, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=0.9703, Train Acc=65.52%, Val Loss=1.2016, Val Acc=57.20%, Grad Norm=4.1163, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=0.9425, Train Acc=66.68%, Val Loss=1.2034, Val Acc=57.89%, Grad Norm=4.2159, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=0.8876, Train Acc=68.71%, Val Loss=1.1244, Val Acc=60.33%, Grad Norm=4.3618, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=0.8656, Train Acc=69.57%, Val Loss=1.1605, Val Acc=59.09%, Grad Norm=4.6056, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=0.8464, Train Acc=70.35%, Val Loss=1.1917, Val Acc=58.76%, Grad Norm=4.8063, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=0.8277, Train Acc=71.18%, Val Loss=1.1785, Val Acc=59.39%, Grad Norm=5.0176, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=0.8101, Train Acc=71.64%, Val Loss=1.1610, Val Acc=59.85%, Grad Norm=5.2186, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=0.7941, Train Acc=72.43%, Val Loss=1.1775, Val Acc=60.03%, Grad Norm=5.4161, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=0.7793, Train Acc=72.78%, Val Loss=1.1589, Val Acc=60.64%, Grad Norm=5.6145, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=0.7653, Train Acc=73.56%, Val Loss=1.1301, Val Acc=61.70%, Grad Norm=5.8622, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=0.7507, Train Acc=74.16%, Val Loss=1.1593, Val Acc=61.19%, Grad Norm=6.0312, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=0.7356, Train Acc=74.76%, Val Loss=1.1153, Val Acc=61.69%, Grad Norm=6.2060, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=0.6998, Train Acc=75.92%, Val Loss=1.1430, Val Acc=61.25%, Grad Norm=6.4716, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=0.6840, Train Acc=76.66%, Val Loss=1.1477, Val Acc=61.66%, Grad Norm=6.6968, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=0.6705, Train Acc=77.10%, Val Loss=1.1283, Val Acc=62.22%, Grad Norm=6.9542, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=0.6547, Train Acc=77.86%, Val Loss=1.1441, Val Acc=62.22%, Grad Norm=7.2568, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=0.6466, Train Acc=78.09%, Val Loss=1.1471, Val Acc=61.94%, Grad Norm=7.4527, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=0.6355, Train Acc=78.42%, Val Loss=1.1166, Val Acc=62.96%, Grad Norm=7.6485, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=0.6280, Train Acc=78.58%, Val Loss=1.1177, Val Acc=62.77%, Grad Norm=7.8869, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=0.6169, Train Acc=79.20%, Val Loss=1.1656, Val Acc=61.51%, Grad Norm=8.0493, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=0.6091, Train Acc=79.26%, Val Loss=1.1443, Val Acc=62.73%, Grad Norm=8.2858, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=0.5996, Train Acc=79.69%, Val Loss=1.1678, Val Acc=62.11%, Grad Norm=8.5136, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=0.5777, Train Acc=80.39%, Val Loss=1.1380, Val Acc=62.59%, Grad Norm=8.6598, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=0.5656, Train Acc=80.85%, Val Loss=1.1396, Val Acc=62.80%, Grad Norm=8.8420, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=0.5602, Train Acc=81.35%, Val Loss=1.1283, Val Acc=63.04%, Grad Norm=8.9818, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=0.5506, Train Acc=81.29%, Val Loss=1.1587, Val Acc=62.86%, Grad Norm=9.1658, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=0.5513, Train Acc=81.47%, Val Loss=1.1250, Val Acc=63.36%, Grad Norm=9.4450, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=0.5387, Train Acc=81.90%, Val Loss=1.1564, Val Acc=62.39%, Grad Norm=9.5422, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=0.5326, Train Acc=82.16%, Val Loss=1.1467, Val Acc=62.79%, Grad Norm=9.6543, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=0.5255, Train Acc=82.36%, Val Loss=1.1541, Val Acc=62.99%, Grad Norm=9.8185, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=0.5242, Train Acc=82.39%, Val Loss=1.1520, Val Acc=62.96%, Grad Norm=9.9897, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=0.5103, Train Acc=82.98%, Val Loss=1.1704, Val Acc=62.81%, Grad Norm=10.0636, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=0.5007, Train Acc=83.23%, Val Loss=1.1569, Val Acc=63.31%, Grad Norm=10.2104, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=0.4932, Train Acc=83.56%, Val Loss=1.1622, Val Acc=62.92%, Grad Norm=10.2607, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=0.4875, Train Acc=83.74%, Val Loss=1.1620, Val Acc=63.31%, Grad Norm=10.3890, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=0.4872, Train Acc=83.67%, Val Loss=1.1599, Val Acc=63.37%, Grad Norm=10.5825, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=0.4871, Train Acc=83.81%, Val Loss=1.1575, Val Acc=63.18%, Grad Norm=10.7262, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=0.4817, Train Acc=84.04%, Val Loss=1.1604, Val Acc=63.26%, Grad Norm=10.8346, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=0.4787, Train Acc=84.27%, Val Loss=1.1760, Val Acc=63.03%, Grad Norm=10.8871, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=0.4704, Train Acc=84.34%, Val Loss=1.1587, Val Acc=63.24%, Grad Norm=10.9212, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=0.4722, Train Acc=84.26%, Val Loss=1.1675, Val Acc=63.08%, Grad Norm=11.0171, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=0.4619, Train Acc=84.72%, Val Loss=1.1573, Val Acc=63.18%, Grad Norm=11.1367, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=0.4643, Train Acc=84.71%, Val Loss=1.1578, Val Acc=63.62%, Grad Norm=11.2079, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=0.4572, Train Acc=84.96%, Val Loss=1.1759, Val Acc=62.94%, Grad Norm=11.2752, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=0.4570, Train Acc=84.94%, Val Loss=1.1726, Val Acc=63.12%, Grad Norm=11.3076, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=0.4548, Train Acc=84.91%, Val Loss=1.1611, Val Acc=63.29%, Grad Norm=11.4035, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=0.4543, Train Acc=84.95%, Val Loss=1.1685, Val Acc=63.42%, Grad Norm=11.4630, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=0.4489, Train Acc=85.09%, Val Loss=1.1662, Val Acc=63.46%, Grad Norm=11.4406, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=0.4540, Train Acc=84.90%, Val Loss=1.1769, Val Acc=63.15%, Grad Norm=11.6059, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=0.4453, Train Acc=85.42%, Val Loss=1.1675, Val Acc=63.32%, Grad Norm=11.6136, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=0.4413, Train Acc=85.34%, Val Loss=1.1629, Val Acc=63.47%, Grad Norm=11.6200, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=0.4427, Train Acc=85.41%, Val Loss=1.1657, Val Acc=63.87%, Grad Norm=11.7433, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=0.4394, Train Acc=85.51%, Val Loss=1.1708, Val Acc=63.31%, Grad Norm=11.7283, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=0.4345, Train Acc=85.72%, Val Loss=1.1757, Val Acc=63.20%, Grad Norm=11.7429, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=0.4337, Train Acc=85.75%, Val Loss=1.1678, Val Acc=63.56%, Grad Norm=11.7701, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=0.4410, Train Acc=85.41%, Val Loss=1.1685, Val Acc=63.35%, Grad Norm=11.8662, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=0.4315, Train Acc=85.83%, Val Loss=1.1731, Val Acc=63.36%, Grad Norm=11.8420, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=0.4266, Train Acc=85.97%, Val Loss=1.1814, Val Acc=63.09%, Grad Norm=11.8044, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=0.4346, Train Acc=85.63%, Val Loss=1.1674, Val Acc=63.69%, Grad Norm=11.9412, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=0.4307, Train Acc=86.00%, Val Loss=1.1768, Val Acc=63.26%, Grad Norm=11.8796, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=0.4339, Train Acc=85.57%, Val Loss=1.1649, Val Acc=63.52%, Grad Norm=12.0109, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=0.4311, Train Acc=85.93%, Val Loss=1.1750, Val Acc=63.22%, Grad Norm=11.9782, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=0.4343, Train Acc=85.60%, Val Loss=1.1722, Val Acc=63.64%, Grad Norm=12.1223, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=0.4288, Train Acc=86.06%, Val Loss=1.1727, Val Acc=63.39%, Grad Norm=11.9955, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=0.4303, Train Acc=85.86%, Val Loss=1.1721, Val Acc=63.45%, Grad Norm=12.0777, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=0.4231, Train Acc=86.07%, Val Loss=1.1888, Val Acc=63.12%, Grad Norm=11.9789, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=0.4243, Train Acc=86.14%, Val Loss=1.1684, Val Acc=63.62%, Grad Norm=12.0828, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=0.4245, Train Acc=85.99%, Val Loss=1.1790, Val Acc=63.57%, Grad Norm=12.0370, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=0.4261, Train Acc=86.10%, Val Loss=1.1748, Val Acc=63.30%, Grad Norm=12.0771, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=0.4254, Train Acc=85.90%, Val Loss=1.1897, Val Acc=63.17%, Grad Norm=12.1760, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=0.4232, Train Acc=85.92%, Val Loss=1.1827, Val Acc=63.34%, Grad Norm=12.1578, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=0.4246, Train Acc=86.02%, Val Loss=1.1845, Val Acc=63.11%, Grad Norm=12.1910, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=0.4238, Train Acc=86.26%, Val Loss=1.1734, Val Acc=63.40%, Grad Norm=12.1830, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=0.4206, Train Acc=86.23%, Val Loss=1.1791, Val Acc=63.35%, Grad Norm=12.1288, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=0.4213, Train Acc=86.17%, Val Loss=1.1963, Val Acc=62.90%, Grad Norm=12.0956, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=0.4226, Train Acc=86.10%, Val Loss=1.1755, Val Acc=63.35%, Grad Norm=12.2149, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=0.4202, Train Acc=86.32%, Val Loss=1.1808, Val Acc=63.29%, Grad Norm=12.1518, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=0.4202, Train Acc=86.20%, Val Loss=1.1759, Val Acc=63.38%, Grad Norm=12.1471, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=0.4258, Train Acc=86.11%, Val Loss=1.1798, Val Acc=63.27%, Grad Norm=12.2431, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=0.4212, Train Acc=86.22%, Val Loss=1.1801, Val Acc=63.41%, Grad Norm=12.1524, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=0.4172, Train Acc=86.28%, Val Loss=1.1717, Val Acc=63.84%, Grad Norm=12.1283, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=0.4165, Train Acc=86.43%, Val Loss=1.1813, Val Acc=63.45%, Grad Norm=12.1146, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=63.87%）\n",
      "Fold 3 DONE | Best Val Acc≈63.87% | Final Val Acc=63.87% | Test Acc=61.23%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.1416, Train Acc=17.44%, Val Loss=2.5079, Val Acc=18.07%, Grad Norm=6.9632, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=1.8099, Train Acc=32.40%, Val Loss=1.9769, Val Acc=35.49%, Grad Norm=5.9482, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=1.4568, Train Acc=46.41%, Val Loss=1.5639, Val Acc=45.07%, Grad Norm=5.0090, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.2595, Train Acc=53.68%, Val Loss=1.3996, Val Acc=51.54%, Grad Norm=4.4587, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.1463, Train Acc=58.36%, Val Loss=1.3980, Val Acc=54.85%, Grad Norm=4.1792, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.0805, Train Acc=61.13%, Val Loss=1.2431, Val Acc=56.86%, Grad Norm=4.1259, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=1.0268, Train Acc=63.25%, Val Loss=1.2389, Val Acc=58.58%, Grad Norm=4.0902, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=0.9859, Train Acc=64.84%, Val Loss=1.1997, Val Acc=59.38%, Grad Norm=4.0959, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=0.9489, Train Acc=66.29%, Val Loss=1.1039, Val Acc=62.23%, Grad Norm=4.2357, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=0.9227, Train Acc=67.12%, Val Loss=1.1421, Val Acc=60.19%, Grad Norm=4.3150, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=0.8637, Train Acc=69.70%, Val Loss=1.0623, Val Acc=62.47%, Grad Norm=4.3841, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=0.8419, Train Acc=70.33%, Val Loss=1.0787, Val Acc=62.22%, Grad Norm=4.6960, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=0.8254, Train Acc=71.03%, Val Loss=1.0971, Val Acc=61.98%, Grad Norm=4.9366, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=0.8039, Train Acc=71.85%, Val Loss=1.1024, Val Acc=61.78%, Grad Norm=5.1833, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=0.7862, Train Acc=72.50%, Val Loss=1.0781, Val Acc=62.57%, Grad Norm=5.4263, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=0.7726, Train Acc=73.10%, Val Loss=1.1038, Val Acc=63.54%, Grad Norm=5.6482, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=0.7556, Train Acc=73.65%, Val Loss=1.0554, Val Acc=63.62%, Grad Norm=5.8654, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=0.7469, Train Acc=73.98%, Val Loss=1.0476, Val Acc=64.00%, Grad Norm=6.0839, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=0.7241, Train Acc=75.03%, Val Loss=1.0940, Val Acc=64.20%, Grad Norm=6.3247, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=0.7102, Train Acc=75.35%, Val Loss=1.0678, Val Acc=64.51%, Grad Norm=6.5079, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=0.6716, Train Acc=76.96%, Val Loss=1.0670, Val Acc=63.95%, Grad Norm=6.7362, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=0.6596, Train Acc=77.32%, Val Loss=1.0517, Val Acc=64.95%, Grad Norm=7.0336, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=0.6438, Train Acc=78.04%, Val Loss=1.0617, Val Acc=65.06%, Grad Norm=7.3185, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=0.6312, Train Acc=78.35%, Val Loss=1.0902, Val Acc=64.62%, Grad Norm=7.5884, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=0.6246, Train Acc=78.56%, Val Loss=1.0597, Val Acc=65.05%, Grad Norm=7.8599, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=0.6112, Train Acc=79.23%, Val Loss=1.0611, Val Acc=65.03%, Grad Norm=8.0418, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=0.6025, Train Acc=79.62%, Val Loss=1.0858, Val Acc=65.30%, Grad Norm=8.2449, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=0.5915, Train Acc=79.82%, Val Loss=1.0784, Val Acc=64.38%, Grad Norm=8.5482, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=0.5800, Train Acc=80.24%, Val Loss=1.0517, Val Acc=65.16%, Grad Norm=8.7349, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=0.5768, Train Acc=80.39%, Val Loss=1.0838, Val Acc=64.98%, Grad Norm=8.9675, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=0.5450, Train Acc=81.73%, Val Loss=1.0676, Val Acc=65.32%, Grad Norm=9.1198, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=0.5334, Train Acc=81.89%, Val Loss=1.0439, Val Acc=65.69%, Grad Norm=9.2830, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=0.5283, Train Acc=82.30%, Val Loss=1.0482, Val Acc=65.63%, Grad Norm=9.4789, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=0.5282, Train Acc=82.17%, Val Loss=1.0572, Val Acc=65.67%, Grad Norm=9.7316, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=0.5166, Train Acc=82.68%, Val Loss=1.0812, Val Acc=65.36%, Grad Norm=9.8917, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=0.5080, Train Acc=82.87%, Val Loss=1.0589, Val Acc=65.65%, Grad Norm=10.1523, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=0.5012, Train Acc=83.19%, Val Loss=1.0728, Val Acc=65.40%, Grad Norm=10.2959, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=0.4943, Train Acc=83.58%, Val Loss=1.0944, Val Acc=65.53%, Grad Norm=10.3728, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=0.4913, Train Acc=83.55%, Val Loss=1.0733, Val Acc=65.68%, Grad Norm=10.6220, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=0.4900, Train Acc=83.61%, Val Loss=1.0538, Val Acc=66.40%, Grad Norm=10.7797, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=0.4767, Train Acc=84.03%, Val Loss=1.0598, Val Acc=66.43%, Grad Norm=10.8412, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=0.4698, Train Acc=84.31%, Val Loss=1.0726, Val Acc=65.90%, Grad Norm=10.9733, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=0.4613, Train Acc=84.46%, Val Loss=1.0823, Val Acc=65.76%, Grad Norm=11.0536, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=0.4576, Train Acc=84.73%, Val Loss=1.0672, Val Acc=66.16%, Grad Norm=11.2856, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=0.4560, Train Acc=84.82%, Val Loss=1.0905, Val Acc=65.99%, Grad Norm=11.3659, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=0.4500, Train Acc=85.02%, Val Loss=1.0942, Val Acc=65.80%, Grad Norm=11.5020, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=0.4436, Train Acc=85.35%, Val Loss=1.0772, Val Acc=65.80%, Grad Norm=11.6117, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=0.4428, Train Acc=85.48%, Val Loss=1.0767, Val Acc=66.10%, Grad Norm=11.6297, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=0.4408, Train Acc=85.33%, Val Loss=1.0935, Val Acc=65.80%, Grad Norm=11.7786, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=0.4347, Train Acc=85.42%, Val Loss=1.1010, Val Acc=65.63%, Grad Norm=11.8894, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=0.4298, Train Acc=85.71%, Val Loss=1.0850, Val Acc=65.95%, Grad Norm=11.9238, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=0.4250, Train Acc=86.02%, Val Loss=1.0997, Val Acc=65.98%, Grad Norm=11.9671, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=0.4222, Train Acc=85.98%, Val Loss=1.0929, Val Acc=66.19%, Grad Norm=12.0534, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=0.4214, Train Acc=86.24%, Val Loss=1.0846, Val Acc=66.25%, Grad Norm=12.1465, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=0.4221, Train Acc=86.10%, Val Loss=1.0958, Val Acc=66.11%, Grad Norm=12.2329, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=0.4189, Train Acc=86.16%, Val Loss=1.1017, Val Acc=65.89%, Grad Norm=12.2659, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=0.4200, Train Acc=86.06%, Val Loss=1.1035, Val Acc=66.17%, Grad Norm=12.3512, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=0.4165, Train Acc=86.06%, Val Loss=1.1170, Val Acc=65.87%, Grad Norm=12.4795, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=0.4081, Train Acc=86.58%, Val Loss=1.0964, Val Acc=66.32%, Grad Norm=12.3848, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=0.4127, Train Acc=86.28%, Val Loss=1.1083, Val Acc=65.94%, Grad Norm=12.5703, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=0.4061, Train Acc=86.57%, Val Loss=1.0951, Val Acc=66.02%, Grad Norm=12.5006, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=0.4069, Train Acc=86.69%, Val Loss=1.1119, Val Acc=65.97%, Grad Norm=12.5256, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=0.4066, Train Acc=86.62%, Val Loss=1.0974, Val Acc=66.24%, Grad Norm=12.6355, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=0.4094, Train Acc=86.56%, Val Loss=1.1079, Val Acc=65.99%, Grad Norm=12.7467, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=0.4052, Train Acc=86.69%, Val Loss=1.0989, Val Acc=66.17%, Grad Norm=12.7263, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=0.4018, Train Acc=86.86%, Val Loss=1.0949, Val Acc=66.27%, Grad Norm=12.7577, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=0.4026, Train Acc=86.67%, Val Loss=1.1067, Val Acc=66.24%, Grad Norm=12.7646, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=0.3986, Train Acc=86.95%, Val Loss=1.0994, Val Acc=66.47%, Grad Norm=12.7848, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=0.3962, Train Acc=86.97%, Val Loss=1.1072, Val Acc=66.39%, Grad Norm=12.7834, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=0.3991, Train Acc=86.99%, Val Loss=1.1028, Val Acc=66.50%, Grad Norm=12.8863, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=0.4001, Train Acc=86.74%, Val Loss=1.0913, Val Acc=66.29%, Grad Norm=13.0191, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=0.3976, Train Acc=86.78%, Val Loss=1.0909, Val Acc=66.44%, Grad Norm=12.9167, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=0.3896, Train Acc=87.12%, Val Loss=1.1041, Val Acc=66.34%, Grad Norm=12.8591, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=0.3943, Train Acc=87.13%, Val Loss=1.1051, Val Acc=66.35%, Grad Norm=12.9527, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=0.3946, Train Acc=87.08%, Val Loss=1.1026, Val Acc=66.38%, Grad Norm=12.9550, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=0.3941, Train Acc=87.08%, Val Loss=1.0958, Val Acc=66.32%, Grad Norm=12.9464, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=0.3965, Train Acc=86.87%, Val Loss=1.1060, Val Acc=66.31%, Grad Norm=13.0717, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=0.3950, Train Acc=87.05%, Val Loss=1.1034, Val Acc=66.42%, Grad Norm=13.0536, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=0.3912, Train Acc=87.23%, Val Loss=1.1072, Val Acc=66.21%, Grad Norm=13.0024, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=0.3908, Train Acc=87.30%, Val Loss=1.1053, Val Acc=66.28%, Grad Norm=12.9820, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=0.3914, Train Acc=87.01%, Val Loss=1.1100, Val Acc=66.18%, Grad Norm=13.0563, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=0.3884, Train Acc=87.26%, Val Loss=1.1064, Val Acc=66.42%, Grad Norm=13.0233, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=0.3886, Train Acc=87.18%, Val Loss=1.1029, Val Acc=66.31%, Grad Norm=13.0503, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=0.3866, Train Acc=87.30%, Val Loss=1.1033, Val Acc=66.27%, Grad Norm=13.0544, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=0.3913, Train Acc=87.13%, Val Loss=1.0949, Val Acc=66.42%, Grad Norm=13.1425, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=0.3868, Train Acc=87.23%, Val Loss=1.1048, Val Acc=66.36%, Grad Norm=13.0574, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=0.3895, Train Acc=87.18%, Val Loss=1.1030, Val Acc=66.21%, Grad Norm=13.1056, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=0.3892, Train Acc=87.22%, Val Loss=1.0973, Val Acc=66.42%, Grad Norm=13.1594, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=0.3896, Train Acc=87.32%, Val Loss=1.1026, Val Acc=66.35%, Grad Norm=13.1437, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=0.3880, Train Acc=87.11%, Val Loss=1.1000, Val Acc=66.48%, Grad Norm=13.1909, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=0.3908, Train Acc=87.11%, Val Loss=1.1033, Val Acc=66.48%, Grad Norm=13.2206, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=0.3875, Train Acc=87.23%, Val Loss=1.1074, Val Acc=66.39%, Grad Norm=13.2033, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=0.3845, Train Acc=87.50%, Val Loss=1.1086, Val Acc=66.12%, Grad Norm=13.0587, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=0.3887, Train Acc=87.26%, Val Loss=1.1112, Val Acc=66.18%, Grad Norm=13.1843, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=0.3888, Train Acc=87.28%, Val Loss=1.1018, Val Acc=66.32%, Grad Norm=13.2022, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=0.3858, Train Acc=87.49%, Val Loss=1.1062, Val Acc=66.39%, Grad Norm=13.0842, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=0.3871, Train Acc=87.36%, Val Loss=1.1045, Val Acc=66.29%, Grad Norm=13.1952, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=0.3865, Train Acc=87.26%, Val Loss=1.1100, Val Acc=66.06%, Grad Norm=13.1851, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=0.3844, Train Acc=87.41%, Val Loss=1.1081, Val Acc=66.22%, Grad Norm=13.1411, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=0.3852, Train Acc=87.51%, Val Loss=1.1033, Val Acc=66.31%, Grad Norm=13.1689, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=66.50%）\n",
      "Fold 4 DONE | Best Val Acc≈66.50% | Final Val Acc=66.50% | Test Acc=63.62%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.1144, Train Acc=18.95%, Val Loss=2.9155, Val Acc=19.57%, Grad Norm=6.6826, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=1.6667, Train Acc=38.39%, Val Loss=2.2865, Val Acc=33.06%, Grad Norm=5.7135, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=1.3447, Train Acc=50.92%, Val Loss=1.7390, Val Acc=43.78%, Grad Norm=4.6692, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=1.1922, Train Acc=56.76%, Val Loss=1.6265, Val Acc=47.25%, Grad Norm=4.2509, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.1107, Train Acc=59.91%, Val Loss=1.5582, Val Acc=47.62%, Grad Norm=4.0136, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.0507, Train Acc=62.28%, Val Loss=1.5087, Val Acc=50.36%, Grad Norm=3.9888, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=1.0068, Train Acc=64.07%, Val Loss=1.5060, Val Acc=51.21%, Grad Norm=4.0002, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=0.9685, Train Acc=65.49%, Val Loss=1.3927, Val Acc=55.06%, Grad Norm=4.0815, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=0.9396, Train Acc=66.68%, Val Loss=1.4448, Val Acc=54.89%, Grad Norm=4.1291, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=0.9068, Train Acc=68.01%, Val Loss=1.3908, Val Acc=55.69%, Grad Norm=4.2162, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=0.8522, Train Acc=70.09%, Val Loss=1.3599, Val Acc=56.42%, Grad Norm=4.3759, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=0.8271, Train Acc=71.06%, Val Loss=1.3714, Val Acc=55.09%, Grad Norm=4.6996, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=0.8101, Train Acc=71.63%, Val Loss=1.3653, Val Acc=56.79%, Grad Norm=4.9582, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=0.7923, Train Acc=72.31%, Val Loss=1.3533, Val Acc=55.31%, Grad Norm=5.1898, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=0.7763, Train Acc=72.90%, Val Loss=1.3316, Val Acc=56.24%, Grad Norm=5.4024, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=0.7558, Train Acc=73.78%, Val Loss=1.3490, Val Acc=57.15%, Grad Norm=5.6233, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=0.7424, Train Acc=74.26%, Val Loss=1.3221, Val Acc=56.90%, Grad Norm=5.8475, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=0.7275, Train Acc=74.76%, Val Loss=1.3491, Val Acc=56.75%, Grad Norm=6.0236, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=0.7159, Train Acc=75.16%, Val Loss=1.3358, Val Acc=58.32%, Grad Norm=6.2689, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=0.6962, Train Acc=76.19%, Val Loss=1.2982, Val Acc=57.61%, Grad Norm=6.5066, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=0.6601, Train Acc=77.59%, Val Loss=1.2784, Val Acc=58.64%, Grad Norm=6.7410, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=0.6402, Train Acc=78.27%, Val Loss=1.2668, Val Acc=60.07%, Grad Norm=7.0992, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=0.6246, Train Acc=78.68%, Val Loss=1.2477, Val Acc=59.96%, Grad Norm=7.3777, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=0.6139, Train Acc=79.09%, Val Loss=1.2674, Val Acc=59.03%, Grad Norm=7.5680, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=0.6113, Train Acc=79.25%, Val Loss=1.2869, Val Acc=60.09%, Grad Norm=7.8485, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=0.5992, Train Acc=79.91%, Val Loss=1.2685, Val Acc=59.75%, Grad Norm=8.0756, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=0.5829, Train Acc=80.31%, Val Loss=1.3064, Val Acc=59.43%, Grad Norm=8.3163, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=0.5750, Train Acc=80.37%, Val Loss=1.2441, Val Acc=59.97%, Grad Norm=8.5694, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=0.5664, Train Acc=80.93%, Val Loss=1.2718, Val Acc=59.86%, Grad Norm=8.7258, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=0.5565, Train Acc=81.26%, Val Loss=1.2620, Val Acc=60.07%, Grad Norm=8.9648, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=0.5336, Train Acc=82.00%, Val Loss=1.2316, Val Acc=60.49%, Grad Norm=9.0319, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=0.5246, Train Acc=82.50%, Val Loss=1.2830, Val Acc=58.97%, Grad Norm=9.3697, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=0.5146, Train Acc=82.60%, Val Loss=1.2621, Val Acc=59.72%, Grad Norm=9.4983, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=0.5095, Train Acc=82.87%, Val Loss=1.2401, Val Acc=60.31%, Grad Norm=9.7362, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=0.5018, Train Acc=83.33%, Val Loss=1.2313, Val Acc=60.57%, Grad Norm=9.9535, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=0.4925, Train Acc=83.47%, Val Loss=1.2611, Val Acc=60.16%, Grad Norm=10.0762, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=0.4897, Train Acc=83.49%, Val Loss=1.2380, Val Acc=60.51%, Grad Norm=10.2774, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=0.4780, Train Acc=83.95%, Val Loss=1.2370, Val Acc=60.93%, Grad Norm=10.3210, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=0.4771, Train Acc=84.24%, Val Loss=1.2362, Val Acc=60.89%, Grad Norm=10.5548, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=0.4726, Train Acc=84.40%, Val Loss=1.2470, Val Acc=61.20%, Grad Norm=10.7250, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=0.4558, Train Acc=84.87%, Val Loss=1.2661, Val Acc=60.61%, Grad Norm=10.8093, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=0.4576, Train Acc=84.76%, Val Loss=1.2653, Val Acc=60.51%, Grad Norm=11.0272, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=0.4484, Train Acc=85.08%, Val Loss=1.2592, Val Acc=61.21%, Grad Norm=11.0571, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=0.4448, Train Acc=85.17%, Val Loss=1.2437, Val Acc=60.90%, Grad Norm=11.2224, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=0.4417, Train Acc=85.47%, Val Loss=1.2542, Val Acc=60.78%, Grad Norm=11.3407, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=0.4424, Train Acc=85.41%, Val Loss=1.2675, Val Acc=60.31%, Grad Norm=11.5016, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=0.4335, Train Acc=85.62%, Val Loss=1.2584, Val Acc=60.83%, Grad Norm=11.5389, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=0.4313, Train Acc=85.55%, Val Loss=1.2670, Val Acc=60.84%, Grad Norm=11.7486, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=0.4279, Train Acc=85.88%, Val Loss=1.2711, Val Acc=60.80%, Grad Norm=11.7412, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=0.4241, Train Acc=86.07%, Val Loss=1.2682, Val Acc=61.09%, Grad Norm=11.8134, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=0.4184, Train Acc=86.32%, Val Loss=1.2633, Val Acc=60.84%, Grad Norm=11.9123, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=0.4120, Train Acc=86.30%, Val Loss=1.2580, Val Acc=61.15%, Grad Norm=11.9735, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=0.4118, Train Acc=86.51%, Val Loss=1.2805, Val Acc=60.72%, Grad Norm=12.0565, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=0.4072, Train Acc=86.61%, Val Loss=1.2785, Val Acc=60.60%, Grad Norm=12.0550, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=0.4107, Train Acc=86.59%, Val Loss=1.2829, Val Acc=60.75%, Grad Norm=12.2332, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=0.4037, Train Acc=86.58%, Val Loss=1.2702, Val Acc=60.88%, Grad Norm=12.2002, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=0.4054, Train Acc=86.68%, Val Loss=1.2656, Val Acc=61.32%, Grad Norm=12.3512, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=0.4005, Train Acc=86.83%, Val Loss=1.2699, Val Acc=61.46%, Grad Norm=12.3687, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=0.4019, Train Acc=86.78%, Val Loss=1.2630, Val Acc=60.72%, Grad Norm=12.4740, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=0.4008, Train Acc=86.85%, Val Loss=1.2698, Val Acc=61.00%, Grad Norm=12.4983, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=0.4015, Train Acc=86.73%, Val Loss=1.2703, Val Acc=61.24%, Grad Norm=12.6616, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=0.3953, Train Acc=86.95%, Val Loss=1.2694, Val Acc=61.21%, Grad Norm=12.5619, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=0.3908, Train Acc=87.12%, Val Loss=1.2602, Val Acc=61.13%, Grad Norm=12.6362, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=0.3897, Train Acc=87.16%, Val Loss=1.2717, Val Acc=61.05%, Grad Norm=12.6436, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=0.3952, Train Acc=86.97%, Val Loss=1.2725, Val Acc=61.14%, Grad Norm=12.7699, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=0.3893, Train Acc=87.30%, Val Loss=1.2824, Val Acc=60.75%, Grad Norm=12.7225, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=0.3878, Train Acc=87.29%, Val Loss=1.2712, Val Acc=61.30%, Grad Norm=12.7156, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=0.3891, Train Acc=87.07%, Val Loss=1.2650, Val Acc=61.46%, Grad Norm=12.8220, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=0.3863, Train Acc=87.25%, Val Loss=1.2744, Val Acc=61.43%, Grad Norm=12.8421, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=0.3848, Train Acc=87.31%, Val Loss=1.2810, Val Acc=61.25%, Grad Norm=12.8726, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=0.3828, Train Acc=87.48%, Val Loss=1.2791, Val Acc=61.00%, Grad Norm=12.8041, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=0.3850, Train Acc=87.43%, Val Loss=1.2795, Val Acc=61.15%, Grad Norm=12.8487, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=0.3827, Train Acc=87.53%, Val Loss=1.2678, Val Acc=61.24%, Grad Norm=12.8963, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=0.3811, Train Acc=87.52%, Val Loss=1.2741, Val Acc=61.45%, Grad Norm=12.9267, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=0.3860, Train Acc=87.29%, Val Loss=1.2912, Val Acc=60.98%, Grad Norm=12.9990, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=0.3826, Train Acc=87.46%, Val Loss=1.2923, Val Acc=60.88%, Grad Norm=12.9156, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=0.3768, Train Acc=87.58%, Val Loss=1.2849, Val Acc=61.14%, Grad Norm=12.9208, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=0.3784, Train Acc=87.67%, Val Loss=1.3019, Val Acc=60.77%, Grad Norm=12.9616, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=0.3790, Train Acc=87.52%, Val Loss=1.2706, Val Acc=61.57%, Grad Norm=13.0278, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=0.3805, Train Acc=87.54%, Val Loss=1.2773, Val Acc=61.17%, Grad Norm=13.0337, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=0.3756, Train Acc=87.72%, Val Loss=1.2747, Val Acc=61.19%, Grad Norm=12.9914, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=0.3788, Train Acc=87.70%, Val Loss=1.2699, Val Acc=61.55%, Grad Norm=13.0259, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=0.3814, Train Acc=87.45%, Val Loss=1.2767, Val Acc=61.37%, Grad Norm=13.1352, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=0.3762, Train Acc=87.61%, Val Loss=1.2801, Val Acc=61.16%, Grad Norm=13.0413, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=0.3764, Train Acc=87.73%, Val Loss=1.2788, Val Acc=61.35%, Grad Norm=13.0817, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=0.3774, Train Acc=87.51%, Val Loss=1.2766, Val Acc=61.36%, Grad Norm=13.0467, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=0.3773, Train Acc=87.59%, Val Loss=1.2906, Val Acc=61.24%, Grad Norm=13.0748, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=0.3779, Train Acc=87.61%, Val Loss=1.2793, Val Acc=61.08%, Grad Norm=13.1046, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=0.3751, Train Acc=87.71%, Val Loss=1.2771, Val Acc=61.23%, Grad Norm=13.0647, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=0.3790, Train Acc=87.55%, Val Loss=1.2743, Val Acc=61.42%, Grad Norm=13.1591, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=0.3738, Train Acc=87.89%, Val Loss=1.2684, Val Acc=61.51%, Grad Norm=13.0257, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=0.3788, Train Acc=87.69%, Val Loss=1.2766, Val Acc=61.24%, Grad Norm=13.1397, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=0.3719, Train Acc=87.79%, Val Loss=1.2807, Val Acc=61.29%, Grad Norm=13.0745, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=0.3741, Train Acc=87.69%, Val Loss=1.2824, Val Acc=61.23%, Grad Norm=13.1159, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=0.3781, Train Acc=87.55%, Val Loss=1.2808, Val Acc=61.21%, Grad Norm=13.1690, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=0.3731, Train Acc=87.86%, Val Loss=1.2791, Val Acc=61.39%, Grad Norm=13.0488, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=0.3719, Train Acc=87.93%, Val Loss=1.2761, Val Acc=61.51%, Grad Norm=13.0532, LR=1.95313e-07\n",
      "Fold 5, Epoch 98: Train Loss=0.3700, Train Acc=87.95%, Val Loss=1.2688, Val Acc=61.39%, Grad Norm=12.9832, LR=1.95313e-07\n",
      "Fold 5, Epoch 99: Train Loss=0.3752, Train Acc=87.76%, Val Loss=1.2708, Val Acc=61.50%, Grad Norm=13.1663, LR=1.95313e-07\n",
      "Fold 5, Epoch 100: Train Loss=0.3763, Train Acc=87.61%, Val Loss=1.2899, Val Acc=61.00%, Grad Norm=13.1929, LR=1.95313e-07\n",
      "Fold 5, Epoch 101: Train Loss=0.3707, Train Acc=87.92%, Val Loss=1.2782, Val Acc=61.05%, Grad Norm=13.0891, LR=9.76563e-08\n",
      "Fold 5, Epoch 102: Train Loss=0.3757, Train Acc=87.60%, Val Loss=1.2775, Val Acc=61.48%, Grad Norm=13.1997, LR=9.76563e-08\n",
      "Fold 5, Epoch 103: Train Loss=0.3697, Train Acc=88.11%, Val Loss=1.2655, Val Acc=61.69%, Grad Norm=13.0683, LR=9.76563e-08\n",
      "Fold 5, Epoch 104: Train Loss=0.3771, Train Acc=87.69%, Val Loss=1.2831, Val Acc=61.17%, Grad Norm=13.1341, LR=9.76563e-08\n",
      "Fold 5, Epoch 105: Train Loss=0.3752, Train Acc=87.67%, Val Loss=1.2774, Val Acc=61.23%, Grad Norm=13.1829, LR=9.76563e-08\n",
      "Fold 5, Epoch 106: Train Loss=0.3757, Train Acc=87.54%, Val Loss=1.2857, Val Acc=61.22%, Grad Norm=13.1951, LR=9.76563e-08\n",
      "Fold 5, Epoch 107: Train Loss=0.3746, Train Acc=87.75%, Val Loss=1.2860, Val Acc=61.23%, Grad Norm=13.2108, LR=9.76563e-08\n",
      "Fold 5, Epoch 108: Train Loss=0.3736, Train Acc=87.73%, Val Loss=1.2680, Val Acc=61.26%, Grad Norm=13.1490, LR=9.76563e-08\n",
      "Fold 5, Epoch 109: Train Loss=0.3719, Train Acc=87.88%, Val Loss=1.2662, Val Acc=61.42%, Grad Norm=13.1511, LR=9.76563e-08\n",
      "Fold 5, Epoch 110: Train Loss=0.3731, Train Acc=87.73%, Val Loss=1.2784, Val Acc=61.21%, Grad Norm=13.1367, LR=9.76563e-08\n",
      "Fold 5, Epoch 111: Train Loss=0.3719, Train Acc=87.89%, Val Loss=1.2780, Val Acc=61.18%, Grad Norm=13.1001, LR=4.88281e-08\n",
      "Fold 5, Epoch 112: Train Loss=0.3723, Train Acc=87.94%, Val Loss=1.2809, Val Acc=61.37%, Grad Norm=13.0840, LR=4.88281e-08\n",
      "Fold 5, Epoch 113: Train Loss=0.3718, Train Acc=87.90%, Val Loss=1.2775, Val Acc=61.29%, Grad Norm=13.1820, LR=4.88281e-08\n",
      "Fold 5, Epoch 114: Train Loss=0.3756, Train Acc=87.68%, Val Loss=1.2878, Val Acc=61.14%, Grad Norm=13.1988, LR=4.88281e-08\n",
      "Fold 5, Epoch 115: Train Loss=0.3760, Train Acc=87.66%, Val Loss=1.2785, Val Acc=61.50%, Grad Norm=13.2666, LR=4.88281e-08\n",
      "Fold 5, Epoch 116: Train Loss=0.3724, Train Acc=87.87%, Val Loss=1.2799, Val Acc=61.26%, Grad Norm=13.1516, LR=4.88281e-08\n",
      "Fold 5, Epoch 117: Train Loss=0.3717, Train Acc=87.93%, Val Loss=1.2755, Val Acc=61.51%, Grad Norm=13.1371, LR=4.88281e-08\n",
      "Fold 5, Epoch 118: Train Loss=0.3739, Train Acc=87.77%, Val Loss=1.2785, Val Acc=61.26%, Grad Norm=13.1566, LR=4.88281e-08\n",
      "Fold 5, Epoch 119: Train Loss=0.3764, Train Acc=87.67%, Val Loss=1.2738, Val Acc=61.43%, Grad Norm=13.2382, LR=4.88281e-08\n",
      "Fold 5, Epoch 120: Train Loss=0.3691, Train Acc=87.83%, Val Loss=1.2835, Val Acc=61.30%, Grad Norm=13.0817, LR=4.88281e-08\n",
      "Fold 5, Epoch 121: Train Loss=0.3753, Train Acc=87.66%, Val Loss=1.2793, Val Acc=61.38%, Grad Norm=13.2904, LR=2.44141e-08\n",
      "Fold 5, Epoch 122: Train Loss=0.3672, Train Acc=88.09%, Val Loss=1.2727, Val Acc=61.46%, Grad Norm=13.1129, LR=2.44141e-08\n",
      "Fold 5, Epoch 123: Train Loss=0.3721, Train Acc=87.96%, Val Loss=1.2796, Val Acc=61.35%, Grad Norm=13.1777, LR=2.44141e-08\n",
      "Fold 5, Epoch 124: Train Loss=0.3691, Train Acc=88.00%, Val Loss=1.2611, Val Acc=61.62%, Grad Norm=13.1100, LR=2.44141e-08\n",
      "Fold 5, Epoch 125: Train Loss=0.3721, Train Acc=87.89%, Val Loss=1.2681, Val Acc=61.35%, Grad Norm=13.1275, LR=2.44141e-08\n",
      "Fold 5, Epoch 126: Train Loss=0.3754, Train Acc=87.70%, Val Loss=1.2828, Val Acc=61.12%, Grad Norm=13.2277, LR=2.44141e-08\n",
      "Fold 5, Epoch 127: Train Loss=0.3727, Train Acc=87.76%, Val Loss=1.2706, Val Acc=61.41%, Grad Norm=13.1531, LR=2.44141e-08\n",
      "Fold 5, Epoch 128: Train Loss=0.3696, Train Acc=87.86%, Val Loss=1.2722, Val Acc=61.56%, Grad Norm=13.1407, LR=2.44141e-08\n",
      "Fold 5, Epoch 129: Train Loss=0.3759, Train Acc=87.59%, Val Loss=1.2652, Val Acc=61.63%, Grad Norm=13.2011, LR=2.44141e-08\n",
      "Fold 5, Epoch 130: Train Loss=0.3676, Train Acc=88.20%, Val Loss=1.2776, Val Acc=61.34%, Grad Norm=13.0883, LR=2.44141e-08\n",
      "Fold 5, Epoch 131: Train Loss=0.3740, Train Acc=87.80%, Val Loss=1.2742, Val Acc=61.24%, Grad Norm=13.1792, LR=1.2207e-08\n",
      "Fold 5, Epoch 132: Train Loss=0.3751, Train Acc=87.70%, Val Loss=1.2759, Val Acc=61.25%, Grad Norm=13.2187, LR=1.2207e-08\n",
      "Fold 5, Epoch 133: Train Loss=0.3764, Train Acc=87.73%, Val Loss=1.2840, Val Acc=61.34%, Grad Norm=13.2462, LR=1.2207e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=61.69%）\n",
      "Fold 5 DONE | Best Val Acc≈61.69% | Final Val Acc=61.69% | Test Acc=64.33%\n",
      "[INFO] SNR=10 dB | Mean Test Acc: 62.58% ± 1.34%\n",
      "[INFO] SNR  10 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR10dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = 5 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.1707, Train Acc=15.61%, Val Loss=2.2851, Val Acc=17.55%, Grad Norm=6.5773, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=1.9026, Train Acc=28.86%, Val Loss=1.9792, Val Acc=29.51%, Grad Norm=5.8390, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=1.5724, Train Acc=42.10%, Val Loss=1.5816, Val Acc=41.15%, Grad Norm=5.0432, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=1.3797, Train Acc=49.90%, Val Loss=1.4077, Val Acc=46.68%, Grad Norm=4.6055, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=1.2603, Train Acc=54.26%, Val Loss=1.3828, Val Acc=49.09%, Grad Norm=4.3741, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.1848, Train Acc=57.18%, Val Loss=1.3024, Val Acc=51.78%, Grad Norm=4.2081, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=1.1287, Train Acc=59.34%, Val Loss=1.2546, Val Acc=54.22%, Grad Norm=4.1369, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=1.0882, Train Acc=60.76%, Val Loss=1.2563, Val Acc=53.60%, Grad Norm=4.1478, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=1.0487, Train Acc=62.61%, Val Loss=1.2876, Val Acc=55.32%, Grad Norm=4.1846, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=1.0202, Train Acc=63.69%, Val Loss=1.2178, Val Acc=55.92%, Grad Norm=4.1793, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=0.9668, Train Acc=65.64%, Val Loss=1.2048, Val Acc=57.17%, Grad Norm=4.2639, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=0.9465, Train Acc=66.54%, Val Loss=1.1834, Val Acc=57.01%, Grad Norm=4.5174, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=0.9309, Train Acc=67.23%, Val Loss=1.1706, Val Acc=58.78%, Grad Norm=4.7440, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=0.9107, Train Acc=67.99%, Val Loss=1.1864, Val Acc=58.08%, Grad Norm=4.9506, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=0.8997, Train Acc=68.40%, Val Loss=1.1886, Val Acc=57.67%, Grad Norm=5.0963, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=0.8835, Train Acc=68.98%, Val Loss=1.1881, Val Acc=58.13%, Grad Norm=5.2496, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=0.8695, Train Acc=69.60%, Val Loss=1.1909, Val Acc=58.65%, Grad Norm=5.4509, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=0.8616, Train Acc=69.94%, Val Loss=1.1976, Val Acc=57.65%, Grad Norm=5.5612, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=0.8458, Train Acc=70.65%, Val Loss=1.1866, Val Acc=59.11%, Grad Norm=5.7669, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=0.8340, Train Acc=70.98%, Val Loss=1.1857, Val Acc=59.29%, Grad Norm=5.9401, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=0.8016, Train Acc=72.02%, Val Loss=1.1598, Val Acc=60.02%, Grad Norm=6.0701, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=0.7880, Train Acc=72.55%, Val Loss=1.1669, Val Acc=59.86%, Grad Norm=6.4570, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=0.7718, Train Acc=73.22%, Val Loss=1.1603, Val Acc=60.36%, Grad Norm=6.6302, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=0.7646, Train Acc=73.73%, Val Loss=1.1620, Val Acc=60.51%, Grad Norm=6.7948, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=0.7565, Train Acc=73.76%, Val Loss=1.1743, Val Acc=60.38%, Grad Norm=7.0896, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=0.7452, Train Acc=74.16%, Val Loss=1.1555, Val Acc=60.55%, Grad Norm=7.2023, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=0.7441, Train Acc=74.45%, Val Loss=1.1772, Val Acc=60.30%, Grad Norm=7.4736, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=0.7308, Train Acc=74.95%, Val Loss=1.1865, Val Acc=59.88%, Grad Norm=7.6414, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=0.7183, Train Acc=75.38%, Val Loss=1.1676, Val Acc=61.13%, Grad Norm=7.8266, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=0.7132, Train Acc=75.47%, Val Loss=1.1739, Val Acc=61.12%, Grad Norm=8.0179, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=0.6938, Train Acc=76.18%, Val Loss=1.1738, Val Acc=61.32%, Grad Norm=8.1812, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=0.6832, Train Acc=76.73%, Val Loss=1.1723, Val Acc=61.18%, Grad Norm=8.3573, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=0.6771, Train Acc=77.02%, Val Loss=1.1704, Val Acc=60.88%, Grad Norm=8.5689, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=0.6690, Train Acc=77.32%, Val Loss=1.1610, Val Acc=61.64%, Grad Norm=8.8043, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=0.6637, Train Acc=77.48%, Val Loss=1.1671, Val Acc=61.74%, Grad Norm=8.9599, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=0.6593, Train Acc=77.80%, Val Loss=1.1812, Val Acc=61.17%, Grad Norm=9.0916, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=0.6497, Train Acc=77.95%, Val Loss=1.1817, Val Acc=61.70%, Grad Norm=9.2659, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=0.6449, Train Acc=77.99%, Val Loss=1.1656, Val Acc=61.44%, Grad Norm=9.5041, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=0.6407, Train Acc=78.40%, Val Loss=1.1670, Val Acc=61.52%, Grad Norm=9.5276, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=0.6396, Train Acc=78.24%, Val Loss=1.1728, Val Acc=61.76%, Grad Norm=9.7528, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=0.6339, Train Acc=78.52%, Val Loss=1.1675, Val Acc=61.89%, Grad Norm=9.8308, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=0.6206, Train Acc=78.92%, Val Loss=1.1736, Val Acc=61.94%, Grad Norm=9.9416, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=0.6180, Train Acc=79.17%, Val Loss=1.1553, Val Acc=61.81%, Grad Norm=10.0154, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=0.6170, Train Acc=79.19%, Val Loss=1.1673, Val Acc=61.87%, Grad Norm=10.1489, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=0.6106, Train Acc=79.50%, Val Loss=1.1705, Val Acc=61.63%, Grad Norm=10.3489, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=0.6086, Train Acc=79.45%, Val Loss=1.1837, Val Acc=61.47%, Grad Norm=10.4273, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=0.6017, Train Acc=79.67%, Val Loss=1.1815, Val Acc=61.88%, Grad Norm=10.4937, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=0.5976, Train Acc=79.87%, Val Loss=1.1724, Val Acc=61.96%, Grad Norm=10.6148, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=0.5976, Train Acc=79.74%, Val Loss=1.1960, Val Acc=62.23%, Grad Norm=10.7456, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=0.5897, Train Acc=80.02%, Val Loss=1.1856, Val Acc=62.04%, Grad Norm=10.7719, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=0.5891, Train Acc=80.17%, Val Loss=1.1827, Val Acc=61.92%, Grad Norm=10.9493, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=0.5915, Train Acc=80.32%, Val Loss=1.1793, Val Acc=61.93%, Grad Norm=11.0673, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=0.5839, Train Acc=80.53%, Val Loss=1.1791, Val Acc=61.79%, Grad Norm=11.0174, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=0.5841, Train Acc=80.21%, Val Loss=1.1740, Val Acc=62.26%, Grad Norm=11.1331, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=0.5801, Train Acc=80.56%, Val Loss=1.1845, Val Acc=62.11%, Grad Norm=11.1706, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=0.5817, Train Acc=80.41%, Val Loss=1.1871, Val Acc=62.09%, Grad Norm=11.2416, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=0.5795, Train Acc=80.55%, Val Loss=1.1773, Val Acc=61.79%, Grad Norm=11.3149, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=0.5762, Train Acc=80.66%, Val Loss=1.1918, Val Acc=61.72%, Grad Norm=11.3514, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=0.5728, Train Acc=80.80%, Val Loss=1.1814, Val Acc=61.86%, Grad Norm=11.4310, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=0.5659, Train Acc=81.10%, Val Loss=1.1847, Val Acc=62.03%, Grad Norm=11.4834, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=0.5650, Train Acc=81.01%, Val Loss=1.1906, Val Acc=61.82%, Grad Norm=11.5375, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=0.5703, Train Acc=80.77%, Val Loss=1.1848, Val Acc=61.97%, Grad Norm=11.6625, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=0.5720, Train Acc=80.74%, Val Loss=1.1899, Val Acc=62.04%, Grad Norm=11.7035, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=0.5624, Train Acc=81.11%, Val Loss=1.1932, Val Acc=62.11%, Grad Norm=11.5966, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=0.5631, Train Acc=81.04%, Val Loss=1.2007, Val Acc=61.97%, Grad Norm=11.6848, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=0.5607, Train Acc=81.21%, Val Loss=1.1903, Val Acc=62.02%, Grad Norm=11.7484, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=0.5617, Train Acc=81.13%, Val Loss=1.1930, Val Acc=62.05%, Grad Norm=11.7724, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=0.5648, Train Acc=80.98%, Val Loss=1.1857, Val Acc=61.90%, Grad Norm=11.8117, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=0.5542, Train Acc=81.53%, Val Loss=1.1962, Val Acc=62.05%, Grad Norm=11.7731, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=0.5576, Train Acc=81.34%, Val Loss=1.1868, Val Acc=62.05%, Grad Norm=11.8550, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=0.5656, Train Acc=81.15%, Val Loss=1.1910, Val Acc=62.09%, Grad Norm=11.9744, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=0.5547, Train Acc=81.65%, Val Loss=1.1893, Val Acc=61.92%, Grad Norm=11.8758, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=0.5566, Train Acc=81.40%, Val Loss=1.1874, Val Acc=62.10%, Grad Norm=11.9458, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=0.5584, Train Acc=81.21%, Val Loss=1.1890, Val Acc=61.92%, Grad Norm=12.0015, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=0.5523, Train Acc=81.53%, Val Loss=1.1878, Val Acc=61.94%, Grad Norm=11.9574, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=0.5574, Train Acc=81.37%, Val Loss=1.1880, Val Acc=62.03%, Grad Norm=11.9987, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=0.5574, Train Acc=81.27%, Val Loss=1.1867, Val Acc=62.03%, Grad Norm=12.0532, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=0.5563, Train Acc=81.46%, Val Loss=1.1914, Val Acc=61.99%, Grad Norm=12.0373, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=0.5557, Train Acc=81.32%, Val Loss=1.1872, Val Acc=61.85%, Grad Norm=12.1135, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=0.5568, Train Acc=81.48%, Val Loss=1.1935, Val Acc=61.90%, Grad Norm=12.0942, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=0.5484, Train Acc=81.58%, Val Loss=1.1937, Val Acc=61.81%, Grad Norm=12.0721, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=0.5477, Train Acc=81.85%, Val Loss=1.1829, Val Acc=62.13%, Grad Norm=12.0388, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=0.5511, Train Acc=81.63%, Val Loss=1.1902, Val Acc=62.04%, Grad Norm=12.0623, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=0.5503, Train Acc=81.54%, Val Loss=1.1929, Val Acc=62.01%, Grad Norm=12.1151, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=62.26%）\n",
      "Fold 1 DONE | Best Val Acc≈62.26% | Final Val Acc=62.26% | Test Acc=60.17%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.1759, Train Acc=15.05%, Val Loss=2.8550, Val Acc=13.13%, Grad Norm=6.8405, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=1.9326, Train Acc=27.18%, Val Loss=2.1241, Val Acc=31.02%, Grad Norm=6.2133, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=1.5761, Train Acc=41.42%, Val Loss=1.6417, Val Acc=42.52%, Grad Norm=5.0448, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=1.3828, Train Acc=49.35%, Val Loss=1.5285, Val Acc=45.89%, Grad Norm=4.4517, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.2677, Train Acc=53.89%, Val Loss=1.4282, Val Acc=49.53%, Grad Norm=4.2169, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.1904, Train Acc=56.73%, Val Loss=1.3576, Val Acc=50.79%, Grad Norm=4.0904, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=1.1361, Train Acc=58.85%, Val Loss=1.3809, Val Acc=52.05%, Grad Norm=4.0032, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=1.0934, Train Acc=60.48%, Val Loss=1.3880, Val Acc=50.75%, Grad Norm=3.9358, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=1.0642, Train Acc=61.64%, Val Loss=1.3630, Val Acc=51.54%, Grad Norm=3.9920, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=1.0345, Train Acc=63.05%, Val Loss=1.2950, Val Acc=53.26%, Grad Norm=3.9868, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=0.9858, Train Acc=64.81%, Val Loss=1.2947, Val Acc=54.50%, Grad Norm=4.0719, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=0.9641, Train Acc=65.54%, Val Loss=1.2963, Val Acc=54.36%, Grad Norm=4.2817, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=0.9454, Train Acc=66.48%, Val Loss=1.2942, Val Acc=55.58%, Grad Norm=4.5186, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=0.9325, Train Acc=67.05%, Val Loss=1.2851, Val Acc=56.10%, Grad Norm=4.6698, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=0.9185, Train Acc=67.43%, Val Loss=1.2966, Val Acc=55.83%, Grad Norm=4.8384, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=0.9055, Train Acc=68.00%, Val Loss=1.2457, Val Acc=56.91%, Grad Norm=5.0266, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=0.8956, Train Acc=68.63%, Val Loss=1.2220, Val Acc=57.26%, Grad Norm=5.1577, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=0.8774, Train Acc=69.20%, Val Loss=1.2190, Val Acc=56.83%, Grad Norm=5.3946, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=0.8747, Train Acc=69.13%, Val Loss=1.2209, Val Acc=57.50%, Grad Norm=5.4752, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=0.8550, Train Acc=70.28%, Val Loss=1.2311, Val Acc=57.22%, Grad Norm=5.6769, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=0.8272, Train Acc=71.31%, Val Loss=1.2093, Val Acc=58.12%, Grad Norm=5.9620, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=0.8122, Train Acc=71.59%, Val Loss=1.2145, Val Acc=58.22%, Grad Norm=6.2546, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=0.8032, Train Acc=72.17%, Val Loss=1.2319, Val Acc=57.99%, Grad Norm=6.4303, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=0.7925, Train Acc=72.48%, Val Loss=1.2143, Val Acc=58.56%, Grad Norm=6.7283, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=0.7824, Train Acc=72.77%, Val Loss=1.2151, Val Acc=58.26%, Grad Norm=6.8191, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=0.7803, Train Acc=72.94%, Val Loss=1.2054, Val Acc=58.29%, Grad Norm=7.0850, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=0.7718, Train Acc=73.25%, Val Loss=1.2093, Val Acc=58.63%, Grad Norm=7.2446, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=0.7592, Train Acc=73.64%, Val Loss=1.2083, Val Acc=58.63%, Grad Norm=7.5130, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=0.7518, Train Acc=74.20%, Val Loss=1.2017, Val Acc=59.12%, Grad Norm=7.6625, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=0.7428, Train Acc=74.30%, Val Loss=1.1985, Val Acc=59.33%, Grad Norm=7.9023, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=0.7297, Train Acc=75.00%, Val Loss=1.2008, Val Acc=59.25%, Grad Norm=8.0736, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=0.7123, Train Acc=75.65%, Val Loss=1.2114, Val Acc=59.03%, Grad Norm=8.2356, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=0.7048, Train Acc=75.61%, Val Loss=1.2241, Val Acc=58.85%, Grad Norm=8.5563, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=0.6994, Train Acc=76.08%, Val Loss=1.2083, Val Acc=59.28%, Grad Norm=8.7081, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=0.6969, Train Acc=76.13%, Val Loss=1.1922, Val Acc=59.61%, Grad Norm=8.9274, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=0.6862, Train Acc=76.56%, Val Loss=1.1824, Val Acc=59.39%, Grad Norm=9.0564, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=0.6901, Train Acc=76.35%, Val Loss=1.1974, Val Acc=59.25%, Grad Norm=9.2079, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=0.6818, Train Acc=76.74%, Val Loss=1.2455, Val Acc=59.29%, Grad Norm=9.3627, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=0.6742, Train Acc=77.04%, Val Loss=1.2086, Val Acc=59.51%, Grad Norm=9.4775, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=0.6679, Train Acc=77.20%, Val Loss=1.1965, Val Acc=59.95%, Grad Norm=9.6474, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=0.6521, Train Acc=77.85%, Val Loss=1.2156, Val Acc=59.51%, Grad Norm=9.7696, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=0.6535, Train Acc=77.55%, Val Loss=1.1992, Val Acc=60.06%, Grad Norm=9.9610, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=0.6479, Train Acc=77.83%, Val Loss=1.2039, Val Acc=59.88%, Grad Norm=10.1416, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=0.6385, Train Acc=78.25%, Val Loss=1.2236, Val Acc=59.76%, Grad Norm=10.2386, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=0.6386, Train Acc=78.42%, Val Loss=1.2158, Val Acc=59.79%, Grad Norm=10.3430, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=0.6378, Train Acc=78.49%, Val Loss=1.2023, Val Acc=59.84%, Grad Norm=10.4401, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=0.6286, Train Acc=78.78%, Val Loss=1.2030, Val Acc=60.10%, Grad Norm=10.4925, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=0.6292, Train Acc=78.71%, Val Loss=1.2189, Val Acc=59.86%, Grad Norm=10.6729, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=0.6283, Train Acc=78.91%, Val Loss=1.2130, Val Acc=60.06%, Grad Norm=10.7897, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=0.6249, Train Acc=79.02%, Val Loss=1.2064, Val Acc=60.14%, Grad Norm=10.9206, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=0.6152, Train Acc=79.10%, Val Loss=1.2218, Val Acc=59.71%, Grad Norm=10.9654, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=0.6156, Train Acc=79.43%, Val Loss=1.2071, Val Acc=60.10%, Grad Norm=11.0544, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=0.6096, Train Acc=79.40%, Val Loss=1.2089, Val Acc=60.10%, Grad Norm=11.0641, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=0.6109, Train Acc=79.37%, Val Loss=1.2128, Val Acc=60.01%, Grad Norm=11.2250, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=0.6047, Train Acc=79.71%, Val Loss=1.2090, Val Acc=60.02%, Grad Norm=11.2036, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=0.6046, Train Acc=79.63%, Val Loss=1.2157, Val Acc=59.91%, Grad Norm=11.3865, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=0.6010, Train Acc=79.73%, Val Loss=1.2151, Val Acc=59.83%, Grad Norm=11.4110, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=0.6004, Train Acc=79.85%, Val Loss=1.2179, Val Acc=59.73%, Grad Norm=11.4856, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=0.5996, Train Acc=79.66%, Val Loss=1.2133, Val Acc=59.98%, Grad Norm=11.5417, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=0.5951, Train Acc=79.95%, Val Loss=1.2170, Val Acc=60.03%, Grad Norm=11.6941, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=0.5943, Train Acc=80.00%, Val Loss=1.2178, Val Acc=59.88%, Grad Norm=11.7315, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=0.5930, Train Acc=80.07%, Val Loss=1.2161, Val Acc=59.78%, Grad Norm=11.7140, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=0.5963, Train Acc=79.85%, Val Loss=1.2239, Val Acc=59.87%, Grad Norm=11.7910, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=0.5899, Train Acc=80.16%, Val Loss=1.2195, Val Acc=60.00%, Grad Norm=11.7583, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=0.5925, Train Acc=79.87%, Val Loss=1.2255, Val Acc=59.86%, Grad Norm=11.7808, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=0.5913, Train Acc=80.15%, Val Loss=1.2198, Val Acc=60.13%, Grad Norm=11.8736, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=0.5898, Train Acc=80.30%, Val Loss=1.2177, Val Acc=60.16%, Grad Norm=11.9023, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=0.5894, Train Acc=80.22%, Val Loss=1.2287, Val Acc=59.86%, Grad Norm=11.9694, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=0.5873, Train Acc=80.30%, Val Loss=1.2252, Val Acc=60.01%, Grad Norm=11.9199, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=0.5892, Train Acc=80.22%, Val Loss=1.2223, Val Acc=59.88%, Grad Norm=12.0236, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=0.5892, Train Acc=79.99%, Val Loss=1.2330, Val Acc=59.92%, Grad Norm=12.0865, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=0.5876, Train Acc=80.25%, Val Loss=1.2165, Val Acc=59.95%, Grad Norm=12.0925, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=0.5821, Train Acc=80.45%, Val Loss=1.2215, Val Acc=60.02%, Grad Norm=12.0706, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=0.5839, Train Acc=80.28%, Val Loss=1.2240, Val Acc=59.92%, Grad Norm=12.0865, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=0.5818, Train Acc=80.33%, Val Loss=1.2296, Val Acc=60.11%, Grad Norm=12.0831, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=0.5798, Train Acc=80.52%, Val Loss=1.2240, Val Acc=60.00%, Grad Norm=12.1191, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=0.5788, Train Acc=80.57%, Val Loss=1.2263, Val Acc=59.79%, Grad Norm=12.1268, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=0.5833, Train Acc=80.21%, Val Loss=1.2246, Val Acc=60.02%, Grad Norm=12.1904, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=0.5799, Train Acc=80.30%, Val Loss=1.2318, Val Acc=60.05%, Grad Norm=12.2186, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=0.5761, Train Acc=80.65%, Val Loss=1.2193, Val Acc=59.99%, Grad Norm=12.1900, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=0.5768, Train Acc=80.71%, Val Loss=1.2284, Val Acc=60.05%, Grad Norm=12.2378, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=0.5827, Train Acc=80.35%, Val Loss=1.2186, Val Acc=60.05%, Grad Norm=12.3227, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=0.5750, Train Acc=80.77%, Val Loss=1.2254, Val Acc=60.03%, Grad Norm=12.2262, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=0.5821, Train Acc=80.46%, Val Loss=1.2272, Val Acc=60.00%, Grad Norm=12.2718, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=0.5811, Train Acc=80.28%, Val Loss=1.2284, Val Acc=60.02%, Grad Norm=12.3398, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=0.5767, Train Acc=80.64%, Val Loss=1.2272, Val Acc=59.77%, Grad Norm=12.2730, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=0.5786, Train Acc=80.47%, Val Loss=1.2227, Val Acc=59.90%, Grad Norm=12.2883, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=0.5712, Train Acc=80.88%, Val Loss=1.2292, Val Acc=59.94%, Grad Norm=12.2189, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=0.5772, Train Acc=80.52%, Val Loss=1.2292, Val Acc=59.94%, Grad Norm=12.3238, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=0.5798, Train Acc=80.61%, Val Loss=1.2227, Val Acc=59.92%, Grad Norm=12.3193, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=0.5767, Train Acc=80.71%, Val Loss=1.2269, Val Acc=59.85%, Grad Norm=12.2968, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=0.5790, Train Acc=80.51%, Val Loss=1.2249, Val Acc=59.97%, Grad Norm=12.3631, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=0.5749, Train Acc=80.65%, Val Loss=1.2309, Val Acc=59.91%, Grad Norm=12.3173, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=0.5716, Train Acc=80.71%, Val Loss=1.2303, Val Acc=59.99%, Grad Norm=12.2962, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=0.5746, Train Acc=80.61%, Val Loss=1.2225, Val Acc=59.87%, Grad Norm=12.3250, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=0.5764, Train Acc=80.74%, Val Loss=1.2229, Val Acc=59.91%, Grad Norm=12.3231, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=0.5773, Train Acc=80.48%, Val Loss=1.2311, Val Acc=59.95%, Grad Norm=12.3927, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=60.16%）\n",
      "Fold 2 DONE | Best Val Acc≈60.16% | Final Val Acc=60.16% | Test Acc=59.13%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.1626, Train Acc=16.29%, Val Loss=2.8183, Val Acc=13.56%, Grad Norm=6.7667, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=1.9277, Train Acc=27.47%, Val Loss=2.3501, Val Acc=26.01%, Grad Norm=6.0960, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=1.6159, Train Acc=40.31%, Val Loss=1.7625, Val Acc=39.43%, Grad Norm=5.3215, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=1.3939, Train Acc=49.32%, Val Loss=1.4459, Val Acc=45.86%, Grad Norm=4.7547, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.2598, Train Acc=54.38%, Val Loss=1.4640, Val Acc=48.06%, Grad Norm=4.3831, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.1861, Train Acc=57.05%, Val Loss=1.3623, Val Acc=50.47%, Grad Norm=4.1385, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=1.1360, Train Acc=59.36%, Val Loss=1.3208, Val Acc=52.86%, Grad Norm=4.1831, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=1.0886, Train Acc=60.77%, Val Loss=1.3936, Val Acc=50.89%, Grad Norm=4.1125, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=1.0556, Train Acc=62.32%, Val Loss=1.3233, Val Acc=53.29%, Grad Norm=4.2159, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=1.0255, Train Acc=63.57%, Val Loss=1.3191, Val Acc=54.14%, Grad Norm=4.2092, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=0.9723, Train Acc=65.76%, Val Loss=1.2143, Val Acc=56.38%, Grad Norm=4.2973, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=0.9505, Train Acc=66.48%, Val Loss=1.2012, Val Acc=56.42%, Grad Norm=4.5880, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=0.9312, Train Acc=67.19%, Val Loss=1.1908, Val Acc=57.76%, Grad Norm=4.7530, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=0.9155, Train Acc=67.59%, Val Loss=1.2059, Val Acc=57.19%, Grad Norm=4.9317, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=0.9029, Train Acc=68.10%, Val Loss=1.2379, Val Acc=56.58%, Grad Norm=5.0754, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=0.8891, Train Acc=68.64%, Val Loss=1.1835, Val Acc=58.11%, Grad Norm=5.2658, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=0.8745, Train Acc=69.41%, Val Loss=1.1974, Val Acc=57.65%, Grad Norm=5.3944, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=0.8610, Train Acc=69.94%, Val Loss=1.1933, Val Acc=58.33%, Grad Norm=5.6300, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=0.8471, Train Acc=70.44%, Val Loss=1.2079, Val Acc=57.84%, Grad Norm=5.8204, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=0.8401, Train Acc=70.75%, Val Loss=1.1552, Val Acc=58.63%, Grad Norm=5.9189, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=0.8026, Train Acc=72.23%, Val Loss=1.1786, Val Acc=58.70%, Grad Norm=6.1237, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=0.7891, Train Acc=72.75%, Val Loss=1.1693, Val Acc=59.15%, Grad Norm=6.3573, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=0.7816, Train Acc=73.04%, Val Loss=1.1523, Val Acc=59.52%, Grad Norm=6.5392, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=0.7706, Train Acc=73.30%, Val Loss=1.1871, Val Acc=59.06%, Grad Norm=6.8349, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=0.7627, Train Acc=73.65%, Val Loss=1.1735, Val Acc=59.37%, Grad Norm=7.0461, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=0.7540, Train Acc=73.98%, Val Loss=1.1736, Val Acc=59.62%, Grad Norm=7.2265, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=0.7437, Train Acc=74.42%, Val Loss=1.1788, Val Acc=59.65%, Grad Norm=7.4010, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=0.7367, Train Acc=74.70%, Val Loss=1.1717, Val Acc=59.98%, Grad Norm=7.5720, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=0.7296, Train Acc=74.80%, Val Loss=1.1667, Val Acc=59.74%, Grad Norm=7.7828, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=0.7204, Train Acc=75.14%, Val Loss=1.1750, Val Acc=59.94%, Grad Norm=7.9477, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=0.6976, Train Acc=75.96%, Val Loss=1.1905, Val Acc=59.61%, Grad Norm=8.1847, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=0.6930, Train Acc=76.42%, Val Loss=1.1733, Val Acc=60.13%, Grad Norm=8.4151, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=0.6815, Train Acc=76.83%, Val Loss=1.1609, Val Acc=61.02%, Grad Norm=8.5355, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=0.6771, Train Acc=76.83%, Val Loss=1.1708, Val Acc=60.44%, Grad Norm=8.7748, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=0.6697, Train Acc=77.07%, Val Loss=1.1844, Val Acc=60.18%, Grad Norm=8.9274, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=0.6666, Train Acc=77.32%, Val Loss=1.1623, Val Acc=60.75%, Grad Norm=9.1411, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=0.6611, Train Acc=77.48%, Val Loss=1.1707, Val Acc=60.74%, Grad Norm=9.2076, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=0.6564, Train Acc=77.72%, Val Loss=1.1800, Val Acc=60.65%, Grad Norm=9.3999, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=0.6488, Train Acc=77.86%, Val Loss=1.1888, Val Acc=60.26%, Grad Norm=9.6145, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=0.6448, Train Acc=78.22%, Val Loss=1.1864, Val Acc=60.16%, Grad Norm=9.7601, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=0.6348, Train Acc=78.50%, Val Loss=1.1922, Val Acc=60.53%, Grad Norm=9.8763, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=0.6248, Train Acc=78.93%, Val Loss=1.1826, Val Acc=60.68%, Grad Norm=9.9462, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=0.6243, Train Acc=78.94%, Val Loss=1.1970, Val Acc=59.96%, Grad Norm=10.0882, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=0.6165, Train Acc=79.04%, Val Loss=1.1889, Val Acc=60.60%, Grad Norm=10.1784, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=0.6168, Train Acc=79.14%, Val Loss=1.1907, Val Acc=60.60%, Grad Norm=10.3256, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=0.6107, Train Acc=79.21%, Val Loss=1.1967, Val Acc=60.35%, Grad Norm=10.4423, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=0.6097, Train Acc=79.34%, Val Loss=1.2097, Val Acc=60.14%, Grad Norm=10.6667, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=0.6093, Train Acc=79.33%, Val Loss=1.2122, Val Acc=60.10%, Grad Norm=10.7303, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=0.6043, Train Acc=79.58%, Val Loss=1.1933, Val Acc=60.57%, Grad Norm=10.7695, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=0.5951, Train Acc=79.93%, Val Loss=1.1965, Val Acc=60.65%, Grad Norm=10.9096, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=0.5975, Train Acc=79.99%, Val Loss=1.1880, Val Acc=60.86%, Grad Norm=10.9955, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=0.5928, Train Acc=79.79%, Val Loss=1.1948, Val Acc=60.72%, Grad Norm=11.0455, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=0.5852, Train Acc=80.23%, Val Loss=1.2000, Val Acc=60.85%, Grad Norm=11.0428, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=0.5880, Train Acc=80.13%, Val Loss=1.1963, Val Acc=60.56%, Grad Norm=11.1513, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=0.5866, Train Acc=80.23%, Val Loss=1.2001, Val Acc=60.75%, Grad Norm=11.2571, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=0.5820, Train Acc=80.14%, Val Loss=1.1987, Val Acc=60.89%, Grad Norm=11.2959, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=0.5832, Train Acc=80.30%, Val Loss=1.1962, Val Acc=60.92%, Grad Norm=11.3397, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=0.5800, Train Acc=80.36%, Val Loss=1.1854, Val Acc=61.06%, Grad Norm=11.4199, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=0.5740, Train Acc=80.73%, Val Loss=1.1966, Val Acc=60.85%, Grad Norm=11.4574, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=0.5807, Train Acc=80.47%, Val Loss=1.1925, Val Acc=61.23%, Grad Norm=11.5764, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=0.5743, Train Acc=80.64%, Val Loss=1.1999, Val Acc=60.89%, Grad Norm=11.5734, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=0.5708, Train Acc=80.77%, Val Loss=1.2049, Val Acc=60.80%, Grad Norm=11.6149, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=0.5726, Train Acc=80.82%, Val Loss=1.1986, Val Acc=61.02%, Grad Norm=11.6277, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=0.5705, Train Acc=80.95%, Val Loss=1.2008, Val Acc=61.07%, Grad Norm=11.7188, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=0.5725, Train Acc=80.81%, Val Loss=1.2091, Val Acc=60.74%, Grad Norm=11.7391, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=0.5639, Train Acc=81.09%, Val Loss=1.2057, Val Acc=61.02%, Grad Norm=11.7198, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=0.5694, Train Acc=80.68%, Val Loss=1.2100, Val Acc=60.54%, Grad Norm=11.8306, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=0.5671, Train Acc=80.98%, Val Loss=1.2055, Val Acc=60.79%, Grad Norm=11.8726, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=0.5650, Train Acc=81.04%, Val Loss=1.1977, Val Acc=61.02%, Grad Norm=11.8150, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=0.5639, Train Acc=81.15%, Val Loss=1.2023, Val Acc=60.74%, Grad Norm=11.8809, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=0.5636, Train Acc=81.02%, Val Loss=1.2080, Val Acc=60.84%, Grad Norm=11.8907, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=0.5632, Train Acc=81.14%, Val Loss=1.2155, Val Acc=60.35%, Grad Norm=11.9552, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=0.5696, Train Acc=80.77%, Val Loss=1.2047, Val Acc=60.91%, Grad Norm=12.0653, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=0.5586, Train Acc=81.32%, Val Loss=1.2100, Val Acc=60.90%, Grad Norm=11.8985, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=0.5627, Train Acc=81.19%, Val Loss=1.2080, Val Acc=60.80%, Grad Norm=11.9783, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=0.5600, Train Acc=81.15%, Val Loss=1.2063, Val Acc=60.92%, Grad Norm=12.0193, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=0.5579, Train Acc=81.18%, Val Loss=1.2140, Val Acc=60.68%, Grad Norm=11.9786, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=0.5605, Train Acc=81.32%, Val Loss=1.2024, Val Acc=61.05%, Grad Norm=12.0334, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=0.5596, Train Acc=81.24%, Val Loss=1.2062, Val Acc=61.06%, Grad Norm=12.0361, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=0.5586, Train Acc=81.19%, Val Loss=1.2046, Val Acc=61.00%, Grad Norm=12.0789, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=0.5506, Train Acc=81.74%, Val Loss=1.2118, Val Acc=60.77%, Grad Norm=12.0101, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=0.5569, Train Acc=81.44%, Val Loss=1.2128, Val Acc=60.61%, Grad Norm=12.0602, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=0.5588, Train Acc=81.35%, Val Loss=1.2070, Val Acc=60.96%, Grad Norm=12.1271, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=0.5578, Train Acc=81.45%, Val Loss=1.2125, Val Acc=60.69%, Grad Norm=12.1119, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=0.5490, Train Acc=81.55%, Val Loss=1.2051, Val Acc=61.03%, Grad Norm=12.0455, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=0.5585, Train Acc=81.37%, Val Loss=1.2153, Val Acc=60.83%, Grad Norm=12.1290, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=0.5601, Train Acc=81.19%, Val Loss=1.2059, Val Acc=61.06%, Grad Norm=12.1898, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=0.5552, Train Acc=81.40%, Val Loss=1.2097, Val Acc=60.85%, Grad Norm=12.1312, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=0.5555, Train Acc=81.40%, Val Loss=1.2011, Val Acc=61.15%, Grad Norm=12.1360, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=0.5550, Train Acc=81.29%, Val Loss=1.2086, Val Acc=61.03%, Grad Norm=12.1919, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=61.23%）\n",
      "Fold 3 DONE | Best Val Acc≈61.23% | Final Val Acc=61.23% | Test Acc=58.85%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.1473, Train Acc=17.04%, Val Loss=2.9118, Val Acc=17.81%, Grad Norm=6.6438, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=1.8480, Train Acc=30.38%, Val Loss=2.1826, Val Acc=29.73%, Grad Norm=5.4703, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=1.5580, Train Acc=42.68%, Val Loss=1.6827, Val Acc=41.86%, Grad Norm=4.9424, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.3531, Train Acc=50.36%, Val Loss=1.4956, Val Acc=47.68%, Grad Norm=4.4414, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.2387, Train Acc=54.81%, Val Loss=1.4251, Val Acc=49.55%, Grad Norm=4.2650, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.1688, Train Acc=57.77%, Val Loss=1.3483, Val Acc=52.96%, Grad Norm=4.1214, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=1.1164, Train Acc=59.83%, Val Loss=1.2952, Val Acc=54.95%, Grad Norm=4.0259, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=1.0787, Train Acc=61.28%, Val Loss=1.2754, Val Acc=54.11%, Grad Norm=4.0190, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=1.0536, Train Acc=62.50%, Val Loss=1.2675, Val Acc=54.99%, Grad Norm=4.0644, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=1.0277, Train Acc=63.27%, Val Loss=1.1808, Val Acc=57.42%, Grad Norm=4.1466, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=0.9761, Train Acc=65.42%, Val Loss=1.1922, Val Acc=58.48%, Grad Norm=4.2366, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=0.9574, Train Acc=66.22%, Val Loss=1.2117, Val Acc=57.71%, Grad Norm=4.4916, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=0.9388, Train Acc=66.78%, Val Loss=1.2226, Val Acc=58.35%, Grad Norm=4.6642, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=0.9214, Train Acc=67.62%, Val Loss=1.1586, Val Acc=59.26%, Grad Norm=4.9539, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=0.9121, Train Acc=67.92%, Val Loss=1.1801, Val Acc=60.31%, Grad Norm=5.1308, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=0.8982, Train Acc=68.46%, Val Loss=1.1689, Val Acc=59.77%, Grad Norm=5.3444, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=0.8789, Train Acc=69.17%, Val Loss=1.1484, Val Acc=60.81%, Grad Norm=5.5576, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=0.8701, Train Acc=69.51%, Val Loss=1.1397, Val Acc=60.37%, Grad Norm=5.7487, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=0.8561, Train Acc=70.05%, Val Loss=1.1436, Val Acc=61.62%, Grad Norm=5.9696, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=0.8406, Train Acc=70.59%, Val Loss=1.1891, Val Acc=59.55%, Grad Norm=6.1125, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=0.8088, Train Acc=72.01%, Val Loss=1.1454, Val Acc=61.85%, Grad Norm=6.4142, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=0.7955, Train Acc=72.49%, Val Loss=1.1204, Val Acc=61.53%, Grad Norm=6.7227, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=0.7855, Train Acc=72.78%, Val Loss=1.1148, Val Acc=61.72%, Grad Norm=6.9913, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=0.7724, Train Acc=73.28%, Val Loss=1.1472, Val Acc=61.43%, Grad Norm=7.1843, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=0.7586, Train Acc=73.82%, Val Loss=1.1192, Val Acc=62.14%, Grad Norm=7.5033, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=0.7528, Train Acc=74.00%, Val Loss=1.1342, Val Acc=62.22%, Grad Norm=7.6646, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=0.7438, Train Acc=74.30%, Val Loss=1.1122, Val Acc=62.33%, Grad Norm=7.9287, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=0.7340, Train Acc=74.88%, Val Loss=1.1433, Val Acc=61.46%, Grad Norm=8.1392, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=0.7295, Train Acc=74.74%, Val Loss=1.1397, Val Acc=62.04%, Grad Norm=8.4254, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=0.7248, Train Acc=75.24%, Val Loss=1.1074, Val Acc=63.19%, Grad Norm=8.5973, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=0.6970, Train Acc=76.11%, Val Loss=1.1286, Val Acc=62.11%, Grad Norm=8.8368, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=0.6873, Train Acc=76.38%, Val Loss=1.1238, Val Acc=62.72%, Grad Norm=9.0797, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=0.6832, Train Acc=76.47%, Val Loss=1.1126, Val Acc=62.78%, Grad Norm=9.2916, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=0.6742, Train Acc=76.99%, Val Loss=1.1132, Val Acc=62.70%, Grad Norm=9.4692, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=0.6670, Train Acc=77.16%, Val Loss=1.1385, Val Acc=62.79%, Grad Norm=9.7258, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=0.6527, Train Acc=77.81%, Val Loss=1.1167, Val Acc=62.92%, Grad Norm=9.9201, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=0.6553, Train Acc=77.75%, Val Loss=1.1123, Val Acc=63.18%, Grad Norm=10.1372, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=0.6470, Train Acc=78.07%, Val Loss=1.1138, Val Acc=63.58%, Grad Norm=10.3023, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=0.6428, Train Acc=78.12%, Val Loss=1.1250, Val Acc=63.13%, Grad Norm=10.4512, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=0.6360, Train Acc=78.38%, Val Loss=1.1428, Val Acc=62.71%, Grad Norm=10.6156, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=0.6229, Train Acc=79.00%, Val Loss=1.1217, Val Acc=63.43%, Grad Norm=10.7859, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=0.6215, Train Acc=79.13%, Val Loss=1.1149, Val Acc=63.38%, Grad Norm=10.9562, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=0.6165, Train Acc=79.20%, Val Loss=1.1217, Val Acc=63.25%, Grad Norm=11.0993, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=0.6093, Train Acc=79.46%, Val Loss=1.1246, Val Acc=63.05%, Grad Norm=11.2180, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=0.6084, Train Acc=79.47%, Val Loss=1.1230, Val Acc=63.17%, Grad Norm=11.3939, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=0.6068, Train Acc=79.60%, Val Loss=1.1363, Val Acc=63.39%, Grad Norm=11.5814, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=0.6031, Train Acc=79.75%, Val Loss=1.1507, Val Acc=62.95%, Grad Norm=11.6546, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=0.5957, Train Acc=79.86%, Val Loss=1.1200, Val Acc=63.39%, Grad Norm=11.8229, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=0.5971, Train Acc=79.76%, Val Loss=1.1118, Val Acc=63.37%, Grad Norm=12.0083, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=0.5879, Train Acc=80.30%, Val Loss=1.1334, Val Acc=63.63%, Grad Norm=12.0088, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=0.5825, Train Acc=80.44%, Val Loss=1.1347, Val Acc=63.45%, Grad Norm=12.0544, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=0.5793, Train Acc=80.60%, Val Loss=1.1307, Val Acc=63.35%, Grad Norm=12.2103, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=0.5787, Train Acc=80.62%, Val Loss=1.1266, Val Acc=63.42%, Grad Norm=12.2991, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=0.5783, Train Acc=80.55%, Val Loss=1.1440, Val Acc=63.50%, Grad Norm=12.4035, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=0.5760, Train Acc=80.67%, Val Loss=1.1331, Val Acc=63.50%, Grad Norm=12.4564, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=0.5677, Train Acc=80.88%, Val Loss=1.1355, Val Acc=63.57%, Grad Norm=12.4468, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=0.5678, Train Acc=80.93%, Val Loss=1.1367, Val Acc=63.37%, Grad Norm=12.5577, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=0.5683, Train Acc=80.97%, Val Loss=1.1355, Val Acc=63.34%, Grad Norm=12.6595, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=0.5624, Train Acc=81.15%, Val Loss=1.1388, Val Acc=63.17%, Grad Norm=12.6532, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=0.5617, Train Acc=81.21%, Val Loss=1.1351, Val Acc=63.69%, Grad Norm=12.7760, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=0.5564, Train Acc=81.22%, Val Loss=1.1312, Val Acc=63.75%, Grad Norm=12.8070, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=0.5570, Train Acc=81.35%, Val Loss=1.1343, Val Acc=63.47%, Grad Norm=12.9393, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=0.5579, Train Acc=81.35%, Val Loss=1.1386, Val Acc=63.83%, Grad Norm=12.9295, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=0.5569, Train Acc=81.33%, Val Loss=1.1357, Val Acc=63.58%, Grad Norm=13.0090, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=0.5552, Train Acc=81.51%, Val Loss=1.1379, Val Acc=63.59%, Grad Norm=12.9736, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=0.5574, Train Acc=81.41%, Val Loss=1.1284, Val Acc=63.60%, Grad Norm=13.1243, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=0.5532, Train Acc=81.74%, Val Loss=1.1330, Val Acc=63.67%, Grad Norm=13.1210, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=0.5509, Train Acc=81.54%, Val Loss=1.1429, Val Acc=63.43%, Grad Norm=13.0763, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=0.5486, Train Acc=81.75%, Val Loss=1.1310, Val Acc=63.71%, Grad Norm=13.1559, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=0.5531, Train Acc=81.56%, Val Loss=1.1351, Val Acc=63.66%, Grad Norm=13.2689, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=0.5514, Train Acc=81.43%, Val Loss=1.1353, Val Acc=63.67%, Grad Norm=13.3029, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=0.5520, Train Acc=81.57%, Val Loss=1.1324, Val Acc=63.54%, Grad Norm=13.2964, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=0.5463, Train Acc=81.73%, Val Loss=1.1333, Val Acc=63.81%, Grad Norm=13.2645, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=0.5467, Train Acc=81.76%, Val Loss=1.1330, Val Acc=63.88%, Grad Norm=13.3260, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=0.5480, Train Acc=81.60%, Val Loss=1.1318, Val Acc=63.87%, Grad Norm=13.3709, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=0.5501, Train Acc=81.37%, Val Loss=1.1403, Val Acc=63.51%, Grad Norm=13.4093, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=0.5474, Train Acc=81.64%, Val Loss=1.1369, Val Acc=63.55%, Grad Norm=13.4510, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=0.5491, Train Acc=81.85%, Val Loss=1.1367, Val Acc=63.54%, Grad Norm=13.4266, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=0.5420, Train Acc=81.80%, Val Loss=1.1240, Val Acc=63.78%, Grad Norm=13.4234, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=0.5438, Train Acc=81.94%, Val Loss=1.1311, Val Acc=63.55%, Grad Norm=13.4261, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=0.5386, Train Acc=82.21%, Val Loss=1.1376, Val Acc=63.59%, Grad Norm=13.3933, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=0.5446, Train Acc=81.91%, Val Loss=1.1333, Val Acc=63.60%, Grad Norm=13.5107, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=0.5416, Train Acc=81.82%, Val Loss=1.1307, Val Acc=63.69%, Grad Norm=13.4871, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=0.5402, Train Acc=81.95%, Val Loss=1.1366, Val Acc=63.67%, Grad Norm=13.4779, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=0.5431, Train Acc=81.97%, Val Loss=1.1329, Val Acc=63.66%, Grad Norm=13.5004, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=0.5371, Train Acc=81.91%, Val Loss=1.1341, Val Acc=63.72%, Grad Norm=13.5142, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=0.5433, Train Acc=81.81%, Val Loss=1.1290, Val Acc=63.61%, Grad Norm=13.5392, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=0.5409, Train Acc=81.83%, Val Loss=1.1379, Val Acc=63.49%, Grad Norm=13.5132, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=0.5379, Train Acc=82.04%, Val Loss=1.1302, Val Acc=63.82%, Grad Norm=13.5331, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=0.5434, Train Acc=81.75%, Val Loss=1.1365, Val Acc=63.71%, Grad Norm=13.6690, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=0.5390, Train Acc=81.95%, Val Loss=1.1371, Val Acc=63.56%, Grad Norm=13.5447, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=0.5395, Train Acc=81.99%, Val Loss=1.1392, Val Acc=63.65%, Grad Norm=13.6000, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=0.5380, Train Acc=82.01%, Val Loss=1.1339, Val Acc=63.79%, Grad Norm=13.5796, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=0.5425, Train Acc=81.90%, Val Loss=1.1379, Val Acc=63.51%, Grad Norm=13.6273, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=0.5411, Train Acc=81.92%, Val Loss=1.1347, Val Acc=63.62%, Grad Norm=13.6047, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=0.5372, Train Acc=82.08%, Val Loss=1.1339, Val Acc=63.61%, Grad Norm=13.5733, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=0.5379, Train Acc=81.98%, Val Loss=1.1367, Val Acc=63.63%, Grad Norm=13.6148, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=0.5360, Train Acc=82.16%, Val Loss=1.1319, Val Acc=63.69%, Grad Norm=13.5512, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=0.5430, Train Acc=81.86%, Val Loss=1.1404, Val Acc=63.61%, Grad Norm=13.6695, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=0.5381, Train Acc=81.99%, Val Loss=1.1354, Val Acc=63.56%, Grad Norm=13.6615, LR=1.95313e-07\n",
      "Fold 4, Epoch 101: Train Loss=0.5414, Train Acc=81.94%, Val Loss=1.1382, Val Acc=63.50%, Grad Norm=13.6819, LR=9.76563e-08\n",
      "Fold 4, Epoch 102: Train Loss=0.5365, Train Acc=82.09%, Val Loss=1.1344, Val Acc=63.71%, Grad Norm=13.6180, LR=9.76563e-08\n",
      "Fold 4, Epoch 103: Train Loss=0.5368, Train Acc=82.01%, Val Loss=1.1371, Val Acc=63.51%, Grad Norm=13.6168, LR=9.76563e-08\n",
      "Fold 4, Epoch 104: Train Loss=0.5318, Train Acc=82.11%, Val Loss=1.1357, Val Acc=63.70%, Grad Norm=13.5547, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=63.88%）\n",
      "Fold 4 DONE | Best Val Acc≈63.88% | Final Val Acc=63.88% | Test Acc=60.43%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.1606, Train Acc=16.19%, Val Loss=3.2990, Val Acc=16.34%, Grad Norm=6.4709, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=1.8616, Train Acc=30.53%, Val Loss=2.0980, Val Acc=30.41%, Grad Norm=5.7563, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=1.5083, Train Acc=44.52%, Val Loss=1.8057, Val Acc=37.40%, Grad Norm=4.8979, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=1.3190, Train Acc=51.79%, Val Loss=1.6669, Val Acc=43.66%, Grad Norm=4.2790, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.2140, Train Acc=56.11%, Val Loss=1.5739, Val Acc=46.60%, Grad Norm=4.0925, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.1469, Train Acc=58.71%, Val Loss=1.5829, Val Acc=46.79%, Grad Norm=3.9783, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=1.1036, Train Acc=60.33%, Val Loss=1.5270, Val Acc=48.46%, Grad Norm=3.9668, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=1.0724, Train Acc=61.57%, Val Loss=1.4313, Val Acc=49.65%, Grad Norm=3.9363, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=1.0455, Train Acc=62.74%, Val Loss=1.4917, Val Acc=49.15%, Grad Norm=3.9356, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=1.0127, Train Acc=64.32%, Val Loss=1.4555, Val Acc=49.97%, Grad Norm=4.0779, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=0.9630, Train Acc=65.88%, Val Loss=1.3209, Val Acc=52.12%, Grad Norm=4.1902, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=0.9437, Train Acc=66.62%, Val Loss=1.3481, Val Acc=53.16%, Grad Norm=4.4157, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=0.9276, Train Acc=67.21%, Val Loss=1.3175, Val Acc=53.64%, Grad Norm=4.6762, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=0.9136, Train Acc=67.83%, Val Loss=1.3735, Val Acc=52.47%, Grad Norm=4.8500, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=0.9029, Train Acc=68.33%, Val Loss=1.3297, Val Acc=53.31%, Grad Norm=5.0478, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=0.8890, Train Acc=68.99%, Val Loss=1.3073, Val Acc=53.90%, Grad Norm=5.2647, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=0.8747, Train Acc=69.39%, Val Loss=1.3527, Val Acc=53.88%, Grad Norm=5.4321, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=0.8637, Train Acc=69.85%, Val Loss=1.3291, Val Acc=53.74%, Grad Norm=5.6185, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=0.8511, Train Acc=70.43%, Val Loss=1.3164, Val Acc=54.94%, Grad Norm=5.8464, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=0.8380, Train Acc=70.75%, Val Loss=1.2967, Val Acc=53.62%, Grad Norm=6.0515, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=0.8053, Train Acc=71.95%, Val Loss=1.3180, Val Acc=54.90%, Grad Norm=6.3121, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=0.7916, Train Acc=72.64%, Val Loss=1.2749, Val Acc=55.42%, Grad Norm=6.6181, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=0.7722, Train Acc=73.11%, Val Loss=1.2866, Val Acc=55.42%, Grad Norm=6.9014, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=0.7642, Train Acc=73.64%, Val Loss=1.2917, Val Acc=55.38%, Grad Norm=7.1646, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=0.7570, Train Acc=73.70%, Val Loss=1.3329, Val Acc=55.05%, Grad Norm=7.4150, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=0.7540, Train Acc=74.01%, Val Loss=1.3179, Val Acc=55.59%, Grad Norm=7.5955, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=0.7435, Train Acc=74.46%, Val Loss=1.2975, Val Acc=56.18%, Grad Norm=7.8618, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=0.7356, Train Acc=74.63%, Val Loss=1.2599, Val Acc=57.38%, Grad Norm=7.9880, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=0.7270, Train Acc=75.05%, Val Loss=1.2982, Val Acc=56.26%, Grad Norm=8.2752, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=0.7189, Train Acc=75.32%, Val Loss=1.3239, Val Acc=55.75%, Grad Norm=8.5635, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=0.6980, Train Acc=76.48%, Val Loss=1.2894, Val Acc=55.96%, Grad Norm=8.7434, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=0.6818, Train Acc=76.84%, Val Loss=1.2812, Val Acc=56.68%, Grad Norm=9.0414, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=0.6780, Train Acc=76.78%, Val Loss=1.2883, Val Acc=56.78%, Grad Norm=9.2427, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=0.6741, Train Acc=77.01%, Val Loss=1.2908, Val Acc=57.30%, Grad Norm=9.4645, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=0.6663, Train Acc=77.25%, Val Loss=1.2584, Val Acc=56.84%, Grad Norm=9.6308, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=0.6589, Train Acc=77.46%, Val Loss=1.3035, Val Acc=56.23%, Grad Norm=9.9075, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=0.6532, Train Acc=77.80%, Val Loss=1.2930, Val Acc=56.88%, Grad Norm=9.9741, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=0.6483, Train Acc=78.08%, Val Loss=1.2824, Val Acc=56.94%, Grad Norm=10.1977, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=0.6451, Train Acc=78.03%, Val Loss=1.2953, Val Acc=57.32%, Grad Norm=10.4321, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=0.6351, Train Acc=78.50%, Val Loss=1.3196, Val Acc=56.60%, Grad Norm=10.5572, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=0.6229, Train Acc=79.05%, Val Loss=1.3048, Val Acc=56.79%, Grad Norm=10.7511, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=0.6189, Train Acc=79.14%, Val Loss=1.2901, Val Acc=57.28%, Grad Norm=10.9599, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=0.6122, Train Acc=79.33%, Val Loss=1.3092, Val Acc=57.06%, Grad Norm=11.0546, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=0.6089, Train Acc=79.46%, Val Loss=1.3119, Val Acc=56.83%, Grad Norm=11.2182, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=0.6048, Train Acc=79.58%, Val Loss=1.3028, Val Acc=57.03%, Grad Norm=11.3035, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=0.6073, Train Acc=79.42%, Val Loss=1.3127, Val Acc=57.28%, Grad Norm=11.4974, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=0.6021, Train Acc=79.70%, Val Loss=1.2845, Val Acc=57.43%, Grad Norm=11.5971, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=0.5936, Train Acc=79.80%, Val Loss=1.2967, Val Acc=57.39%, Grad Norm=11.7853, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=0.5941, Train Acc=79.97%, Val Loss=1.2994, Val Acc=56.93%, Grad Norm=11.9033, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=0.5912, Train Acc=80.03%, Val Loss=1.2993, Val Acc=57.35%, Grad Norm=12.0060, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=0.5836, Train Acc=80.45%, Val Loss=1.2917, Val Acc=57.47%, Grad Norm=12.0263, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=0.5786, Train Acc=80.65%, Val Loss=1.3046, Val Acc=57.05%, Grad Norm=12.1670, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=0.5757, Train Acc=80.64%, Val Loss=1.2983, Val Acc=57.52%, Grad Norm=12.2727, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=0.5741, Train Acc=80.76%, Val Loss=1.3022, Val Acc=57.42%, Grad Norm=12.3035, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=0.5776, Train Acc=80.63%, Val Loss=1.3073, Val Acc=57.59%, Grad Norm=12.4277, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=0.5694, Train Acc=80.82%, Val Loss=1.3051, Val Acc=57.17%, Grad Norm=12.4279, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=0.5708, Train Acc=80.78%, Val Loss=1.3059, Val Acc=57.48%, Grad Norm=12.5422, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=0.5710, Train Acc=80.87%, Val Loss=1.2996, Val Acc=57.68%, Grad Norm=12.5878, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=0.5667, Train Acc=81.07%, Val Loss=1.2911, Val Acc=57.67%, Grad Norm=12.7156, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=0.5652, Train Acc=80.98%, Val Loss=1.2847, Val Acc=57.45%, Grad Norm=12.6945, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=0.5626, Train Acc=81.20%, Val Loss=1.2922, Val Acc=57.31%, Grad Norm=12.8530, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=0.5652, Train Acc=81.01%, Val Loss=1.2914, Val Acc=57.41%, Grad Norm=12.9377, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=0.5583, Train Acc=81.17%, Val Loss=1.2941, Val Acc=57.82%, Grad Norm=12.9177, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=0.5608, Train Acc=81.19%, Val Loss=1.3042, Val Acc=57.35%, Grad Norm=12.9622, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=0.5522, Train Acc=81.64%, Val Loss=1.2990, Val Acc=57.28%, Grad Norm=12.9216, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=0.5554, Train Acc=81.34%, Val Loss=1.2958, Val Acc=57.48%, Grad Norm=13.0315, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=0.5542, Train Acc=81.36%, Val Loss=1.3062, Val Acc=57.42%, Grad Norm=13.1051, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=0.5529, Train Acc=81.44%, Val Loss=1.3119, Val Acc=57.57%, Grad Norm=13.1243, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=0.5508, Train Acc=81.51%, Val Loss=1.3013, Val Acc=57.70%, Grad Norm=13.2159, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=0.5501, Train Acc=81.61%, Val Loss=1.3129, Val Acc=57.47%, Grad Norm=13.2549, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=0.5463, Train Acc=81.83%, Val Loss=1.3192, Val Acc=57.34%, Grad Norm=13.2315, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=0.5516, Train Acc=81.33%, Val Loss=1.3110, Val Acc=57.39%, Grad Norm=13.3485, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=0.5535, Train Acc=81.39%, Val Loss=1.3091, Val Acc=57.57%, Grad Norm=13.3731, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=0.5473, Train Acc=81.78%, Val Loss=1.3001, Val Acc=57.51%, Grad Norm=13.2997, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=0.5464, Train Acc=81.61%, Val Loss=1.3157, Val Acc=57.31%, Grad Norm=13.3491, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=0.5467, Train Acc=81.81%, Val Loss=1.2990, Val Acc=57.51%, Grad Norm=13.3183, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=0.5490, Train Acc=81.62%, Val Loss=1.3034, Val Acc=57.43%, Grad Norm=13.4006, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=0.5442, Train Acc=81.83%, Val Loss=1.2970, Val Acc=57.49%, Grad Norm=13.3734, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=0.5446, Train Acc=81.87%, Val Loss=1.3141, Val Acc=57.54%, Grad Norm=13.4077, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=0.5421, Train Acc=81.79%, Val Loss=1.2981, Val Acc=57.50%, Grad Norm=13.3884, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=0.5437, Train Acc=81.96%, Val Loss=1.3077, Val Acc=57.57%, Grad Norm=13.4222, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=0.5395, Train Acc=82.06%, Val Loss=1.3101, Val Acc=57.75%, Grad Norm=13.4193, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=0.5454, Train Acc=81.83%, Val Loss=1.2975, Val Acc=57.61%, Grad Norm=13.4611, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=0.5442, Train Acc=81.78%, Val Loss=1.3043, Val Acc=57.32%, Grad Norm=13.4465, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=0.5431, Train Acc=81.92%, Val Loss=1.3090, Val Acc=57.49%, Grad Norm=13.4988, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=0.5413, Train Acc=81.91%, Val Loss=1.3037, Val Acc=57.68%, Grad Norm=13.4934, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=0.5431, Train Acc=81.92%, Val Loss=1.3144, Val Acc=57.37%, Grad Norm=13.4948, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=0.5401, Train Acc=81.96%, Val Loss=1.3027, Val Acc=57.61%, Grad Norm=13.4885, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=0.5426, Train Acc=81.83%, Val Loss=1.3068, Val Acc=57.49%, Grad Norm=13.5815, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=0.5401, Train Acc=81.89%, Val Loss=1.3148, Val Acc=57.47%, Grad Norm=13.5152, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=0.5400, Train Acc=82.13%, Val Loss=1.3129, Val Acc=57.40%, Grad Norm=13.5048, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=0.5424, Train Acc=81.93%, Val Loss=1.3040, Val Acc=57.34%, Grad Norm=13.5758, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=0.5407, Train Acc=82.05%, Val Loss=1.3093, Val Acc=57.38%, Grad Norm=13.5729, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=57.82%）\n",
      "Fold 5 DONE | Best Val Acc≈57.82% | Final Val Acc=57.82% | Test Acc=60.11%\n",
      "[INFO] SNR=5 dB | Mean Test Acc: 59.74% ± 0.63%\n",
      "[INFO] SNR   5 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR5dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = 0 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2040, Train Acc=13.15%, Val Loss=3.0665, Val Acc=11.76%, Grad Norm=6.7784, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.1171, Train Acc=19.19%, Val Loss=2.3919, Val Acc=18.41%, Grad Norm=6.0822, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=1.9088, Train Acc=27.95%, Val Loss=2.1360, Val Acc=25.30%, Grad Norm=5.1423, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=1.6915, Train Acc=37.19%, Val Loss=1.7429, Val Acc=35.50%, Grad Norm=4.8035, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=1.5451, Train Acc=43.03%, Val Loss=1.6227, Val Acc=39.15%, Grad Norm=4.4454, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.4479, Train Acc=47.01%, Val Loss=1.5200, Val Acc=43.09%, Grad Norm=4.3366, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=1.3728, Train Acc=50.08%, Val Loss=1.4655, Val Acc=45.67%, Grad Norm=4.2139, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=1.3202, Train Acc=52.01%, Val Loss=1.4045, Val Acc=47.97%, Grad Norm=4.1644, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=1.2825, Train Acc=53.64%, Val Loss=1.3827, Val Acc=48.36%, Grad Norm=4.0645, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=1.2458, Train Acc=55.18%, Val Loss=1.3786, Val Acc=48.99%, Grad Norm=4.0817, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=1.2004, Train Acc=57.02%, Val Loss=1.3211, Val Acc=51.42%, Grad Norm=4.1339, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=1.1806, Train Acc=57.63%, Val Loss=1.3088, Val Acc=52.25%, Grad Norm=4.3244, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=1.1653, Train Acc=58.37%, Val Loss=1.3014, Val Acc=52.21%, Grad Norm=4.4924, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=1.1527, Train Acc=58.99%, Val Loss=1.3234, Val Acc=51.94%, Grad Norm=4.6541, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=1.1388, Train Acc=59.54%, Val Loss=1.2845, Val Acc=52.72%, Grad Norm=4.8029, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=1.1243, Train Acc=60.08%, Val Loss=1.2693, Val Acc=53.41%, Grad Norm=4.9263, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=1.1189, Train Acc=60.45%, Val Loss=1.3182, Val Acc=52.39%, Grad Norm=5.0679, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=1.1020, Train Acc=61.07%, Val Loss=1.2879, Val Acc=53.25%, Grad Norm=5.2178, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=1.1018, Train Acc=61.21%, Val Loss=1.2749, Val Acc=53.42%, Grad Norm=5.2828, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=1.0828, Train Acc=61.81%, Val Loss=1.2912, Val Acc=53.11%, Grad Norm=5.3985, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=1.0623, Train Acc=62.61%, Val Loss=1.2621, Val Acc=54.44%, Grad Norm=5.6417, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=1.0480, Train Acc=63.19%, Val Loss=1.2635, Val Acc=54.35%, Grad Norm=5.8410, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=1.0388, Train Acc=63.59%, Val Loss=1.2586, Val Acc=54.41%, Grad Norm=6.0401, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=1.0306, Train Acc=63.88%, Val Loss=1.2546, Val Acc=54.51%, Grad Norm=6.1738, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=1.0212, Train Acc=64.18%, Val Loss=1.2487, Val Acc=54.70%, Grad Norm=6.3467, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=1.0142, Train Acc=64.62%, Val Loss=1.2574, Val Acc=54.79%, Grad Norm=6.6034, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=1.0115, Train Acc=64.79%, Val Loss=1.2520, Val Acc=54.52%, Grad Norm=6.7105, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=1.0059, Train Acc=64.87%, Val Loss=1.2578, Val Acc=54.75%, Grad Norm=6.9526, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=0.9967, Train Acc=65.29%, Val Loss=1.2579, Val Acc=54.87%, Grad Norm=7.1512, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=0.9897, Train Acc=65.61%, Val Loss=1.2542, Val Acc=55.14%, Grad Norm=7.2714, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=0.9697, Train Acc=66.27%, Val Loss=1.2404, Val Acc=55.54%, Grad Norm=7.4824, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=0.9658, Train Acc=66.41%, Val Loss=1.2623, Val Acc=55.27%, Grad Norm=7.6828, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=0.9617, Train Acc=66.46%, Val Loss=1.2486, Val Acc=55.42%, Grad Norm=7.9044, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=0.9529, Train Acc=67.03%, Val Loss=1.2494, Val Acc=55.36%, Grad Norm=8.0347, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=0.9459, Train Acc=67.14%, Val Loss=1.2613, Val Acc=55.23%, Grad Norm=8.1807, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=0.9465, Train Acc=67.12%, Val Loss=1.2477, Val Acc=55.40%, Grad Norm=8.3470, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=0.9408, Train Acc=67.34%, Val Loss=1.2559, Val Acc=55.37%, Grad Norm=8.5779, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=0.9338, Train Acc=67.75%, Val Loss=1.2606, Val Acc=55.31%, Grad Norm=8.6280, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=0.9358, Train Acc=67.74%, Val Loss=1.2468, Val Acc=55.44%, Grad Norm=8.7927, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=0.9282, Train Acc=67.87%, Val Loss=1.2386, Val Acc=55.59%, Grad Norm=9.0038, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=0.9126, Train Acc=68.50%, Val Loss=1.2482, Val Acc=55.57%, Grad Norm=9.1742, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=0.9157, Train Acc=68.55%, Val Loss=1.2485, Val Acc=55.54%, Grad Norm=9.3748, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=0.9111, Train Acc=68.50%, Val Loss=1.2578, Val Acc=55.23%, Grad Norm=9.4249, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=0.9064, Train Acc=68.60%, Val Loss=1.2561, Val Acc=55.43%, Grad Norm=9.4469, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=0.9028, Train Acc=68.93%, Val Loss=1.2549, Val Acc=55.76%, Grad Norm=9.5589, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=0.8960, Train Acc=69.02%, Val Loss=1.2665, Val Acc=55.08%, Grad Norm=9.7642, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=0.8996, Train Acc=69.02%, Val Loss=1.2651, Val Acc=55.49%, Grad Norm=9.8698, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=0.8915, Train Acc=69.46%, Val Loss=1.2554, Val Acc=55.70%, Grad Norm=9.9912, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=0.8897, Train Acc=69.11%, Val Loss=1.2547, Val Acc=55.60%, Grad Norm=10.1343, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=0.8933, Train Acc=69.16%, Val Loss=1.2525, Val Acc=55.55%, Grad Norm=10.1964, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=0.8840, Train Acc=69.58%, Val Loss=1.2526, Val Acc=55.51%, Grad Norm=10.2368, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=0.8874, Train Acc=69.41%, Val Loss=1.2437, Val Acc=56.01%, Grad Norm=10.4206, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=0.8762, Train Acc=69.94%, Val Loss=1.2540, Val Acc=55.85%, Grad Norm=10.3807, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=0.8844, Train Acc=69.68%, Val Loss=1.2566, Val Acc=55.69%, Grad Norm=10.5571, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=0.8779, Train Acc=69.78%, Val Loss=1.2613, Val Acc=55.85%, Grad Norm=10.5542, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=0.8726, Train Acc=70.04%, Val Loss=1.2697, Val Acc=55.40%, Grad Norm=10.6516, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=0.8755, Train Acc=70.00%, Val Loss=1.2589, Val Acc=55.73%, Grad Norm=10.7286, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=0.8787, Train Acc=69.76%, Val Loss=1.2545, Val Acc=55.88%, Grad Norm=10.8295, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=0.8717, Train Acc=69.91%, Val Loss=1.2548, Val Acc=55.77%, Grad Norm=10.8267, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=0.8677, Train Acc=70.20%, Val Loss=1.2570, Val Acc=55.75%, Grad Norm=10.8930, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=0.8683, Train Acc=70.37%, Val Loss=1.2607, Val Acc=55.53%, Grad Norm=10.9628, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=0.8685, Train Acc=70.16%, Val Loss=1.2612, Val Acc=55.79%, Grad Norm=11.0130, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=0.8609, Train Acc=70.60%, Val Loss=1.2568, Val Acc=55.67%, Grad Norm=11.0159, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=0.8584, Train Acc=70.55%, Val Loss=1.2608, Val Acc=55.80%, Grad Norm=11.0632, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=0.8603, Train Acc=70.33%, Val Loss=1.2615, Val Acc=55.68%, Grad Norm=11.1733, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=0.8650, Train Acc=70.35%, Val Loss=1.2585, Val Acc=55.85%, Grad Norm=11.1958, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=0.8629, Train Acc=70.17%, Val Loss=1.2623, Val Acc=55.56%, Grad Norm=11.2024, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=0.8674, Train Acc=70.17%, Val Loss=1.2621, Val Acc=55.79%, Grad Norm=11.2596, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=0.8634, Train Acc=70.37%, Val Loss=1.2556, Val Acc=55.72%, Grad Norm=11.1969, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=0.8610, Train Acc=70.67%, Val Loss=1.2546, Val Acc=55.98%, Grad Norm=11.2229, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=0.8619, Train Acc=70.35%, Val Loss=1.2594, Val Acc=55.79%, Grad Norm=11.3049, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=0.8608, Train Acc=70.49%, Val Loss=1.2647, Val Acc=55.63%, Grad Norm=11.3463, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=0.8575, Train Acc=70.70%, Val Loss=1.2592, Val Acc=55.87%, Grad Norm=11.3334, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=0.8606, Train Acc=70.44%, Val Loss=1.2577, Val Acc=55.95%, Grad Norm=11.3992, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=0.8527, Train Acc=70.87%, Val Loss=1.2600, Val Acc=55.89%, Grad Norm=11.3667, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=0.8539, Train Acc=70.60%, Val Loss=1.2550, Val Acc=55.92%, Grad Norm=11.3640, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=0.8529, Train Acc=70.78%, Val Loss=1.2591, Val Acc=55.79%, Grad Norm=11.4307, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=0.8582, Train Acc=70.71%, Val Loss=1.2609, Val Acc=55.89%, Grad Norm=11.4672, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=0.8579, Train Acc=70.41%, Val Loss=1.2569, Val Acc=55.84%, Grad Norm=11.4958, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=0.8541, Train Acc=70.87%, Val Loss=1.2605, Val Acc=55.76%, Grad Norm=11.4513, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=0.8524, Train Acc=70.79%, Val Loss=1.2600, Val Acc=55.88%, Grad Norm=11.4557, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=0.8461, Train Acc=70.95%, Val Loss=1.2567, Val Acc=55.93%, Grad Norm=11.4257, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=56.01%）\n",
      "Fold 1 DONE | Best Val Acc≈56.01% | Final Val Acc=56.01% | Test Acc=54.72%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2009, Train Acc=13.35%, Val Loss=3.0932, Val Acc=11.42%, Grad Norm=6.7268, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.0886, Train Acc=20.34%, Val Loss=2.2422, Val Acc=17.81%, Grad Norm=5.8079, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=1.8769, Train Acc=29.51%, Val Loss=2.0282, Val Acc=28.26%, Grad Norm=4.9370, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=1.6681, Train Acc=38.43%, Val Loss=1.6848, Val Acc=38.09%, Grad Norm=4.6801, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.5089, Train Acc=44.43%, Val Loss=1.6429, Val Acc=40.33%, Grad Norm=4.2591, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.4253, Train Acc=47.50%, Val Loss=1.5925, Val Acc=43.11%, Grad Norm=4.0687, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=1.3657, Train Acc=50.38%, Val Loss=1.5652, Val Acc=43.99%, Grad Norm=3.9765, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=1.3183, Train Acc=52.02%, Val Loss=1.5207, Val Acc=46.13%, Grad Norm=3.9682, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=1.2742, Train Acc=53.83%, Val Loss=1.4503, Val Acc=48.55%, Grad Norm=3.9101, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=1.2437, Train Acc=55.16%, Val Loss=1.4691, Val Acc=48.59%, Grad Norm=3.9740, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=1.1937, Train Acc=57.25%, Val Loss=1.4437, Val Acc=49.57%, Grad Norm=4.0305, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=1.1771, Train Acc=58.03%, Val Loss=1.4319, Val Acc=49.75%, Grad Norm=4.1680, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=1.1511, Train Acc=58.92%, Val Loss=1.4191, Val Acc=50.42%, Grad Norm=4.4153, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=1.1429, Train Acc=59.28%, Val Loss=1.4383, Val Acc=49.81%, Grad Norm=4.5249, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=1.1280, Train Acc=60.03%, Val Loss=1.4306, Val Acc=50.84%, Grad Norm=4.6653, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=1.1206, Train Acc=59.95%, Val Loss=1.4037, Val Acc=50.91%, Grad Norm=4.7623, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=1.1077, Train Acc=60.53%, Val Loss=1.4196, Val Acc=50.68%, Grad Norm=4.8678, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=1.0970, Train Acc=61.19%, Val Loss=1.3809, Val Acc=51.87%, Grad Norm=4.9810, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=1.0940, Train Acc=61.48%, Val Loss=1.4033, Val Acc=51.53%, Grad Norm=5.1831, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=1.0810, Train Acc=61.68%, Val Loss=1.3762, Val Acc=51.65%, Grad Norm=5.2369, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=1.0532, Train Acc=62.72%, Val Loss=1.3973, Val Acc=52.06%, Grad Norm=5.4733, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=1.0457, Train Acc=63.08%, Val Loss=1.3984, Val Acc=51.84%, Grad Norm=5.6822, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=1.0351, Train Acc=63.59%, Val Loss=1.3790, Val Acc=52.07%, Grad Norm=5.8758, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=1.0268, Train Acc=64.06%, Val Loss=1.3523, Val Acc=53.06%, Grad Norm=6.0012, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=1.0191, Train Acc=64.12%, Val Loss=1.3746, Val Acc=52.35%, Grad Norm=6.1650, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=1.0111, Train Acc=64.59%, Val Loss=1.3676, Val Acc=52.24%, Grad Norm=6.3757, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=1.0105, Train Acc=64.55%, Val Loss=1.3847, Val Acc=52.35%, Grad Norm=6.5330, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=1.0019, Train Acc=64.79%, Val Loss=1.3839, Val Acc=52.27%, Grad Norm=6.7188, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=0.9967, Train Acc=65.01%, Val Loss=1.3457, Val Acc=52.81%, Grad Norm=6.8217, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=0.9893, Train Acc=65.37%, Val Loss=1.3560, Val Acc=52.92%, Grad Norm=7.0356, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=0.9765, Train Acc=65.78%, Val Loss=1.3556, Val Acc=52.98%, Grad Norm=7.1421, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=0.9671, Train Acc=66.26%, Val Loss=1.3451, Val Acc=53.46%, Grad Norm=7.4492, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=0.9602, Train Acc=66.59%, Val Loss=1.3517, Val Acc=53.49%, Grad Norm=7.6217, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=0.9569, Train Acc=66.55%, Val Loss=1.3526, Val Acc=53.20%, Grad Norm=7.8174, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=0.9533, Train Acc=66.74%, Val Loss=1.3605, Val Acc=53.09%, Grad Norm=7.9999, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=0.9480, Train Acc=67.10%, Val Loss=1.3536, Val Acc=53.32%, Grad Norm=8.1174, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=0.9417, Train Acc=67.24%, Val Loss=1.3615, Val Acc=53.26%, Grad Norm=8.2343, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=0.9386, Train Acc=67.27%, Val Loss=1.3434, Val Acc=53.61%, Grad Norm=8.3869, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=0.9291, Train Acc=67.64%, Val Loss=1.3568, Val Acc=53.46%, Grad Norm=8.6238, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=0.9281, Train Acc=67.58%, Val Loss=1.3366, Val Acc=53.59%, Grad Norm=8.7492, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=0.9180, Train Acc=68.33%, Val Loss=1.3485, Val Acc=53.64%, Grad Norm=8.9200, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=0.9197, Train Acc=68.04%, Val Loss=1.3508, Val Acc=53.81%, Grad Norm=9.0844, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=0.9123, Train Acc=68.53%, Val Loss=1.3467, Val Acc=53.72%, Grad Norm=9.1532, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=0.9116, Train Acc=68.24%, Val Loss=1.3509, Val Acc=53.30%, Grad Norm=9.2254, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=0.9116, Train Acc=68.41%, Val Loss=1.3401, Val Acc=53.60%, Grad Norm=9.4259, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=0.9047, Train Acc=68.73%, Val Loss=1.3605, Val Acc=53.64%, Grad Norm=9.4926, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=0.9023, Train Acc=68.77%, Val Loss=1.3509, Val Acc=53.35%, Grad Norm=9.6576, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=0.8984, Train Acc=68.80%, Val Loss=1.3594, Val Acc=53.37%, Grad Norm=9.8121, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=0.8931, Train Acc=69.21%, Val Loss=1.3600, Val Acc=53.39%, Grad Norm=9.8749, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=0.8967, Train Acc=68.96%, Val Loss=1.3488, Val Acc=53.55%, Grad Norm=10.0055, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=0.8858, Train Acc=69.55%, Val Loss=1.3511, Val Acc=53.71%, Grad Norm=10.0827, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=0.8864, Train Acc=69.13%, Val Loss=1.3457, Val Acc=53.52%, Grad Norm=10.2236, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=0.8825, Train Acc=69.49%, Val Loss=1.3487, Val Acc=53.61%, Grad Norm=10.2003, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=0.8874, Train Acc=69.31%, Val Loss=1.3581, Val Acc=53.46%, Grad Norm=10.3663, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=0.8834, Train Acc=69.39%, Val Loss=1.3615, Val Acc=53.41%, Grad Norm=10.4419, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=0.8780, Train Acc=69.81%, Val Loss=1.3581, Val Acc=53.34%, Grad Norm=10.4591, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=0.8737, Train Acc=69.77%, Val Loss=1.3515, Val Acc=53.61%, Grad Norm=10.5331, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=0.8755, Train Acc=69.75%, Val Loss=1.3617, Val Acc=53.26%, Grad Norm=10.6611, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=0.8763, Train Acc=69.73%, Val Loss=1.3496, Val Acc=53.55%, Grad Norm=10.6495, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=0.8723, Train Acc=69.92%, Val Loss=1.3584, Val Acc=53.43%, Grad Norm=10.7206, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=0.8742, Train Acc=69.90%, Val Loss=1.3491, Val Acc=53.79%, Grad Norm=10.8099, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=0.8667, Train Acc=70.31%, Val Loss=1.3490, Val Acc=53.67%, Grad Norm=10.7538, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=0.8697, Train Acc=70.13%, Val Loss=1.3507, Val Acc=53.72%, Grad Norm=10.8764, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=0.8689, Train Acc=70.05%, Val Loss=1.3551, Val Acc=53.59%, Grad Norm=10.9704, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=0.8693, Train Acc=69.85%, Val Loss=1.3499, Val Acc=53.72%, Grad Norm=10.9802, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=0.8708, Train Acc=69.83%, Val Loss=1.3462, Val Acc=53.87%, Grad Norm=11.0147, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=0.8642, Train Acc=70.27%, Val Loss=1.3497, Val Acc=53.60%, Grad Norm=11.0307, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=0.8658, Train Acc=70.10%, Val Loss=1.3576, Val Acc=53.52%, Grad Norm=11.0821, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=0.8627, Train Acc=70.26%, Val Loss=1.3504, Val Acc=53.70%, Grad Norm=11.1194, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=0.8654, Train Acc=70.35%, Val Loss=1.3425, Val Acc=53.93%, Grad Norm=11.1533, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=0.8627, Train Acc=70.18%, Val Loss=1.3615, Val Acc=53.63%, Grad Norm=11.2061, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=0.8607, Train Acc=70.24%, Val Loss=1.3436, Val Acc=53.87%, Grad Norm=11.1987, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=0.8668, Train Acc=70.18%, Val Loss=1.3503, Val Acc=53.69%, Grad Norm=11.3361, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=0.8584, Train Acc=70.48%, Val Loss=1.3546, Val Acc=53.63%, Grad Norm=11.2037, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=0.8644, Train Acc=70.14%, Val Loss=1.3594, Val Acc=53.72%, Grad Norm=11.2942, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=0.8566, Train Acc=70.68%, Val Loss=1.3453, Val Acc=53.70%, Grad Norm=11.2624, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=0.8590, Train Acc=70.51%, Val Loss=1.3543, Val Acc=53.61%, Grad Norm=11.2904, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=0.8620, Train Acc=70.38%, Val Loss=1.3490, Val Acc=53.72%, Grad Norm=11.3117, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=0.8573, Train Acc=70.67%, Val Loss=1.3565, Val Acc=53.72%, Grad Norm=11.3945, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=0.8592, Train Acc=70.30%, Val Loss=1.3600, Val Acc=53.59%, Grad Norm=11.4157, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=0.8586, Train Acc=70.28%, Val Loss=1.3518, Val Acc=53.52%, Grad Norm=11.4243, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=0.8589, Train Acc=70.45%, Val Loss=1.3538, Val Acc=53.53%, Grad Norm=11.4140, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=0.8570, Train Acc=70.61%, Val Loss=1.3519, Val Acc=53.68%, Grad Norm=11.3797, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=0.8598, Train Acc=70.37%, Val Loss=1.3556, Val Acc=53.56%, Grad Norm=11.4437, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=0.8585, Train Acc=70.38%, Val Loss=1.3526, Val Acc=53.74%, Grad Norm=11.4467, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=0.8529, Train Acc=70.64%, Val Loss=1.3549, Val Acc=53.64%, Grad Norm=11.4192, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=0.8539, Train Acc=70.57%, Val Loss=1.3523, Val Acc=53.65%, Grad Norm=11.4453, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=0.8574, Train Acc=70.43%, Val Loss=1.3537, Val Acc=53.69%, Grad Norm=11.5160, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=0.8592, Train Acc=70.37%, Val Loss=1.3555, Val Acc=53.60%, Grad Norm=11.5233, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=0.8610, Train Acc=70.54%, Val Loss=1.3530, Val Acc=53.73%, Grad Norm=11.5310, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=0.8549, Train Acc=70.48%, Val Loss=1.3553, Val Acc=53.64%, Grad Norm=11.5438, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=0.8529, Train Acc=70.66%, Val Loss=1.3462, Val Acc=53.61%, Grad Norm=11.4316, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=0.8552, Train Acc=70.46%, Val Loss=1.3577, Val Acc=53.65%, Grad Norm=11.4791, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=0.8576, Train Acc=70.52%, Val Loss=1.3515, Val Acc=53.64%, Grad Norm=11.4997, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=0.8525, Train Acc=70.70%, Val Loss=1.3553, Val Acc=53.49%, Grad Norm=11.4386, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=0.8581, Train Acc=70.67%, Val Loss=1.3472, Val Acc=53.71%, Grad Norm=11.5081, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=0.8519, Train Acc=70.73%, Val Loss=1.3511, Val Acc=53.79%, Grad Norm=11.5293, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=0.8524, Train Acc=70.71%, Val Loss=1.3573, Val Acc=53.74%, Grad Norm=11.4954, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=0.8558, Train Acc=70.51%, Val Loss=1.3498, Val Acc=53.77%, Grad Norm=11.5389, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=0.8504, Train Acc=70.78%, Val Loss=1.3568, Val Acc=53.64%, Grad Norm=11.5110, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=53.93%）\n",
      "Fold 2 DONE | Best Val Acc≈53.93% | Final Val Acc=53.93% | Test Acc=53.50%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.1904, Train Acc=13.83%, Val Loss=2.8624, Val Acc=12.89%, Grad Norm=6.4079, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.0556, Train Acc=21.60%, Val Loss=2.7138, Val Acc=20.11%, Grad Norm=5.0374, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=1.8483, Train Acc=30.71%, Val Loss=2.2616, Val Acc=26.23%, Grad Norm=4.7201, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=1.6495, Train Acc=38.77%, Val Loss=1.6815, Val Acc=37.03%, Grad Norm=4.5846, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.5027, Train Acc=44.43%, Val Loss=1.6011, Val Acc=41.55%, Grad Norm=4.3531, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.4103, Train Acc=48.63%, Val Loss=1.5074, Val Acc=44.35%, Grad Norm=4.1751, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=1.3544, Train Acc=50.69%, Val Loss=1.4419, Val Acc=46.51%, Grad Norm=4.1099, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=1.3069, Train Acc=52.52%, Val Loss=1.3970, Val Acc=47.65%, Grad Norm=4.0149, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=1.2689, Train Acc=53.99%, Val Loss=1.4030, Val Acc=48.80%, Grad Norm=3.9750, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=1.2418, Train Acc=55.30%, Val Loss=1.3384, Val Acc=50.81%, Grad Norm=4.0426, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=1.2008, Train Acc=56.94%, Val Loss=1.3264, Val Acc=51.48%, Grad Norm=4.0620, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=1.1771, Train Acc=57.94%, Val Loss=1.3231, Val Acc=51.92%, Grad Norm=4.2776, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=1.1626, Train Acc=58.70%, Val Loss=1.2962, Val Acc=53.11%, Grad Norm=4.3968, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=1.1450, Train Acc=59.15%, Val Loss=1.3100, Val Acc=52.30%, Grad Norm=4.5122, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=1.1373, Train Acc=59.64%, Val Loss=1.3028, Val Acc=53.19%, Grad Norm=4.7287, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=1.1334, Train Acc=59.76%, Val Loss=1.3413, Val Acc=52.07%, Grad Norm=4.8412, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=1.1163, Train Acc=60.23%, Val Loss=1.3032, Val Acc=53.46%, Grad Norm=5.0083, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=1.1087, Train Acc=60.71%, Val Loss=1.2796, Val Acc=53.46%, Grad Norm=5.0934, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=1.0984, Train Acc=61.24%, Val Loss=1.2948, Val Acc=53.55%, Grad Norm=5.2689, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=1.0907, Train Acc=61.38%, Val Loss=1.2887, Val Acc=54.17%, Grad Norm=5.3696, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=1.0579, Train Acc=62.89%, Val Loss=1.2731, Val Acc=54.64%, Grad Norm=5.6005, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=1.0521, Train Acc=63.15%, Val Loss=1.2785, Val Acc=54.34%, Grad Norm=5.7717, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=1.0410, Train Acc=63.65%, Val Loss=1.2685, Val Acc=54.47%, Grad Norm=5.9891, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=1.0340, Train Acc=63.72%, Val Loss=1.2643, Val Acc=54.49%, Grad Norm=6.1348, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=1.0251, Train Acc=63.93%, Val Loss=1.2818, Val Acc=54.22%, Grad Norm=6.3027, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=1.0264, Train Acc=64.02%, Val Loss=1.2810, Val Acc=54.14%, Grad Norm=6.4467, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=1.0166, Train Acc=64.25%, Val Loss=1.2760, Val Acc=54.58%, Grad Norm=6.6464, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=1.0104, Train Acc=64.66%, Val Loss=1.2614, Val Acc=54.92%, Grad Norm=6.8651, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=1.0050, Train Acc=64.88%, Val Loss=1.2532, Val Acc=54.57%, Grad Norm=6.9898, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=1.0041, Train Acc=64.62%, Val Loss=1.2753, Val Acc=54.46%, Grad Norm=7.1574, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=0.9843, Train Acc=65.79%, Val Loss=1.2690, Val Acc=54.66%, Grad Norm=7.4421, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=0.9749, Train Acc=66.01%, Val Loss=1.2684, Val Acc=54.67%, Grad Norm=7.5424, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=0.9687, Train Acc=66.24%, Val Loss=1.2467, Val Acc=55.30%, Grad Norm=7.8417, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=0.9640, Train Acc=66.28%, Val Loss=1.2556, Val Acc=55.05%, Grad Norm=7.9440, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=0.9603, Train Acc=66.49%, Val Loss=1.2732, Val Acc=54.58%, Grad Norm=8.1417, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=0.9551, Train Acc=66.67%, Val Loss=1.2653, Val Acc=54.99%, Grad Norm=8.2912, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=0.9475, Train Acc=67.01%, Val Loss=1.2641, Val Acc=54.71%, Grad Norm=8.4675, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=0.9450, Train Acc=67.09%, Val Loss=1.2799, Val Acc=54.55%, Grad Norm=8.6098, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=0.9466, Train Acc=67.23%, Val Loss=1.2659, Val Acc=54.74%, Grad Norm=8.7562, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=0.9360, Train Acc=67.54%, Val Loss=1.2821, Val Acc=54.33%, Grad Norm=8.9294, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=0.9311, Train Acc=67.66%, Val Loss=1.2854, Val Acc=54.32%, Grad Norm=9.0618, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=0.9271, Train Acc=67.97%, Val Loss=1.2587, Val Acc=55.22%, Grad Norm=9.2889, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=0.9169, Train Acc=68.20%, Val Loss=1.2814, Val Acc=54.75%, Grad Norm=9.3081, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=0.9124, Train Acc=68.63%, Val Loss=1.2722, Val Acc=54.68%, Grad Norm=9.5222, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=0.9081, Train Acc=68.92%, Val Loss=1.2644, Val Acc=55.19%, Grad Norm=9.6743, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=0.9102, Train Acc=68.55%, Val Loss=1.2830, Val Acc=54.74%, Grad Norm=9.7654, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=0.9065, Train Acc=68.53%, Val Loss=1.2786, Val Acc=54.74%, Grad Norm=9.9261, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=0.9009, Train Acc=68.95%, Val Loss=1.2811, Val Acc=54.75%, Grad Norm=9.9776, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=0.8975, Train Acc=69.01%, Val Loss=1.2853, Val Acc=54.72%, Grad Norm=10.1543, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=0.8993, Train Acc=68.88%, Val Loss=1.2786, Val Acc=54.93%, Grad Norm=10.1414, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=0.8943, Train Acc=69.04%, Val Loss=1.2769, Val Acc=54.84%, Grad Norm=10.3077, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=0.8917, Train Acc=69.25%, Val Loss=1.2823, Val Acc=54.93%, Grad Norm=10.4515, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=0.8849, Train Acc=69.50%, Val Loss=1.2706, Val Acc=55.18%, Grad Norm=10.5026, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=0.8859, Train Acc=69.49%, Val Loss=1.2713, Val Acc=55.25%, Grad Norm=10.6053, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=0.8839, Train Acc=69.52%, Val Loss=1.2725, Val Acc=55.17%, Grad Norm=10.6648, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=0.8845, Train Acc=69.46%, Val Loss=1.2736, Val Acc=55.11%, Grad Norm=10.7813, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=0.8861, Train Acc=69.53%, Val Loss=1.2777, Val Acc=54.82%, Grad Norm=10.7572, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=0.8771, Train Acc=69.82%, Val Loss=1.2749, Val Acc=54.91%, Grad Norm=10.8394, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=0.8803, Train Acc=69.62%, Val Loss=1.2797, Val Acc=55.15%, Grad Norm=10.9454, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=0.8805, Train Acc=69.53%, Val Loss=1.2823, Val Acc=54.73%, Grad Norm=10.9547, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=0.8729, Train Acc=70.01%, Val Loss=1.2787, Val Acc=55.01%, Grad Norm=11.0522, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=0.8708, Train Acc=70.07%, Val Loss=1.2795, Val Acc=54.82%, Grad Norm=11.1209, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=0.8781, Train Acc=69.81%, Val Loss=1.2874, Val Acc=54.82%, Grad Norm=11.1527, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=55.30%）\n",
      "Fold 3 DONE | Best Val Acc≈55.30% | Final Val Acc=55.30% | Test Acc=52.73%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.1977, Train Acc=13.69%, Val Loss=3.0557, Val Acc=12.48%, Grad Norm=6.3605, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.0687, Train Acc=21.16%, Val Loss=2.4397, Val Acc=19.64%, Grad Norm=5.3561, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=1.8136, Train Acc=31.97%, Val Loss=1.8925, Val Acc=32.23%, Grad Norm=4.8022, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.6122, Train Acc=40.00%, Val Loss=1.7053, Val Acc=37.39%, Grad Norm=4.4589, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.4777, Train Acc=45.66%, Val Loss=1.5117, Val Acc=44.72%, Grad Norm=4.2721, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.3944, Train Acc=48.95%, Val Loss=1.4938, Val Acc=45.71%, Grad Norm=4.1689, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=1.3322, Train Acc=51.38%, Val Loss=1.4049, Val Acc=49.60%, Grad Norm=4.0318, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=1.2904, Train Acc=53.03%, Val Loss=1.3820, Val Acc=49.20%, Grad Norm=3.9992, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=1.2578, Train Acc=54.47%, Val Loss=1.3764, Val Acc=50.27%, Grad Norm=3.9566, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=1.2303, Train Acc=55.61%, Val Loss=1.3121, Val Acc=52.54%, Grad Norm=4.0311, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=1.1790, Train Acc=57.61%, Val Loss=1.2995, Val Acc=53.72%, Grad Norm=4.0624, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=1.1656, Train Acc=58.10%, Val Loss=1.2649, Val Acc=54.39%, Grad Norm=4.3017, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=1.1473, Train Acc=58.97%, Val Loss=1.2856, Val Acc=53.67%, Grad Norm=4.4832, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=1.1329, Train Acc=59.64%, Val Loss=1.2673, Val Acc=55.11%, Grad Norm=4.6934, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=1.1228, Train Acc=60.07%, Val Loss=1.2614, Val Acc=55.58%, Grad Norm=4.8862, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=1.1129, Train Acc=60.29%, Val Loss=1.2652, Val Acc=55.34%, Grad Norm=4.9709, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=1.0985, Train Acc=60.86%, Val Loss=1.2603, Val Acc=56.35%, Grad Norm=5.1193, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=1.0920, Train Acc=61.28%, Val Loss=1.2560, Val Acc=56.13%, Grad Norm=5.2996, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=1.0819, Train Acc=61.69%, Val Loss=1.2436, Val Acc=56.53%, Grad Norm=5.4487, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=1.0732, Train Acc=61.97%, Val Loss=1.2528, Val Acc=56.24%, Grad Norm=5.5424, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=1.0504, Train Acc=63.02%, Val Loss=1.1993, Val Acc=57.18%, Grad Norm=5.7847, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=1.0305, Train Acc=63.78%, Val Loss=1.1925, Val Acc=57.40%, Grad Norm=6.0053, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=1.0221, Train Acc=63.97%, Val Loss=1.2036, Val Acc=57.62%, Grad Norm=6.3430, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=1.0163, Train Acc=64.20%, Val Loss=1.1996, Val Acc=57.07%, Grad Norm=6.4818, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=1.0085, Train Acc=64.44%, Val Loss=1.1993, Val Acc=57.26%, Grad Norm=6.6875, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=1.0011, Train Acc=64.82%, Val Loss=1.1956, Val Acc=57.16%, Grad Norm=6.8890, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=0.9960, Train Acc=65.01%, Val Loss=1.1972, Val Acc=57.74%, Grad Norm=7.0937, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=0.9877, Train Acc=65.32%, Val Loss=1.1924, Val Acc=58.06%, Grad Norm=7.3042, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=0.9860, Train Acc=65.47%, Val Loss=1.1933, Val Acc=57.95%, Grad Norm=7.5123, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=0.9831, Train Acc=65.60%, Val Loss=1.1929, Val Acc=57.86%, Grad Norm=7.6092, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=0.9596, Train Acc=66.33%, Val Loss=1.1926, Val Acc=58.00%, Grad Norm=7.9412, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=0.9488, Train Acc=66.65%, Val Loss=1.1889, Val Acc=58.40%, Grad Norm=8.1552, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=0.9428, Train Acc=67.27%, Val Loss=1.1896, Val Acc=57.96%, Grad Norm=8.4415, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=0.9456, Train Acc=66.95%, Val Loss=1.1680, Val Acc=58.70%, Grad Norm=8.5517, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=0.9373, Train Acc=67.41%, Val Loss=1.2001, Val Acc=58.15%, Grad Norm=8.7541, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=0.9297, Train Acc=67.72%, Val Loss=1.1845, Val Acc=58.20%, Grad Norm=8.9216, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=0.9227, Train Acc=68.04%, Val Loss=1.1839, Val Acc=58.21%, Grad Norm=9.1243, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=0.9191, Train Acc=68.12%, Val Loss=1.1875, Val Acc=58.48%, Grad Norm=9.2947, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=0.9207, Train Acc=67.87%, Val Loss=1.1872, Val Acc=58.28%, Grad Norm=9.4926, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=0.9120, Train Acc=68.31%, Val Loss=1.1914, Val Acc=58.01%, Grad Norm=9.6372, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=0.9029, Train Acc=68.68%, Val Loss=1.1899, Val Acc=58.33%, Grad Norm=9.8182, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=0.8949, Train Acc=68.79%, Val Loss=1.1796, Val Acc=58.50%, Grad Norm=10.0492, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=0.8971, Train Acc=69.02%, Val Loss=1.1875, Val Acc=58.37%, Grad Norm=10.1064, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=0.8861, Train Acc=69.39%, Val Loss=1.1953, Val Acc=58.52%, Grad Norm=10.3009, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=0.8866, Train Acc=69.37%, Val Loss=1.1867, Val Acc=58.48%, Grad Norm=10.4583, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=0.8869, Train Acc=69.42%, Val Loss=1.1873, Val Acc=58.67%, Grad Norm=10.5555, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=0.8814, Train Acc=69.46%, Val Loss=1.1917, Val Acc=58.22%, Grad Norm=10.6581, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=0.8780, Train Acc=69.69%, Val Loss=1.1909, Val Acc=58.58%, Grad Norm=10.8608, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=0.8747, Train Acc=69.71%, Val Loss=1.1969, Val Acc=58.50%, Grad Norm=10.9016, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=0.8740, Train Acc=69.89%, Val Loss=1.1967, Val Acc=58.45%, Grad Norm=11.0654, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=0.8677, Train Acc=70.07%, Val Loss=1.1920, Val Acc=58.56%, Grad Norm=11.1914, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=0.8677, Train Acc=70.01%, Val Loss=1.1923, Val Acc=58.45%, Grad Norm=11.3210, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=0.8577, Train Acc=70.62%, Val Loss=1.1976, Val Acc=58.50%, Grad Norm=11.4328, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=0.8580, Train Acc=70.43%, Val Loss=1.1970, Val Acc=58.66%, Grad Norm=11.5240, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=0.8615, Train Acc=70.23%, Val Loss=1.1979, Val Acc=58.82%, Grad Norm=11.5844, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=0.8590, Train Acc=70.30%, Val Loss=1.1976, Val Acc=58.47%, Grad Norm=11.6268, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=0.8543, Train Acc=70.77%, Val Loss=1.2019, Val Acc=58.58%, Grad Norm=11.7011, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=0.8536, Train Acc=70.41%, Val Loss=1.2066, Val Acc=58.30%, Grad Norm=11.8379, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=0.8507, Train Acc=70.73%, Val Loss=1.2085, Val Acc=58.51%, Grad Norm=11.9774, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=0.8463, Train Acc=70.65%, Val Loss=1.2029, Val Acc=58.62%, Grad Norm=12.0290, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=0.8462, Train Acc=70.68%, Val Loss=1.1959, Val Acc=58.58%, Grad Norm=12.0961, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=0.8469, Train Acc=70.95%, Val Loss=1.2066, Val Acc=58.54%, Grad Norm=12.1843, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=0.8450, Train Acc=71.00%, Val Loss=1.2062, Val Acc=58.53%, Grad Norm=12.2109, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=0.8411, Train Acc=70.98%, Val Loss=1.2100, Val Acc=58.41%, Grad Norm=12.2313, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=0.8403, Train Acc=71.22%, Val Loss=1.2030, Val Acc=58.76%, Grad Norm=12.3184, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=0.8440, Train Acc=70.92%, Val Loss=1.2073, Val Acc=58.46%, Grad Norm=12.3875, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=0.8374, Train Acc=71.22%, Val Loss=1.2031, Val Acc=58.56%, Grad Norm=12.3502, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=0.8405, Train Acc=71.07%, Val Loss=1.2021, Val Acc=58.76%, Grad Norm=12.4743, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=0.8376, Train Acc=71.39%, Val Loss=1.2051, Val Acc=58.68%, Grad Norm=12.5099, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=0.8418, Train Acc=70.88%, Val Loss=1.2072, Val Acc=58.69%, Grad Norm=12.5384, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=0.8348, Train Acc=71.35%, Val Loss=1.2096, Val Acc=58.85%, Grad Norm=12.4878, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=0.8402, Train Acc=71.16%, Val Loss=1.2056, Val Acc=58.49%, Grad Norm=12.6173, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=0.8364, Train Acc=71.19%, Val Loss=1.2055, Val Acc=58.68%, Grad Norm=12.5927, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=0.8388, Train Acc=71.28%, Val Loss=1.2079, Val Acc=58.62%, Grad Norm=12.6756, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=0.8319, Train Acc=71.45%, Val Loss=1.2082, Val Acc=58.53%, Grad Norm=12.6382, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=0.8371, Train Acc=71.08%, Val Loss=1.2065, Val Acc=58.59%, Grad Norm=12.6982, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=0.8351, Train Acc=71.47%, Val Loss=1.2024, Val Acc=58.69%, Grad Norm=12.6935, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=0.8319, Train Acc=71.56%, Val Loss=1.2083, Val Acc=58.65%, Grad Norm=12.7363, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=0.8310, Train Acc=71.52%, Val Loss=1.2079, Val Acc=58.47%, Grad Norm=12.7866, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=0.8325, Train Acc=71.45%, Val Loss=1.2078, Val Acc=58.76%, Grad Norm=12.8058, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=0.8322, Train Acc=71.51%, Val Loss=1.2096, Val Acc=58.66%, Grad Norm=12.7740, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=0.8282, Train Acc=71.84%, Val Loss=1.2094, Val Acc=58.65%, Grad Norm=12.8070, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=0.8345, Train Acc=71.40%, Val Loss=1.2064, Val Acc=58.63%, Grad Norm=12.9003, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=0.8321, Train Acc=71.49%, Val Loss=1.2142, Val Acc=58.59%, Grad Norm=12.8549, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=0.8300, Train Acc=71.55%, Val Loss=1.2096, Val Acc=58.75%, Grad Norm=12.8309, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=0.8286, Train Acc=71.60%, Val Loss=1.2082, Val Acc=58.62%, Grad Norm=12.8173, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=0.8306, Train Acc=71.46%, Val Loss=1.2093, Val Acc=58.70%, Grad Norm=12.8729, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=0.8289, Train Acc=71.52%, Val Loss=1.2075, Val Acc=58.71%, Grad Norm=12.8631, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=0.8335, Train Acc=71.46%, Val Loss=1.2052, Val Acc=58.75%, Grad Norm=12.9036, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=0.8296, Train Acc=71.64%, Val Loss=1.2005, Val Acc=58.84%, Grad Norm=12.9298, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=0.8255, Train Acc=71.72%, Val Loss=1.2007, Val Acc=58.79%, Grad Norm=12.9061, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=0.8310, Train Acc=71.58%, Val Loss=1.2021, Val Acc=58.84%, Grad Norm=12.9419, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=0.8312, Train Acc=71.40%, Val Loss=1.2029, Val Acc=58.72%, Grad Norm=12.9429, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=0.8331, Train Acc=71.38%, Val Loss=1.2046, Val Acc=58.90%, Grad Norm=12.9255, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=0.8289, Train Acc=71.74%, Val Loss=1.2018, Val Acc=58.84%, Grad Norm=12.9345, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=0.8304, Train Acc=71.53%, Val Loss=1.2039, Val Acc=58.76%, Grad Norm=12.9474, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=0.8281, Train Acc=71.58%, Val Loss=1.2026, Val Acc=58.64%, Grad Norm=12.9936, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=0.8233, Train Acc=71.78%, Val Loss=1.2045, Val Acc=58.71%, Grad Norm=12.9356, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=0.8269, Train Acc=71.56%, Val Loss=1.2024, Val Acc=58.83%, Grad Norm=12.9799, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=0.8295, Train Acc=71.56%, Val Loss=1.2052, Val Acc=58.76%, Grad Norm=13.0047, LR=1.95313e-07\n",
      "Fold 4, Epoch 101: Train Loss=0.8275, Train Acc=71.62%, Val Loss=1.2029, Val Acc=58.85%, Grad Norm=12.9926, LR=9.76563e-08\n",
      "Fold 4, Epoch 102: Train Loss=0.8315, Train Acc=71.45%, Val Loss=1.2084, Val Acc=58.81%, Grad Norm=13.0252, LR=9.76563e-08\n",
      "Fold 4, Epoch 103: Train Loss=0.8304, Train Acc=71.48%, Val Loss=1.2068, Val Acc=58.74%, Grad Norm=13.0047, LR=9.76563e-08\n",
      "Fold 4, Epoch 104: Train Loss=0.8253, Train Acc=71.65%, Val Loss=1.2030, Val Acc=58.71%, Grad Norm=12.9787, LR=9.76563e-08\n",
      "Fold 4, Epoch 105: Train Loss=0.8228, Train Acc=71.79%, Val Loss=1.2070, Val Acc=58.82%, Grad Norm=12.9555, LR=9.76563e-08\n",
      "Fold 4, Epoch 106: Train Loss=0.8252, Train Acc=71.79%, Val Loss=1.2076, Val Acc=58.89%, Grad Norm=12.9809, LR=9.76563e-08\n",
      "Fold 4, Epoch 107: Train Loss=0.8236, Train Acc=71.90%, Val Loss=1.2049, Val Acc=58.78%, Grad Norm=12.9866, LR=9.76563e-08\n",
      "Fold 4, Epoch 108: Train Loss=0.8314, Train Acc=71.39%, Val Loss=1.2056, Val Acc=58.85%, Grad Norm=13.0405, LR=9.76563e-08\n",
      "Fold 4, Epoch 109: Train Loss=0.8272, Train Acc=71.72%, Val Loss=1.2034, Val Acc=58.74%, Grad Norm=12.9952, LR=9.76563e-08\n",
      "Fold 4, Epoch 110: Train Loss=0.8241, Train Acc=71.73%, Val Loss=1.2051, Val Acc=58.83%, Grad Norm=13.0117, LR=9.76563e-08\n",
      "Fold 4, Epoch 111: Train Loss=0.8296, Train Acc=71.54%, Val Loss=1.2075, Val Acc=58.79%, Grad Norm=13.0223, LR=4.88281e-08\n",
      "Fold 4, Epoch 112: Train Loss=0.8238, Train Acc=71.86%, Val Loss=1.2042, Val Acc=58.69%, Grad Norm=13.0530, LR=4.88281e-08\n",
      "Fold 4, Epoch 113: Train Loss=0.8244, Train Acc=71.80%, Val Loss=1.2053, Val Acc=58.76%, Grad Norm=12.9830, LR=4.88281e-08\n",
      "Fold 4, Epoch 114: Train Loss=0.8286, Train Acc=71.51%, Val Loss=1.2077, Val Acc=58.69%, Grad Norm=13.0383, LR=4.88281e-08\n",
      "Fold 4, Epoch 115: Train Loss=0.8314, Train Acc=71.43%, Val Loss=1.2121, Val Acc=58.82%, Grad Norm=13.0225, LR=4.88281e-08\n",
      "Fold 4, Epoch 116: Train Loss=0.8281, Train Acc=71.50%, Val Loss=1.2027, Val Acc=58.77%, Grad Norm=13.0592, LR=4.88281e-08\n",
      "Fold 4, Epoch 117: Train Loss=0.8236, Train Acc=71.98%, Val Loss=1.2078, Val Acc=58.75%, Grad Norm=12.9874, LR=4.88281e-08\n",
      "Fold 4, Epoch 118: Train Loss=0.8276, Train Acc=71.65%, Val Loss=1.2076, Val Acc=58.82%, Grad Norm=13.0000, LR=4.88281e-08\n",
      "Fold 4, Epoch 119: Train Loss=0.8264, Train Acc=71.65%, Val Loss=1.2071, Val Acc=58.76%, Grad Norm=13.0349, LR=4.88281e-08\n",
      "Fold 4, Epoch 120: Train Loss=0.8273, Train Acc=71.70%, Val Loss=1.2045, Val Acc=58.71%, Grad Norm=12.9948, LR=4.88281e-08\n",
      "Fold 4, Epoch 121: Train Loss=0.8255, Train Acc=71.91%, Val Loss=1.2096, Val Acc=58.65%, Grad Norm=13.0085, LR=2.44141e-08\n",
      "Fold 4, Epoch 122: Train Loss=0.8286, Train Acc=71.74%, Val Loss=1.2090, Val Acc=58.71%, Grad Norm=13.0596, LR=2.44141e-08\n",
      "Fold 4, Epoch 123: Train Loss=0.8296, Train Acc=71.49%, Val Loss=1.2119, Val Acc=58.68%, Grad Norm=13.0747, LR=2.44141e-08\n",
      "Fold 4, Epoch 124: Train Loss=0.8246, Train Acc=71.68%, Val Loss=1.2090, Val Acc=58.68%, Grad Norm=13.0307, LR=2.44141e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=58.90%）\n",
      "Fold 4 DONE | Best Val Acc≈58.90% | Final Val Acc=58.90% | Test Acc=55.61%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.1900, Train Acc=14.25%, Val Loss=2.6316, Val Acc=12.74%, Grad Norm=6.6033, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.0351, Train Acc=22.46%, Val Loss=2.2749, Val Acc=22.06%, Grad Norm=4.9447, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=1.8084, Train Acc=32.28%, Val Loss=2.0543, Val Acc=30.84%, Grad Norm=4.6283, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=1.6066, Train Acc=40.86%, Val Loss=1.7065, Val Acc=38.30%, Grad Norm=4.4447, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.4731, Train Acc=46.08%, Val Loss=1.6718, Val Acc=39.46%, Grad Norm=4.1493, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.3867, Train Acc=49.26%, Val Loss=1.6849, Val Acc=41.22%, Grad Norm=4.0538, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=1.3267, Train Acc=51.57%, Val Loss=1.5528, Val Acc=43.77%, Grad Norm=3.9398, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=1.2891, Train Acc=53.39%, Val Loss=1.5904, Val Acc=44.12%, Grad Norm=3.9559, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=1.2501, Train Acc=55.02%, Val Loss=1.5541, Val Acc=45.42%, Grad Norm=3.9752, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=1.2232, Train Acc=56.11%, Val Loss=1.5325, Val Acc=44.30%, Grad Norm=4.0159, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=1.1758, Train Acc=58.05%, Val Loss=1.4623, Val Acc=48.03%, Grad Norm=4.1031, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=1.1513, Train Acc=59.04%, Val Loss=1.5238, Val Acc=46.69%, Grad Norm=4.3939, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=1.1386, Train Acc=59.72%, Val Loss=1.4702, Val Acc=47.69%, Grad Norm=4.5185, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=1.1266, Train Acc=60.01%, Val Loss=1.4774, Val Acc=47.89%, Grad Norm=4.6622, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=1.1165, Train Acc=60.52%, Val Loss=1.4511, Val Acc=48.51%, Grad Norm=4.8810, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=1.1023, Train Acc=61.08%, Val Loss=1.4284, Val Acc=48.86%, Grad Norm=4.9947, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=1.0952, Train Acc=61.34%, Val Loss=1.4468, Val Acc=49.27%, Grad Norm=5.1345, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=1.0828, Train Acc=61.81%, Val Loss=1.4495, Val Acc=49.06%, Grad Norm=5.2381, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=1.0704, Train Acc=62.19%, Val Loss=1.4412, Val Acc=49.92%, Grad Norm=5.3668, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=1.0621, Train Acc=62.67%, Val Loss=1.4034, Val Acc=50.28%, Grad Norm=5.6264, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=1.0358, Train Acc=63.62%, Val Loss=1.4204, Val Acc=50.38%, Grad Norm=5.7771, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=1.0276, Train Acc=63.82%, Val Loss=1.3946, Val Acc=50.57%, Grad Norm=6.0507, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=1.0105, Train Acc=64.53%, Val Loss=1.3926, Val Acc=50.36%, Grad Norm=6.3038, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=1.0057, Train Acc=64.79%, Val Loss=1.4423, Val Acc=50.29%, Grad Norm=6.4463, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=1.0005, Train Acc=64.95%, Val Loss=1.3811, Val Acc=51.08%, Grad Norm=6.6822, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=0.9920, Train Acc=65.34%, Val Loss=1.3986, Val Acc=50.79%, Grad Norm=6.8586, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=0.9814, Train Acc=65.66%, Val Loss=1.4434, Val Acc=50.72%, Grad Norm=7.1228, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=0.9780, Train Acc=65.84%, Val Loss=1.3915, Val Acc=51.68%, Grad Norm=7.2709, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=0.9708, Train Acc=66.17%, Val Loss=1.3840, Val Acc=51.52%, Grad Norm=7.5220, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=0.9701, Train Acc=66.19%, Val Loss=1.3863, Val Acc=51.22%, Grad Norm=7.7172, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=0.9539, Train Acc=66.80%, Val Loss=1.3890, Val Acc=51.70%, Grad Norm=7.8792, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=0.9413, Train Acc=67.35%, Val Loss=1.3708, Val Acc=51.98%, Grad Norm=8.0866, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=0.9357, Train Acc=67.68%, Val Loss=1.4015, Val Acc=51.60%, Grad Norm=8.4039, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=0.9302, Train Acc=67.71%, Val Loss=1.3808, Val Acc=52.16%, Grad Norm=8.5579, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=0.9252, Train Acc=67.92%, Val Loss=1.3883, Val Acc=51.86%, Grad Norm=8.8124, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=0.9175, Train Acc=68.13%, Val Loss=1.3890, Val Acc=51.99%, Grad Norm=8.9927, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=0.9145, Train Acc=68.32%, Val Loss=1.3846, Val Acc=51.69%, Grad Norm=9.2295, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=0.9084, Train Acc=68.37%, Val Loss=1.3831, Val Acc=52.16%, Grad Norm=9.3066, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=0.9054, Train Acc=68.65%, Val Loss=1.3626, Val Acc=52.18%, Grad Norm=9.5336, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=0.9059, Train Acc=68.71%, Val Loss=1.3827, Val Acc=51.76%, Grad Norm=9.6305, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=0.8855, Train Acc=69.55%, Val Loss=1.3826, Val Acc=51.97%, Grad Norm=9.8150, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=0.8893, Train Acc=69.25%, Val Loss=1.3909, Val Acc=51.90%, Grad Norm=10.1123, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=0.8792, Train Acc=69.68%, Val Loss=1.3826, Val Acc=51.96%, Grad Norm=10.1423, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=0.8853, Train Acc=69.53%, Val Loss=1.3806, Val Acc=52.20%, Grad Norm=10.2795, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=0.8774, Train Acc=69.85%, Val Loss=1.3893, Val Acc=51.78%, Grad Norm=10.4252, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=0.8735, Train Acc=69.91%, Val Loss=1.3888, Val Acc=51.95%, Grad Norm=10.6563, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=0.8703, Train Acc=70.05%, Val Loss=1.3864, Val Acc=52.38%, Grad Norm=10.6669, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=0.8700, Train Acc=69.80%, Val Loss=1.3945, Val Acc=51.83%, Grad Norm=10.8220, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=0.8651, Train Acc=70.25%, Val Loss=1.4075, Val Acc=52.05%, Grad Norm=11.0186, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=0.8595, Train Acc=70.35%, Val Loss=1.3972, Val Acc=51.68%, Grad Norm=11.1246, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=0.8556, Train Acc=70.54%, Val Loss=1.4039, Val Acc=51.88%, Grad Norm=11.2604, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=0.8527, Train Acc=70.60%, Val Loss=1.4009, Val Acc=52.05%, Grad Norm=11.3818, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=0.8503, Train Acc=70.89%, Val Loss=1.3995, Val Acc=52.04%, Grad Norm=11.5124, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=0.8570, Train Acc=70.56%, Val Loss=1.3898, Val Acc=52.20%, Grad Norm=11.5827, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=0.8477, Train Acc=70.91%, Val Loss=1.3897, Val Acc=52.10%, Grad Norm=11.6422, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=0.8480, Train Acc=70.63%, Val Loss=1.3938, Val Acc=52.24%, Grad Norm=11.7614, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=0.8459, Train Acc=71.03%, Val Loss=1.3979, Val Acc=51.94%, Grad Norm=11.7672, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=0.8387, Train Acc=71.14%, Val Loss=1.4011, Val Acc=52.21%, Grad Norm=11.8756, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=0.8454, Train Acc=71.00%, Val Loss=1.3992, Val Acc=51.88%, Grad Norm=12.0010, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=0.8393, Train Acc=71.27%, Val Loss=1.3995, Val Acc=52.44%, Grad Norm=12.0305, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=0.8392, Train Acc=71.22%, Val Loss=1.3955, Val Acc=52.16%, Grad Norm=12.0713, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=0.8385, Train Acc=71.29%, Val Loss=1.3943, Val Acc=51.96%, Grad Norm=12.1313, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=0.8339, Train Acc=71.52%, Val Loss=1.4029, Val Acc=52.15%, Grad Norm=12.1926, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=0.8345, Train Acc=71.43%, Val Loss=1.4005, Val Acc=52.10%, Grad Norm=12.2947, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=0.8363, Train Acc=71.16%, Val Loss=1.3961, Val Acc=52.02%, Grad Norm=12.3280, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=0.8280, Train Acc=71.63%, Val Loss=1.3919, Val Acc=52.08%, Grad Norm=12.3146, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=0.8282, Train Acc=71.76%, Val Loss=1.4084, Val Acc=52.18%, Grad Norm=12.4382, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=0.8274, Train Acc=71.59%, Val Loss=1.4059, Val Acc=52.18%, Grad Norm=12.5108, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=0.8278, Train Acc=71.72%, Val Loss=1.3943, Val Acc=52.26%, Grad Norm=12.5788, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=0.8250, Train Acc=71.93%, Val Loss=1.4030, Val Acc=52.12%, Grad Norm=12.6005, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=0.8280, Train Acc=71.60%, Val Loss=1.3969, Val Acc=52.12%, Grad Norm=12.6109, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=0.8239, Train Acc=71.82%, Val Loss=1.4010, Val Acc=51.97%, Grad Norm=12.5826, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=0.8282, Train Acc=71.62%, Val Loss=1.3944, Val Acc=52.38%, Grad Norm=12.6043, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=0.8242, Train Acc=71.66%, Val Loss=1.4144, Val Acc=52.08%, Grad Norm=12.6005, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=0.8232, Train Acc=71.81%, Val Loss=1.4059, Val Acc=52.18%, Grad Norm=12.7039, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=0.8256, Train Acc=71.84%, Val Loss=1.4118, Val Acc=52.16%, Grad Norm=12.7256, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=0.8239, Train Acc=71.75%, Val Loss=1.4040, Val Acc=52.05%, Grad Norm=12.7849, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=0.8258, Train Acc=71.70%, Val Loss=1.4058, Val Acc=52.18%, Grad Norm=12.8133, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=0.8184, Train Acc=72.10%, Val Loss=1.3956, Val Acc=52.15%, Grad Norm=12.7809, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=0.8280, Train Acc=71.73%, Val Loss=1.4004, Val Acc=52.30%, Grad Norm=12.8465, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=0.8233, Train Acc=71.77%, Val Loss=1.4014, Val Acc=52.29%, Grad Norm=12.8473, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=0.8191, Train Acc=71.91%, Val Loss=1.4005, Val Acc=51.92%, Grad Norm=12.8374, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=0.8248, Train Acc=71.67%, Val Loss=1.3902, Val Acc=52.21%, Grad Norm=12.8991, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=0.8200, Train Acc=72.01%, Val Loss=1.3929, Val Acc=52.22%, Grad Norm=12.8187, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=0.8189, Train Acc=71.92%, Val Loss=1.3913, Val Acc=52.30%, Grad Norm=12.9058, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=0.8209, Train Acc=71.86%, Val Loss=1.4024, Val Acc=52.12%, Grad Norm=12.9067, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=0.8197, Train Acc=72.09%, Val Loss=1.4006, Val Acc=52.33%, Grad Norm=12.9106, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=0.8230, Train Acc=71.84%, Val Loss=1.4065, Val Acc=52.19%, Grad Norm=12.9335, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=0.8204, Train Acc=71.90%, Val Loss=1.4033, Val Acc=52.21%, Grad Norm=12.9458, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=0.8208, Train Acc=71.98%, Val Loss=1.4020, Val Acc=52.28%, Grad Norm=12.9867, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=52.44%）\n",
      "Fold 5 DONE | Best Val Acc≈52.44% | Final Val Acc=52.44% | Test Acc=54.96%\n",
      "[INFO] SNR=0 dB | Mean Test Acc: 54.30% ± 1.04%\n",
      "[INFO] SNR   0 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR0dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -5 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:11<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2185, Train Acc=11.70%, Val Loss=2.6287, Val Acc=11.20%, Grad Norm=6.6273, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2106, Train Acc=12.52%, Val Loss=2.8082, Val Acc=11.11%, Grad Norm=6.2507, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.1896, Train Acc=13.99%, Val Loss=2.4206, Val Acc=11.29%, Grad Norm=5.1310, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.1332, Train Acc=17.66%, Val Loss=2.1837, Val Acc=16.94%, Grad Norm=4.1727, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.0306, Train Acc=22.81%, Val Loss=2.0230, Val Acc=22.84%, Grad Norm=4.1785, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=1.9071, Train Acc=28.95%, Val Loss=1.9160, Val Acc=27.15%, Grad Norm=4.1836, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=1.8104, Train Acc=33.09%, Val Loss=1.7764, Val Acc=32.39%, Grad Norm=4.0586, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=1.7336, Train Acc=36.13%, Val Loss=1.7318, Val Acc=33.83%, Grad Norm=3.9312, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=1.6761, Train Acc=38.46%, Val Loss=1.6834, Val Acc=35.90%, Grad Norm=3.8615, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=1.6420, Train Acc=39.40%, Val Loss=1.6779, Val Acc=36.60%, Grad Norm=3.8245, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=1.5884, Train Acc=41.82%, Val Loss=1.6418, Val Acc=37.62%, Grad Norm=3.9420, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=1.5627, Train Acc=43.11%, Val Loss=1.6152, Val Acc=38.96%, Grad Norm=4.1216, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=1.5416, Train Acc=43.94%, Val Loss=1.6131, Val Acc=39.00%, Grad Norm=4.2799, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=1.5267, Train Acc=44.68%, Val Loss=1.6011, Val Acc=39.56%, Grad Norm=4.4722, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=1.5101, Train Acc=45.32%, Val Loss=1.5984, Val Acc=40.05%, Grad Norm=4.5482, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=1.4972, Train Acc=45.71%, Val Loss=1.5800, Val Acc=40.72%, Grad Norm=4.6527, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=1.4889, Train Acc=46.08%, Val Loss=1.5776, Val Acc=40.73%, Grad Norm=4.7139, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=1.4747, Train Acc=46.47%, Val Loss=1.5615, Val Acc=41.03%, Grad Norm=4.8178, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=1.4664, Train Acc=47.21%, Val Loss=1.5622, Val Acc=41.82%, Grad Norm=4.9410, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=1.4594, Train Acc=47.33%, Val Loss=1.5599, Val Acc=41.63%, Grad Norm=5.0484, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=1.4299, Train Acc=48.75%, Val Loss=1.5432, Val Acc=42.69%, Grad Norm=5.1743, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=1.4187, Train Acc=49.03%, Val Loss=1.5342, Val Acc=42.82%, Grad Norm=5.3868, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=1.4156, Train Acc=49.06%, Val Loss=1.5247, Val Acc=42.65%, Grad Norm=5.5362, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=1.3974, Train Acc=49.85%, Val Loss=1.5266, Val Acc=43.04%, Grad Norm=5.6651, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=1.4001, Train Acc=49.87%, Val Loss=1.5285, Val Acc=43.03%, Grad Norm=5.9318, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=1.3912, Train Acc=50.10%, Val Loss=1.5315, Val Acc=42.81%, Grad Norm=6.0306, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=1.3837, Train Acc=50.52%, Val Loss=1.5141, Val Acc=43.36%, Grad Norm=6.2381, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=1.3784, Train Acc=50.78%, Val Loss=1.5081, Val Acc=43.84%, Grad Norm=6.3693, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=1.3728, Train Acc=50.96%, Val Loss=1.5082, Val Acc=43.71%, Grad Norm=6.5334, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=1.3676, Train Acc=51.14%, Val Loss=1.5161, Val Acc=43.53%, Grad Norm=6.6513, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=1.3543, Train Acc=51.75%, Val Loss=1.5073, Val Acc=44.06%, Grad Norm=6.8572, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=1.3452, Train Acc=52.20%, Val Loss=1.5020, Val Acc=44.24%, Grad Norm=7.0532, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=1.3436, Train Acc=52.05%, Val Loss=1.4956, Val Acc=44.44%, Grad Norm=7.2397, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=1.3345, Train Acc=52.61%, Val Loss=1.5026, Val Acc=44.10%, Grad Norm=7.4078, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=1.3319, Train Acc=52.50%, Val Loss=1.5018, Val Acc=44.18%, Grad Norm=7.4866, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=1.3282, Train Acc=52.76%, Val Loss=1.5012, Val Acc=44.19%, Grad Norm=7.6440, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=1.3250, Train Acc=52.76%, Val Loss=1.5025, Val Acc=44.12%, Grad Norm=7.7705, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=1.3236, Train Acc=52.79%, Val Loss=1.4963, Val Acc=44.25%, Grad Norm=7.8965, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=1.3157, Train Acc=53.39%, Val Loss=1.4985, Val Acc=44.30%, Grad Norm=8.0908, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=1.3122, Train Acc=53.33%, Val Loss=1.4979, Val Acc=44.55%, Grad Norm=8.2240, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=1.2979, Train Acc=54.05%, Val Loss=1.4925, Val Acc=44.64%, Grad Norm=8.4024, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=1.2995, Train Acc=54.09%, Val Loss=1.4932, Val Acc=44.50%, Grad Norm=8.5428, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=1.2984, Train Acc=54.01%, Val Loss=1.4932, Val Acc=44.82%, Grad Norm=8.7229, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=1.2929, Train Acc=54.21%, Val Loss=1.4972, Val Acc=44.65%, Grad Norm=8.7409, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=1.2949, Train Acc=54.31%, Val Loss=1.4915, Val Acc=44.62%, Grad Norm=8.8804, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=1.2869, Train Acc=54.45%, Val Loss=1.4961, Val Acc=44.69%, Grad Norm=8.9780, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=1.2852, Train Acc=54.55%, Val Loss=1.4982, Val Acc=44.47%, Grad Norm=9.1014, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=1.2854, Train Acc=54.48%, Val Loss=1.4929, Val Acc=44.85%, Grad Norm=9.2983, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=1.2799, Train Acc=54.86%, Val Loss=1.4882, Val Acc=44.85%, Grad Norm=9.3106, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=1.2752, Train Acc=54.94%, Val Loss=1.4938, Val Acc=44.96%, Grad Norm=9.4221, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=1.2733, Train Acc=54.95%, Val Loss=1.4926, Val Acc=45.00%, Grad Norm=9.5336, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=1.2734, Train Acc=55.02%, Val Loss=1.4928, Val Acc=44.85%, Grad Norm=9.6489, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=1.2672, Train Acc=55.33%, Val Loss=1.4945, Val Acc=44.80%, Grad Norm=9.7637, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=1.2718, Train Acc=54.91%, Val Loss=1.4985, Val Acc=44.80%, Grad Norm=9.8031, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=1.2682, Train Acc=55.17%, Val Loss=1.4994, Val Acc=44.70%, Grad Norm=9.8076, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=1.2644, Train Acc=55.54%, Val Loss=1.4963, Val Acc=44.75%, Grad Norm=9.9237, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=1.2726, Train Acc=55.01%, Val Loss=1.4987, Val Acc=44.78%, Grad Norm=10.0776, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=1.2642, Train Acc=55.37%, Val Loss=1.4976, Val Acc=44.91%, Grad Norm=10.0509, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=1.2593, Train Acc=55.51%, Val Loss=1.4934, Val Acc=44.93%, Grad Norm=10.1123, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=1.2596, Train Acc=55.73%, Val Loss=1.4902, Val Acc=45.06%, Grad Norm=10.1981, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=1.2586, Train Acc=55.55%, Val Loss=1.4973, Val Acc=45.07%, Grad Norm=10.2837, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=1.2572, Train Acc=55.48%, Val Loss=1.4987, Val Acc=44.92%, Grad Norm=10.2894, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=1.2602, Train Acc=55.56%, Val Loss=1.4918, Val Acc=45.11%, Grad Norm=10.3507, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=1.2555, Train Acc=56.12%, Val Loss=1.4879, Val Acc=45.21%, Grad Norm=10.3738, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=1.2537, Train Acc=56.01%, Val Loss=1.4913, Val Acc=45.13%, Grad Norm=10.4067, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=1.2538, Train Acc=56.05%, Val Loss=1.4869, Val Acc=45.26%, Grad Norm=10.4343, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=1.2496, Train Acc=56.16%, Val Loss=1.4939, Val Acc=45.09%, Grad Norm=10.4958, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=1.2527, Train Acc=55.96%, Val Loss=1.4950, Val Acc=44.94%, Grad Norm=10.5815, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=1.2485, Train Acc=56.15%, Val Loss=1.4937, Val Acc=45.12%, Grad Norm=10.5541, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=1.2469, Train Acc=55.98%, Val Loss=1.4983, Val Acc=44.94%, Grad Norm=10.5689, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=1.2529, Train Acc=55.80%, Val Loss=1.4938, Val Acc=45.11%, Grad Norm=10.6537, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=1.2539, Train Acc=55.92%, Val Loss=1.4918, Val Acc=45.04%, Grad Norm=10.7117, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=1.2464, Train Acc=56.18%, Val Loss=1.4895, Val Acc=45.19%, Grad Norm=10.7306, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=1.2441, Train Acc=56.24%, Val Loss=1.4940, Val Acc=45.08%, Grad Norm=10.7027, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=1.2467, Train Acc=56.24%, Val Loss=1.4900, Val Acc=45.16%, Grad Norm=10.7023, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=1.2447, Train Acc=56.27%, Val Loss=1.4980, Val Acc=45.08%, Grad Norm=10.8415, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=1.2482, Train Acc=56.13%, Val Loss=1.4939, Val Acc=45.07%, Grad Norm=10.8132, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=1.2452, Train Acc=56.23%, Val Loss=1.4944, Val Acc=44.98%, Grad Norm=10.8092, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=1.2445, Train Acc=56.19%, Val Loss=1.4911, Val Acc=45.11%, Grad Norm=10.8314, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=1.2488, Train Acc=55.92%, Val Loss=1.4971, Val Acc=44.91%, Grad Norm=10.8972, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=1.2483, Train Acc=55.91%, Val Loss=1.4946, Val Acc=45.02%, Grad Norm=10.8726, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=1.2440, Train Acc=56.35%, Val Loss=1.4944, Val Acc=45.04%, Grad Norm=10.8278, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=1.2463, Train Acc=55.95%, Val Loss=1.4915, Val Acc=45.13%, Grad Norm=10.8862, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=1.2451, Train Acc=56.30%, Val Loss=1.4972, Val Acc=45.02%, Grad Norm=10.8533, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=1.2458, Train Acc=56.17%, Val Loss=1.4920, Val Acc=45.21%, Grad Norm=10.8899, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=1.2440, Train Acc=55.96%, Val Loss=1.4961, Val Acc=45.05%, Grad Norm=10.9367, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=1.2433, Train Acc=56.42%, Val Loss=1.4915, Val Acc=45.21%, Grad Norm=10.9165, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=1.2444, Train Acc=56.25%, Val Loss=1.4969, Val Acc=45.03%, Grad Norm=10.9557, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=1.2453, Train Acc=56.22%, Val Loss=1.4915, Val Acc=45.10%, Grad Norm=10.9877, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=1.2400, Train Acc=56.35%, Val Loss=1.4940, Val Acc=45.16%, Grad Norm=10.9664, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=1.2425, Train Acc=56.43%, Val Loss=1.4936, Val Acc=45.21%, Grad Norm=10.9649, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=1.2406, Train Acc=56.48%, Val Loss=1.4923, Val Acc=45.16%, Grad Norm=11.0042, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=1.2466, Train Acc=56.19%, Val Loss=1.4930, Val Acc=45.15%, Grad Norm=10.9868, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=1.2430, Train Acc=56.30%, Val Loss=1.4921, Val Acc=45.15%, Grad Norm=10.9830, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=1.2418, Train Acc=56.43%, Val Loss=1.4926, Val Acc=45.07%, Grad Norm=11.0315, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=1.2406, Train Acc=56.53%, Val Loss=1.4939, Val Acc=45.08%, Grad Norm=10.9966, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=45.26%）\n",
      "Fold 1 DONE | Best Val Acc≈45.26% | Final Val Acc=45.26% | Test Acc=44.26%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2189, Train Acc=11.67%, Val Loss=2.5554, Val Acc=11.09%, Grad Norm=6.7343, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.1935, Train Acc=13.57%, Val Loss=2.3257, Val Acc=13.35%, Grad Norm=5.6576, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.1390, Train Acc=17.29%, Val Loss=2.3654, Val Acc=15.66%, Grad Norm=3.9731, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.0535, Train Acc=21.33%, Val Loss=2.0503, Val Acc=21.64%, Grad Norm=4.0804, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=1.9299, Train Acc=27.02%, Val Loss=1.9233, Val Acc=26.37%, Grad Norm=3.9789, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=1.8404, Train Acc=31.03%, Val Loss=1.8731, Val Acc=28.70%, Grad Norm=3.7949, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=1.7729, Train Acc=34.00%, Val Loss=1.7874, Val Acc=32.82%, Grad Norm=3.7634, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=1.7214, Train Acc=36.35%, Val Loss=1.7494, Val Acc=34.49%, Grad Norm=3.7202, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=1.6755, Train Acc=38.44%, Val Loss=1.7353, Val Acc=34.65%, Grad Norm=3.7262, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=1.6320, Train Acc=40.13%, Val Loss=1.6834, Val Acc=37.63%, Grad Norm=3.7614, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=1.5747, Train Acc=42.49%, Val Loss=1.6583, Val Acc=38.35%, Grad Norm=3.8776, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=1.5474, Train Acc=43.86%, Val Loss=1.6464, Val Acc=38.82%, Grad Norm=4.0877, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=1.5253, Train Acc=44.46%, Val Loss=1.6447, Val Acc=38.87%, Grad Norm=4.2384, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=1.5100, Train Acc=45.18%, Val Loss=1.6316, Val Acc=39.47%, Grad Norm=4.3836, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=1.4976, Train Acc=45.90%, Val Loss=1.6463, Val Acc=39.19%, Grad Norm=4.4759, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=1.4827, Train Acc=46.49%, Val Loss=1.6406, Val Acc=39.35%, Grad Norm=4.6306, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=1.4717, Train Acc=47.05%, Val Loss=1.6062, Val Acc=40.65%, Grad Norm=4.7520, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=1.4613, Train Acc=47.56%, Val Loss=1.6276, Val Acc=40.05%, Grad Norm=4.8643, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=1.4472, Train Acc=47.81%, Val Loss=1.5859, Val Acc=41.16%, Grad Norm=4.9557, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=1.4381, Train Acc=48.06%, Val Loss=1.5747, Val Acc=41.28%, Grad Norm=5.0839, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=1.4124, Train Acc=49.25%, Val Loss=1.5710, Val Acc=41.95%, Grad Norm=5.2202, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=1.4003, Train Acc=49.45%, Val Loss=1.5647, Val Acc=41.79%, Grad Norm=5.4104, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=1.3939, Train Acc=49.86%, Val Loss=1.5677, Val Acc=41.81%, Grad Norm=5.5610, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=1.3803, Train Acc=50.51%, Val Loss=1.5807, Val Acc=41.41%, Grad Norm=5.7382, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=1.3776, Train Acc=50.57%, Val Loss=1.5765, Val Acc=42.00%, Grad Norm=5.9478, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=1.3664, Train Acc=50.98%, Val Loss=1.5624, Val Acc=42.14%, Grad Norm=6.0303, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=1.3627, Train Acc=51.02%, Val Loss=1.5665, Val Acc=41.99%, Grad Norm=6.1880, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=1.3567, Train Acc=51.49%, Val Loss=1.5672, Val Acc=42.24%, Grad Norm=6.3416, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=1.3507, Train Acc=51.63%, Val Loss=1.5635, Val Acc=42.08%, Grad Norm=6.5296, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=1.3438, Train Acc=51.90%, Val Loss=1.5604, Val Acc=42.20%, Grad Norm=6.6566, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=1.3286, Train Acc=52.70%, Val Loss=1.5537, Val Acc=42.60%, Grad Norm=6.8318, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=1.3231, Train Acc=52.92%, Val Loss=1.5599, Val Acc=42.41%, Grad Norm=6.9919, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=1.3220, Train Acc=52.76%, Val Loss=1.5664, Val Acc=42.40%, Grad Norm=7.1228, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=1.3172, Train Acc=53.06%, Val Loss=1.5520, Val Acc=43.09%, Grad Norm=7.2927, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=1.3200, Train Acc=52.85%, Val Loss=1.5500, Val Acc=42.72%, Grad Norm=7.4929, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=1.3038, Train Acc=53.75%, Val Loss=1.5479, Val Acc=43.08%, Grad Norm=7.6395, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=1.3090, Train Acc=53.37%, Val Loss=1.5531, Val Acc=42.93%, Grad Norm=7.7085, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=1.2984, Train Acc=53.87%, Val Loss=1.5592, Val Acc=42.64%, Grad Norm=7.8652, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=1.2976, Train Acc=53.94%, Val Loss=1.5469, Val Acc=43.08%, Grad Norm=8.0440, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=1.2926, Train Acc=54.21%, Val Loss=1.5558, Val Acc=43.29%, Grad Norm=8.1893, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=1.2865, Train Acc=54.56%, Val Loss=1.5499, Val Acc=43.19%, Grad Norm=8.3841, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=1.2816, Train Acc=54.67%, Val Loss=1.5492, Val Acc=43.02%, Grad Norm=8.4150, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=1.2760, Train Acc=54.82%, Val Loss=1.5479, Val Acc=43.28%, Grad Norm=8.5647, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=1.2700, Train Acc=54.95%, Val Loss=1.5495, Val Acc=43.15%, Grad Norm=8.7506, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=1.2694, Train Acc=55.16%, Val Loss=1.5603, Val Acc=42.86%, Grad Norm=8.8552, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=1.2633, Train Acc=55.46%, Val Loss=1.5556, Val Acc=43.08%, Grad Norm=8.9483, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=1.2636, Train Acc=55.29%, Val Loss=1.5519, Val Acc=43.17%, Grad Norm=9.1274, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=1.2642, Train Acc=55.28%, Val Loss=1.5550, Val Acc=42.99%, Grad Norm=9.2372, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=1.2628, Train Acc=55.14%, Val Loss=1.5597, Val Acc=42.84%, Grad Norm=9.3437, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=1.2587, Train Acc=55.50%, Val Loss=1.5503, Val Acc=43.41%, Grad Norm=9.4436, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=1.2492, Train Acc=55.81%, Val Loss=1.5465, Val Acc=43.36%, Grad Norm=9.4905, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=1.2532, Train Acc=55.57%, Val Loss=1.5542, Val Acc=43.19%, Grad Norm=9.5827, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=1.2488, Train Acc=55.80%, Val Loss=1.5574, Val Acc=43.04%, Grad Norm=9.6420, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=1.2540, Train Acc=55.66%, Val Loss=1.5477, Val Acc=43.49%, Grad Norm=9.7951, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=1.2500, Train Acc=55.92%, Val Loss=1.5525, Val Acc=43.12%, Grad Norm=9.7511, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=1.2453, Train Acc=56.12%, Val Loss=1.5508, Val Acc=43.38%, Grad Norm=9.8892, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=1.2400, Train Acc=56.20%, Val Loss=1.5544, Val Acc=43.19%, Grad Norm=10.0104, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=1.2417, Train Acc=56.12%, Val Loss=1.5511, Val Acc=43.31%, Grad Norm=10.0064, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=1.2384, Train Acc=56.32%, Val Loss=1.5539, Val Acc=43.33%, Grad Norm=10.1037, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=1.2367, Train Acc=56.39%, Val Loss=1.5546, Val Acc=43.27%, Grad Norm=10.2420, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=1.2349, Train Acc=56.53%, Val Loss=1.5548, Val Acc=43.27%, Grad Norm=10.3035, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=1.2329, Train Acc=56.67%, Val Loss=1.5589, Val Acc=43.15%, Grad Norm=10.2985, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=1.2367, Train Acc=56.43%, Val Loss=1.5578, Val Acc=43.03%, Grad Norm=10.4655, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=1.2390, Train Acc=56.29%, Val Loss=1.5583, Val Acc=43.13%, Grad Norm=10.4339, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=1.2326, Train Acc=56.55%, Val Loss=1.5557, Val Acc=43.33%, Grad Norm=10.4288, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=1.2320, Train Acc=56.49%, Val Loss=1.5540, Val Acc=43.30%, Grad Norm=10.5039, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=1.2308, Train Acc=56.53%, Val Loss=1.5525, Val Acc=43.44%, Grad Norm=10.5312, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=1.2268, Train Acc=56.83%, Val Loss=1.5584, Val Acc=43.28%, Grad Norm=10.5299, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=1.2287, Train Acc=56.75%, Val Loss=1.5580, Val Acc=43.20%, Grad Norm=10.6069, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=1.2328, Train Acc=56.74%, Val Loss=1.5549, Val Acc=43.30%, Grad Norm=10.6474, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=1.2267, Train Acc=56.69%, Val Loss=1.5617, Val Acc=43.18%, Grad Norm=10.6652, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=1.2282, Train Acc=56.76%, Val Loss=1.5587, Val Acc=43.19%, Grad Norm=10.6751, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=1.2271, Train Acc=56.76%, Val Loss=1.5556, Val Acc=43.25%, Grad Norm=10.7199, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=1.2244, Train Acc=56.90%, Val Loss=1.5576, Val Acc=43.20%, Grad Norm=10.7646, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=1.2257, Train Acc=56.70%, Val Loss=1.5589, Val Acc=43.15%, Grad Norm=10.7860, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=1.2265, Train Acc=56.98%, Val Loss=1.5574, Val Acc=43.21%, Grad Norm=10.8531, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=1.2263, Train Acc=56.82%, Val Loss=1.5576, Val Acc=43.28%, Grad Norm=10.7822, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=1.2231, Train Acc=56.78%, Val Loss=1.5530, Val Acc=43.43%, Grad Norm=10.8000, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=1.2279, Train Acc=56.80%, Val Loss=1.5561, Val Acc=43.25%, Grad Norm=10.8713, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=1.2270, Train Acc=56.78%, Val Loss=1.5588, Val Acc=43.21%, Grad Norm=10.8497, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=1.2258, Train Acc=57.15%, Val Loss=1.5608, Val Acc=43.22%, Grad Norm=10.9093, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=1.2249, Train Acc=57.07%, Val Loss=1.5585, Val Acc=43.19%, Grad Norm=10.8917, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=1.2202, Train Acc=56.92%, Val Loss=1.5564, Val Acc=43.36%, Grad Norm=10.8675, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=1.2262, Train Acc=56.77%, Val Loss=1.5601, Val Acc=43.30%, Grad Norm=10.9085, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=43.49%）\n",
      "Fold 2 DONE | Best Val Acc≈43.49% | Final Val Acc=43.49% | Test Acc=43.86%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2193, Train Acc=11.55%, Val Loss=2.5431, Val Acc=11.07%, Grad Norm=6.8574, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.1999, Train Acc=13.18%, Val Loss=2.5901, Val Acc=11.47%, Grad Norm=6.5209, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.1395, Train Acc=17.25%, Val Loss=2.2019, Val Acc=16.31%, Grad Norm=4.7986, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.0247, Train Acc=22.73%, Val Loss=2.0656, Val Acc=20.90%, Grad Norm=4.3190, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=1.9200, Train Acc=27.45%, Val Loss=1.9774, Val Acc=24.83%, Grad Norm=3.8825, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=1.8469, Train Acc=30.85%, Val Loss=1.8686, Val Acc=29.60%, Grad Norm=3.7051, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=1.7875, Train Acc=33.75%, Val Loss=1.8073, Val Acc=31.95%, Grad Norm=3.6793, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=1.7395, Train Acc=35.65%, Val Loss=1.7715, Val Acc=33.44%, Grad Norm=3.5754, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=1.7061, Train Acc=37.27%, Val Loss=1.7472, Val Acc=35.09%, Grad Norm=3.5933, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=1.6692, Train Acc=38.60%, Val Loss=1.7000, Val Acc=36.28%, Grad Norm=3.6467, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=1.6115, Train Acc=40.72%, Val Loss=1.6513, Val Acc=37.61%, Grad Norm=3.7415, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=1.5890, Train Acc=41.56%, Val Loss=1.6291, Val Acc=38.17%, Grad Norm=3.9964, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=1.5675, Train Acc=42.39%, Val Loss=1.6310, Val Acc=38.52%, Grad Norm=4.1209, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=1.5456, Train Acc=43.47%, Val Loss=1.6061, Val Acc=39.82%, Grad Norm=4.2945, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=1.5307, Train Acc=43.91%, Val Loss=1.5864, Val Acc=40.24%, Grad Norm=4.4617, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=1.5156, Train Acc=44.80%, Val Loss=1.5759, Val Acc=40.38%, Grad Norm=4.5695, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=1.4989, Train Acc=45.55%, Val Loss=1.5738, Val Acc=40.82%, Grad Norm=4.7000, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=1.4883, Train Acc=45.90%, Val Loss=1.5691, Val Acc=41.58%, Grad Norm=4.7816, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=1.4732, Train Acc=46.40%, Val Loss=1.5592, Val Acc=41.40%, Grad Norm=4.8659, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=1.4641, Train Acc=47.18%, Val Loss=1.5605, Val Acc=41.51%, Grad Norm=5.0318, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=1.4310, Train Acc=48.37%, Val Loss=1.5407, Val Acc=42.96%, Grad Norm=5.1312, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=1.4210, Train Acc=48.96%, Val Loss=1.5366, Val Acc=42.97%, Grad Norm=5.3840, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=1.4164, Train Acc=49.12%, Val Loss=1.5410, Val Acc=42.76%, Grad Norm=5.5189, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=1.4114, Train Acc=49.38%, Val Loss=1.5426, Val Acc=42.49%, Grad Norm=5.7102, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=1.4026, Train Acc=49.62%, Val Loss=1.5265, Val Acc=43.20%, Grad Norm=5.8422, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=1.3945, Train Acc=49.95%, Val Loss=1.5155, Val Acc=43.33%, Grad Norm=6.0173, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=1.3837, Train Acc=50.36%, Val Loss=1.5124, Val Acc=43.55%, Grad Norm=6.1454, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=1.3834, Train Acc=50.37%, Val Loss=1.5189, Val Acc=43.64%, Grad Norm=6.3341, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=1.3767, Train Acc=50.61%, Val Loss=1.5144, Val Acc=43.87%, Grad Norm=6.5386, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=1.3741, Train Acc=50.73%, Val Loss=1.5200, Val Acc=43.61%, Grad Norm=6.6054, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=1.3578, Train Acc=51.55%, Val Loss=1.5070, Val Acc=44.27%, Grad Norm=6.7779, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=1.3444, Train Acc=52.14%, Val Loss=1.5021, Val Acc=44.53%, Grad Norm=7.0362, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=1.3405, Train Acc=52.04%, Val Loss=1.5055, Val Acc=44.18%, Grad Norm=7.1606, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=1.3399, Train Acc=52.26%, Val Loss=1.5090, Val Acc=44.28%, Grad Norm=7.3562, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=1.3350, Train Acc=52.50%, Val Loss=1.4945, Val Acc=45.04%, Grad Norm=7.5471, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=1.3280, Train Acc=52.65%, Val Loss=1.5196, Val Acc=44.24%, Grad Norm=7.6280, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=1.3232, Train Acc=53.02%, Val Loss=1.5040, Val Acc=44.82%, Grad Norm=7.7665, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=1.3246, Train Acc=52.88%, Val Loss=1.5037, Val Acc=44.70%, Grad Norm=7.9240, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=1.3224, Train Acc=52.96%, Val Loss=1.5056, Val Acc=44.70%, Grad Norm=8.0434, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=1.3094, Train Acc=53.39%, Val Loss=1.5041, Val Acc=44.78%, Grad Norm=8.1886, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=1.3058, Train Acc=53.77%, Val Loss=1.5000, Val Acc=44.82%, Grad Norm=8.3467, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=1.2981, Train Acc=54.13%, Val Loss=1.4982, Val Acc=44.85%, Grad Norm=8.4950, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=1.2979, Train Acc=54.08%, Val Loss=1.5096, Val Acc=44.60%, Grad Norm=8.6930, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=1.2980, Train Acc=53.69%, Val Loss=1.5013, Val Acc=44.90%, Grad Norm=8.7458, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=1.2933, Train Acc=54.10%, Val Loss=1.5033, Val Acc=45.03%, Grad Norm=8.9108, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=1.2895, Train Acc=54.33%, Val Loss=1.5011, Val Acc=44.85%, Grad Norm=9.0020, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=1.2877, Train Acc=54.37%, Val Loss=1.5022, Val Acc=45.18%, Grad Norm=9.0774, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=1.2818, Train Acc=54.56%, Val Loss=1.5045, Val Acc=45.01%, Grad Norm=9.2102, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=1.2795, Train Acc=54.83%, Val Loss=1.5010, Val Acc=45.00%, Grad Norm=9.3590, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=1.2804, Train Acc=54.64%, Val Loss=1.5036, Val Acc=45.10%, Grad Norm=9.4333, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=1.2750, Train Acc=55.00%, Val Loss=1.4964, Val Acc=45.07%, Grad Norm=9.4934, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=1.2741, Train Acc=54.89%, Val Loss=1.4999, Val Acc=45.03%, Grad Norm=9.6271, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=1.2704, Train Acc=55.04%, Val Loss=1.4980, Val Acc=45.16%, Grad Norm=9.6914, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=1.2735, Train Acc=55.06%, Val Loss=1.5004, Val Acc=44.88%, Grad Norm=9.7957, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=1.2650, Train Acc=55.22%, Val Loss=1.5012, Val Acc=44.89%, Grad Norm=9.8630, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=1.2693, Train Acc=55.25%, Val Loss=1.4987, Val Acc=45.21%, Grad Norm=9.9351, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=1.2646, Train Acc=55.27%, Val Loss=1.5027, Val Acc=45.16%, Grad Norm=9.9130, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=1.2617, Train Acc=55.45%, Val Loss=1.5045, Val Acc=45.06%, Grad Norm=10.0056, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=1.2627, Train Acc=55.36%, Val Loss=1.5058, Val Acc=45.10%, Grad Norm=10.1311, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=1.2679, Train Acc=55.34%, Val Loss=1.4994, Val Acc=45.17%, Grad Norm=10.1610, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=1.2610, Train Acc=55.45%, Val Loss=1.5017, Val Acc=45.13%, Grad Norm=10.2399, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=1.2567, Train Acc=55.71%, Val Loss=1.4973, Val Acc=45.25%, Grad Norm=10.2957, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=1.2552, Train Acc=55.59%, Val Loss=1.5069, Val Acc=45.16%, Grad Norm=10.3845, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=1.2503, Train Acc=56.07%, Val Loss=1.5002, Val Acc=45.23%, Grad Norm=10.3648, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=1.2533, Train Acc=55.83%, Val Loss=1.5019, Val Acc=45.25%, Grad Norm=10.4517, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=1.2524, Train Acc=56.06%, Val Loss=1.5006, Val Acc=45.23%, Grad Norm=10.5035, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=1.2510, Train Acc=56.00%, Val Loss=1.4998, Val Acc=45.22%, Grad Norm=10.5051, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=1.2561, Train Acc=55.64%, Val Loss=1.4977, Val Acc=45.32%, Grad Norm=10.6100, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=1.2506, Train Acc=55.91%, Val Loss=1.5019, Val Acc=45.16%, Grad Norm=10.6081, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=1.2522, Train Acc=55.87%, Val Loss=1.4999, Val Acc=45.28%, Grad Norm=10.6126, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=1.2476, Train Acc=56.17%, Val Loss=1.4992, Val Acc=45.14%, Grad Norm=10.6515, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=1.2481, Train Acc=55.85%, Val Loss=1.5002, Val Acc=45.15%, Grad Norm=10.7048, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=1.2536, Train Acc=55.74%, Val Loss=1.5028, Val Acc=45.23%, Grad Norm=10.7556, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=1.2484, Train Acc=55.97%, Val Loss=1.5005, Val Acc=45.16%, Grad Norm=10.7017, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=1.2435, Train Acc=56.06%, Val Loss=1.5030, Val Acc=45.14%, Grad Norm=10.7225, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=1.2499, Train Acc=55.77%, Val Loss=1.5027, Val Acc=45.12%, Grad Norm=10.8023, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=1.2490, Train Acc=56.09%, Val Loss=1.5030, Val Acc=45.10%, Grad Norm=10.8584, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=1.2474, Train Acc=56.12%, Val Loss=1.5008, Val Acc=45.35%, Grad Norm=10.8613, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=1.2426, Train Acc=56.36%, Val Loss=1.5017, Val Acc=45.01%, Grad Norm=10.8455, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=1.2500, Train Acc=56.04%, Val Loss=1.5023, Val Acc=45.13%, Grad Norm=10.8896, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=1.2439, Train Acc=56.20%, Val Loss=1.5033, Val Acc=45.23%, Grad Norm=10.8620, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=1.2490, Train Acc=56.06%, Val Loss=1.5047, Val Acc=45.15%, Grad Norm=10.8767, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=1.2502, Train Acc=55.96%, Val Loss=1.5034, Val Acc=45.21%, Grad Norm=10.9467, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=1.2466, Train Acc=56.03%, Val Loss=1.5055, Val Acc=45.06%, Grad Norm=10.9134, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=1.2441, Train Acc=56.17%, Val Loss=1.5040, Val Acc=45.08%, Grad Norm=10.9394, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=1.2443, Train Acc=56.30%, Val Loss=1.5020, Val Acc=45.27%, Grad Norm=10.9935, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=1.2465, Train Acc=56.01%, Val Loss=1.5009, Val Acc=45.24%, Grad Norm=10.9616, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=1.2450, Train Acc=56.21%, Val Loss=1.5002, Val Acc=45.23%, Grad Norm=10.9306, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=1.2422, Train Acc=56.02%, Val Loss=1.5022, Val Acc=45.30%, Grad Norm=10.9320, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=1.2427, Train Acc=56.33%, Val Loss=1.5001, Val Acc=45.31%, Grad Norm=11.0305, LR=3.90625e-07\n",
      "Fold 3, Epoch 91: Train Loss=1.2435, Train Acc=56.21%, Val Loss=1.4970, Val Acc=45.29%, Grad Norm=10.9869, LR=1.95313e-07\n",
      "Fold 3, Epoch 92: Train Loss=1.2393, Train Acc=56.26%, Val Loss=1.5000, Val Acc=45.29%, Grad Norm=10.9676, LR=1.95313e-07\n",
      "Fold 3, Epoch 93: Train Loss=1.2418, Train Acc=56.38%, Val Loss=1.5013, Val Acc=45.24%, Grad Norm=10.9960, LR=1.95313e-07\n",
      "Fold 3, Epoch 94: Train Loss=1.2465, Train Acc=56.18%, Val Loss=1.5036, Val Acc=45.16%, Grad Norm=11.0231, LR=1.95313e-07\n",
      "Fold 3, Epoch 95: Train Loss=1.2402, Train Acc=56.21%, Val Loss=1.4995, Val Acc=45.32%, Grad Norm=11.0109, LR=1.95313e-07\n",
      "Fold 3, Epoch 96: Train Loss=1.2418, Train Acc=56.46%, Val Loss=1.5041, Val Acc=45.11%, Grad Norm=11.0437, LR=1.95313e-07\n",
      "Fold 3, Epoch 97: Train Loss=1.2419, Train Acc=56.35%, Val Loss=1.4998, Val Acc=45.30%, Grad Norm=11.0074, LR=1.95313e-07\n",
      "Fold 3, Epoch 98: Train Loss=1.2437, Train Acc=56.19%, Val Loss=1.5028, Val Acc=45.18%, Grad Norm=11.0209, LR=1.95313e-07\n",
      "Fold 3, Epoch 99: Train Loss=1.2419, Train Acc=56.48%, Val Loss=1.5031, Val Acc=45.17%, Grad Norm=11.0448, LR=1.95313e-07\n",
      "Fold 3, Epoch 100: Train Loss=1.2427, Train Acc=56.33%, Val Loss=1.5023, Val Acc=45.12%, Grad Norm=11.0569, LR=1.95313e-07\n",
      "Fold 3, Epoch 101: Train Loss=1.2456, Train Acc=56.21%, Val Loss=1.5028, Val Acc=45.21%, Grad Norm=11.0246, LR=9.76563e-08\n",
      "Fold 3, Epoch 102: Train Loss=1.2430, Train Acc=56.26%, Val Loss=1.5009, Val Acc=45.31%, Grad Norm=11.0177, LR=9.76563e-08\n",
      "Fold 3, Epoch 103: Train Loss=1.2406, Train Acc=56.21%, Val Loss=1.5055, Val Acc=45.24%, Grad Norm=11.0246, LR=9.76563e-08\n",
      "Fold 3, Epoch 104: Train Loss=1.2436, Train Acc=56.32%, Val Loss=1.5004, Val Acc=45.33%, Grad Norm=11.0484, LR=9.76563e-08\n",
      "Fold 3, Epoch 105: Train Loss=1.2470, Train Acc=56.15%, Val Loss=1.5006, Val Acc=45.23%, Grad Norm=11.1060, LR=9.76563e-08\n",
      "Fold 3, Epoch 106: Train Loss=1.2370, Train Acc=56.55%, Val Loss=1.4988, Val Acc=45.38%, Grad Norm=11.0497, LR=9.76563e-08\n",
      "Fold 3, Epoch 107: Train Loss=1.2415, Train Acc=56.14%, Val Loss=1.4995, Val Acc=45.38%, Grad Norm=11.0684, LR=9.76563e-08\n",
      "Fold 3, Epoch 108: Train Loss=1.2467, Train Acc=56.10%, Val Loss=1.5026, Val Acc=45.25%, Grad Norm=11.1028, LR=9.76563e-08\n",
      "Fold 3, Epoch 109: Train Loss=1.2423, Train Acc=56.29%, Val Loss=1.5039, Val Acc=45.05%, Grad Norm=11.0605, LR=9.76563e-08\n",
      "Fold 3, Epoch 110: Train Loss=1.2409, Train Acc=56.46%, Val Loss=1.5032, Val Acc=45.28%, Grad Norm=11.0473, LR=9.76563e-08\n",
      "Fold 3, Epoch 111: Train Loss=1.2416, Train Acc=56.41%, Val Loss=1.5023, Val Acc=45.27%, Grad Norm=11.0630, LR=4.88281e-08\n",
      "Fold 3, Epoch 112: Train Loss=1.2402, Train Acc=56.48%, Val Loss=1.5024, Val Acc=45.25%, Grad Norm=11.0870, LR=4.88281e-08\n",
      "Fold 3, Epoch 113: Train Loss=1.2411, Train Acc=56.61%, Val Loss=1.5029, Val Acc=45.19%, Grad Norm=11.0555, LR=4.88281e-08\n",
      "Fold 3, Epoch 114: Train Loss=1.2431, Train Acc=56.22%, Val Loss=1.5025, Val Acc=45.34%, Grad Norm=11.0989, LR=4.88281e-08\n",
      "Fold 3, Epoch 115: Train Loss=1.2383, Train Acc=56.53%, Val Loss=1.5012, Val Acc=45.24%, Grad Norm=11.0735, LR=4.88281e-08\n",
      "Fold 3, Epoch 116: Train Loss=1.2411, Train Acc=56.48%, Val Loss=1.5003, Val Acc=45.27%, Grad Norm=11.0425, LR=4.88281e-08\n",
      "Fold 3, Epoch 117: Train Loss=1.2391, Train Acc=56.51%, Val Loss=1.5016, Val Acc=45.23%, Grad Norm=11.1059, LR=4.88281e-08\n",
      "Fold 3, Epoch 118: Train Loss=1.2409, Train Acc=56.45%, Val Loss=1.5025, Val Acc=45.26%, Grad Norm=11.0807, LR=4.88281e-08\n",
      "Fold 3, Epoch 119: Train Loss=1.2443, Train Acc=56.05%, Val Loss=1.5011, Val Acc=45.31%, Grad Norm=11.0830, LR=4.88281e-08\n",
      "Fold 3, Epoch 120: Train Loss=1.2392, Train Acc=56.48%, Val Loss=1.5028, Val Acc=45.23%, Grad Norm=11.0902, LR=4.88281e-08\n",
      "Fold 3, Epoch 121: Train Loss=1.2399, Train Acc=56.53%, Val Loss=1.5024, Val Acc=45.21%, Grad Norm=11.0694, LR=2.44141e-08\n",
      "Fold 3, Epoch 122: Train Loss=1.2440, Train Acc=56.20%, Val Loss=1.5028, Val Acc=45.28%, Grad Norm=11.1227, LR=2.44141e-08\n",
      "Fold 3, Epoch 123: Train Loss=1.2453, Train Acc=56.21%, Val Loss=1.4994, Val Acc=45.23%, Grad Norm=11.0842, LR=2.44141e-08\n",
      "Fold 3, Epoch 124: Train Loss=1.2376, Train Acc=56.57%, Val Loss=1.5001, Val Acc=45.33%, Grad Norm=11.0839, LR=2.44141e-08\n",
      "Fold 3, Epoch 125: Train Loss=1.2439, Train Acc=56.34%, Val Loss=1.5017, Val Acc=45.31%, Grad Norm=11.1232, LR=2.44141e-08\n",
      "Fold 3, Epoch 126: Train Loss=1.2392, Train Acc=56.27%, Val Loss=1.4994, Val Acc=45.41%, Grad Norm=11.0466, LR=2.44141e-08\n",
      "Fold 3, Epoch 127: Train Loss=1.2429, Train Acc=56.37%, Val Loss=1.5025, Val Acc=45.10%, Grad Norm=11.0859, LR=2.44141e-08\n",
      "Fold 3, Epoch 128: Train Loss=1.2413, Train Acc=56.41%, Val Loss=1.4982, Val Acc=45.40%, Grad Norm=11.0661, LR=2.44141e-08\n",
      "Fold 3, Epoch 129: Train Loss=1.2362, Train Acc=56.62%, Val Loss=1.5032, Val Acc=45.17%, Grad Norm=11.0858, LR=2.44141e-08\n",
      "Fold 3, Epoch 130: Train Loss=1.2447, Train Acc=56.13%, Val Loss=1.5035, Val Acc=45.17%, Grad Norm=11.1209, LR=2.44141e-08\n",
      "Fold 3, Epoch 131: Train Loss=1.2413, Train Acc=56.01%, Val Loss=1.5024, Val Acc=45.16%, Grad Norm=11.1232, LR=1.2207e-08\n",
      "Fold 3, Epoch 132: Train Loss=1.2413, Train Acc=56.42%, Val Loss=1.5030, Val Acc=45.27%, Grad Norm=11.0857, LR=1.2207e-08\n",
      "Fold 3, Epoch 133: Train Loss=1.2357, Train Acc=56.31%, Val Loss=1.5036, Val Acc=45.00%, Grad Norm=11.0635, LR=1.2207e-08\n",
      "Fold 3, Epoch 134: Train Loss=1.2423, Train Acc=56.17%, Val Loss=1.5043, Val Acc=45.14%, Grad Norm=11.0989, LR=1.2207e-08\n",
      "Fold 3, Epoch 135: Train Loss=1.2439, Train Acc=56.37%, Val Loss=1.5015, Val Acc=45.34%, Grad Norm=11.1156, LR=1.2207e-08\n",
      "Fold 3, Epoch 136: Train Loss=1.2415, Train Acc=56.39%, Val Loss=1.4994, Val Acc=45.32%, Grad Norm=11.0580, LR=1.2207e-08\n",
      "Fold 3, Epoch 137: Train Loss=1.2392, Train Acc=56.34%, Val Loss=1.5011, Val Acc=45.29%, Grad Norm=11.0833, LR=1.2207e-08\n",
      "Fold 3, Epoch 138: Train Loss=1.2457, Train Acc=56.37%, Val Loss=1.5021, Val Acc=45.23%, Grad Norm=11.0961, LR=1.2207e-08\n",
      "Fold 3, Epoch 139: Train Loss=1.2407, Train Acc=56.34%, Val Loss=1.5016, Val Acc=45.09%, Grad Norm=11.0671, LR=1.2207e-08\n",
      "Fold 3, Epoch 140: Train Loss=1.2387, Train Acc=56.31%, Val Loss=1.5046, Val Acc=45.13%, Grad Norm=11.1232, LR=1.2207e-08\n",
      "Fold 3, Epoch 141: Train Loss=1.2413, Train Acc=56.25%, Val Loss=1.5051, Val Acc=45.21%, Grad Norm=11.1324, LR=6.10352e-09\n",
      "Fold 3, Epoch 142: Train Loss=1.2436, Train Acc=56.06%, Val Loss=1.5022, Val Acc=45.30%, Grad Norm=11.1286, LR=6.10352e-09\n",
      "Fold 3, Epoch 143: Train Loss=1.2479, Train Acc=56.07%, Val Loss=1.5027, Val Acc=45.23%, Grad Norm=11.1173, LR=6.10352e-09\n",
      "Fold 3, Epoch 144: Train Loss=1.2425, Train Acc=56.49%, Val Loss=1.5021, Val Acc=45.31%, Grad Norm=11.0945, LR=6.10352e-09\n",
      "Fold 3, Epoch 145: Train Loss=1.2443, Train Acc=56.40%, Val Loss=1.5024, Val Acc=45.19%, Grad Norm=11.1133, LR=6.10352e-09\n",
      "Fold 3, Epoch 146: Train Loss=1.2385, Train Acc=56.26%, Val Loss=1.5061, Val Acc=44.98%, Grad Norm=11.1099, LR=6.10352e-09\n",
      "Fold 3, Epoch 147: Train Loss=1.2406, Train Acc=56.30%, Val Loss=1.5030, Val Acc=45.25%, Grad Norm=11.0540, LR=6.10352e-09\n",
      "Fold 3, Epoch 148: Train Loss=1.2393, Train Acc=56.33%, Val Loss=1.5015, Val Acc=45.28%, Grad Norm=11.1069, LR=6.10352e-09\n",
      "Fold 3, Epoch 149: Train Loss=1.2439, Train Acc=56.26%, Val Loss=1.5008, Val Acc=45.29%, Grad Norm=11.1394, LR=6.10352e-09\n",
      "Fold 3, Epoch 150: Train Loss=1.2426, Train Acc=56.50%, Val Loss=1.5025, Val Acc=45.19%, Grad Norm=11.1225, LR=6.10352e-09\n",
      "Fold 3, Epoch 151: Train Loss=1.2396, Train Acc=56.41%, Val Loss=1.5001, Val Acc=45.25%, Grad Norm=11.1171, LR=3.05176e-09\n",
      "Fold 3, Epoch 152: Train Loss=1.2400, Train Acc=56.14%, Val Loss=1.5035, Val Acc=45.21%, Grad Norm=11.1175, LR=3.05176e-09\n",
      "Fold 3, Epoch 153: Train Loss=1.2383, Train Acc=56.60%, Val Loss=1.5050, Val Acc=45.07%, Grad Norm=11.0407, LR=3.05176e-09\n",
      "Fold 3, Epoch 154: Train Loss=1.2444, Train Acc=56.21%, Val Loss=1.5000, Val Acc=45.36%, Grad Norm=11.0989, LR=3.05176e-09\n",
      "Fold 3, Epoch 155: Train Loss=1.2441, Train Acc=56.27%, Val Loss=1.5024, Val Acc=45.32%, Grad Norm=11.1408, LR=3.05176e-09\n",
      "Fold 3, Epoch 156: Train Loss=1.2427, Train Acc=56.18%, Val Loss=1.5006, Val Acc=45.34%, Grad Norm=11.0732, LR=3.05176e-09\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=45.41%）\n",
      "Fold 3 DONE | Best Val Acc≈45.41% | Final Val Acc=45.41% | Test Acc=43.74%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2173, Train Acc=11.76%, Val Loss=3.1178, Val Acc=11.04%, Grad Norm=6.5235, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2027, Train Acc=13.23%, Val Loss=2.5773, Val Acc=11.26%, Grad Norm=5.7612, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.1408, Train Acc=16.91%, Val Loss=2.1293, Val Acc=16.39%, Grad Norm=4.2806, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=1.9955, Train Acc=23.89%, Val Loss=1.9621, Val Acc=24.95%, Grad Norm=4.2796, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=1.8646, Train Acc=29.76%, Val Loss=1.8437, Val Acc=30.74%, Grad Norm=3.9955, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=1.7828, Train Acc=33.25%, Val Loss=1.7711, Val Acc=33.75%, Grad Norm=3.8152, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=1.7067, Train Acc=36.65%, Val Loss=1.7087, Val Acc=36.10%, Grad Norm=3.8125, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=1.6647, Train Acc=38.57%, Val Loss=1.6678, Val Acc=37.28%, Grad Norm=3.7493, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=1.6252, Train Acc=40.40%, Val Loss=1.6437, Val Acc=38.59%, Grad Norm=3.7166, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=1.5945, Train Acc=41.73%, Val Loss=1.6051, Val Acc=40.23%, Grad Norm=3.7064, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=1.5430, Train Acc=43.81%, Val Loss=1.5601, Val Acc=42.35%, Grad Norm=3.8720, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=1.5261, Train Acc=44.56%, Val Loss=1.5484, Val Acc=43.13%, Grad Norm=4.0726, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=1.5071, Train Acc=45.63%, Val Loss=1.5420, Val Acc=43.76%, Grad Norm=4.2930, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=1.4909, Train Acc=45.98%, Val Loss=1.5336, Val Acc=44.09%, Grad Norm=4.4093, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=1.4814, Train Acc=46.15%, Val Loss=1.5359, Val Acc=43.54%, Grad Norm=4.5990, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=1.4662, Train Acc=46.88%, Val Loss=1.5295, Val Acc=43.99%, Grad Norm=4.7367, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=1.4577, Train Acc=47.27%, Val Loss=1.5110, Val Acc=44.45%, Grad Norm=4.8438, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=1.4521, Train Acc=47.40%, Val Loss=1.5029, Val Acc=44.74%, Grad Norm=4.9688, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=1.4366, Train Acc=48.19%, Val Loss=1.5030, Val Acc=44.72%, Grad Norm=5.1034, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=1.4293, Train Acc=48.59%, Val Loss=1.5029, Val Acc=45.23%, Grad Norm=5.2298, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=1.4046, Train Acc=49.58%, Val Loss=1.4788, Val Acc=45.79%, Grad Norm=5.4240, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=1.3924, Train Acc=50.18%, Val Loss=1.4730, Val Acc=45.81%, Grad Norm=5.6391, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=1.3871, Train Acc=50.23%, Val Loss=1.4684, Val Acc=45.96%, Grad Norm=5.8222, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=1.3778, Train Acc=50.56%, Val Loss=1.4664, Val Acc=46.24%, Grad Norm=6.0352, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=1.3761, Train Acc=50.61%, Val Loss=1.4661, Val Acc=46.39%, Grad Norm=6.2615, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=1.3688, Train Acc=51.02%, Val Loss=1.4706, Val Acc=46.25%, Grad Norm=6.3931, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=1.3576, Train Acc=51.44%, Val Loss=1.4601, Val Acc=46.85%, Grad Norm=6.5965, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=1.3552, Train Acc=51.53%, Val Loss=1.4740, Val Acc=46.12%, Grad Norm=6.7430, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=1.3490, Train Acc=51.86%, Val Loss=1.4722, Val Acc=46.34%, Grad Norm=6.9392, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=1.3486, Train Acc=51.60%, Val Loss=1.4605, Val Acc=46.69%, Grad Norm=7.1504, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=1.3262, Train Acc=52.76%, Val Loss=1.4484, Val Acc=47.03%, Grad Norm=7.2969, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=1.3197, Train Acc=53.21%, Val Loss=1.4547, Val Acc=46.70%, Grad Norm=7.6119, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=1.3137, Train Acc=53.18%, Val Loss=1.4484, Val Acc=46.98%, Grad Norm=7.8093, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=1.3114, Train Acc=53.27%, Val Loss=1.4517, Val Acc=46.97%, Grad Norm=7.9788, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=1.3065, Train Acc=53.62%, Val Loss=1.4512, Val Acc=46.98%, Grad Norm=8.2640, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=1.3020, Train Acc=53.94%, Val Loss=1.4482, Val Acc=47.27%, Grad Norm=8.3700, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=1.2927, Train Acc=54.28%, Val Loss=1.4440, Val Acc=47.46%, Grad Norm=8.5178, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=1.2885, Train Acc=54.36%, Val Loss=1.4451, Val Acc=47.68%, Grad Norm=8.7061, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=1.2865, Train Acc=54.35%, Val Loss=1.4408, Val Acc=47.71%, Grad Norm=8.9693, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=1.2847, Train Acc=54.59%, Val Loss=1.4399, Val Acc=47.63%, Grad Norm=9.0780, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=1.2729, Train Acc=54.93%, Val Loss=1.4375, Val Acc=47.89%, Grad Norm=9.3103, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=1.2705, Train Acc=55.08%, Val Loss=1.4416, Val Acc=47.77%, Grad Norm=9.4169, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=1.2670, Train Acc=55.15%, Val Loss=1.4339, Val Acc=47.84%, Grad Norm=9.5609, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=1.2632, Train Acc=55.47%, Val Loss=1.4394, Val Acc=47.92%, Grad Norm=9.8027, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=1.2594, Train Acc=55.71%, Val Loss=1.4384, Val Acc=48.12%, Grad Norm=9.8787, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=1.2564, Train Acc=56.10%, Val Loss=1.4388, Val Acc=47.89%, Grad Norm=10.0355, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=1.2583, Train Acc=55.47%, Val Loss=1.4372, Val Acc=47.98%, Grad Norm=10.0951, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=1.2522, Train Acc=55.86%, Val Loss=1.4414, Val Acc=47.92%, Grad Norm=10.2746, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=1.2543, Train Acc=55.95%, Val Loss=1.4377, Val Acc=47.68%, Grad Norm=10.5249, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=1.2448, Train Acc=56.05%, Val Loss=1.4384, Val Acc=47.88%, Grad Norm=10.5140, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=1.2449, Train Acc=56.00%, Val Loss=1.4378, Val Acc=47.88%, Grad Norm=10.6133, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=1.2439, Train Acc=56.00%, Val Loss=1.4375, Val Acc=47.86%, Grad Norm=10.7769, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=1.2388, Train Acc=56.39%, Val Loss=1.4385, Val Acc=47.92%, Grad Norm=10.9434, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=1.2425, Train Acc=56.33%, Val Loss=1.4373, Val Acc=47.92%, Grad Norm=11.0539, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=1.2371, Train Acc=56.25%, Val Loss=1.4385, Val Acc=48.07%, Grad Norm=11.0762, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=1.2344, Train Acc=56.52%, Val Loss=1.4395, Val Acc=48.11%, Grad Norm=11.1593, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=1.2323, Train Acc=56.39%, Val Loss=1.4389, Val Acc=47.84%, Grad Norm=11.2436, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=1.2289, Train Acc=56.86%, Val Loss=1.4417, Val Acc=47.97%, Grad Norm=11.3158, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=1.2256, Train Acc=56.94%, Val Loss=1.4432, Val Acc=47.92%, Grad Norm=11.4678, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=1.2283, Train Acc=56.88%, Val Loss=1.4448, Val Acc=47.93%, Grad Norm=11.5722, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=1.2214, Train Acc=57.16%, Val Loss=1.4441, Val Acc=47.73%, Grad Norm=11.5936, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=1.2204, Train Acc=57.04%, Val Loss=1.4406, Val Acc=48.01%, Grad Norm=11.6539, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=1.2198, Train Acc=57.30%, Val Loss=1.4422, Val Acc=47.80%, Grad Norm=11.6674, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=1.2241, Train Acc=56.99%, Val Loss=1.4393, Val Acc=48.00%, Grad Norm=11.7392, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=1.2200, Train Acc=57.11%, Val Loss=1.4378, Val Acc=48.10%, Grad Norm=11.7899, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=1.2175, Train Acc=57.36%, Val Loss=1.4403, Val Acc=48.07%, Grad Norm=11.8105, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=1.2181, Train Acc=57.08%, Val Loss=1.4426, Val Acc=47.90%, Grad Norm=11.8559, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=1.2164, Train Acc=57.24%, Val Loss=1.4416, Val Acc=48.08%, Grad Norm=11.8749, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=1.2149, Train Acc=57.40%, Val Loss=1.4420, Val Acc=47.92%, Grad Norm=11.9411, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=1.2129, Train Acc=57.59%, Val Loss=1.4430, Val Acc=47.93%, Grad Norm=12.0173, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=1.2126, Train Acc=57.45%, Val Loss=1.4413, Val Acc=48.05%, Grad Norm=12.0746, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=1.2146, Train Acc=57.62%, Val Loss=1.4411, Val Acc=48.07%, Grad Norm=12.1483, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=1.2083, Train Acc=57.56%, Val Loss=1.4405, Val Acc=48.06%, Grad Norm=12.0764, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=1.2114, Train Acc=57.58%, Val Loss=1.4414, Val Acc=48.00%, Grad Norm=12.1470, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=1.2171, Train Acc=57.10%, Val Loss=1.4389, Val Acc=48.02%, Grad Norm=12.1895, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=48.12%）\n",
      "Fold 4 DONE | Best Val Acc≈48.12% | Final Val Acc=48.12% | Test Acc=45.63%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2183, Train Acc=11.58%, Val Loss=2.6563, Val Acc=10.93%, Grad Norm=6.7018, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.1994, Train Acc=13.46%, Val Loss=2.4221, Val Acc=11.68%, Grad Norm=5.8421, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.1408, Train Acc=16.96%, Val Loss=2.1675, Val Acc=16.30%, Grad Norm=4.1564, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.0254, Train Acc=23.14%, Val Loss=2.0028, Val Acc=23.87%, Grad Norm=4.0229, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=1.8870, Train Acc=29.52%, Val Loss=1.8884, Val Acc=28.24%, Grad Norm=4.1295, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=1.7780, Train Acc=34.20%, Val Loss=1.8387, Val Acc=30.22%, Grad Norm=4.1086, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=1.6917, Train Acc=37.64%, Val Loss=1.7582, Val Acc=32.49%, Grad Norm=3.9869, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=1.6365, Train Acc=39.60%, Val Loss=1.7576, Val Acc=34.15%, Grad Norm=3.9226, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=1.5943, Train Acc=41.66%, Val Loss=1.7531, Val Acc=33.20%, Grad Norm=3.8839, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=1.5598, Train Acc=42.82%, Val Loss=1.6915, Val Acc=36.43%, Grad Norm=3.8830, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=1.5147, Train Acc=44.90%, Val Loss=1.6506, Val Acc=37.77%, Grad Norm=3.9927, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=1.4930, Train Acc=46.05%, Val Loss=1.6333, Val Acc=38.18%, Grad Norm=4.1942, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=1.4764, Train Acc=46.60%, Val Loss=1.6367, Val Acc=38.83%, Grad Norm=4.3579, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=1.4669, Train Acc=47.14%, Val Loss=1.6182, Val Acc=39.56%, Grad Norm=4.5337, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=1.4551, Train Acc=47.45%, Val Loss=1.6115, Val Acc=39.56%, Grad Norm=4.6832, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=1.4435, Train Acc=47.94%, Val Loss=1.6208, Val Acc=40.04%, Grad Norm=4.7784, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=1.4397, Train Acc=48.10%, Val Loss=1.6273, Val Acc=39.78%, Grad Norm=4.9249, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=1.4304, Train Acc=48.74%, Val Loss=1.6153, Val Acc=40.13%, Grad Norm=5.0088, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=1.4202, Train Acc=48.78%, Val Loss=1.6007, Val Acc=41.08%, Grad Norm=5.1570, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=1.4097, Train Acc=49.53%, Val Loss=1.6288, Val Acc=39.81%, Grad Norm=5.3046, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=1.3888, Train Acc=50.42%, Val Loss=1.6015, Val Acc=41.10%, Grad Norm=5.4489, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=1.3814, Train Acc=50.62%, Val Loss=1.5946, Val Acc=41.22%, Grad Norm=5.6699, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=1.3664, Train Acc=51.27%, Val Loss=1.5836, Val Acc=41.29%, Grad Norm=5.7980, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=1.3596, Train Acc=51.50%, Val Loss=1.5911, Val Acc=41.08%, Grad Norm=6.0596, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=1.3564, Train Acc=51.67%, Val Loss=1.6012, Val Acc=41.33%, Grad Norm=6.2372, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=1.3544, Train Acc=51.71%, Val Loss=1.5896, Val Acc=41.19%, Grad Norm=6.3677, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=1.3439, Train Acc=52.30%, Val Loss=1.6025, Val Acc=41.13%, Grad Norm=6.6313, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=1.3429, Train Acc=52.10%, Val Loss=1.5877, Val Acc=41.51%, Grad Norm=6.7632, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=1.3352, Train Acc=52.46%, Val Loss=1.5726, Val Acc=41.91%, Grad Norm=6.9215, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=1.3339, Train Acc=52.48%, Val Loss=1.6051, Val Acc=41.01%, Grad Norm=7.0600, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=1.3183, Train Acc=53.23%, Val Loss=1.5845, Val Acc=41.71%, Grad Norm=7.3146, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=1.3105, Train Acc=53.38%, Val Loss=1.5719, Val Acc=42.35%, Grad Norm=7.5478, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=1.3035, Train Acc=53.58%, Val Loss=1.5865, Val Acc=41.81%, Grad Norm=7.7013, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=1.3021, Train Acc=53.92%, Val Loss=1.5769, Val Acc=42.23%, Grad Norm=7.8814, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=1.2944, Train Acc=54.07%, Val Loss=1.5573, Val Acc=42.37%, Grad Norm=8.0486, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=1.2887, Train Acc=54.43%, Val Loss=1.5639, Val Acc=42.27%, Grad Norm=8.2413, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=1.2892, Train Acc=54.38%, Val Loss=1.5778, Val Acc=42.43%, Grad Norm=8.4745, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=1.2823, Train Acc=54.70%, Val Loss=1.5694, Val Acc=42.64%, Grad Norm=8.5679, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=1.2804, Train Acc=54.74%, Val Loss=1.5688, Val Acc=42.30%, Grad Norm=8.7758, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=1.2727, Train Acc=54.99%, Val Loss=1.5842, Val Acc=41.92%, Grad Norm=8.9703, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=1.2653, Train Acc=55.27%, Val Loss=1.5790, Val Acc=42.41%, Grad Norm=9.1726, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=1.2607, Train Acc=55.80%, Val Loss=1.5754, Val Acc=42.26%, Grad Norm=9.3012, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=1.2574, Train Acc=55.61%, Val Loss=1.5635, Val Acc=42.50%, Grad Norm=9.4418, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=1.2547, Train Acc=55.66%, Val Loss=1.5837, Val Acc=42.51%, Grad Norm=9.5579, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=1.2512, Train Acc=55.89%, Val Loss=1.5780, Val Acc=42.43%, Grad Norm=9.7574, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=1.2545, Train Acc=55.74%, Val Loss=1.5750, Val Acc=42.53%, Grad Norm=9.7391, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=1.2487, Train Acc=55.94%, Val Loss=1.5675, Val Acc=42.51%, Grad Norm=9.8553, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=1.2474, Train Acc=56.23%, Val Loss=1.5717, Val Acc=42.87%, Grad Norm=10.0881, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=1.2440, Train Acc=56.20%, Val Loss=1.5757, Val Acc=42.56%, Grad Norm=10.1772, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=1.2421, Train Acc=56.32%, Val Loss=1.5839, Val Acc=42.25%, Grad Norm=10.3353, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=1.2357, Train Acc=56.45%, Val Loss=1.5686, Val Acc=42.63%, Grad Norm=10.4641, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=1.2340, Train Acc=56.72%, Val Loss=1.5779, Val Acc=42.41%, Grad Norm=10.5963, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=1.2316, Train Acc=56.78%, Val Loss=1.5838, Val Acc=42.72%, Grad Norm=10.7360, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=1.2293, Train Acc=56.63%, Val Loss=1.5741, Val Acc=42.78%, Grad Norm=10.7573, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=1.2307, Train Acc=56.70%, Val Loss=1.5763, Val Acc=42.59%, Grad Norm=10.8446, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=1.2268, Train Acc=56.97%, Val Loss=1.5762, Val Acc=42.58%, Grad Norm=10.9741, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=1.2281, Train Acc=56.82%, Val Loss=1.5808, Val Acc=42.43%, Grad Norm=11.0657, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=1.2176, Train Acc=57.47%, Val Loss=1.5772, Val Acc=42.72%, Grad Norm=11.1004, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=1.2173, Train Acc=57.16%, Val Loss=1.5716, Val Acc=42.90%, Grad Norm=11.1701, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=1.2216, Train Acc=57.15%, Val Loss=1.5730, Val Acc=42.89%, Grad Norm=11.2602, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=1.2214, Train Acc=57.05%, Val Loss=1.5706, Val Acc=42.67%, Grad Norm=11.3526, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=1.2204, Train Acc=57.38%, Val Loss=1.5686, Val Acc=42.76%, Grad Norm=11.3699, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=1.2164, Train Acc=57.23%, Val Loss=1.5758, Val Acc=42.78%, Grad Norm=11.4697, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=1.2159, Train Acc=57.33%, Val Loss=1.5783, Val Acc=42.43%, Grad Norm=11.5038, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=1.2142, Train Acc=57.32%, Val Loss=1.5829, Val Acc=42.72%, Grad Norm=11.4811, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=1.2121, Train Acc=57.60%, Val Loss=1.5731, Val Acc=42.96%, Grad Norm=11.6025, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=1.2091, Train Acc=57.49%, Val Loss=1.5642, Val Acc=43.01%, Grad Norm=11.6840, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=1.2147, Train Acc=57.55%, Val Loss=1.5714, Val Acc=42.73%, Grad Norm=11.6779, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=1.2127, Train Acc=57.48%, Val Loss=1.5703, Val Acc=42.95%, Grad Norm=11.7367, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=1.2126, Train Acc=57.35%, Val Loss=1.5781, Val Acc=43.00%, Grad Norm=11.7405, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=1.2102, Train Acc=57.53%, Val Loss=1.5711, Val Acc=42.90%, Grad Norm=11.8015, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=1.2086, Train Acc=57.63%, Val Loss=1.5777, Val Acc=42.85%, Grad Norm=11.8555, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=1.2130, Train Acc=57.52%, Val Loss=1.5795, Val Acc=42.84%, Grad Norm=11.8972, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=1.2071, Train Acc=57.91%, Val Loss=1.5771, Val Acc=42.90%, Grad Norm=11.8662, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=1.2096, Train Acc=57.76%, Val Loss=1.5738, Val Acc=42.87%, Grad Norm=11.9620, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=1.2078, Train Acc=57.57%, Val Loss=1.5669, Val Acc=42.97%, Grad Norm=11.9556, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=1.2097, Train Acc=57.72%, Val Loss=1.5777, Val Acc=43.01%, Grad Norm=11.9878, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=1.2057, Train Acc=57.65%, Val Loss=1.5722, Val Acc=42.97%, Grad Norm=11.9854, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=1.2052, Train Acc=57.91%, Val Loss=1.5692, Val Acc=42.89%, Grad Norm=12.0118, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=1.2041, Train Acc=57.93%, Val Loss=1.5715, Val Acc=42.98%, Grad Norm=12.0458, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=1.2062, Train Acc=57.80%, Val Loss=1.5758, Val Acc=42.80%, Grad Norm=12.0847, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=1.2007, Train Acc=57.95%, Val Loss=1.5726, Val Acc=42.97%, Grad Norm=12.0554, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=1.2081, Train Acc=57.67%, Val Loss=1.5707, Val Acc=42.90%, Grad Norm=12.1324, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=1.2085, Train Acc=57.59%, Val Loss=1.5717, Val Acc=43.00%, Grad Norm=12.1150, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=1.2076, Train Acc=57.73%, Val Loss=1.5715, Val Acc=42.91%, Grad Norm=12.1744, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=1.2039, Train Acc=57.69%, Val Loss=1.5702, Val Acc=43.01%, Grad Norm=12.1262, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=1.2028, Train Acc=57.85%, Val Loss=1.5742, Val Acc=42.84%, Grad Norm=12.1278, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=1.2024, Train Acc=57.69%, Val Loss=1.5738, Val Acc=42.99%, Grad Norm=12.1843, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=1.2008, Train Acc=58.00%, Val Loss=1.5693, Val Acc=42.86%, Grad Norm=12.1284, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=1.1999, Train Acc=58.11%, Val Loss=1.5742, Val Acc=42.78%, Grad Norm=12.1769, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=1.2009, Train Acc=58.15%, Val Loss=1.5708, Val Acc=42.79%, Grad Norm=12.1778, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=1.2005, Train Acc=57.89%, Val Loss=1.5752, Val Acc=42.91%, Grad Norm=12.2240, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=1.2017, Train Acc=57.84%, Val Loss=1.5778, Val Acc=42.85%, Grad Norm=12.2319, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=1.2022, Train Acc=57.75%, Val Loss=1.5804, Val Acc=42.81%, Grad Norm=12.2039, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=1.1995, Train Acc=58.05%, Val Loss=1.5799, Val Acc=42.68%, Grad Norm=12.2123, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=1.1996, Train Acc=58.01%, Val Loss=1.5763, Val Acc=42.91%, Grad Norm=12.2015, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=1.2018, Train Acc=57.95%, Val Loss=1.5784, Val Acc=42.95%, Grad Norm=12.2680, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=43.01%）\n",
      "Fold 5 DONE | Best Val Acc≈43.01% | Final Val Acc=43.01% | Test Acc=45.36%\n",
      "[INFO] SNR=-5 dB | Mean Test Acc: 44.57% ± 0.78%\n",
      "[INFO] SNR  -5 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-5dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -10 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2232, Train Acc=11.26%, Val Loss=2.2843, Val Acc=11.15%, Grad Norm=6.7327, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2201, Train Acc=11.32%, Val Loss=2.2757, Val Acc=11.23%, Grad Norm=6.3959, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2164, Train Acc=11.49%, Val Loss=2.2327, Val Acc=11.34%, Grad Norm=5.5976, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2081, Train Acc=11.55%, Val Loss=2.2289, Val Acc=11.10%, Grad Norm=4.3466, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.1980, Train Acc=12.38%, Val Loss=2.2032, Val Acc=12.25%, Grad Norm=3.2460, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.1847, Train Acc=13.50%, Val Loss=2.1942, Val Acc=13.52%, Grad Norm=2.8112, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.1729, Train Acc=14.98%, Val Loss=2.1956, Val Acc=14.23%, Grad Norm=2.6293, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.1554, Train Acc=16.05%, Val Loss=2.1823, Val Acc=15.14%, Grad Norm=2.5002, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.1363, Train Acc=17.69%, Val Loss=2.1163, Val Acc=18.76%, Grad Norm=2.5307, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.0983, Train Acc=19.40%, Val Loss=2.0902, Val Acc=19.12%, Grad Norm=2.6089, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.0611, Train Acc=21.20%, Val Loss=2.0429, Val Acc=21.75%, Grad Norm=2.6801, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.0430, Train Acc=22.46%, Val Loss=2.0458, Val Acc=21.37%, Grad Norm=2.9172, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.0266, Train Acc=23.39%, Val Loss=2.0205, Val Acc=23.35%, Grad Norm=3.0975, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.0068, Train Acc=24.35%, Val Loss=2.0054, Val Acc=23.90%, Grad Norm=3.3974, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=1.9891, Train Acc=25.26%, Val Loss=1.9950, Val Acc=24.26%, Grad Norm=3.5895, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=1.9689, Train Acc=26.36%, Val Loss=1.9762, Val Acc=25.32%, Grad Norm=3.7135, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=1.9511, Train Acc=27.19%, Val Loss=1.9689, Val Acc=25.95%, Grad Norm=3.8574, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=1.9335, Train Acc=28.16%, Val Loss=1.9585, Val Acc=26.63%, Grad Norm=3.9931, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=1.9226, Train Acc=28.37%, Val Loss=1.9497, Val Acc=26.35%, Grad Norm=4.1058, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=1.9111, Train Acc=29.08%, Val Loss=1.9436, Val Acc=27.20%, Grad Norm=4.2104, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=1.8844, Train Acc=30.57%, Val Loss=1.9250, Val Acc=27.66%, Grad Norm=4.3522, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=1.8693, Train Acc=31.01%, Val Loss=1.9195, Val Acc=28.39%, Grad Norm=4.6356, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=1.8603, Train Acc=31.35%, Val Loss=1.9154, Val Acc=28.02%, Grad Norm=4.7918, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=1.8543, Train Acc=32.18%, Val Loss=1.9065, Val Acc=28.50%, Grad Norm=4.9782, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=1.8476, Train Acc=32.33%, Val Loss=1.9000, Val Acc=29.00%, Grad Norm=5.0900, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=1.8429, Train Acc=32.42%, Val Loss=1.8942, Val Acc=29.16%, Grad Norm=5.2934, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=1.8324, Train Acc=32.97%, Val Loss=1.8927, Val Acc=29.45%, Grad Norm=5.4489, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=1.8231, Train Acc=33.25%, Val Loss=1.8940, Val Acc=29.23%, Grad Norm=5.6342, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=1.8209, Train Acc=33.40%, Val Loss=1.8805, Val Acc=29.88%, Grad Norm=5.8024, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=1.8098, Train Acc=33.76%, Val Loss=1.8790, Val Acc=29.79%, Grad Norm=5.9514, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=1.7938, Train Acc=34.61%, Val Loss=1.8702, Val Acc=30.22%, Grad Norm=6.0785, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=1.7858, Train Acc=35.18%, Val Loss=1.8692, Val Acc=30.28%, Grad Norm=6.2692, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=1.7802, Train Acc=35.12%, Val Loss=1.8691, Val Acc=30.16%, Grad Norm=6.4246, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=1.7790, Train Acc=35.46%, Val Loss=1.8651, Val Acc=30.47%, Grad Norm=6.6314, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=1.7742, Train Acc=35.59%, Val Loss=1.8634, Val Acc=30.14%, Grad Norm=6.7823, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=1.7718, Train Acc=35.65%, Val Loss=1.8667, Val Acc=30.40%, Grad Norm=6.9110, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=1.7601, Train Acc=36.18%, Val Loss=1.8615, Val Acc=30.53%, Grad Norm=7.1181, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=1.7581, Train Acc=36.37%, Val Loss=1.8562, Val Acc=30.70%, Grad Norm=7.2661, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=1.7547, Train Acc=36.27%, Val Loss=1.8694, Val Acc=30.02%, Grad Norm=7.4313, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=1.7554, Train Acc=36.26%, Val Loss=1.8617, Val Acc=30.58%, Grad Norm=7.5942, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=1.7422, Train Acc=37.14%, Val Loss=1.8564, Val Acc=30.70%, Grad Norm=7.7095, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=1.7418, Train Acc=37.15%, Val Loss=1.8553, Val Acc=30.77%, Grad Norm=7.8929, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=1.7363, Train Acc=37.16%, Val Loss=1.8520, Val Acc=30.79%, Grad Norm=8.0443, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=1.7318, Train Acc=37.50%, Val Loss=1.8532, Val Acc=31.07%, Grad Norm=8.1463, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=1.7277, Train Acc=37.61%, Val Loss=1.8513, Val Acc=30.91%, Grad Norm=8.2589, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=1.7320, Train Acc=37.43%, Val Loss=1.8482, Val Acc=31.01%, Grad Norm=8.4384, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=1.7241, Train Acc=37.63%, Val Loss=1.8521, Val Acc=30.86%, Grad Norm=8.5330, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=1.7282, Train Acc=37.76%, Val Loss=1.8516, Val Acc=30.69%, Grad Norm=8.7698, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=1.7208, Train Acc=38.18%, Val Loss=1.8531, Val Acc=31.18%, Grad Norm=8.7834, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=1.7161, Train Acc=38.23%, Val Loss=1.8560, Val Acc=30.83%, Grad Norm=8.9737, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=1.7139, Train Acc=38.44%, Val Loss=1.8492, Val Acc=31.01%, Grad Norm=9.0913, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=1.7119, Train Acc=38.36%, Val Loss=1.8513, Val Acc=31.03%, Grad Norm=9.1626, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=1.7048, Train Acc=38.67%, Val Loss=1.8485, Val Acc=31.01%, Grad Norm=9.2338, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=1.7062, Train Acc=38.39%, Val Loss=1.8494, Val Acc=31.13%, Grad Norm=9.3433, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=1.7074, Train Acc=38.61%, Val Loss=1.8475, Val Acc=31.05%, Grad Norm=9.4250, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=1.7060, Train Acc=38.79%, Val Loss=1.8464, Val Acc=31.00%, Grad Norm=9.4970, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=1.7009, Train Acc=38.66%, Val Loss=1.8493, Val Acc=31.00%, Grad Norm=9.5830, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=1.7007, Train Acc=39.23%, Val Loss=1.8477, Val Acc=30.94%, Grad Norm=9.7297, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=1.6919, Train Acc=39.30%, Val Loss=1.8467, Val Acc=31.20%, Grad Norm=9.7304, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=1.6978, Train Acc=38.86%, Val Loss=1.8473, Val Acc=31.17%, Grad Norm=9.8905, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=1.6962, Train Acc=38.91%, Val Loss=1.8463, Val Acc=31.13%, Grad Norm=10.0120, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=1.6912, Train Acc=39.52%, Val Loss=1.8469, Val Acc=31.21%, Grad Norm=10.0108, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=1.6910, Train Acc=39.29%, Val Loss=1.8466, Val Acc=31.19%, Grad Norm=10.0586, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=1.6908, Train Acc=39.25%, Val Loss=1.8463, Val Acc=31.11%, Grad Norm=10.0522, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=1.6952, Train Acc=38.89%, Val Loss=1.8467, Val Acc=31.18%, Grad Norm=10.1596, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=1.6882, Train Acc=39.40%, Val Loss=1.8468, Val Acc=31.19%, Grad Norm=10.2001, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=1.6911, Train Acc=39.42%, Val Loss=1.8457, Val Acc=31.19%, Grad Norm=10.2560, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=1.6855, Train Acc=39.47%, Val Loss=1.8477, Val Acc=31.14%, Grad Norm=10.3042, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=1.6872, Train Acc=39.51%, Val Loss=1.8460, Val Acc=31.19%, Grad Norm=10.3048, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=1.6847, Train Acc=39.61%, Val Loss=1.8462, Val Acc=31.18%, Grad Norm=10.3931, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=1.6819, Train Acc=39.86%, Val Loss=1.8462, Val Acc=31.23%, Grad Norm=10.4520, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=1.6853, Train Acc=39.65%, Val Loss=1.8468, Val Acc=31.13%, Grad Norm=10.4795, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=1.6857, Train Acc=39.44%, Val Loss=1.8460, Val Acc=31.14%, Grad Norm=10.5298, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=1.6855, Train Acc=39.40%, Val Loss=1.8461, Val Acc=31.16%, Grad Norm=10.5056, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=1.6842, Train Acc=39.62%, Val Loss=1.8471, Val Acc=31.17%, Grad Norm=10.5803, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=1.6782, Train Acc=39.93%, Val Loss=1.8469, Val Acc=31.13%, Grad Norm=10.5927, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=1.6815, Train Acc=39.56%, Val Loss=1.8467, Val Acc=31.11%, Grad Norm=10.6848, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=1.6837, Train Acc=39.53%, Val Loss=1.8459, Val Acc=31.17%, Grad Norm=10.6434, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=1.6761, Train Acc=39.89%, Val Loss=1.8461, Val Acc=31.02%, Grad Norm=10.6387, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=1.6796, Train Acc=39.67%, Val Loss=1.8482, Val Acc=31.06%, Grad Norm=10.6615, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=1.6809, Train Acc=39.71%, Val Loss=1.8471, Val Acc=31.06%, Grad Norm=10.7719, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=1.6792, Train Acc=39.89%, Val Loss=1.8471, Val Acc=31.14%, Grad Norm=10.7150, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=1.6770, Train Acc=40.00%, Val Loss=1.8467, Val Acc=31.20%, Grad Norm=10.7808, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=1.6778, Train Acc=39.72%, Val Loss=1.8461, Val Acc=31.23%, Grad Norm=10.7354, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=1.6783, Train Acc=39.62%, Val Loss=1.8459, Val Acc=31.14%, Grad Norm=10.7625, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=1.6789, Train Acc=39.92%, Val Loss=1.8460, Val Acc=31.10%, Grad Norm=10.7824, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=1.6816, Train Acc=39.84%, Val Loss=1.8459, Val Acc=31.23%, Grad Norm=10.8304, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=1.6762, Train Acc=39.92%, Val Loss=1.8460, Val Acc=31.20%, Grad Norm=10.8151, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=1.6775, Train Acc=40.15%, Val Loss=1.8446, Val Acc=31.19%, Grad Norm=10.8468, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=1.6815, Train Acc=39.74%, Val Loss=1.8449, Val Acc=31.30%, Grad Norm=10.8551, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=1.6729, Train Acc=40.34%, Val Loss=1.8452, Val Acc=31.19%, Grad Norm=10.8350, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=1.6774, Train Acc=39.93%, Val Loss=1.8466, Val Acc=31.24%, Grad Norm=10.8869, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=1.6762, Train Acc=39.94%, Val Loss=1.8466, Val Acc=31.14%, Grad Norm=10.8629, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=1.6748, Train Acc=39.96%, Val Loss=1.8451, Val Acc=31.18%, Grad Norm=10.8874, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=1.6735, Train Acc=40.30%, Val Loss=1.8455, Val Acc=31.13%, Grad Norm=10.9338, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=1.6800, Train Acc=39.84%, Val Loss=1.8467, Val Acc=31.12%, Grad Norm=10.9373, LR=1.95313e-07\n",
      "Fold 1, Epoch 97: Train Loss=1.6729, Train Acc=40.00%, Val Loss=1.8464, Val Acc=31.13%, Grad Norm=10.9101, LR=1.95313e-07\n",
      "Fold 1, Epoch 98: Train Loss=1.6719, Train Acc=40.16%, Val Loss=1.8452, Val Acc=31.12%, Grad Norm=10.9378, LR=1.95313e-07\n",
      "Fold 1, Epoch 99: Train Loss=1.6747, Train Acc=39.99%, Val Loss=1.8455, Val Acc=31.18%, Grad Norm=10.9328, LR=1.95313e-07\n",
      "Fold 1, Epoch 100: Train Loss=1.6719, Train Acc=40.33%, Val Loss=1.8465, Val Acc=31.14%, Grad Norm=10.9031, LR=1.95313e-07\n",
      "Fold 1, Epoch 101: Train Loss=1.6761, Train Acc=39.95%, Val Loss=1.8469, Val Acc=31.12%, Grad Norm=10.9495, LR=9.76563e-08\n",
      "Fold 1, Epoch 102: Train Loss=1.6738, Train Acc=39.72%, Val Loss=1.8449, Val Acc=31.23%, Grad Norm=10.9380, LR=9.76563e-08\n",
      "Fold 1, Epoch 103: Train Loss=1.6766, Train Acc=40.10%, Val Loss=1.8472, Val Acc=31.18%, Grad Norm=10.9576, LR=9.76563e-08\n",
      "Fold 1, Epoch 104: Train Loss=1.6771, Train Acc=40.12%, Val Loss=1.8467, Val Acc=31.21%, Grad Norm=10.9901, LR=9.76563e-08\n",
      "Fold 1, Epoch 105: Train Loss=1.6730, Train Acc=40.31%, Val Loss=1.8467, Val Acc=31.17%, Grad Norm=10.8724, LR=9.76563e-08\n",
      "Fold 1, Epoch 106: Train Loss=1.6787, Train Acc=39.60%, Val Loss=1.8468, Val Acc=31.23%, Grad Norm=10.9582, LR=9.76563e-08\n",
      "Fold 1, Epoch 107: Train Loss=1.6767, Train Acc=39.99%, Val Loss=1.8449, Val Acc=31.24%, Grad Norm=10.9539, LR=9.76563e-08\n",
      "Fold 1, Epoch 108: Train Loss=1.6748, Train Acc=40.01%, Val Loss=1.8449, Val Acc=31.20%, Grad Norm=10.9445, LR=9.76563e-08\n",
      "Fold 1, Epoch 109: Train Loss=1.6744, Train Acc=40.05%, Val Loss=1.8460, Val Acc=31.31%, Grad Norm=10.9454, LR=9.76563e-08\n",
      "Fold 1, Epoch 110: Train Loss=1.6763, Train Acc=40.08%, Val Loss=1.8451, Val Acc=31.20%, Grad Norm=10.9636, LR=9.76563e-08\n",
      "Fold 1, Epoch 111: Train Loss=1.6774, Train Acc=39.87%, Val Loss=1.8474, Val Acc=31.12%, Grad Norm=10.9854, LR=4.88281e-08\n",
      "Fold 1, Epoch 112: Train Loss=1.6711, Train Acc=40.05%, Val Loss=1.8475, Val Acc=31.25%, Grad Norm=10.9902, LR=4.88281e-08\n",
      "Fold 1, Epoch 113: Train Loss=1.6747, Train Acc=40.08%, Val Loss=1.8448, Val Acc=31.20%, Grad Norm=10.9535, LR=4.88281e-08\n",
      "Fold 1, Epoch 114: Train Loss=1.6742, Train Acc=40.13%, Val Loss=1.8462, Val Acc=31.19%, Grad Norm=11.0179, LR=4.88281e-08\n",
      "Fold 1, Epoch 115: Train Loss=1.6777, Train Acc=39.98%, Val Loss=1.8453, Val Acc=31.26%, Grad Norm=10.9878, LR=4.88281e-08\n",
      "Fold 1, Epoch 116: Train Loss=1.6743, Train Acc=39.84%, Val Loss=1.8465, Val Acc=31.16%, Grad Norm=10.9827, LR=4.88281e-08\n",
      "Fold 1, Epoch 117: Train Loss=1.6727, Train Acc=40.28%, Val Loss=1.8459, Val Acc=31.21%, Grad Norm=10.9471, LR=4.88281e-08\n",
      "Fold 1, Epoch 118: Train Loss=1.6712, Train Acc=40.44%, Val Loss=1.8459, Val Acc=31.19%, Grad Norm=10.9897, LR=4.88281e-08\n",
      "Fold 1, Epoch 119: Train Loss=1.6727, Train Acc=40.30%, Val Loss=1.8458, Val Acc=31.24%, Grad Norm=10.9866, LR=4.88281e-08\n",
      "Fold 1, Epoch 120: Train Loss=1.6759, Train Acc=39.91%, Val Loss=1.8466, Val Acc=31.16%, Grad Norm=10.9890, LR=4.88281e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=31.30%）\n",
      "Fold 1 DONE | Best Val Acc≈31.30% | Final Val Acc=31.30% | Test Acc=30.74%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2241, Train Acc=10.93%, Val Loss=2.2356, Val Acc=11.26%, Grad Norm=6.7718, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2208, Train Acc=11.29%, Val Loss=2.3062, Val Acc=11.32%, Grad Norm=6.5231, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2170, Train Acc=11.42%, Val Loss=2.3129, Val Acc=10.96%, Grad Norm=5.8591, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2106, Train Acc=11.38%, Val Loss=2.2950, Val Acc=11.20%, Grad Norm=4.8441, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2056, Train Acc=11.94%, Val Loss=2.2341, Val Acc=11.03%, Grad Norm=3.9227, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.1992, Train Acc=12.26%, Val Loss=2.2560, Val Acc=12.29%, Grad Norm=3.5136, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.1907, Train Acc=13.65%, Val Loss=2.2452, Val Acc=12.31%, Grad Norm=3.2076, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.1673, Train Acc=16.03%, Val Loss=2.1712, Val Acc=16.02%, Grad Norm=3.0319, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.1316, Train Acc=18.15%, Val Loss=2.1215, Val Acc=18.04%, Grad Norm=2.9854, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.0804, Train Acc=21.07%, Val Loss=2.0795, Val Acc=19.92%, Grad Norm=3.0920, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.0357, Train Acc=22.93%, Val Loss=2.0514, Val Acc=21.40%, Grad Norm=3.0622, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.0130, Train Acc=24.16%, Val Loss=2.0394, Val Acc=22.22%, Grad Norm=3.2580, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=1.9929, Train Acc=25.31%, Val Loss=2.0098, Val Acc=23.49%, Grad Norm=3.4867, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=1.9711, Train Acc=26.42%, Val Loss=1.9943, Val Acc=24.31%, Grad Norm=3.6463, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=1.9533, Train Acc=27.20%, Val Loss=1.9814, Val Acc=24.99%, Grad Norm=3.7457, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=1.9358, Train Acc=28.26%, Val Loss=1.9726, Val Acc=25.32%, Grad Norm=3.8322, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=1.9265, Train Acc=28.60%, Val Loss=1.9617, Val Acc=26.07%, Grad Norm=3.9537, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=1.9109, Train Acc=29.30%, Val Loss=1.9564, Val Acc=26.24%, Grad Norm=4.0540, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=1.8964, Train Acc=29.92%, Val Loss=1.9533, Val Acc=26.43%, Grad Norm=4.2030, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=1.8880, Train Acc=30.32%, Val Loss=1.9381, Val Acc=27.38%, Grad Norm=4.2480, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=1.8582, Train Acc=31.51%, Val Loss=1.9288, Val Acc=27.38%, Grad Norm=4.4626, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=1.8537, Train Acc=31.84%, Val Loss=1.9158, Val Acc=28.09%, Grad Norm=4.6941, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=1.8454, Train Acc=32.40%, Val Loss=1.9141, Val Acc=28.20%, Grad Norm=4.8354, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=1.8315, Train Acc=33.08%, Val Loss=1.9123, Val Acc=28.29%, Grad Norm=5.0350, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=1.8232, Train Acc=33.49%, Val Loss=1.9129, Val Acc=28.34%, Grad Norm=5.2032, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=1.8178, Train Acc=33.49%, Val Loss=1.9079, Val Acc=28.24%, Grad Norm=5.3958, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=1.8095, Train Acc=34.17%, Val Loss=1.9013, Val Acc=28.56%, Grad Norm=5.5661, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=1.8037, Train Acc=34.39%, Val Loss=1.8982, Val Acc=28.93%, Grad Norm=5.7082, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=1.7962, Train Acc=34.47%, Val Loss=1.8941, Val Acc=29.01%, Grad Norm=5.8587, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=1.7872, Train Acc=34.96%, Val Loss=1.8921, Val Acc=28.79%, Grad Norm=5.9966, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=1.7768, Train Acc=35.67%, Val Loss=1.8879, Val Acc=29.25%, Grad Norm=6.2096, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=1.7680, Train Acc=35.94%, Val Loss=1.8883, Val Acc=29.14%, Grad Norm=6.3478, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=1.7617, Train Acc=36.05%, Val Loss=1.8862, Val Acc=29.26%, Grad Norm=6.4745, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=1.7603, Train Acc=36.07%, Val Loss=1.8812, Val Acc=29.60%, Grad Norm=6.6512, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=1.7560, Train Acc=36.43%, Val Loss=1.8853, Val Acc=29.13%, Grad Norm=6.7816, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=1.7510, Train Acc=36.80%, Val Loss=1.8835, Val Acc=29.45%, Grad Norm=6.9946, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=1.7455, Train Acc=37.09%, Val Loss=1.8831, Val Acc=29.74%, Grad Norm=7.1423, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=1.7486, Train Acc=36.58%, Val Loss=1.8829, Val Acc=29.65%, Grad Norm=7.3090, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=1.7429, Train Acc=37.11%, Val Loss=1.8849, Val Acc=29.67%, Grad Norm=7.3828, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=1.7368, Train Acc=37.26%, Val Loss=1.8783, Val Acc=29.70%, Grad Norm=7.5646, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=1.7226, Train Acc=38.20%, Val Loss=1.8761, Val Acc=30.02%, Grad Norm=7.6840, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=1.7218, Train Acc=38.00%, Val Loss=1.8786, Val Acc=29.73%, Grad Norm=7.8855, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=1.7206, Train Acc=37.98%, Val Loss=1.8744, Val Acc=29.99%, Grad Norm=8.0323, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=1.7177, Train Acc=38.04%, Val Loss=1.8742, Val Acc=29.89%, Grad Norm=8.1123, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=1.7146, Train Acc=38.28%, Val Loss=1.8770, Val Acc=29.90%, Grad Norm=8.2604, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=1.7113, Train Acc=38.49%, Val Loss=1.8792, Val Acc=29.89%, Grad Norm=8.3473, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=1.7058, Train Acc=38.84%, Val Loss=1.8745, Val Acc=29.88%, Grad Norm=8.4642, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=1.7079, Train Acc=38.46%, Val Loss=1.8739, Val Acc=29.95%, Grad Norm=8.5885, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=1.7004, Train Acc=38.75%, Val Loss=1.8755, Val Acc=29.80%, Grad Norm=8.7191, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=1.7031, Train Acc=38.75%, Val Loss=1.8735, Val Acc=30.12%, Grad Norm=8.8477, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=1.6936, Train Acc=39.43%, Val Loss=1.8777, Val Acc=29.86%, Grad Norm=8.9211, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=1.6926, Train Acc=39.35%, Val Loss=1.8745, Val Acc=29.93%, Grad Norm=9.0242, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=1.6914, Train Acc=39.23%, Val Loss=1.8729, Val Acc=30.13%, Grad Norm=9.1486, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=1.6934, Train Acc=39.10%, Val Loss=1.8735, Val Acc=30.01%, Grad Norm=9.2142, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=1.6918, Train Acc=39.43%, Val Loss=1.8745, Val Acc=30.04%, Grad Norm=9.2783, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=1.6862, Train Acc=39.53%, Val Loss=1.8757, Val Acc=29.80%, Grad Norm=9.3876, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=1.6924, Train Acc=39.33%, Val Loss=1.8721, Val Acc=30.20%, Grad Norm=9.4409, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=1.6893, Train Acc=39.17%, Val Loss=1.8747, Val Acc=29.91%, Grad Norm=9.5550, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=1.6828, Train Acc=39.88%, Val Loss=1.8736, Val Acc=30.04%, Grad Norm=9.5953, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=1.6806, Train Acc=39.88%, Val Loss=1.8732, Val Acc=29.96%, Grad Norm=9.6509, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=1.6816, Train Acc=39.90%, Val Loss=1.8720, Val Acc=30.00%, Grad Norm=9.7217, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=1.6782, Train Acc=39.76%, Val Loss=1.8744, Val Acc=30.01%, Grad Norm=9.8298, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=1.6836, Train Acc=39.82%, Val Loss=1.8732, Val Acc=30.17%, Grad Norm=9.8913, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=1.6766, Train Acc=40.01%, Val Loss=1.8735, Val Acc=30.11%, Grad Norm=9.9142, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=1.6767, Train Acc=39.88%, Val Loss=1.8740, Val Acc=30.00%, Grad Norm=9.9046, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=1.6781, Train Acc=39.91%, Val Loss=1.8722, Val Acc=30.12%, Grad Norm=9.9898, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=1.6758, Train Acc=40.03%, Val Loss=1.8752, Val Acc=30.08%, Grad Norm=10.0197, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=1.6764, Train Acc=39.77%, Val Loss=1.8744, Val Acc=30.10%, Grad Norm=10.0941, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=1.6777, Train Acc=39.94%, Val Loss=1.8742, Val Acc=30.13%, Grad Norm=10.1573, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=1.6727, Train Acc=40.01%, Val Loss=1.8738, Val Acc=30.09%, Grad Norm=10.1401, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=1.6738, Train Acc=40.15%, Val Loss=1.8738, Val Acc=30.10%, Grad Norm=10.1580, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=1.6711, Train Acc=40.28%, Val Loss=1.8737, Val Acc=30.19%, Grad Norm=10.1865, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=1.6749, Train Acc=39.95%, Val Loss=1.8725, Val Acc=30.28%, Grad Norm=10.2721, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=1.6691, Train Acc=40.05%, Val Loss=1.8726, Val Acc=30.13%, Grad Norm=10.2238, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=1.6732, Train Acc=40.23%, Val Loss=1.8718, Val Acc=30.11%, Grad Norm=10.2904, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=1.6714, Train Acc=40.19%, Val Loss=1.8741, Val Acc=30.05%, Grad Norm=10.3535, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=1.6665, Train Acc=40.15%, Val Loss=1.8720, Val Acc=30.13%, Grad Norm=10.3227, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=1.6653, Train Acc=40.44%, Val Loss=1.8727, Val Acc=30.15%, Grad Norm=10.4066, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=1.6657, Train Acc=40.63%, Val Loss=1.8730, Val Acc=30.16%, Grad Norm=10.4079, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=1.6655, Train Acc=40.47%, Val Loss=1.8726, Val Acc=30.22%, Grad Norm=10.4066, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=1.6722, Train Acc=40.16%, Val Loss=1.8744, Val Acc=30.08%, Grad Norm=10.4758, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=1.6659, Train Acc=40.55%, Val Loss=1.8725, Val Acc=30.12%, Grad Norm=10.4228, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=1.6654, Train Acc=40.65%, Val Loss=1.8722, Val Acc=30.15%, Grad Norm=10.4643, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=1.6658, Train Acc=40.58%, Val Loss=1.8746, Val Acc=30.21%, Grad Norm=10.4786, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=1.6641, Train Acc=40.46%, Val Loss=1.8733, Val Acc=30.24%, Grad Norm=10.4241, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=1.6682, Train Acc=40.40%, Val Loss=1.8734, Val Acc=30.16%, Grad Norm=10.5213, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=1.6646, Train Acc=40.46%, Val Loss=1.8736, Val Acc=30.15%, Grad Norm=10.5031, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=1.6730, Train Acc=40.13%, Val Loss=1.8730, Val Acc=30.27%, Grad Norm=10.5788, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=1.6660, Train Acc=40.58%, Val Loss=1.8757, Val Acc=30.14%, Grad Norm=10.5813, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=1.6652, Train Acc=40.58%, Val Loss=1.8750, Val Acc=30.12%, Grad Norm=10.5425, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=1.6662, Train Acc=40.51%, Val Loss=1.8738, Val Acc=30.11%, Grad Norm=10.6057, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=1.6659, Train Acc=40.36%, Val Loss=1.8750, Val Acc=30.08%, Grad Norm=10.5700, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=1.6645, Train Acc=40.47%, Val Loss=1.8740, Val Acc=30.15%, Grad Norm=10.5331, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=1.6632, Train Acc=40.58%, Val Loss=1.8745, Val Acc=30.11%, Grad Norm=10.5702, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=1.6604, Train Acc=40.65%, Val Loss=1.8731, Val Acc=30.16%, Grad Norm=10.5753, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=1.6665, Train Acc=40.30%, Val Loss=1.8744, Val Acc=30.12%, Grad Norm=10.5817, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=1.6661, Train Acc=40.49%, Val Loss=1.8742, Val Acc=30.13%, Grad Norm=10.6323, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=1.6636, Train Acc=40.61%, Val Loss=1.8734, Val Acc=30.26%, Grad Norm=10.5543, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=1.6672, Train Acc=40.31%, Val Loss=1.8737, Val Acc=30.13%, Grad Norm=10.5987, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=1.6587, Train Acc=40.91%, Val Loss=1.8734, Val Acc=30.20%, Grad Norm=10.5746, LR=1.95313e-07\n",
      "Fold 2, Epoch 101: Train Loss=1.6639, Train Acc=40.48%, Val Loss=1.8730, Val Acc=30.20%, Grad Norm=10.6207, LR=9.76563e-08\n",
      "Fold 2, Epoch 102: Train Loss=1.6681, Train Acc=40.31%, Val Loss=1.8749, Val Acc=30.09%, Grad Norm=10.6017, LR=9.76563e-08\n",
      "Fold 2, Epoch 103: Train Loss=1.6615, Train Acc=40.55%, Val Loss=1.8748, Val Acc=30.21%, Grad Norm=10.5947, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=30.28%）\n",
      "Fold 2 DONE | Best Val Acc≈30.28% | Final Val Acc=30.28% | Test Acc=30.33%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2251, Train Acc=11.22%, Val Loss=2.3150, Val Acc=11.09%, Grad Norm=6.7379, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2165, Train Acc=11.91%, Val Loss=2.5320, Val Acc=11.10%, Grad Norm=6.4229, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2095, Train Acc=12.44%, Val Loss=2.2999, Val Acc=11.04%, Grad Norm=5.2374, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.1940, Train Acc=13.53%, Val Loss=2.2468, Val Acc=11.56%, Grad Norm=3.7125, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.1740, Train Acc=15.22%, Val Loss=2.2097, Val Acc=14.12%, Grad Norm=3.3026, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.1420, Train Acc=17.60%, Val Loss=2.1265, Val Acc=17.41%, Grad Norm=3.2825, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.1079, Train Acc=19.16%, Val Loss=2.0868, Val Acc=19.33%, Grad Norm=3.0528, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.0735, Train Acc=21.06%, Val Loss=2.0769, Val Acc=19.68%, Grad Norm=2.9029, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.0530, Train Acc=21.94%, Val Loss=2.0620, Val Acc=20.17%, Grad Norm=2.7107, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.0402, Train Acc=22.81%, Val Loss=2.0590, Val Acc=20.98%, Grad Norm=2.6489, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.0106, Train Acc=23.97%, Val Loss=2.0310, Val Acc=22.32%, Grad Norm=2.7130, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=1.9987, Train Acc=24.73%, Val Loss=2.0291, Val Acc=21.80%, Grad Norm=2.8856, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=1.9900, Train Acc=25.35%, Val Loss=2.0110, Val Acc=22.89%, Grad Norm=3.0123, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=1.9793, Train Acc=25.73%, Val Loss=2.0187, Val Acc=23.35%, Grad Norm=3.2185, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=1.9716, Train Acc=26.17%, Val Loss=2.0118, Val Acc=23.72%, Grad Norm=3.2872, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=1.9616, Train Acc=27.16%, Val Loss=1.9995, Val Acc=23.54%, Grad Norm=3.4689, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=1.9487, Train Acc=27.56%, Val Loss=1.9857, Val Acc=24.71%, Grad Norm=3.6027, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=1.9440, Train Acc=27.75%, Val Loss=1.9718, Val Acc=25.37%, Grad Norm=3.7096, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=1.9338, Train Acc=28.17%, Val Loss=1.9723, Val Acc=25.61%, Grad Norm=3.8405, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=1.9222, Train Acc=29.00%, Val Loss=1.9610, Val Acc=26.17%, Grad Norm=3.9801, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=1.9004, Train Acc=30.16%, Val Loss=1.9411, Val Acc=27.18%, Grad Norm=4.2129, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=1.8827, Train Acc=30.73%, Val Loss=1.9304, Val Acc=27.36%, Grad Norm=4.4686, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=1.8763, Train Acc=31.01%, Val Loss=1.9357, Val Acc=27.43%, Grad Norm=4.7065, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=1.8695, Train Acc=31.25%, Val Loss=1.9260, Val Acc=27.80%, Grad Norm=4.8856, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=1.8585, Train Acc=31.96%, Val Loss=1.9184, Val Acc=27.97%, Grad Norm=5.0612, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=1.8524, Train Acc=32.21%, Val Loss=1.9101, Val Acc=28.32%, Grad Norm=5.2540, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=1.8396, Train Acc=32.78%, Val Loss=1.9106, Val Acc=28.33%, Grad Norm=5.4557, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=1.8376, Train Acc=32.81%, Val Loss=1.9001, Val Acc=28.82%, Grad Norm=5.6125, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=1.8325, Train Acc=32.98%, Val Loss=1.9023, Val Acc=28.73%, Grad Norm=5.7800, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=1.8213, Train Acc=33.66%, Val Loss=1.8830, Val Acc=29.62%, Grad Norm=5.8879, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=1.8033, Train Acc=34.45%, Val Loss=1.8821, Val Acc=29.60%, Grad Norm=6.1157, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=1.7995, Train Acc=34.36%, Val Loss=1.8815, Val Acc=29.61%, Grad Norm=6.2997, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=1.7888, Train Acc=34.60%, Val Loss=1.8747, Val Acc=29.88%, Grad Norm=6.4428, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=1.7862, Train Acc=35.27%, Val Loss=1.8725, Val Acc=30.16%, Grad Norm=6.6391, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=1.7850, Train Acc=34.98%, Val Loss=1.8723, Val Acc=30.09%, Grad Norm=6.7874, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=1.7783, Train Acc=35.49%, Val Loss=1.8731, Val Acc=30.08%, Grad Norm=6.9646, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=1.7711, Train Acc=35.67%, Val Loss=1.8753, Val Acc=29.79%, Grad Norm=7.1208, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=1.7690, Train Acc=35.80%, Val Loss=1.8692, Val Acc=30.25%, Grad Norm=7.2753, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=1.7642, Train Acc=36.07%, Val Loss=1.8688, Val Acc=30.13%, Grad Norm=7.4745, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=1.7561, Train Acc=36.48%, Val Loss=1.8674, Val Acc=30.18%, Grad Norm=7.6015, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=1.7526, Train Acc=36.41%, Val Loss=1.8626, Val Acc=30.48%, Grad Norm=7.7630, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=1.7420, Train Acc=36.95%, Val Loss=1.8590, Val Acc=30.45%, Grad Norm=7.9137, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=1.7393, Train Acc=37.32%, Val Loss=1.8563, Val Acc=30.80%, Grad Norm=8.0261, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=1.7364, Train Acc=37.44%, Val Loss=1.8610, Val Acc=30.67%, Grad Norm=8.1768, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=1.7367, Train Acc=37.27%, Val Loss=1.8600, Val Acc=30.79%, Grad Norm=8.3458, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=1.7284, Train Acc=37.65%, Val Loss=1.8599, Val Acc=30.62%, Grad Norm=8.4421, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=1.7330, Train Acc=37.35%, Val Loss=1.8568, Val Acc=30.99%, Grad Norm=8.6210, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=1.7198, Train Acc=38.13%, Val Loss=1.8567, Val Acc=30.80%, Grad Norm=8.7035, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=1.7257, Train Acc=37.68%, Val Loss=1.8549, Val Acc=30.95%, Grad Norm=8.8335, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=1.7148, Train Acc=38.32%, Val Loss=1.8591, Val Acc=30.89%, Grad Norm=8.9673, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=1.7170, Train Acc=38.22%, Val Loss=1.8542, Val Acc=30.85%, Grad Norm=9.1467, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=1.7118, Train Acc=38.66%, Val Loss=1.8548, Val Acc=30.88%, Grad Norm=9.1504, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=1.7123, Train Acc=38.32%, Val Loss=1.8516, Val Acc=31.15%, Grad Norm=9.3402, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=1.7132, Train Acc=38.37%, Val Loss=1.8558, Val Acc=30.89%, Grad Norm=9.3829, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=1.7150, Train Acc=38.35%, Val Loss=1.8519, Val Acc=31.10%, Grad Norm=9.5001, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=1.7064, Train Acc=38.85%, Val Loss=1.8534, Val Acc=31.12%, Grad Norm=9.5278, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=1.7016, Train Acc=38.98%, Val Loss=1.8526, Val Acc=31.11%, Grad Norm=9.6395, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=1.7094, Train Acc=38.43%, Val Loss=1.8521, Val Acc=31.20%, Grad Norm=9.7800, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=1.7015, Train Acc=39.07%, Val Loss=1.8523, Val Acc=31.14%, Grad Norm=9.8503, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=1.6982, Train Acc=38.85%, Val Loss=1.8559, Val Acc=31.11%, Grad Norm=9.9236, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=1.6964, Train Acc=39.27%, Val Loss=1.8520, Val Acc=31.31%, Grad Norm=10.0437, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=1.6977, Train Acc=39.07%, Val Loss=1.8502, Val Acc=31.31%, Grad Norm=10.0572, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=1.6963, Train Acc=39.36%, Val Loss=1.8513, Val Acc=31.29%, Grad Norm=10.1392, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=1.6910, Train Acc=39.22%, Val Loss=1.8502, Val Acc=31.25%, Grad Norm=10.0863, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=1.6949, Train Acc=39.05%, Val Loss=1.8515, Val Acc=31.16%, Grad Norm=10.2094, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=1.6916, Train Acc=39.26%, Val Loss=1.8483, Val Acc=31.38%, Grad Norm=10.2276, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=1.6902, Train Acc=39.53%, Val Loss=1.8522, Val Acc=31.09%, Grad Norm=10.2674, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=1.6949, Train Acc=39.19%, Val Loss=1.8511, Val Acc=31.28%, Grad Norm=10.3824, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=1.6885, Train Acc=39.46%, Val Loss=1.8512, Val Acc=31.30%, Grad Norm=10.3884, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=1.6929, Train Acc=39.20%, Val Loss=1.8501, Val Acc=31.34%, Grad Norm=10.5291, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=1.6836, Train Acc=39.73%, Val Loss=1.8498, Val Acc=31.32%, Grad Norm=10.4823, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=1.6838, Train Acc=39.68%, Val Loss=1.8501, Val Acc=31.24%, Grad Norm=10.5017, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=1.6886, Train Acc=39.59%, Val Loss=1.8507, Val Acc=31.21%, Grad Norm=10.5715, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=1.6861, Train Acc=39.53%, Val Loss=1.8489, Val Acc=31.40%, Grad Norm=10.5797, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=1.6839, Train Acc=39.73%, Val Loss=1.8513, Val Acc=31.33%, Grad Norm=10.5551, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=1.6869, Train Acc=39.61%, Val Loss=1.8508, Val Acc=31.29%, Grad Norm=10.6656, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=1.6862, Train Acc=39.55%, Val Loss=1.8500, Val Acc=31.43%, Grad Norm=10.7132, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=1.6848, Train Acc=39.79%, Val Loss=1.8514, Val Acc=31.26%, Grad Norm=10.7173, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=1.6809, Train Acc=39.84%, Val Loss=1.8513, Val Acc=31.26%, Grad Norm=10.6751, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=1.6824, Train Acc=39.78%, Val Loss=1.8502, Val Acc=31.26%, Grad Norm=10.7774, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=1.6821, Train Acc=39.77%, Val Loss=1.8490, Val Acc=31.37%, Grad Norm=10.7378, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=1.6810, Train Acc=39.69%, Val Loss=1.8512, Val Acc=31.27%, Grad Norm=10.7145, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=1.6864, Train Acc=39.56%, Val Loss=1.8506, Val Acc=31.25%, Grad Norm=10.7717, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=1.6837, Train Acc=39.70%, Val Loss=1.8498, Val Acc=31.48%, Grad Norm=10.7797, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=1.6804, Train Acc=40.01%, Val Loss=1.8501, Val Acc=31.42%, Grad Norm=10.8359, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=1.6820, Train Acc=39.70%, Val Loss=1.8483, Val Acc=31.48%, Grad Norm=10.8688, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=1.6802, Train Acc=40.04%, Val Loss=1.8496, Val Acc=31.44%, Grad Norm=10.8641, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=1.6830, Train Acc=39.81%, Val Loss=1.8507, Val Acc=31.40%, Grad Norm=10.8822, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=1.6785, Train Acc=40.13%, Val Loss=1.8499, Val Acc=31.28%, Grad Norm=10.8708, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=1.6802, Train Acc=39.93%, Val Loss=1.8502, Val Acc=31.28%, Grad Norm=10.8915, LR=3.90625e-07\n",
      "Fold 3, Epoch 91: Train Loss=1.6793, Train Acc=39.90%, Val Loss=1.8494, Val Acc=31.46%, Grad Norm=10.9514, LR=1.95313e-07\n",
      "Fold 3, Epoch 92: Train Loss=1.6838, Train Acc=39.87%, Val Loss=1.8501, Val Acc=31.46%, Grad Norm=10.9215, LR=1.95313e-07\n",
      "Fold 3, Epoch 93: Train Loss=1.6783, Train Acc=40.00%, Val Loss=1.8509, Val Acc=31.32%, Grad Norm=10.9140, LR=1.95313e-07\n",
      "Fold 3, Epoch 94: Train Loss=1.6796, Train Acc=39.82%, Val Loss=1.8505, Val Acc=31.34%, Grad Norm=10.9033, LR=1.95313e-07\n",
      "Fold 3, Epoch 95: Train Loss=1.6781, Train Acc=39.75%, Val Loss=1.8497, Val Acc=31.32%, Grad Norm=10.9427, LR=1.95313e-07\n",
      "Fold 3, Epoch 96: Train Loss=1.6802, Train Acc=39.88%, Val Loss=1.8503, Val Acc=31.33%, Grad Norm=10.9395, LR=1.95313e-07\n",
      "Fold 3, Epoch 97: Train Loss=1.6762, Train Acc=39.95%, Val Loss=1.8493, Val Acc=31.41%, Grad Norm=10.8757, LR=1.95313e-07\n",
      "Fold 3, Epoch 98: Train Loss=1.6804, Train Acc=40.02%, Val Loss=1.8498, Val Acc=31.36%, Grad Norm=10.9656, LR=1.95313e-07\n",
      "Fold 3, Epoch 99: Train Loss=1.6782, Train Acc=39.99%, Val Loss=1.8494, Val Acc=31.39%, Grad Norm=10.9429, LR=1.95313e-07\n",
      "Fold 3, Epoch 100: Train Loss=1.6786, Train Acc=39.97%, Val Loss=1.8491, Val Acc=31.37%, Grad Norm=10.9798, LR=1.95313e-07\n",
      "Fold 3, Epoch 101: Train Loss=1.6801, Train Acc=39.85%, Val Loss=1.8494, Val Acc=31.29%, Grad Norm=10.9852, LR=9.76563e-08\n",
      "Fold 3, Epoch 102: Train Loss=1.6757, Train Acc=39.92%, Val Loss=1.8504, Val Acc=31.30%, Grad Norm=10.9371, LR=9.76563e-08\n",
      "Fold 3, Epoch 103: Train Loss=1.6775, Train Acc=40.02%, Val Loss=1.8493, Val Acc=31.42%, Grad Norm=10.9671, LR=9.76563e-08\n",
      "Fold 3, Epoch 104: Train Loss=1.6745, Train Acc=40.05%, Val Loss=1.8500, Val Acc=31.36%, Grad Norm=10.9398, LR=9.76563e-08\n",
      "Fold 3, Epoch 105: Train Loss=1.6776, Train Acc=39.96%, Val Loss=1.8484, Val Acc=31.52%, Grad Norm=11.0023, LR=9.76563e-08\n",
      "Fold 3, Epoch 106: Train Loss=1.6826, Train Acc=39.74%, Val Loss=1.8501, Val Acc=31.33%, Grad Norm=11.0389, LR=9.76563e-08\n",
      "Fold 3, Epoch 107: Train Loss=1.6764, Train Acc=40.08%, Val Loss=1.8497, Val Acc=31.34%, Grad Norm=10.9679, LR=9.76563e-08\n",
      "Fold 3, Epoch 108: Train Loss=1.6802, Train Acc=39.86%, Val Loss=1.8502, Val Acc=31.44%, Grad Norm=10.9933, LR=9.76563e-08\n",
      "Fold 3, Epoch 109: Train Loss=1.6809, Train Acc=39.77%, Val Loss=1.8483, Val Acc=31.40%, Grad Norm=11.0021, LR=9.76563e-08\n",
      "Fold 3, Epoch 110: Train Loss=1.6731, Train Acc=40.10%, Val Loss=1.8502, Val Acc=31.49%, Grad Norm=10.9258, LR=9.76563e-08\n",
      "Fold 3, Epoch 111: Train Loss=1.6788, Train Acc=39.88%, Val Loss=1.8488, Val Acc=31.42%, Grad Norm=11.0022, LR=4.88281e-08\n",
      "Fold 3, Epoch 112: Train Loss=1.6813, Train Acc=39.70%, Val Loss=1.8489, Val Acc=31.45%, Grad Norm=11.0466, LR=4.88281e-08\n",
      "Fold 3, Epoch 113: Train Loss=1.6793, Train Acc=39.87%, Val Loss=1.8497, Val Acc=31.32%, Grad Norm=10.9899, LR=4.88281e-08\n",
      "Fold 3, Epoch 114: Train Loss=1.6756, Train Acc=39.76%, Val Loss=1.8494, Val Acc=31.34%, Grad Norm=11.0090, LR=4.88281e-08\n",
      "Fold 3, Epoch 115: Train Loss=1.6768, Train Acc=39.95%, Val Loss=1.8485, Val Acc=31.34%, Grad Norm=11.0111, LR=4.88281e-08\n",
      "Fold 3, Epoch 116: Train Loss=1.6766, Train Acc=39.96%, Val Loss=1.8499, Val Acc=31.38%, Grad Norm=11.0197, LR=4.88281e-08\n",
      "Fold 3, Epoch 117: Train Loss=1.6771, Train Acc=39.94%, Val Loss=1.8488, Val Acc=31.48%, Grad Norm=10.9942, LR=4.88281e-08\n",
      "Fold 3, Epoch 118: Train Loss=1.6781, Train Acc=39.87%, Val Loss=1.8501, Val Acc=31.26%, Grad Norm=11.0078, LR=4.88281e-08\n",
      "Fold 3, Epoch 119: Train Loss=1.6781, Train Acc=39.71%, Val Loss=1.8503, Val Acc=31.33%, Grad Norm=10.9879, LR=4.88281e-08\n",
      "Fold 3, Epoch 120: Train Loss=1.6742, Train Acc=40.18%, Val Loss=1.8485, Val Acc=31.43%, Grad Norm=10.9873, LR=4.88281e-08\n",
      "Fold 3, Epoch 121: Train Loss=1.6764, Train Acc=40.15%, Val Loss=1.8501, Val Acc=31.34%, Grad Norm=10.9958, LR=2.44141e-08\n",
      "Fold 3, Epoch 122: Train Loss=1.6777, Train Acc=39.85%, Val Loss=1.8495, Val Acc=31.34%, Grad Norm=11.0109, LR=2.44141e-08\n",
      "Fold 3, Epoch 123: Train Loss=1.6774, Train Acc=40.11%, Val Loss=1.8493, Val Acc=31.33%, Grad Norm=11.0141, LR=2.44141e-08\n",
      "Fold 3, Epoch 124: Train Loss=1.6790, Train Acc=39.70%, Val Loss=1.8489, Val Acc=31.36%, Grad Norm=11.0201, LR=2.44141e-08\n",
      "Fold 3, Epoch 125: Train Loss=1.6755, Train Acc=39.89%, Val Loss=1.8492, Val Acc=31.42%, Grad Norm=11.0223, LR=2.44141e-08\n",
      "Fold 3, Epoch 126: Train Loss=1.6786, Train Acc=39.76%, Val Loss=1.8495, Val Acc=31.38%, Grad Norm=11.0642, LR=2.44141e-08\n",
      "Fold 3, Epoch 127: Train Loss=1.6735, Train Acc=40.12%, Val Loss=1.8487, Val Acc=31.49%, Grad Norm=10.9654, LR=2.44141e-08\n",
      "Fold 3, Epoch 128: Train Loss=1.6769, Train Acc=39.90%, Val Loss=1.8495, Val Acc=31.44%, Grad Norm=11.0003, LR=2.44141e-08\n",
      "Fold 3, Epoch 129: Train Loss=1.6802, Train Acc=39.92%, Val Loss=1.8484, Val Acc=31.44%, Grad Norm=11.0239, LR=2.44141e-08\n",
      "Fold 3, Epoch 130: Train Loss=1.6808, Train Acc=39.86%, Val Loss=1.8486, Val Acc=31.44%, Grad Norm=11.0367, LR=2.44141e-08\n",
      "Fold 3, Epoch 131: Train Loss=1.6808, Train Acc=39.91%, Val Loss=1.8503, Val Acc=31.36%, Grad Norm=11.0376, LR=1.2207e-08\n",
      "Fold 3, Epoch 132: Train Loss=1.6749, Train Acc=40.18%, Val Loss=1.8493, Val Acc=31.42%, Grad Norm=10.9626, LR=1.2207e-08\n",
      "Fold 3, Epoch 133: Train Loss=1.6786, Train Acc=39.94%, Val Loss=1.8495, Val Acc=31.33%, Grad Norm=11.0362, LR=1.2207e-08\n",
      "Fold 3, Epoch 134: Train Loss=1.6761, Train Acc=39.88%, Val Loss=1.8499, Val Acc=31.42%, Grad Norm=10.9818, LR=1.2207e-08\n",
      "Fold 3, Epoch 135: Train Loss=1.6793, Train Acc=39.81%, Val Loss=1.8492, Val Acc=31.40%, Grad Norm=11.0648, LR=1.2207e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=31.52%）\n",
      "Fold 3 DONE | Best Val Acc≈31.52% | Final Val Acc=31.52% | Test Acc=29.96%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2233, Train Acc=11.43%, Val Loss=2.2481, Val Acc=11.19%, Grad Norm=6.8279, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2195, Train Acc=11.09%, Val Loss=2.2892, Val Acc=11.56%, Grad Norm=6.3914, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2125, Train Acc=11.73%, Val Loss=2.3146, Val Acc=11.12%, Grad Norm=5.4252, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2039, Train Acc=12.29%, Val Loss=2.2487, Val Acc=11.07%, Grad Norm=4.2305, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.1888, Train Acc=13.78%, Val Loss=2.2104, Val Acc=12.17%, Grad Norm=3.3198, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.1552, Train Acc=16.49%, Val Loss=2.1461, Val Acc=16.53%, Grad Norm=3.2922, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.1076, Train Acc=19.07%, Val Loss=2.1120, Val Acc=17.44%, Grad Norm=3.0804, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.0726, Train Acc=21.09%, Val Loss=2.1003, Val Acc=19.47%, Grad Norm=2.9157, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.0458, Train Acc=22.84%, Val Loss=2.0555, Val Acc=21.66%, Grad Norm=2.8384, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.0139, Train Acc=24.15%, Val Loss=2.0356, Val Acc=22.12%, Grad Norm=2.9099, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=1.9742, Train Acc=26.06%, Val Loss=2.0079, Val Acc=24.46%, Grad Norm=3.0559, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=1.9556, Train Acc=26.89%, Val Loss=1.9985, Val Acc=24.50%, Grad Norm=3.2876, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=1.9456, Train Acc=27.64%, Val Loss=1.9751, Val Acc=26.11%, Grad Norm=3.4178, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=1.9306, Train Acc=28.14%, Val Loss=1.9621, Val Acc=26.68%, Grad Norm=3.5709, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=1.9149, Train Acc=28.73%, Val Loss=1.9529, Val Acc=27.16%, Grad Norm=3.7537, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=1.9014, Train Acc=29.76%, Val Loss=1.9423, Val Acc=27.87%, Grad Norm=3.8390, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=1.8952, Train Acc=29.79%, Val Loss=1.9341, Val Acc=28.15%, Grad Norm=3.9904, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=1.8859, Train Acc=30.39%, Val Loss=1.9340, Val Acc=27.96%, Grad Norm=4.0332, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=1.8796, Train Acc=30.48%, Val Loss=1.9221, Val Acc=28.27%, Grad Norm=4.1471, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=1.8660, Train Acc=31.20%, Val Loss=1.9148, Val Acc=28.65%, Grad Norm=4.2864, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=1.8452, Train Acc=31.96%, Val Loss=1.8927, Val Acc=29.89%, Grad Norm=4.4674, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=1.8334, Train Acc=32.74%, Val Loss=1.8894, Val Acc=29.70%, Grad Norm=4.7152, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=1.8291, Train Acc=32.71%, Val Loss=1.8840, Val Acc=30.01%, Grad Norm=4.9379, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=1.8174, Train Acc=33.66%, Val Loss=1.8768, Val Acc=30.31%, Grad Norm=5.1758, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=1.8159, Train Acc=33.36%, Val Loss=1.8786, Val Acc=30.26%, Grad Norm=5.3706, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=1.8055, Train Acc=33.93%, Val Loss=1.8824, Val Acc=29.71%, Grad Norm=5.5165, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=1.7999, Train Acc=34.11%, Val Loss=1.8717, Val Acc=30.19%, Grad Norm=5.7239, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=1.7956, Train Acc=34.26%, Val Loss=1.8565, Val Acc=30.75%, Grad Norm=5.8789, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=1.7894, Train Acc=34.69%, Val Loss=1.8700, Val Acc=30.41%, Grad Norm=6.0419, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=1.7852, Train Acc=34.97%, Val Loss=1.8650, Val Acc=30.75%, Grad Norm=6.2399, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=1.7658, Train Acc=35.68%, Val Loss=1.8559, Val Acc=31.53%, Grad Norm=6.4215, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=1.7619, Train Acc=36.05%, Val Loss=1.8550, Val Acc=31.61%, Grad Norm=6.6497, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=1.7588, Train Acc=36.09%, Val Loss=1.8483, Val Acc=31.70%, Grad Norm=6.8438, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=1.7538, Train Acc=36.53%, Val Loss=1.8448, Val Acc=31.66%, Grad Norm=7.0211, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=1.7479, Train Acc=36.72%, Val Loss=1.8429, Val Acc=31.73%, Grad Norm=7.2382, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=1.7478, Train Acc=36.65%, Val Loss=1.8392, Val Acc=31.94%, Grad Norm=7.4054, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=1.7381, Train Acc=37.09%, Val Loss=1.8400, Val Acc=31.87%, Grad Norm=7.6205, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=1.7366, Train Acc=37.09%, Val Loss=1.8393, Val Acc=31.72%, Grad Norm=7.7160, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=1.7331, Train Acc=37.24%, Val Loss=1.8392, Val Acc=31.94%, Grad Norm=7.9340, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=1.7252, Train Acc=37.55%, Val Loss=1.8432, Val Acc=31.84%, Grad Norm=8.0848, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=1.7162, Train Acc=38.12%, Val Loss=1.8344, Val Acc=32.12%, Grad Norm=8.3582, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=1.7154, Train Acc=37.77%, Val Loss=1.8352, Val Acc=32.49%, Grad Norm=8.4420, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=1.7118, Train Acc=38.36%, Val Loss=1.8321, Val Acc=32.41%, Grad Norm=8.6045, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=1.7181, Train Acc=37.80%, Val Loss=1.8325, Val Acc=32.28%, Grad Norm=8.7852, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=1.7058, Train Acc=38.48%, Val Loss=1.8308, Val Acc=32.44%, Grad Norm=8.8877, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=1.7029, Train Acc=38.83%, Val Loss=1.8347, Val Acc=32.22%, Grad Norm=9.0620, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=1.7009, Train Acc=38.88%, Val Loss=1.8357, Val Acc=32.35%, Grad Norm=9.2500, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=1.6954, Train Acc=39.06%, Val Loss=1.8327, Val Acc=32.46%, Grad Norm=9.3948, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=1.6949, Train Acc=38.89%, Val Loss=1.8365, Val Acc=32.11%, Grad Norm=9.5541, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=1.6948, Train Acc=39.01%, Val Loss=1.8318, Val Acc=32.63%, Grad Norm=9.6507, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=1.6845, Train Acc=39.47%, Val Loss=1.8308, Val Acc=32.45%, Grad Norm=9.7945, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=1.6842, Train Acc=39.39%, Val Loss=1.8274, Val Acc=32.77%, Grad Norm=9.8888, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=1.6830, Train Acc=39.46%, Val Loss=1.8308, Val Acc=32.37%, Grad Norm=10.0388, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=1.6766, Train Acc=39.88%, Val Loss=1.8354, Val Acc=32.26%, Grad Norm=10.1086, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=1.6815, Train Acc=39.42%, Val Loss=1.8307, Val Acc=32.58%, Grad Norm=10.2649, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=1.6752, Train Acc=40.01%, Val Loss=1.8291, Val Acc=32.50%, Grad Norm=10.3499, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=1.6737, Train Acc=39.97%, Val Loss=1.8315, Val Acc=32.48%, Grad Norm=10.5010, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=1.6757, Train Acc=39.92%, Val Loss=1.8294, Val Acc=32.58%, Grad Norm=10.5532, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=1.6717, Train Acc=40.05%, Val Loss=1.8288, Val Acc=32.58%, Grad Norm=10.6990, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=1.6734, Train Acc=40.24%, Val Loss=1.8279, Val Acc=32.75%, Grad Norm=10.7951, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=1.6693, Train Acc=40.21%, Val Loss=1.8300, Val Acc=32.54%, Grad Norm=10.8123, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=1.6644, Train Acc=40.42%, Val Loss=1.8313, Val Acc=32.73%, Grad Norm=10.8803, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=1.6668, Train Acc=40.62%, Val Loss=1.8291, Val Acc=32.81%, Grad Norm=11.0159, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=1.6666, Train Acc=40.51%, Val Loss=1.8281, Val Acc=32.67%, Grad Norm=11.0931, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=1.6625, Train Acc=40.31%, Val Loss=1.8292, Val Acc=32.92%, Grad Norm=11.1270, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=1.6649, Train Acc=40.34%, Val Loss=1.8309, Val Acc=32.75%, Grad Norm=11.1892, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=1.6616, Train Acc=40.41%, Val Loss=1.8303, Val Acc=32.52%, Grad Norm=11.1732, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=1.6637, Train Acc=40.62%, Val Loss=1.8286, Val Acc=32.89%, Grad Norm=11.2893, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=1.6597, Train Acc=40.65%, Val Loss=1.8299, Val Acc=32.81%, Grad Norm=11.3522, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=1.6630, Train Acc=40.47%, Val Loss=1.8315, Val Acc=32.54%, Grad Norm=11.4133, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=1.6576, Train Acc=40.96%, Val Loss=1.8319, Val Acc=32.79%, Grad Norm=11.3955, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=1.6580, Train Acc=40.79%, Val Loss=1.8318, Val Acc=32.67%, Grad Norm=11.4997, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=1.6567, Train Acc=40.81%, Val Loss=1.8304, Val Acc=32.79%, Grad Norm=11.5257, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=1.6540, Train Acc=40.81%, Val Loss=1.8328, Val Acc=32.59%, Grad Norm=11.5789, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=1.6580, Train Acc=40.73%, Val Loss=1.8302, Val Acc=32.94%, Grad Norm=11.5589, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=1.6549, Train Acc=40.82%, Val Loss=1.8285, Val Acc=32.74%, Grad Norm=11.5987, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=1.6516, Train Acc=41.08%, Val Loss=1.8301, Val Acc=32.78%, Grad Norm=11.6300, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=1.6540, Train Acc=41.04%, Val Loss=1.8309, Val Acc=32.83%, Grad Norm=11.7049, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=1.6519, Train Acc=40.80%, Val Loss=1.8292, Val Acc=32.71%, Grad Norm=11.7215, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=1.6518, Train Acc=40.99%, Val Loss=1.8297, Val Acc=32.76%, Grad Norm=11.7139, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=1.6491, Train Acc=41.08%, Val Loss=1.8296, Val Acc=32.55%, Grad Norm=11.7559, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=1.6514, Train Acc=40.75%, Val Loss=1.8295, Val Acc=32.67%, Grad Norm=11.8031, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=1.6566, Train Acc=40.55%, Val Loss=1.8292, Val Acc=32.71%, Grad Norm=11.8695, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=1.6505, Train Acc=41.04%, Val Loss=1.8288, Val Acc=32.78%, Grad Norm=11.8356, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=1.6532, Train Acc=40.98%, Val Loss=1.8297, Val Acc=32.76%, Grad Norm=11.8097, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=1.6495, Train Acc=41.21%, Val Loss=1.8291, Val Acc=32.76%, Grad Norm=11.8607, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=1.6537, Train Acc=40.96%, Val Loss=1.8287, Val Acc=32.71%, Grad Norm=11.8864, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=1.6463, Train Acc=41.29%, Val Loss=1.8296, Val Acc=32.73%, Grad Norm=11.8987, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=1.6475, Train Acc=41.09%, Val Loss=1.8286, Val Acc=32.80%, Grad Norm=11.8716, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=1.6529, Train Acc=40.96%, Val Loss=1.8307, Val Acc=32.69%, Grad Norm=11.9673, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=1.6515, Train Acc=40.66%, Val Loss=1.8293, Val Acc=32.66%, Grad Norm=11.9389, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=1.6498, Train Acc=41.09%, Val Loss=1.8278, Val Acc=32.85%, Grad Norm=11.9485, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=1.6484, Train Acc=41.22%, Val Loss=1.8291, Val Acc=32.87%, Grad Norm=11.9055, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=1.6486, Train Acc=41.17%, Val Loss=1.8281, Val Acc=32.80%, Grad Norm=11.9238, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=1.6490, Train Acc=41.06%, Val Loss=1.8274, Val Acc=32.87%, Grad Norm=11.9591, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=1.6476, Train Acc=41.27%, Val Loss=1.8297, Val Acc=32.81%, Grad Norm=11.9811, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=1.6497, Train Acc=41.04%, Val Loss=1.8288, Val Acc=32.75%, Grad Norm=11.9835, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=1.6462, Train Acc=41.38%, Val Loss=1.8287, Val Acc=32.66%, Grad Norm=11.9750, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=1.6475, Train Acc=41.32%, Val Loss=1.8291, Val Acc=32.82%, Grad Norm=11.9769, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=1.6448, Train Acc=41.27%, Val Loss=1.8283, Val Acc=32.85%, Grad Norm=12.0086, LR=1.95313e-07\n",
      "Fold 4, Epoch 101: Train Loss=1.6461, Train Acc=41.16%, Val Loss=1.8276, Val Acc=32.74%, Grad Norm=11.9703, LR=9.76563e-08\n",
      "Fold 4, Epoch 102: Train Loss=1.6475, Train Acc=41.07%, Val Loss=1.8282, Val Acc=32.74%, Grad Norm=12.0067, LR=9.76563e-08\n",
      "Fold 4, Epoch 103: Train Loss=1.6480, Train Acc=41.17%, Val Loss=1.8289, Val Acc=32.94%, Grad Norm=12.0384, LR=9.76563e-08\n",
      "Fold 4, Epoch 104: Train Loss=1.6475, Train Acc=41.02%, Val Loss=1.8273, Val Acc=32.75%, Grad Norm=12.0153, LR=9.76563e-08\n",
      "Fold 4, Epoch 105: Train Loss=1.6521, Train Acc=41.01%, Val Loss=1.8301, Val Acc=32.70%, Grad Norm=12.0773, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=32.94%）\n",
      "Fold 4 DONE | Best Val Acc≈32.94% | Final Val Acc=32.94% | Test Acc=31.04%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2229, Train Acc=10.97%, Val Loss=2.2912, Val Acc=11.09%, Grad Norm=6.7096, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2184, Train Acc=11.31%, Val Loss=2.3194, Val Acc=11.19%, Grad Norm=6.2398, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2092, Train Acc=11.92%, Val Loss=2.3324, Val Acc=11.27%, Grad Norm=4.8187, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.1976, Train Acc=13.05%, Val Loss=2.2040, Val Acc=12.11%, Grad Norm=3.3928, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.1867, Train Acc=14.07%, Val Loss=2.1930, Val Acc=13.28%, Grad Norm=2.8989, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.1561, Train Acc=16.86%, Val Loss=2.1448, Val Acc=16.35%, Grad Norm=3.0156, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.1145, Train Acc=18.73%, Val Loss=2.1001, Val Acc=18.44%, Grad Norm=2.9336, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.0799, Train Acc=20.61%, Val Loss=2.0494, Val Acc=21.41%, Grad Norm=2.8313, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.0470, Train Acc=22.50%, Val Loss=2.0339, Val Acc=21.62%, Grad Norm=2.8384, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.0199, Train Acc=24.04%, Val Loss=2.0359, Val Acc=22.14%, Grad Norm=2.9220, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=1.9776, Train Acc=26.08%, Val Loss=2.0017, Val Acc=23.38%, Grad Norm=3.0938, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=1.9550, Train Acc=27.13%, Val Loss=1.9852, Val Acc=23.90%, Grad Norm=3.3940, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=1.9380, Train Acc=27.92%, Val Loss=1.9605, Val Acc=25.35%, Grad Norm=3.5601, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=1.9241, Train Acc=28.70%, Val Loss=1.9668, Val Acc=25.23%, Grad Norm=3.7550, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=1.9095, Train Acc=29.33%, Val Loss=1.9415, Val Acc=26.54%, Grad Norm=3.9300, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=1.8993, Train Acc=29.91%, Val Loss=1.9462, Val Acc=26.37%, Grad Norm=4.0127, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=1.8860, Train Acc=30.57%, Val Loss=1.9369, Val Acc=26.19%, Grad Norm=4.1228, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=1.8765, Train Acc=31.26%, Val Loss=1.9284, Val Acc=26.12%, Grad Norm=4.2802, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=1.8667, Train Acc=31.41%, Val Loss=1.9256, Val Acc=27.60%, Grad Norm=4.3946, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=1.8536, Train Acc=32.06%, Val Loss=1.9277, Val Acc=26.93%, Grad Norm=4.4651, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=1.8326, Train Acc=33.03%, Val Loss=1.9074, Val Acc=27.77%, Grad Norm=4.6963, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=1.8239, Train Acc=33.44%, Val Loss=1.8974, Val Acc=28.31%, Grad Norm=4.9347, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=1.8099, Train Acc=33.82%, Val Loss=1.8962, Val Acc=28.22%, Grad Norm=5.1642, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=1.8061, Train Acc=34.28%, Val Loss=1.8948, Val Acc=28.46%, Grad Norm=5.3496, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=1.7978, Train Acc=34.45%, Val Loss=1.8961, Val Acc=28.30%, Grad Norm=5.5328, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=1.7895, Train Acc=35.09%, Val Loss=1.8979, Val Acc=28.64%, Grad Norm=5.7211, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=1.7867, Train Acc=35.21%, Val Loss=1.8831, Val Acc=29.23%, Grad Norm=5.9302, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=1.7790, Train Acc=35.40%, Val Loss=1.8944, Val Acc=28.49%, Grad Norm=6.1058, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=1.7727, Train Acc=35.73%, Val Loss=1.8799, Val Acc=28.86%, Grad Norm=6.2420, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=1.7630, Train Acc=35.87%, Val Loss=1.8903, Val Acc=28.75%, Grad Norm=6.4579, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=1.7551, Train Acc=36.55%, Val Loss=1.8767, Val Acc=29.22%, Grad Norm=6.6285, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=1.7442, Train Acc=36.92%, Val Loss=1.8776, Val Acc=29.30%, Grad Norm=6.8547, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=1.7390, Train Acc=37.13%, Val Loss=1.8756, Val Acc=29.47%, Grad Norm=7.0557, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=1.7349, Train Acc=37.39%, Val Loss=1.8690, Val Acc=29.85%, Grad Norm=7.2420, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=1.7334, Train Acc=37.41%, Val Loss=1.8796, Val Acc=29.24%, Grad Norm=7.3775, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=1.7226, Train Acc=37.94%, Val Loss=1.8728, Val Acc=29.45%, Grad Norm=7.5801, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=1.7220, Train Acc=37.77%, Val Loss=1.8764, Val Acc=29.32%, Grad Norm=7.7893, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=1.7151, Train Acc=38.26%, Val Loss=1.8702, Val Acc=29.54%, Grad Norm=7.9624, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=1.7182, Train Acc=38.06%, Val Loss=1.8690, Val Acc=29.92%, Grad Norm=8.1535, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=1.7097, Train Acc=38.46%, Val Loss=1.8745, Val Acc=29.57%, Grad Norm=8.3157, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=1.7008, Train Acc=38.81%, Val Loss=1.8693, Val Acc=29.71%, Grad Norm=8.5137, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=1.6997, Train Acc=39.03%, Val Loss=1.8625, Val Acc=30.03%, Grad Norm=8.6904, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=1.6956, Train Acc=38.84%, Val Loss=1.8665, Val Acc=30.13%, Grad Norm=8.8704, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=1.6948, Train Acc=38.95%, Val Loss=1.8677, Val Acc=29.65%, Grad Norm=8.9515, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=1.6844, Train Acc=39.43%, Val Loss=1.8715, Val Acc=29.54%, Grad Norm=9.1010, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=1.6832, Train Acc=39.94%, Val Loss=1.8705, Val Acc=29.65%, Grad Norm=9.3214, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=1.6767, Train Acc=40.06%, Val Loss=1.8665, Val Acc=29.91%, Grad Norm=9.4422, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=1.6808, Train Acc=39.61%, Val Loss=1.8771, Val Acc=29.65%, Grad Norm=9.5842, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=1.6791, Train Acc=39.80%, Val Loss=1.8630, Val Acc=29.91%, Grad Norm=9.8044, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=1.6803, Train Acc=39.97%, Val Loss=1.8714, Val Acc=29.90%, Grad Norm=9.9316, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=1.6715, Train Acc=40.18%, Val Loss=1.8652, Val Acc=30.12%, Grad Norm=10.0454, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=1.6657, Train Acc=40.43%, Val Loss=1.8688, Val Acc=29.64%, Grad Norm=10.1590, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=1.6703, Train Acc=40.27%, Val Loss=1.8645, Val Acc=29.93%, Grad Norm=10.2969, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=1.6640, Train Acc=40.39%, Val Loss=1.8648, Val Acc=29.99%, Grad Norm=10.2982, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=1.6661, Train Acc=40.36%, Val Loss=1.8658, Val Acc=30.02%, Grad Norm=10.4284, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=1.6612, Train Acc=40.62%, Val Loss=1.8670, Val Acc=29.86%, Grad Norm=10.5297, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=1.6558, Train Acc=41.00%, Val Loss=1.8680, Val Acc=29.97%, Grad Norm=10.6497, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=1.6584, Train Acc=40.80%, Val Loss=1.8699, Val Acc=30.01%, Grad Norm=10.6977, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=1.6583, Train Acc=40.81%, Val Loss=1.8670, Val Acc=29.89%, Grad Norm=10.8080, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=1.6539, Train Acc=40.89%, Val Loss=1.8697, Val Acc=29.92%, Grad Norm=10.9766, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=1.6493, Train Acc=40.97%, Val Loss=1.8722, Val Acc=29.65%, Grad Norm=11.0345, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=1.6457, Train Acc=41.55%, Val Loss=1.8687, Val Acc=29.84%, Grad Norm=11.0853, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=1.6518, Train Acc=41.07%, Val Loss=1.8674, Val Acc=29.93%, Grad Norm=11.1957, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=1.6487, Train Acc=41.09%, Val Loss=1.8709, Val Acc=29.94%, Grad Norm=11.2673, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=1.6461, Train Acc=41.34%, Val Loss=1.8690, Val Acc=30.05%, Grad Norm=11.3357, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=1.6465, Train Acc=41.16%, Val Loss=1.8674, Val Acc=29.98%, Grad Norm=11.3826, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=1.6448, Train Acc=41.41%, Val Loss=1.8673, Val Acc=29.98%, Grad Norm=11.4219, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=1.6415, Train Acc=41.55%, Val Loss=1.8701, Val Acc=29.87%, Grad Norm=11.4949, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=1.6404, Train Acc=41.41%, Val Loss=1.8692, Val Acc=29.97%, Grad Norm=11.5602, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=1.6426, Train Acc=41.30%, Val Loss=1.8708, Val Acc=29.84%, Grad Norm=11.6549, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=1.6455, Train Acc=41.12%, Val Loss=1.8683, Val Acc=29.98%, Grad Norm=11.7502, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=1.6367, Train Acc=41.64%, Val Loss=1.8696, Val Acc=29.81%, Grad Norm=11.7809, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=1.6412, Train Acc=41.44%, Val Loss=1.8696, Val Acc=29.76%, Grad Norm=11.7961, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=30.13%）\n",
      "Fold 5 DONE | Best Val Acc≈30.13% | Final Val Acc=30.13% | Test Acc=30.91%\n",
      "[INFO] SNR=-10 dB | Mean Test Acc: 30.60% ± 0.40%\n",
      "[INFO] SNR -10 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-10dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -15 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2246, Train Acc=11.40%, Val Loss=2.2642, Val Acc=11.06%, Grad Norm=6.7064, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2213, Train Acc=11.12%, Val Loss=2.2546, Val Acc=11.11%, Grad Norm=6.4044, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2177, Train Acc=11.33%, Val Loss=2.3007, Val Acc=11.43%, Grad Norm=5.7000, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2118, Train Acc=11.41%, Val Loss=2.2190, Val Acc=11.17%, Grad Norm=4.6174, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2076, Train Acc=11.20%, Val Loss=2.2343, Val Acc=11.28%, Grad Norm=3.6957, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2060, Train Acc=11.15%, Val Loss=2.2206, Val Acc=11.15%, Grad Norm=3.1645, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2042, Train Acc=11.21%, Val Loss=2.2269, Val Acc=11.04%, Grad Norm=2.8442, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2026, Train Acc=11.46%, Val Loss=2.2165, Val Acc=11.39%, Grad Norm=2.6118, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2017, Train Acc=11.85%, Val Loss=2.2212, Val Acc=11.21%, Grad Norm=2.4285, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2005, Train Acc=11.90%, Val Loss=2.2046, Val Acc=11.21%, Grad Norm=2.1412, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.1965, Train Acc=12.21%, Val Loss=2.2053, Val Acc=12.32%, Grad Norm=2.0044, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.1953, Train Acc=12.69%, Val Loss=2.2025, Val Acc=11.89%, Grad Norm=1.9824, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.1936, Train Acc=13.04%, Val Loss=2.1982, Val Acc=12.38%, Grad Norm=1.9744, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1919, Train Acc=13.29%, Val Loss=2.2003, Val Acc=12.42%, Grad Norm=2.0045, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1898, Train Acc=13.51%, Val Loss=2.1931, Val Acc=13.20%, Grad Norm=1.9727, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1876, Train Acc=14.02%, Val Loss=2.1934, Val Acc=13.69%, Grad Norm=1.9430, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1832, Train Acc=14.39%, Val Loss=2.1868, Val Acc=13.95%, Grad Norm=2.0216, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1789, Train Acc=14.93%, Val Loss=2.1858, Val Acc=14.35%, Grad Norm=2.1056, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1758, Train Acc=15.16%, Val Loss=2.1809, Val Acc=14.57%, Grad Norm=2.1444, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1725, Train Acc=15.55%, Val Loss=2.1768, Val Acc=15.18%, Grad Norm=2.1424, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1637, Train Acc=16.33%, Val Loss=2.1721, Val Acc=15.41%, Grad Norm=2.3497, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1613, Train Acc=16.79%, Val Loss=2.1713, Val Acc=15.53%, Grad Norm=2.5865, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1539, Train Acc=17.39%, Val Loss=2.1695, Val Acc=15.74%, Grad Norm=2.7450, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1527, Train Acc=17.28%, Val Loss=2.1686, Val Acc=15.71%, Grad Norm=2.7636, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1485, Train Acc=18.07%, Val Loss=2.1660, Val Acc=16.23%, Grad Norm=2.9860, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1461, Train Acc=17.98%, Val Loss=2.1628, Val Acc=16.36%, Grad Norm=3.0620, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1430, Train Acc=18.08%, Val Loss=2.1594, Val Acc=16.53%, Grad Norm=3.1318, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1388, Train Acc=18.52%, Val Loss=2.1585, Val Acc=16.50%, Grad Norm=3.2448, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1389, Train Acc=18.56%, Val Loss=2.1564, Val Acc=16.79%, Grad Norm=3.3128, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1347, Train Acc=18.94%, Val Loss=2.1559, Val Acc=16.78%, Grad Norm=3.3726, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1271, Train Acc=19.23%, Val Loss=2.1527, Val Acc=17.09%, Grad Norm=3.4533, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1237, Train Acc=19.58%, Val Loss=2.1517, Val Acc=17.03%, Grad Norm=3.6179, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1225, Train Acc=19.68%, Val Loss=2.1506, Val Acc=17.28%, Grad Norm=3.7027, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1205, Train Acc=19.85%, Val Loss=2.1507, Val Acc=17.23%, Grad Norm=3.8610, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1167, Train Acc=20.24%, Val Loss=2.1484, Val Acc=17.40%, Grad Norm=3.9565, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1133, Train Acc=20.67%, Val Loss=2.1473, Val Acc=17.62%, Grad Norm=4.0978, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1111, Train Acc=20.30%, Val Loss=2.1474, Val Acc=17.50%, Grad Norm=4.2317, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1103, Train Acc=20.56%, Val Loss=2.1484, Val Acc=17.40%, Grad Norm=4.3548, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1081, Train Acc=20.68%, Val Loss=2.1474, Val Acc=17.37%, Grad Norm=4.4969, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1074, Train Acc=20.87%, Val Loss=2.1473, Val Acc=17.60%, Grad Norm=4.6419, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1024, Train Acc=20.88%, Val Loss=2.1446, Val Acc=17.75%, Grad Norm=4.7653, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.0979, Train Acc=21.41%, Val Loss=2.1440, Val Acc=17.70%, Grad Norm=4.9049, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=2.0947, Train Acc=21.72%, Val Loss=2.1424, Val Acc=18.14%, Grad Norm=5.0115, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=2.0959, Train Acc=21.53%, Val Loss=2.1430, Val Acc=17.94%, Grad Norm=5.1520, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=2.0926, Train Acc=21.89%, Val Loss=2.1439, Val Acc=17.87%, Grad Norm=5.2422, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=2.0915, Train Acc=21.98%, Val Loss=2.1422, Val Acc=17.89%, Grad Norm=5.3611, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=2.0904, Train Acc=21.90%, Val Loss=2.1424, Val Acc=17.81%, Grad Norm=5.4800, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=2.0896, Train Acc=21.99%, Val Loss=2.1413, Val Acc=18.04%, Grad Norm=5.6450, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=2.0840, Train Acc=22.24%, Val Loss=2.1411, Val Acc=18.19%, Grad Norm=5.7907, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=2.0841, Train Acc=22.23%, Val Loss=2.1409, Val Acc=18.34%, Grad Norm=5.9238, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=2.0811, Train Acc=22.54%, Val Loss=2.1407, Val Acc=18.23%, Grad Norm=6.0496, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=2.0790, Train Acc=22.74%, Val Loss=2.1402, Val Acc=18.28%, Grad Norm=6.1076, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=2.0788, Train Acc=22.29%, Val Loss=2.1402, Val Acc=18.28%, Grad Norm=6.2215, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=2.0751, Train Acc=23.03%, Val Loss=2.1402, Val Acc=18.24%, Grad Norm=6.2669, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=2.0756, Train Acc=22.73%, Val Loss=2.1391, Val Acc=18.31%, Grad Norm=6.3534, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=2.0759, Train Acc=22.50%, Val Loss=2.1387, Val Acc=18.23%, Grad Norm=6.4299, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=2.0766, Train Acc=22.69%, Val Loss=2.1400, Val Acc=18.13%, Grad Norm=6.5430, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=2.0739, Train Acc=22.85%, Val Loss=2.1401, Val Acc=18.32%, Grad Norm=6.6415, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=2.0701, Train Acc=23.11%, Val Loss=2.1391, Val Acc=18.29%, Grad Norm=6.7515, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=2.0702, Train Acc=23.01%, Val Loss=2.1392, Val Acc=18.25%, Grad Norm=6.8424, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=2.0686, Train Acc=23.25%, Val Loss=2.1386, Val Acc=18.31%, Grad Norm=6.9257, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=2.0658, Train Acc=23.36%, Val Loss=2.1390, Val Acc=18.28%, Grad Norm=7.0030, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=2.0683, Train Acc=23.41%, Val Loss=2.1389, Val Acc=18.19%, Grad Norm=7.0745, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=2.0675, Train Acc=23.25%, Val Loss=2.1394, Val Acc=18.15%, Grad Norm=7.1148, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=2.0669, Train Acc=23.49%, Val Loss=2.1381, Val Acc=18.23%, Grad Norm=7.1657, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=2.0650, Train Acc=23.20%, Val Loss=2.1393, Val Acc=18.27%, Grad Norm=7.2294, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=2.0622, Train Acc=23.74%, Val Loss=2.1384, Val Acc=18.22%, Grad Norm=7.2944, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=2.0629, Train Acc=23.77%, Val Loss=2.1388, Val Acc=18.32%, Grad Norm=7.3690, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=2.0610, Train Acc=23.62%, Val Loss=2.1386, Val Acc=18.38%, Grad Norm=7.4003, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=2.0621, Train Acc=23.37%, Val Loss=2.1379, Val Acc=18.36%, Grad Norm=7.4661, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=2.0618, Train Acc=23.67%, Val Loss=2.1383, Val Acc=18.35%, Grad Norm=7.5237, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=2.0632, Train Acc=23.56%, Val Loss=2.1382, Val Acc=18.38%, Grad Norm=7.5463, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=2.0602, Train Acc=23.72%, Val Loss=2.1384, Val Acc=18.29%, Grad Norm=7.5727, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=2.0610, Train Acc=23.72%, Val Loss=2.1384, Val Acc=18.35%, Grad Norm=7.6062, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=2.0639, Train Acc=23.41%, Val Loss=2.1379, Val Acc=18.40%, Grad Norm=7.6407, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=2.0588, Train Acc=23.96%, Val Loss=2.1385, Val Acc=18.31%, Grad Norm=7.6793, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=2.0588, Train Acc=23.74%, Val Loss=2.1380, Val Acc=18.36%, Grad Norm=7.7016, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=2.0569, Train Acc=23.81%, Val Loss=2.1372, Val Acc=18.39%, Grad Norm=7.7284, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=2.0569, Train Acc=23.91%, Val Loss=2.1378, Val Acc=18.29%, Grad Norm=7.7664, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=2.0571, Train Acc=24.19%, Val Loss=2.1378, Val Acc=18.32%, Grad Norm=7.8081, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=2.0584, Train Acc=23.80%, Val Loss=2.1376, Val Acc=18.37%, Grad Norm=7.8329, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=2.0560, Train Acc=24.17%, Val Loss=2.1374, Val Acc=18.36%, Grad Norm=7.8559, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=2.0547, Train Acc=24.04%, Val Loss=2.1377, Val Acc=18.33%, Grad Norm=7.8570, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=2.0526, Train Acc=24.22%, Val Loss=2.1373, Val Acc=18.36%, Grad Norm=7.8837, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=2.0581, Train Acc=23.78%, Val Loss=2.1369, Val Acc=18.43%, Grad Norm=7.9122, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=2.0585, Train Acc=23.73%, Val Loss=2.1373, Val Acc=18.43%, Grad Norm=7.9254, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=2.0578, Train Acc=23.84%, Val Loss=2.1373, Val Acc=18.42%, Grad Norm=7.9426, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=2.0577, Train Acc=23.94%, Val Loss=2.1374, Val Acc=18.37%, Grad Norm=7.9702, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=2.0548, Train Acc=24.01%, Val Loss=2.1376, Val Acc=18.34%, Grad Norm=7.9902, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=2.0557, Train Acc=23.96%, Val Loss=2.1374, Val Acc=18.35%, Grad Norm=7.9921, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=2.0528, Train Acc=23.90%, Val Loss=2.1376, Val Acc=18.39%, Grad Norm=8.0087, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=2.0571, Train Acc=24.08%, Val Loss=2.1377, Val Acc=18.31%, Grad Norm=8.0290, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=2.0558, Train Acc=23.83%, Val Loss=2.1374, Val Acc=18.41%, Grad Norm=8.0303, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=2.0568, Train Acc=23.91%, Val Loss=2.1377, Val Acc=18.38%, Grad Norm=8.0429, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=2.0541, Train Acc=24.32%, Val Loss=2.1375, Val Acc=18.38%, Grad Norm=8.0418, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=2.0553, Train Acc=23.91%, Val Loss=2.1376, Val Acc=18.34%, Grad Norm=8.0515, LR=1.95313e-07\n",
      "Fold 1, Epoch 97: Train Loss=2.0542, Train Acc=24.02%, Val Loss=2.1374, Val Acc=18.38%, Grad Norm=8.0609, LR=1.95313e-07\n",
      "Fold 1, Epoch 98: Train Loss=2.0544, Train Acc=24.30%, Val Loss=2.1378, Val Acc=18.42%, Grad Norm=8.0614, LR=1.95313e-07\n",
      "Fold 1, Epoch 99: Train Loss=2.0537, Train Acc=24.07%, Val Loss=2.1375, Val Acc=18.37%, Grad Norm=8.0899, LR=1.95313e-07\n",
      "Fold 1, Epoch 100: Train Loss=2.0544, Train Acc=24.12%, Val Loss=2.1379, Val Acc=18.44%, Grad Norm=8.1044, LR=1.95313e-07\n",
      "Fold 1, Epoch 101: Train Loss=2.0528, Train Acc=24.17%, Val Loss=2.1375, Val Acc=18.32%, Grad Norm=8.0984, LR=9.76563e-08\n",
      "Fold 1, Epoch 102: Train Loss=2.0546, Train Acc=23.91%, Val Loss=2.1375, Val Acc=18.37%, Grad Norm=8.1085, LR=9.76563e-08\n",
      "Fold 1, Epoch 103: Train Loss=2.0526, Train Acc=24.00%, Val Loss=2.1374, Val Acc=18.42%, Grad Norm=8.1056, LR=9.76563e-08\n",
      "Fold 1, Epoch 104: Train Loss=2.0520, Train Acc=24.36%, Val Loss=2.1378, Val Acc=18.40%, Grad Norm=8.1035, LR=9.76563e-08\n",
      "Fold 1, Epoch 105: Train Loss=2.0555, Train Acc=23.94%, Val Loss=2.1378, Val Acc=18.38%, Grad Norm=8.1491, LR=9.76563e-08\n",
      "Fold 1, Epoch 106: Train Loss=2.0552, Train Acc=23.69%, Val Loss=2.1375, Val Acc=18.40%, Grad Norm=8.1505, LR=9.76563e-08\n",
      "Fold 1, Epoch 107: Train Loss=2.0548, Train Acc=23.96%, Val Loss=2.1377, Val Acc=18.36%, Grad Norm=8.1376, LR=9.76563e-08\n",
      "Fold 1, Epoch 108: Train Loss=2.0540, Train Acc=24.00%, Val Loss=2.1377, Val Acc=18.37%, Grad Norm=8.1463, LR=9.76563e-08\n",
      "Fold 1, Epoch 109: Train Loss=2.0527, Train Acc=24.16%, Val Loss=2.1373, Val Acc=18.34%, Grad Norm=8.1517, LR=9.76563e-08\n",
      "Fold 1, Epoch 110: Train Loss=2.0527, Train Acc=24.04%, Val Loss=2.1373, Val Acc=18.46%, Grad Norm=8.1646, LR=9.76563e-08\n",
      "Fold 1, Epoch 111: Train Loss=2.0544, Train Acc=23.96%, Val Loss=2.1375, Val Acc=18.42%, Grad Norm=8.1345, LR=4.88281e-08\n",
      "Fold 1, Epoch 112: Train Loss=2.0529, Train Acc=23.98%, Val Loss=2.1373, Val Acc=18.35%, Grad Norm=8.1442, LR=4.88281e-08\n",
      "Fold 1, Epoch 113: Train Loss=2.0552, Train Acc=23.75%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1472, LR=4.88281e-08\n",
      "Fold 1, Epoch 114: Train Loss=2.0535, Train Acc=24.26%, Val Loss=2.1376, Val Acc=18.36%, Grad Norm=8.1523, LR=4.88281e-08\n",
      "Fold 1, Epoch 115: Train Loss=2.0538, Train Acc=24.12%, Val Loss=2.1376, Val Acc=18.42%, Grad Norm=8.1638, LR=4.88281e-08\n",
      "Fold 1, Epoch 116: Train Loss=2.0532, Train Acc=24.36%, Val Loss=2.1378, Val Acc=18.39%, Grad Norm=8.1905, LR=4.88281e-08\n",
      "Fold 1, Epoch 117: Train Loss=2.0541, Train Acc=24.31%, Val Loss=2.1373, Val Acc=18.46%, Grad Norm=8.1623, LR=4.88281e-08\n",
      "Fold 1, Epoch 118: Train Loss=2.0539, Train Acc=24.17%, Val Loss=2.1376, Val Acc=18.38%, Grad Norm=8.1653, LR=4.88281e-08\n",
      "Fold 1, Epoch 119: Train Loss=2.0553, Train Acc=23.82%, Val Loss=2.1376, Val Acc=18.43%, Grad Norm=8.1829, LR=4.88281e-08\n",
      "Fold 1, Epoch 120: Train Loss=2.0506, Train Acc=24.20%, Val Loss=2.1376, Val Acc=18.35%, Grad Norm=8.1523, LR=4.88281e-08\n",
      "Fold 1, Epoch 121: Train Loss=2.0538, Train Acc=23.93%, Val Loss=2.1374, Val Acc=18.38%, Grad Norm=8.2037, LR=2.44141e-08\n",
      "Fold 1, Epoch 122: Train Loss=2.0573, Train Acc=23.79%, Val Loss=2.1377, Val Acc=18.38%, Grad Norm=8.1679, LR=2.44141e-08\n",
      "Fold 1, Epoch 123: Train Loss=2.0522, Train Acc=24.25%, Val Loss=2.1376, Val Acc=18.40%, Grad Norm=8.1901, LR=2.44141e-08\n",
      "Fold 1, Epoch 124: Train Loss=2.0535, Train Acc=24.13%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1478, LR=2.44141e-08\n",
      "Fold 1, Epoch 125: Train Loss=2.0544, Train Acc=24.09%, Val Loss=2.1378, Val Acc=18.47%, Grad Norm=8.1756, LR=2.44141e-08\n",
      "Fold 1, Epoch 126: Train Loss=2.0515, Train Acc=24.40%, Val Loss=2.1374, Val Acc=18.35%, Grad Norm=8.1810, LR=2.44141e-08\n",
      "Fold 1, Epoch 127: Train Loss=2.0562, Train Acc=24.06%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1855, LR=2.44141e-08\n",
      "Fold 1, Epoch 128: Train Loss=2.0534, Train Acc=24.13%, Val Loss=2.1373, Val Acc=18.42%, Grad Norm=8.1937, LR=2.44141e-08\n",
      "Fold 1, Epoch 129: Train Loss=2.0527, Train Acc=23.90%, Val Loss=2.1377, Val Acc=18.28%, Grad Norm=8.1812, LR=2.44141e-08\n",
      "Fold 1, Epoch 130: Train Loss=2.0539, Train Acc=24.05%, Val Loss=2.1374, Val Acc=18.40%, Grad Norm=8.2068, LR=2.44141e-08\n",
      "Fold 1, Epoch 131: Train Loss=2.0549, Train Acc=23.93%, Val Loss=2.1377, Val Acc=18.40%, Grad Norm=8.2162, LR=1.2207e-08\n",
      "Fold 1, Epoch 132: Train Loss=2.0520, Train Acc=24.35%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1708, LR=1.2207e-08\n",
      "Fold 1, Epoch 133: Train Loss=2.0500, Train Acc=24.64%, Val Loss=2.1378, Val Acc=18.42%, Grad Norm=8.1848, LR=1.2207e-08\n",
      "Fold 1, Epoch 134: Train Loss=2.0552, Train Acc=24.19%, Val Loss=2.1375, Val Acc=18.48%, Grad Norm=8.1992, LR=1.2207e-08\n",
      "Fold 1, Epoch 135: Train Loss=2.0530, Train Acc=24.12%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1781, LR=1.2207e-08\n",
      "Fold 1, Epoch 136: Train Loss=2.0531, Train Acc=24.09%, Val Loss=2.1375, Val Acc=18.38%, Grad Norm=8.1903, LR=1.2207e-08\n",
      "Fold 1, Epoch 137: Train Loss=2.0521, Train Acc=24.08%, Val Loss=2.1374, Val Acc=18.39%, Grad Norm=8.1929, LR=1.2207e-08\n",
      "Fold 1, Epoch 138: Train Loss=2.0522, Train Acc=24.03%, Val Loss=2.1376, Val Acc=18.44%, Grad Norm=8.1827, LR=1.2207e-08\n",
      "Fold 1, Epoch 139: Train Loss=2.0554, Train Acc=23.85%, Val Loss=2.1375, Val Acc=18.47%, Grad Norm=8.2117, LR=1.2207e-08\n",
      "Fold 1, Epoch 140: Train Loss=2.0518, Train Acc=24.16%, Val Loss=2.1377, Val Acc=18.40%, Grad Norm=8.1762, LR=1.2207e-08\n",
      "Fold 1, Epoch 141: Train Loss=2.0542, Train Acc=24.07%, Val Loss=2.1379, Val Acc=18.45%, Grad Norm=8.2003, LR=6.10352e-09\n",
      "Fold 1, Epoch 142: Train Loss=2.0551, Train Acc=24.07%, Val Loss=2.1373, Val Acc=18.40%, Grad Norm=8.1865, LR=6.10352e-09\n",
      "Fold 1, Epoch 143: Train Loss=2.0506, Train Acc=24.28%, Val Loss=2.1375, Val Acc=18.44%, Grad Norm=8.1707, LR=6.10352e-09\n",
      "Fold 1, Epoch 144: Train Loss=2.0522, Train Acc=24.39%, Val Loss=2.1376, Val Acc=18.44%, Grad Norm=8.1975, LR=6.10352e-09\n",
      "Fold 1, Epoch 145: Train Loss=2.0527, Train Acc=24.32%, Val Loss=2.1376, Val Acc=18.36%, Grad Norm=8.1912, LR=6.10352e-09\n",
      "Fold 1, Epoch 146: Train Loss=2.0497, Train Acc=24.39%, Val Loss=2.1376, Val Acc=18.42%, Grad Norm=8.1724, LR=6.10352e-09\n",
      "Fold 1, Epoch 147: Train Loss=2.0544, Train Acc=23.99%, Val Loss=2.1376, Val Acc=18.34%, Grad Norm=8.2021, LR=6.10352e-09\n",
      "Fold 1, Epoch 148: Train Loss=2.0505, Train Acc=24.42%, Val Loss=2.1377, Val Acc=18.35%, Grad Norm=8.1990, LR=6.10352e-09\n",
      "Fold 1, Epoch 149: Train Loss=2.0535, Train Acc=24.01%, Val Loss=2.1376, Val Acc=18.42%, Grad Norm=8.1963, LR=6.10352e-09\n",
      "Fold 1, Epoch 150: Train Loss=2.0510, Train Acc=24.36%, Val Loss=2.1378, Val Acc=18.41%, Grad Norm=8.1801, LR=6.10352e-09\n",
      "Fold 1, Epoch 151: Train Loss=2.0548, Train Acc=23.97%, Val Loss=2.1379, Val Acc=18.34%, Grad Norm=8.1994, LR=3.05176e-09\n",
      "Fold 1, Epoch 152: Train Loss=2.0532, Train Acc=24.19%, Val Loss=2.1376, Val Acc=18.31%, Grad Norm=8.1862, LR=3.05176e-09\n",
      "Fold 1, Epoch 153: Train Loss=2.0499, Train Acc=24.42%, Val Loss=2.1378, Val Acc=18.38%, Grad Norm=8.1962, LR=3.05176e-09\n",
      "Fold 1, Epoch 154: Train Loss=2.0535, Train Acc=24.01%, Val Loss=2.1377, Val Acc=18.41%, Grad Norm=8.2044, LR=3.05176e-09\n",
      "Fold 1, Epoch 155: Train Loss=2.0546, Train Acc=24.10%, Val Loss=2.1375, Val Acc=18.39%, Grad Norm=8.1870, LR=3.05176e-09\n",
      "Fold 1, Epoch 156: Train Loss=2.0520, Train Acc=24.03%, Val Loss=2.1380, Val Acc=18.42%, Grad Norm=8.1941, LR=3.05176e-09\n",
      "Fold 1, Epoch 157: Train Loss=2.0499, Train Acc=24.23%, Val Loss=2.1377, Val Acc=18.39%, Grad Norm=8.1994, LR=3.05176e-09\n",
      "Fold 1, Epoch 158: Train Loss=2.0500, Train Acc=24.25%, Val Loss=2.1375, Val Acc=18.39%, Grad Norm=8.1788, LR=3.05176e-09\n",
      "Fold 1, Epoch 159: Train Loss=2.0542, Train Acc=23.97%, Val Loss=2.1375, Val Acc=18.47%, Grad Norm=8.2173, LR=3.05176e-09\n",
      "Fold 1, Epoch 160: Train Loss=2.0533, Train Acc=24.06%, Val Loss=2.1374, Val Acc=18.37%, Grad Norm=8.1897, LR=3.05176e-09\n",
      "Fold 1, Epoch 161: Train Loss=2.0549, Train Acc=23.96%, Val Loss=2.1376, Val Acc=18.41%, Grad Norm=8.2026, LR=1.52588e-09\n",
      "Fold 1, Epoch 162: Train Loss=2.0515, Train Acc=24.30%, Val Loss=2.1376, Val Acc=18.37%, Grad Norm=8.1998, LR=1.52588e-09\n",
      "Fold 1, Epoch 163: Train Loss=2.0560, Train Acc=23.85%, Val Loss=2.1376, Val Acc=18.37%, Grad Norm=8.1943, LR=1.52588e-09\n",
      "Fold 1, Epoch 164: Train Loss=2.0512, Train Acc=24.26%, Val Loss=2.1375, Val Acc=18.39%, Grad Norm=8.1878, LR=1.52588e-09\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=18.48%）\n",
      "Fold 1 DONE | Best Val Acc≈18.48% | Final Val Acc=18.48% | Test Acc=18.12%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2240, Train Acc=11.15%, Val Loss=2.2188, Val Acc=11.11%, Grad Norm=6.7729, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2214, Train Acc=11.33%, Val Loss=2.2541, Val Acc=11.25%, Grad Norm=6.4997, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2166, Train Acc=11.01%, Val Loss=2.2362, Val Acc=11.13%, Grad Norm=5.8168, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2135, Train Acc=11.19%, Val Loss=2.2195, Val Acc=11.34%, Grad Norm=4.7107, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2076, Train Acc=11.15%, Val Loss=2.2637, Val Acc=11.24%, Grad Norm=3.7703, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2055, Train Acc=11.55%, Val Loss=2.2377, Val Acc=11.05%, Grad Norm=3.2951, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2045, Train Acc=11.28%, Val Loss=2.2458, Val Acc=11.11%, Grad Norm=2.9674, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2022, Train Acc=11.49%, Val Loss=2.2144, Val Acc=11.13%, Grad Norm=2.7181, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2020, Train Acc=11.34%, Val Loss=2.2044, Val Acc=11.23%, Grad Norm=2.4332, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.1997, Train Acc=12.08%, Val Loss=2.1980, Val Acc=11.87%, Grad Norm=2.1310, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.1960, Train Acc=12.51%, Val Loss=2.2008, Val Acc=11.45%, Grad Norm=1.9314, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.1948, Train Acc=12.89%, Val Loss=2.1997, Val Acc=11.92%, Grad Norm=1.8980, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.1928, Train Acc=13.23%, Val Loss=2.1966, Val Acc=12.50%, Grad Norm=1.8407, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1902, Train Acc=13.23%, Val Loss=2.1943, Val Acc=12.91%, Grad Norm=1.9140, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1879, Train Acc=13.67%, Val Loss=2.1889, Val Acc=13.26%, Grad Norm=1.9111, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1838, Train Acc=14.46%, Val Loss=2.1904, Val Acc=12.96%, Grad Norm=1.9379, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1812, Train Acc=14.55%, Val Loss=2.1867, Val Acc=13.69%, Grad Norm=1.9497, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1780, Train Acc=14.93%, Val Loss=2.1884, Val Acc=13.38%, Grad Norm=1.9538, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1758, Train Acc=14.97%, Val Loss=2.1849, Val Acc=13.92%, Grad Norm=1.9288, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1722, Train Acc=15.55%, Val Loss=2.1826, Val Acc=14.11%, Grad Norm=2.0378, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1645, Train Acc=15.92%, Val Loss=2.1765, Val Acc=14.35%, Grad Norm=2.1766, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1622, Train Acc=16.21%, Val Loss=2.1742, Val Acc=14.67%, Grad Norm=2.2909, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1600, Train Acc=16.67%, Val Loss=2.1740, Val Acc=15.06%, Grad Norm=2.4320, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1572, Train Acc=16.57%, Val Loss=2.1716, Val Acc=15.13%, Grad Norm=2.4840, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1550, Train Acc=16.89%, Val Loss=2.1700, Val Acc=14.95%, Grad Norm=2.6027, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1543, Train Acc=16.85%, Val Loss=2.1728, Val Acc=14.95%, Grad Norm=2.6381, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1493, Train Acc=17.33%, Val Loss=2.1746, Val Acc=14.97%, Grad Norm=2.7786, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1470, Train Acc=17.71%, Val Loss=2.1677, Val Acc=15.70%, Grad Norm=2.9050, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1450, Train Acc=17.55%, Val Loss=2.1703, Val Acc=15.23%, Grad Norm=2.9726, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1424, Train Acc=17.92%, Val Loss=2.1664, Val Acc=15.58%, Grad Norm=3.0516, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1396, Train Acc=18.38%, Val Loss=2.1655, Val Acc=15.37%, Grad Norm=3.1685, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1335, Train Acc=18.65%, Val Loss=2.1642, Val Acc=15.78%, Grad Norm=3.3176, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1331, Train Acc=18.75%, Val Loss=2.1634, Val Acc=15.83%, Grad Norm=3.4397, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1310, Train Acc=18.85%, Val Loss=2.1623, Val Acc=15.99%, Grad Norm=3.6185, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1308, Train Acc=18.97%, Val Loss=2.1622, Val Acc=15.77%, Grad Norm=3.7188, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1266, Train Acc=19.27%, Val Loss=2.1614, Val Acc=16.13%, Grad Norm=3.8100, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1230, Train Acc=19.67%, Val Loss=2.1626, Val Acc=16.05%, Grad Norm=3.9367, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1225, Train Acc=19.50%, Val Loss=2.1605, Val Acc=16.21%, Grad Norm=4.0887, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1208, Train Acc=19.76%, Val Loss=2.1584, Val Acc=16.33%, Grad Norm=4.2255, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1160, Train Acc=20.24%, Val Loss=2.1576, Val Acc=16.61%, Grad Norm=4.3274, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1145, Train Acc=20.30%, Val Loss=2.1567, Val Acc=16.52%, Grad Norm=4.4683, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1109, Train Acc=20.57%, Val Loss=2.1566, Val Acc=16.62%, Grad Norm=4.5971, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1093, Train Acc=20.84%, Val Loss=2.1560, Val Acc=16.58%, Grad Norm=4.6988, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1091, Train Acc=20.56%, Val Loss=2.1552, Val Acc=16.59%, Grad Norm=4.7945, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1054, Train Acc=20.91%, Val Loss=2.1540, Val Acc=16.89%, Grad Norm=4.9015, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1036, Train Acc=21.00%, Val Loss=2.1538, Val Acc=17.03%, Grad Norm=5.0195, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1031, Train Acc=21.20%, Val Loss=2.1528, Val Acc=16.94%, Grad Norm=5.1367, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.0988, Train Acc=21.23%, Val Loss=2.1530, Val Acc=16.77%, Grad Norm=5.2859, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.0962, Train Acc=21.43%, Val Loss=2.1529, Val Acc=16.81%, Grad Norm=5.4081, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.0992, Train Acc=21.20%, Val Loss=2.1528, Val Acc=16.96%, Grad Norm=5.5155, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.0926, Train Acc=21.91%, Val Loss=2.1528, Val Acc=16.97%, Grad Norm=5.6153, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.0940, Train Acc=21.64%, Val Loss=2.1525, Val Acc=16.96%, Grad Norm=5.7017, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.0950, Train Acc=21.53%, Val Loss=2.1526, Val Acc=16.98%, Grad Norm=5.7800, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.0907, Train Acc=21.90%, Val Loss=2.1521, Val Acc=17.01%, Grad Norm=5.8722, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.0919, Train Acc=21.94%, Val Loss=2.1514, Val Acc=17.19%, Grad Norm=5.9350, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.0905, Train Acc=21.76%, Val Loss=2.1522, Val Acc=17.04%, Grad Norm=6.0104, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.0867, Train Acc=22.19%, Val Loss=2.1515, Val Acc=17.16%, Grad Norm=6.0962, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.0884, Train Acc=21.91%, Val Loss=2.1514, Val Acc=17.16%, Grad Norm=6.1728, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.0875, Train Acc=22.13%, Val Loss=2.1512, Val Acc=17.15%, Grad Norm=6.2649, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.0853, Train Acc=22.07%, Val Loss=2.1502, Val Acc=17.07%, Grad Norm=6.3293, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.0813, Train Acc=22.64%, Val Loss=2.1503, Val Acc=17.20%, Grad Norm=6.4089, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.0818, Train Acc=22.25%, Val Loss=2.1513, Val Acc=17.02%, Grad Norm=6.4941, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=2.0833, Train Acc=22.69%, Val Loss=2.1504, Val Acc=17.04%, Grad Norm=6.5548, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=2.0807, Train Acc=22.60%, Val Loss=2.1508, Val Acc=17.22%, Grad Norm=6.6034, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=2.0808, Train Acc=22.51%, Val Loss=2.1502, Val Acc=17.20%, Grad Norm=6.6539, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=2.0794, Train Acc=22.61%, Val Loss=2.1502, Val Acc=17.25%, Grad Norm=6.6797, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=2.0769, Train Acc=22.68%, Val Loss=2.1499, Val Acc=17.25%, Grad Norm=6.7377, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=2.0774, Train Acc=22.94%, Val Loss=2.1498, Val Acc=17.33%, Grad Norm=6.8177, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=2.0777, Train Acc=22.62%, Val Loss=2.1498, Val Acc=17.38%, Grad Norm=6.8856, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=2.0763, Train Acc=22.65%, Val Loss=2.1496, Val Acc=17.33%, Grad Norm=6.9628, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=2.0764, Train Acc=22.78%, Val Loss=2.1497, Val Acc=17.29%, Grad Norm=6.9697, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=2.0767, Train Acc=22.67%, Val Loss=2.1494, Val Acc=17.30%, Grad Norm=6.9823, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=2.0718, Train Acc=23.12%, Val Loss=2.1496, Val Acc=17.39%, Grad Norm=7.0029, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=2.0746, Train Acc=22.84%, Val Loss=2.1493, Val Acc=17.27%, Grad Norm=7.0552, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=2.0739, Train Acc=22.96%, Val Loss=2.1493, Val Acc=17.35%, Grad Norm=7.0643, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=2.0733, Train Acc=22.96%, Val Loss=2.1489, Val Acc=17.35%, Grad Norm=7.1419, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=2.0738, Train Acc=22.83%, Val Loss=2.1497, Val Acc=17.39%, Grad Norm=7.1639, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=2.0730, Train Acc=23.19%, Val Loss=2.1493, Val Acc=17.36%, Grad Norm=7.1749, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=2.0713, Train Acc=23.19%, Val Loss=2.1490, Val Acc=17.39%, Grad Norm=7.1990, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=2.0710, Train Acc=23.08%, Val Loss=2.1491, Val Acc=17.38%, Grad Norm=7.2675, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=2.0711, Train Acc=23.31%, Val Loss=2.1490, Val Acc=17.44%, Grad Norm=7.2531, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=2.0704, Train Acc=23.21%, Val Loss=2.1491, Val Acc=17.41%, Grad Norm=7.2807, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=2.0720, Train Acc=23.15%, Val Loss=2.1492, Val Acc=17.38%, Grad Norm=7.3141, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=2.0694, Train Acc=23.38%, Val Loss=2.1489, Val Acc=17.45%, Grad Norm=7.3179, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=2.0696, Train Acc=23.29%, Val Loss=2.1492, Val Acc=17.43%, Grad Norm=7.3203, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=2.0704, Train Acc=23.33%, Val Loss=2.1495, Val Acc=17.36%, Grad Norm=7.3633, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=2.0716, Train Acc=22.96%, Val Loss=2.1495, Val Acc=17.29%, Grad Norm=7.3613, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=2.0701, Train Acc=23.09%, Val Loss=2.1496, Val Acc=17.39%, Grad Norm=7.3914, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=2.0705, Train Acc=23.12%, Val Loss=2.1496, Val Acc=17.45%, Grad Norm=7.3713, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=2.0725, Train Acc=22.99%, Val Loss=2.1492, Val Acc=17.34%, Grad Norm=7.4336, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=2.0703, Train Acc=23.06%, Val Loss=2.1490, Val Acc=17.45%, Grad Norm=7.4350, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=2.0699, Train Acc=23.08%, Val Loss=2.1493, Val Acc=17.34%, Grad Norm=7.4469, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=2.0663, Train Acc=23.49%, Val Loss=2.1490, Val Acc=17.38%, Grad Norm=7.4426, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=2.0716, Train Acc=23.06%, Val Loss=2.1490, Val Acc=17.33%, Grad Norm=7.4672, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=2.0712, Train Acc=23.28%, Val Loss=2.1491, Val Acc=17.41%, Grad Norm=7.4579, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=2.0675, Train Acc=23.59%, Val Loss=2.1494, Val Acc=17.40%, Grad Norm=7.4877, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=2.0730, Train Acc=23.01%, Val Loss=2.1489, Val Acc=17.42%, Grad Norm=7.4901, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=2.0692, Train Acc=23.21%, Val Loss=2.1488, Val Acc=17.49%, Grad Norm=7.4949, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=2.0668, Train Acc=23.53%, Val Loss=2.1490, Val Acc=17.33%, Grad Norm=7.4984, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=2.0679, Train Acc=23.33%, Val Loss=2.1488, Val Acc=17.35%, Grad Norm=7.4985, LR=1.95313e-07\n",
      "Fold 2, Epoch 101: Train Loss=2.0707, Train Acc=23.03%, Val Loss=2.1487, Val Acc=17.39%, Grad Norm=7.5136, LR=9.76563e-08\n",
      "Fold 2, Epoch 102: Train Loss=2.0710, Train Acc=23.20%, Val Loss=2.1490, Val Acc=17.42%, Grad Norm=7.5148, LR=9.76563e-08\n",
      "Fold 2, Epoch 103: Train Loss=2.0671, Train Acc=23.11%, Val Loss=2.1491, Val Acc=17.40%, Grad Norm=7.5034, LR=9.76563e-08\n",
      "Fold 2, Epoch 104: Train Loss=2.0683, Train Acc=23.12%, Val Loss=2.1490, Val Acc=17.36%, Grad Norm=7.5387, LR=9.76563e-08\n",
      "Fold 2, Epoch 105: Train Loss=2.0669, Train Acc=23.63%, Val Loss=2.1488, Val Acc=17.46%, Grad Norm=7.5252, LR=9.76563e-08\n",
      "Fold 2, Epoch 106: Train Loss=2.0694, Train Acc=23.31%, Val Loss=2.1489, Val Acc=17.43%, Grad Norm=7.5367, LR=9.76563e-08\n",
      "Fold 2, Epoch 107: Train Loss=2.0702, Train Acc=23.35%, Val Loss=2.1487, Val Acc=17.31%, Grad Norm=7.5322, LR=9.76563e-08\n",
      "Fold 2, Epoch 108: Train Loss=2.0661, Train Acc=23.64%, Val Loss=2.1488, Val Acc=17.31%, Grad Norm=7.5548, LR=9.76563e-08\n",
      "Fold 2, Epoch 109: Train Loss=2.0674, Train Acc=23.74%, Val Loss=2.1489, Val Acc=17.37%, Grad Norm=7.5384, LR=9.76563e-08\n",
      "Fold 2, Epoch 110: Train Loss=2.0687, Train Acc=23.29%, Val Loss=2.1487, Val Acc=17.49%, Grad Norm=7.5405, LR=9.76563e-08\n",
      "Fold 2, Epoch 111: Train Loss=2.0683, Train Acc=23.37%, Val Loss=2.1487, Val Acc=17.36%, Grad Norm=7.5498, LR=4.88281e-08\n",
      "Fold 2, Epoch 112: Train Loss=2.0679, Train Acc=23.27%, Val Loss=2.1491, Val Acc=17.39%, Grad Norm=7.5700, LR=4.88281e-08\n",
      "Fold 2, Epoch 113: Train Loss=2.0677, Train Acc=23.22%, Val Loss=2.1488, Val Acc=17.36%, Grad Norm=7.5735, LR=4.88281e-08\n",
      "Fold 2, Epoch 114: Train Loss=2.0676, Train Acc=23.49%, Val Loss=2.1488, Val Acc=17.40%, Grad Norm=7.5715, LR=4.88281e-08\n",
      "Fold 2, Epoch 115: Train Loss=2.0629, Train Acc=23.60%, Val Loss=2.1484, Val Acc=17.36%, Grad Norm=7.5579, LR=4.88281e-08\n",
      "Fold 2, Epoch 116: Train Loss=2.0680, Train Acc=23.26%, Val Loss=2.1489, Val Acc=17.42%, Grad Norm=7.5767, LR=4.88281e-08\n",
      "Fold 2, Epoch 117: Train Loss=2.0678, Train Acc=23.62%, Val Loss=2.1491, Val Acc=17.45%, Grad Norm=7.5676, LR=4.88281e-08\n",
      "Fold 2, Epoch 118: Train Loss=2.0666, Train Acc=23.43%, Val Loss=2.1488, Val Acc=17.46%, Grad Norm=7.5690, LR=4.88281e-08\n",
      "Fold 2, Epoch 119: Train Loss=2.0676, Train Acc=23.18%, Val Loss=2.1492, Val Acc=17.36%, Grad Norm=7.5813, LR=4.88281e-08\n",
      "Fold 2, Epoch 120: Train Loss=2.0666, Train Acc=23.38%, Val Loss=2.1489, Val Acc=17.41%, Grad Norm=7.5803, LR=4.88281e-08\n",
      "Fold 2, Epoch 121: Train Loss=2.0700, Train Acc=23.33%, Val Loss=2.1490, Val Acc=17.36%, Grad Norm=7.5866, LR=2.44141e-08\n",
      "Fold 2, Epoch 122: Train Loss=2.0672, Train Acc=23.17%, Val Loss=2.1489, Val Acc=17.44%, Grad Norm=7.5544, LR=2.44141e-08\n",
      "Fold 2, Epoch 123: Train Loss=2.0691, Train Acc=23.47%, Val Loss=2.1488, Val Acc=17.39%, Grad Norm=7.5831, LR=2.44141e-08\n",
      "Fold 2, Epoch 124: Train Loss=2.0659, Train Acc=23.64%, Val Loss=2.1493, Val Acc=17.32%, Grad Norm=7.5779, LR=2.44141e-08\n",
      "Fold 2, Epoch 125: Train Loss=2.0656, Train Acc=23.78%, Val Loss=2.1487, Val Acc=17.46%, Grad Norm=7.5678, LR=2.44141e-08\n",
      "Fold 2, Epoch 126: Train Loss=2.0674, Train Acc=23.48%, Val Loss=2.1490, Val Acc=17.54%, Grad Norm=7.5976, LR=2.44141e-08\n",
      "Fold 2, Epoch 127: Train Loss=2.0648, Train Acc=23.58%, Val Loss=2.1487, Val Acc=17.44%, Grad Norm=7.5732, LR=2.44141e-08\n",
      "Fold 2, Epoch 128: Train Loss=2.0680, Train Acc=23.13%, Val Loss=2.1492, Val Acc=17.32%, Grad Norm=7.5792, LR=2.44141e-08\n",
      "Fold 2, Epoch 129: Train Loss=2.0654, Train Acc=23.24%, Val Loss=2.1490, Val Acc=17.49%, Grad Norm=7.5758, LR=2.44141e-08\n",
      "Fold 2, Epoch 130: Train Loss=2.0691, Train Acc=23.45%, Val Loss=2.1487, Val Acc=17.40%, Grad Norm=7.5843, LR=2.44141e-08\n",
      "Fold 2, Epoch 131: Train Loss=2.0684, Train Acc=23.59%, Val Loss=2.1491, Val Acc=17.40%, Grad Norm=7.5843, LR=1.2207e-08\n",
      "Fold 2, Epoch 132: Train Loss=2.0669, Train Acc=23.43%, Val Loss=2.1486, Val Acc=17.45%, Grad Norm=7.5793, LR=1.2207e-08\n",
      "Fold 2, Epoch 133: Train Loss=2.0654, Train Acc=23.82%, Val Loss=2.1485, Val Acc=17.47%, Grad Norm=7.5797, LR=1.2207e-08\n",
      "Fold 2, Epoch 134: Train Loss=2.0666, Train Acc=23.57%, Val Loss=2.1491, Val Acc=17.33%, Grad Norm=7.5667, LR=1.2207e-08\n",
      "Fold 2, Epoch 135: Train Loss=2.0687, Train Acc=23.26%, Val Loss=2.1489, Val Acc=17.41%, Grad Norm=7.5910, LR=1.2207e-08\n",
      "Fold 2, Epoch 136: Train Loss=2.0676, Train Acc=23.52%, Val Loss=2.1488, Val Acc=17.48%, Grad Norm=7.5827, LR=1.2207e-08\n",
      "Fold 2, Epoch 137: Train Loss=2.0655, Train Acc=23.37%, Val Loss=2.1491, Val Acc=17.44%, Grad Norm=7.5786, LR=1.2207e-08\n",
      "Fold 2, Epoch 138: Train Loss=2.0664, Train Acc=23.77%, Val Loss=2.1488, Val Acc=17.38%, Grad Norm=7.5711, LR=1.2207e-08\n",
      "Fold 2, Epoch 139: Train Loss=2.0684, Train Acc=23.37%, Val Loss=2.1488, Val Acc=17.45%, Grad Norm=7.5797, LR=1.2207e-08\n",
      "Fold 2, Epoch 140: Train Loss=2.0685, Train Acc=23.49%, Val Loss=2.1490, Val Acc=17.36%, Grad Norm=7.5789, LR=1.2207e-08\n",
      "Fold 2, Epoch 141: Train Loss=2.0683, Train Acc=23.22%, Val Loss=2.1492, Val Acc=17.39%, Grad Norm=7.5928, LR=6.10352e-09\n",
      "Fold 2, Epoch 142: Train Loss=2.0664, Train Acc=23.42%, Val Loss=2.1488, Val Acc=17.48%, Grad Norm=7.5880, LR=6.10352e-09\n",
      "Fold 2, Epoch 143: Train Loss=2.0683, Train Acc=23.43%, Val Loss=2.1487, Val Acc=17.40%, Grad Norm=7.6021, LR=6.10352e-09\n",
      "Fold 2, Epoch 144: Train Loss=2.0663, Train Acc=23.55%, Val Loss=2.1490, Val Acc=17.39%, Grad Norm=7.5848, LR=6.10352e-09\n",
      "Fold 2, Epoch 145: Train Loss=2.0650, Train Acc=23.42%, Val Loss=2.1487, Val Acc=17.45%, Grad Norm=7.5608, LR=6.10352e-09\n",
      "Fold 2, Epoch 146: Train Loss=2.0682, Train Acc=23.34%, Val Loss=2.1487, Val Acc=17.39%, Grad Norm=7.5800, LR=6.10352e-09\n",
      "Fold 2, Epoch 147: Train Loss=2.0708, Train Acc=23.31%, Val Loss=2.1488, Val Acc=17.44%, Grad Norm=7.5993, LR=6.10352e-09\n",
      "Fold 2, Epoch 148: Train Loss=2.0685, Train Acc=23.32%, Val Loss=2.1485, Val Acc=17.43%, Grad Norm=7.5913, LR=6.10352e-09\n",
      "Fold 2, Epoch 149: Train Loss=2.0692, Train Acc=23.14%, Val Loss=2.1489, Val Acc=17.38%, Grad Norm=7.5939, LR=6.10352e-09\n",
      "Fold 2, Epoch 150: Train Loss=2.0669, Train Acc=23.30%, Val Loss=2.1494, Val Acc=17.30%, Grad Norm=7.5886, LR=6.10352e-09\n",
      "Fold 2, Epoch 151: Train Loss=2.0668, Train Acc=23.38%, Val Loss=2.1490, Val Acc=17.33%, Grad Norm=7.5978, LR=3.05176e-09\n",
      "Fold 2, Epoch 152: Train Loss=2.0672, Train Acc=23.41%, Val Loss=2.1492, Val Acc=17.38%, Grad Norm=7.5768, LR=3.05176e-09\n",
      "Fold 2, Epoch 153: Train Loss=2.0649, Train Acc=23.64%, Val Loss=2.1487, Val Acc=17.37%, Grad Norm=7.5789, LR=3.05176e-09\n",
      "Fold 2, Epoch 154: Train Loss=2.0687, Train Acc=22.97%, Val Loss=2.1490, Val Acc=17.33%, Grad Norm=7.6030, LR=3.05176e-09\n",
      "Fold 2, Epoch 155: Train Loss=2.0692, Train Acc=23.36%, Val Loss=2.1487, Val Acc=17.46%, Grad Norm=7.6064, LR=3.05176e-09\n",
      "Fold 2, Epoch 156: Train Loss=2.0677, Train Acc=23.27%, Val Loss=2.1491, Val Acc=17.45%, Grad Norm=7.5998, LR=3.05176e-09\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=17.54%）\n",
      "Fold 2 DONE | Best Val Acc≈17.54% | Final Val Acc=17.54% | Test Acc=17.44%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2243, Train Acc=11.20%, Val Loss=2.2540, Val Acc=11.04%, Grad Norm=6.8834, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2239, Train Acc=11.11%, Val Loss=2.2293, Val Acc=11.04%, Grad Norm=6.5716, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2203, Train Acc=10.75%, Val Loss=2.2200, Val Acc=11.28%, Grad Norm=5.9382, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2135, Train Acc=11.18%, Val Loss=2.2419, Val Acc=11.12%, Grad Norm=4.9930, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2084, Train Acc=11.30%, Val Loss=2.2203, Val Acc=10.92%, Grad Norm=4.0031, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2044, Train Acc=11.47%, Val Loss=2.2241, Val Acc=11.22%, Grad Norm=3.4416, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2036, Train Acc=11.78%, Val Loss=2.2086, Val Acc=10.86%, Grad Norm=3.0666, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2015, Train Acc=11.85%, Val Loss=2.2096, Val Acc=11.44%, Grad Norm=2.8070, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2006, Train Acc=12.00%, Val Loss=2.2063, Val Acc=11.71%, Grad Norm=2.4881, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.1975, Train Acc=12.56%, Val Loss=2.2081, Val Acc=11.74%, Grad Norm=2.1624, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.1943, Train Acc=12.76%, Val Loss=2.1985, Val Acc=12.46%, Grad Norm=1.9501, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.1908, Train Acc=13.44%, Val Loss=2.1974, Val Acc=12.41%, Grad Norm=1.9315, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1885, Train Acc=13.79%, Val Loss=2.1975, Val Acc=13.10%, Grad Norm=1.9504, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1867, Train Acc=14.11%, Val Loss=2.1957, Val Acc=13.37%, Grad Norm=1.9571, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1838, Train Acc=14.51%, Val Loss=2.1950, Val Acc=13.24%, Grad Norm=2.0264, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1814, Train Acc=14.82%, Val Loss=2.1907, Val Acc=14.12%, Grad Norm=1.9904, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1796, Train Acc=14.82%, Val Loss=2.1866, Val Acc=14.14%, Grad Norm=2.0043, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1773, Train Acc=15.00%, Val Loss=2.1865, Val Acc=14.18%, Grad Norm=2.0311, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1735, Train Acc=15.68%, Val Loss=2.1827, Val Acc=14.46%, Grad Norm=2.1351, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1704, Train Acc=15.99%, Val Loss=2.1810, Val Acc=14.53%, Grad Norm=2.1876, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1629, Train Acc=16.48%, Val Loss=2.1741, Val Acc=15.22%, Grad Norm=2.3186, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1572, Train Acc=17.01%, Val Loss=2.1708, Val Acc=15.43%, Grad Norm=2.6273, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1543, Train Acc=17.33%, Val Loss=2.1673, Val Acc=15.77%, Grad Norm=2.7589, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1507, Train Acc=17.63%, Val Loss=2.1665, Val Acc=15.96%, Grad Norm=2.8957, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1486, Train Acc=17.66%, Val Loss=2.1660, Val Acc=15.81%, Grad Norm=2.9582, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1429, Train Acc=17.66%, Val Loss=2.1646, Val Acc=16.18%, Grad Norm=3.0973, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1413, Train Acc=18.15%, Val Loss=2.1621, Val Acc=16.29%, Grad Norm=3.1880, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1354, Train Acc=19.00%, Val Loss=2.1590, Val Acc=16.48%, Grad Norm=3.2844, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1364, Train Acc=18.62%, Val Loss=2.1571, Val Acc=16.44%, Grad Norm=3.3880, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1333, Train Acc=19.00%, Val Loss=2.1583, Val Acc=16.33%, Grad Norm=3.4041, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1250, Train Acc=19.44%, Val Loss=2.1529, Val Acc=16.85%, Grad Norm=3.5864, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1213, Train Acc=19.97%, Val Loss=2.1529, Val Acc=16.83%, Grad Norm=3.7403, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1184, Train Acc=19.80%, Val Loss=2.1499, Val Acc=17.15%, Grad Norm=3.8627, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1168, Train Acc=20.23%, Val Loss=2.1507, Val Acc=16.98%, Grad Norm=4.0347, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1143, Train Acc=20.34%, Val Loss=2.1496, Val Acc=17.33%, Grad Norm=4.1327, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1119, Train Acc=20.68%, Val Loss=2.1481, Val Acc=17.16%, Grad Norm=4.2608, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1092, Train Acc=20.50%, Val Loss=2.1458, Val Acc=17.33%, Grad Norm=4.3841, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1069, Train Acc=20.66%, Val Loss=2.1483, Val Acc=17.15%, Grad Norm=4.5294, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1043, Train Acc=21.17%, Val Loss=2.1460, Val Acc=17.31%, Grad Norm=4.6614, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.0977, Train Acc=21.10%, Val Loss=2.1439, Val Acc=17.55%, Grad Norm=4.8284, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.0960, Train Acc=21.49%, Val Loss=2.1427, Val Acc=17.74%, Grad Norm=4.9618, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.0966, Train Acc=21.35%, Val Loss=2.1421, Val Acc=17.87%, Grad Norm=5.0841, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.0908, Train Acc=22.05%, Val Loss=2.1417, Val Acc=18.00%, Grad Norm=5.2149, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.0869, Train Acc=22.07%, Val Loss=2.1420, Val Acc=17.91%, Grad Norm=5.3432, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.0907, Train Acc=21.91%, Val Loss=2.1414, Val Acc=17.79%, Grad Norm=5.4902, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.0855, Train Acc=22.11%, Val Loss=2.1398, Val Acc=17.78%, Grad Norm=5.6137, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.0833, Train Acc=22.47%, Val Loss=2.1399, Val Acc=17.87%, Grad Norm=5.7511, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.0822, Train Acc=22.61%, Val Loss=2.1381, Val Acc=18.07%, Grad Norm=5.8693, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.0799, Train Acc=22.55%, Val Loss=2.1403, Val Acc=17.94%, Grad Norm=5.9715, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.0786, Train Acc=22.68%, Val Loss=2.1396, Val Acc=17.80%, Grad Norm=6.1044, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.0763, Train Acc=22.66%, Val Loss=2.1376, Val Acc=18.13%, Grad Norm=6.2432, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.0753, Train Acc=22.56%, Val Loss=2.1376, Val Acc=18.01%, Grad Norm=6.3227, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=2.0713, Train Acc=23.35%, Val Loss=2.1374, Val Acc=18.11%, Grad Norm=6.4113, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=2.0678, Train Acc=23.35%, Val Loss=2.1374, Val Acc=18.13%, Grad Norm=6.5215, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=2.0706, Train Acc=23.45%, Val Loss=2.1373, Val Acc=18.12%, Grad Norm=6.5995, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=2.0704, Train Acc=23.30%, Val Loss=2.1369, Val Acc=18.22%, Grad Norm=6.7016, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=2.0706, Train Acc=23.17%, Val Loss=2.1372, Val Acc=18.15%, Grad Norm=6.7767, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=2.0694, Train Acc=23.20%, Val Loss=2.1378, Val Acc=18.12%, Grad Norm=6.8556, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=2.0692, Train Acc=23.18%, Val Loss=2.1388, Val Acc=18.15%, Grad Norm=6.9473, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=2.0645, Train Acc=23.55%, Val Loss=2.1370, Val Acc=18.13%, Grad Norm=7.0527, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=2.0640, Train Acc=23.44%, Val Loss=2.1367, Val Acc=18.24%, Grad Norm=7.1314, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=2.0608, Train Acc=23.76%, Val Loss=2.1369, Val Acc=18.20%, Grad Norm=7.1832, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=2.0605, Train Acc=23.66%, Val Loss=2.1362, Val Acc=18.20%, Grad Norm=7.2262, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=2.0614, Train Acc=23.62%, Val Loss=2.1362, Val Acc=18.23%, Grad Norm=7.3029, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=2.0592, Train Acc=23.86%, Val Loss=2.1366, Val Acc=18.22%, Grad Norm=7.3526, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=2.0561, Train Acc=24.18%, Val Loss=2.1364, Val Acc=18.31%, Grad Norm=7.4237, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=2.0579, Train Acc=23.90%, Val Loss=2.1362, Val Acc=18.20%, Grad Norm=7.4738, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=2.0561, Train Acc=24.05%, Val Loss=2.1362, Val Acc=18.20%, Grad Norm=7.5471, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=2.0553, Train Acc=24.25%, Val Loss=2.1356, Val Acc=18.27%, Grad Norm=7.5821, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=2.0575, Train Acc=23.98%, Val Loss=2.1357, Val Acc=18.21%, Grad Norm=7.6695, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=2.0549, Train Acc=24.10%, Val Loss=2.1354, Val Acc=18.22%, Grad Norm=7.6923, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=2.0543, Train Acc=24.23%, Val Loss=2.1357, Val Acc=18.28%, Grad Norm=7.7573, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=2.0483, Train Acc=24.30%, Val Loss=2.1357, Val Acc=18.26%, Grad Norm=7.7689, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=2.0515, Train Acc=24.17%, Val Loss=2.1358, Val Acc=18.28%, Grad Norm=7.8020, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=2.0513, Train Acc=24.42%, Val Loss=2.1354, Val Acc=18.23%, Grad Norm=7.8266, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=2.0522, Train Acc=24.19%, Val Loss=2.1356, Val Acc=18.25%, Grad Norm=7.8912, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=2.0508, Train Acc=24.44%, Val Loss=2.1355, Val Acc=18.29%, Grad Norm=7.9007, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=2.0514, Train Acc=24.33%, Val Loss=2.1357, Val Acc=18.34%, Grad Norm=7.9536, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=2.0501, Train Acc=24.62%, Val Loss=2.1356, Val Acc=18.27%, Grad Norm=7.9925, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=2.0512, Train Acc=24.26%, Val Loss=2.1360, Val Acc=18.29%, Grad Norm=8.0323, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=2.0511, Train Acc=24.38%, Val Loss=2.1357, Val Acc=18.23%, Grad Norm=8.0674, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=2.0511, Train Acc=24.24%, Val Loss=2.1355, Val Acc=18.35%, Grad Norm=8.0630, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=2.0503, Train Acc=24.28%, Val Loss=2.1357, Val Acc=18.33%, Grad Norm=8.0943, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=2.0487, Train Acc=24.43%, Val Loss=2.1357, Val Acc=18.25%, Grad Norm=8.1146, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=2.0501, Train Acc=24.45%, Val Loss=2.1355, Val Acc=18.26%, Grad Norm=8.1296, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=2.0486, Train Acc=24.45%, Val Loss=2.1355, Val Acc=18.30%, Grad Norm=8.1229, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=2.0502, Train Acc=24.22%, Val Loss=2.1355, Val Acc=18.26%, Grad Norm=8.1410, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=2.0473, Train Acc=24.67%, Val Loss=2.1356, Val Acc=18.22%, Grad Norm=8.1707, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=2.0477, Train Acc=24.21%, Val Loss=2.1353, Val Acc=18.35%, Grad Norm=8.1967, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=2.0511, Train Acc=24.14%, Val Loss=2.1353, Val Acc=18.33%, Grad Norm=8.1997, LR=3.90625e-07\n",
      "Fold 3, Epoch 91: Train Loss=2.0487, Train Acc=24.39%, Val Loss=2.1354, Val Acc=18.24%, Grad Norm=8.2398, LR=1.95313e-07\n",
      "Fold 3, Epoch 92: Train Loss=2.0487, Train Acc=24.46%, Val Loss=2.1354, Val Acc=18.22%, Grad Norm=8.2311, LR=1.95313e-07\n",
      "Fold 3, Epoch 93: Train Loss=2.0490, Train Acc=24.40%, Val Loss=2.1355, Val Acc=18.28%, Grad Norm=8.2629, LR=1.95313e-07\n",
      "Fold 3, Epoch 94: Train Loss=2.0493, Train Acc=24.19%, Val Loss=2.1356, Val Acc=18.28%, Grad Norm=8.2426, LR=1.95313e-07\n",
      "Fold 3, Epoch 95: Train Loss=2.0487, Train Acc=24.23%, Val Loss=2.1353, Val Acc=18.29%, Grad Norm=8.2802, LR=1.95313e-07\n",
      "Fold 3, Epoch 96: Train Loss=2.0473, Train Acc=24.59%, Val Loss=2.1355, Val Acc=18.21%, Grad Norm=8.2675, LR=1.95313e-07\n",
      "Fold 3, Epoch 97: Train Loss=2.0479, Train Acc=24.59%, Val Loss=2.1358, Val Acc=18.28%, Grad Norm=8.2704, LR=1.95313e-07\n",
      "Fold 3, Epoch 98: Train Loss=2.0461, Train Acc=24.53%, Val Loss=2.1353, Val Acc=18.31%, Grad Norm=8.2728, LR=1.95313e-07\n",
      "Fold 3, Epoch 99: Train Loss=2.0428, Train Acc=24.93%, Val Loss=2.1357, Val Acc=18.22%, Grad Norm=8.2864, LR=1.95313e-07\n",
      "Fold 3, Epoch 100: Train Loss=2.0478, Train Acc=24.38%, Val Loss=2.1354, Val Acc=18.25%, Grad Norm=8.2922, LR=1.95313e-07\n",
      "Fold 3, Epoch 101: Train Loss=2.0488, Train Acc=24.11%, Val Loss=2.1356, Val Acc=18.26%, Grad Norm=8.3057, LR=9.76563e-08\n",
      "Fold 3, Epoch 102: Train Loss=2.0454, Train Acc=24.59%, Val Loss=2.1352, Val Acc=18.27%, Grad Norm=8.3097, LR=9.76563e-08\n",
      "Fold 3, Epoch 103: Train Loss=2.0476, Train Acc=24.29%, Val Loss=2.1359, Val Acc=18.13%, Grad Norm=8.3355, LR=9.76563e-08\n",
      "Fold 3, Epoch 104: Train Loss=2.0477, Train Acc=24.59%, Val Loss=2.1352, Val Acc=18.32%, Grad Norm=8.3018, LR=9.76563e-08\n",
      "Fold 3, Epoch 105: Train Loss=2.0473, Train Acc=24.61%, Val Loss=2.1354, Val Acc=18.41%, Grad Norm=8.3371, LR=9.76563e-08\n",
      "Fold 3, Epoch 106: Train Loss=2.0480, Train Acc=24.75%, Val Loss=2.1357, Val Acc=18.25%, Grad Norm=8.3544, LR=9.76563e-08\n",
      "Fold 3, Epoch 107: Train Loss=2.0440, Train Acc=24.61%, Val Loss=2.1352, Val Acc=18.31%, Grad Norm=8.3160, LR=9.76563e-08\n",
      "Fold 3, Epoch 108: Train Loss=2.0486, Train Acc=24.57%, Val Loss=2.1355, Val Acc=18.36%, Grad Norm=8.3455, LR=9.76563e-08\n",
      "Fold 3, Epoch 109: Train Loss=2.0452, Train Acc=24.57%, Val Loss=2.1356, Val Acc=18.24%, Grad Norm=8.3487, LR=9.76563e-08\n",
      "Fold 3, Epoch 110: Train Loss=2.0461, Train Acc=24.56%, Val Loss=2.1352, Val Acc=18.32%, Grad Norm=8.3720, LR=9.76563e-08\n",
      "Fold 3, Epoch 111: Train Loss=2.0473, Train Acc=24.65%, Val Loss=2.1355, Val Acc=18.31%, Grad Norm=8.3595, LR=4.88281e-08\n",
      "Fold 3, Epoch 112: Train Loss=2.0495, Train Acc=24.44%, Val Loss=2.1354, Val Acc=18.28%, Grad Norm=8.3835, LR=4.88281e-08\n",
      "Fold 3, Epoch 113: Train Loss=2.0458, Train Acc=24.85%, Val Loss=2.1353, Val Acc=18.24%, Grad Norm=8.3495, LR=4.88281e-08\n",
      "Fold 3, Epoch 114: Train Loss=2.0499, Train Acc=24.41%, Val Loss=2.1354, Val Acc=18.23%, Grad Norm=8.3612, LR=4.88281e-08\n",
      "Fold 3, Epoch 115: Train Loss=2.0526, Train Acc=24.20%, Val Loss=2.1352, Val Acc=18.35%, Grad Norm=8.3768, LR=4.88281e-08\n",
      "Fold 3, Epoch 116: Train Loss=2.0493, Train Acc=24.26%, Val Loss=2.1353, Val Acc=18.27%, Grad Norm=8.3745, LR=4.88281e-08\n",
      "Fold 3, Epoch 117: Train Loss=2.0486, Train Acc=24.57%, Val Loss=2.1353, Val Acc=18.28%, Grad Norm=8.3740, LR=4.88281e-08\n",
      "Fold 3, Epoch 118: Train Loss=2.0480, Train Acc=24.26%, Val Loss=2.1358, Val Acc=18.12%, Grad Norm=8.4137, LR=4.88281e-08\n",
      "Fold 3, Epoch 119: Train Loss=2.0460, Train Acc=24.57%, Val Loss=2.1352, Val Acc=18.37%, Grad Norm=8.3746, LR=4.88281e-08\n",
      "Fold 3, Epoch 120: Train Loss=2.0479, Train Acc=24.56%, Val Loss=2.1354, Val Acc=18.24%, Grad Norm=8.3956, LR=4.88281e-08\n",
      "Fold 3, Epoch 121: Train Loss=2.0449, Train Acc=24.79%, Val Loss=2.1355, Val Acc=18.29%, Grad Norm=8.3714, LR=2.44141e-08\n",
      "Fold 3, Epoch 122: Train Loss=2.0444, Train Acc=24.63%, Val Loss=2.1353, Val Acc=18.26%, Grad Norm=8.3957, LR=2.44141e-08\n",
      "Fold 3, Epoch 123: Train Loss=2.0470, Train Acc=24.58%, Val Loss=2.1353, Val Acc=18.29%, Grad Norm=8.3892, LR=2.44141e-08\n",
      "Fold 3, Epoch 124: Train Loss=2.0447, Train Acc=24.66%, Val Loss=2.1355, Val Acc=18.32%, Grad Norm=8.4019, LR=2.44141e-08\n",
      "Fold 3, Epoch 125: Train Loss=2.0467, Train Acc=24.76%, Val Loss=2.1356, Val Acc=18.19%, Grad Norm=8.4010, LR=2.44141e-08\n",
      "Fold 3, Epoch 126: Train Loss=2.0458, Train Acc=24.65%, Val Loss=2.1353, Val Acc=18.28%, Grad Norm=8.4101, LR=2.44141e-08\n",
      "Fold 3, Epoch 127: Train Loss=2.0467, Train Acc=24.35%, Val Loss=2.1351, Val Acc=18.26%, Grad Norm=8.3772, LR=2.44141e-08\n",
      "Fold 3, Epoch 128: Train Loss=2.0479, Train Acc=24.38%, Val Loss=2.1354, Val Acc=18.32%, Grad Norm=8.3753, LR=2.44141e-08\n",
      "Fold 3, Epoch 129: Train Loss=2.0491, Train Acc=24.30%, Val Loss=2.1355, Val Acc=18.30%, Grad Norm=8.4133, LR=2.44141e-08\n",
      "Fold 3, Epoch 130: Train Loss=2.0490, Train Acc=24.40%, Val Loss=2.1357, Val Acc=18.17%, Grad Norm=8.4051, LR=2.44141e-08\n",
      "Fold 3, Epoch 131: Train Loss=2.0484, Train Acc=24.44%, Val Loss=2.1352, Val Acc=18.30%, Grad Norm=8.4127, LR=1.2207e-08\n",
      "Fold 3, Epoch 132: Train Loss=2.0454, Train Acc=24.70%, Val Loss=2.1353, Val Acc=18.26%, Grad Norm=8.3664, LR=1.2207e-08\n",
      "Fold 3, Epoch 133: Train Loss=2.0475, Train Acc=24.62%, Val Loss=2.1354, Val Acc=18.31%, Grad Norm=8.3917, LR=1.2207e-08\n",
      "Fold 3, Epoch 134: Train Loss=2.0472, Train Acc=24.56%, Val Loss=2.1353, Val Acc=18.32%, Grad Norm=8.3921, LR=1.2207e-08\n",
      "Fold 3, Epoch 135: Train Loss=2.0460, Train Acc=24.67%, Val Loss=2.1354, Val Acc=18.29%, Grad Norm=8.3970, LR=1.2207e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=18.41%）\n",
      "Fold 3 DONE | Best Val Acc≈18.41% | Final Val Acc=18.41% | Test Acc=18.39%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2254, Train Acc=11.09%, Val Loss=2.2595, Val Acc=11.04%, Grad Norm=6.8239, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2218, Train Acc=11.25%, Val Loss=2.2567, Val Acc=11.14%, Grad Norm=6.4013, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2156, Train Acc=11.43%, Val Loss=2.2673, Val Acc=11.11%, Grad Norm=5.5126, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2100, Train Acc=11.37%, Val Loss=2.2009, Val Acc=11.01%, Grad Norm=4.2555, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2055, Train Acc=11.35%, Val Loss=2.2183, Val Acc=11.09%, Grad Norm=3.4848, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2031, Train Acc=11.47%, Val Loss=2.2145, Val Acc=11.10%, Grad Norm=3.0226, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2018, Train Acc=11.82%, Val Loss=2.2052, Val Acc=11.78%, Grad Norm=2.6767, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.1997, Train Acc=12.12%, Val Loss=2.2032, Val Acc=11.78%, Grad Norm=2.2850, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.1979, Train Acc=12.49%, Val Loss=2.2120, Val Acc=11.30%, Grad Norm=1.9848, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.1941, Train Acc=13.14%, Val Loss=2.1999, Val Acc=12.06%, Grad Norm=1.8042, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1885, Train Acc=13.83%, Val Loss=2.1971, Val Acc=12.60%, Grad Norm=1.7339, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1861, Train Acc=13.99%, Val Loss=2.1927, Val Acc=13.19%, Grad Norm=1.7541, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1820, Train Acc=14.65%, Val Loss=2.1911, Val Acc=13.02%, Grad Norm=1.8291, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1796, Train Acc=15.04%, Val Loss=2.1870, Val Acc=13.85%, Grad Norm=1.8314, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1767, Train Acc=15.49%, Val Loss=2.1890, Val Acc=13.77%, Grad Norm=1.8757, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1725, Train Acc=15.51%, Val Loss=2.1845, Val Acc=14.23%, Grad Norm=1.9565, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1693, Train Acc=15.97%, Val Loss=2.1817, Val Acc=14.46%, Grad Norm=1.9955, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1648, Train Acc=16.40%, Val Loss=2.1805, Val Acc=14.24%, Grad Norm=2.0448, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1638, Train Acc=16.34%, Val Loss=2.1804, Val Acc=14.70%, Grad Norm=2.0831, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1600, Train Acc=16.84%, Val Loss=2.1784, Val Acc=14.82%, Grad Norm=2.1028, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1517, Train Acc=17.61%, Val Loss=2.1704, Val Acc=15.53%, Grad Norm=2.2407, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1482, Train Acc=17.71%, Val Loss=2.1650, Val Acc=15.80%, Grad Norm=2.4441, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1424, Train Acc=18.16%, Val Loss=2.1644, Val Acc=15.86%, Grad Norm=2.5719, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1402, Train Acc=18.29%, Val Loss=2.1613, Val Acc=16.10%, Grad Norm=2.7343, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1363, Train Acc=18.47%, Val Loss=2.1607, Val Acc=16.28%, Grad Norm=2.8691, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1361, Train Acc=18.57%, Val Loss=2.1623, Val Acc=15.63%, Grad Norm=2.9418, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1332, Train Acc=18.71%, Val Loss=2.1590, Val Acc=16.21%, Grad Norm=3.0550, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1301, Train Acc=18.99%, Val Loss=2.1584, Val Acc=16.63%, Grad Norm=3.1777, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1294, Train Acc=19.21%, Val Loss=2.1551, Val Acc=16.63%, Grad Norm=3.2833, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1268, Train Acc=19.16%, Val Loss=2.1548, Val Acc=16.80%, Grad Norm=3.3639, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1194, Train Acc=19.87%, Val Loss=2.1523, Val Acc=16.94%, Grad Norm=3.4938, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1142, Train Acc=20.21%, Val Loss=2.1507, Val Acc=16.80%, Grad Norm=3.7026, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=2.1105, Train Acc=20.47%, Val Loss=2.1499, Val Acc=17.01%, Grad Norm=3.8925, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=2.1101, Train Acc=20.40%, Val Loss=2.1516, Val Acc=16.93%, Grad Norm=4.0336, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=2.1043, Train Acc=20.70%, Val Loss=2.1512, Val Acc=16.86%, Grad Norm=4.1670, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=2.1036, Train Acc=20.84%, Val Loss=2.1478, Val Acc=17.02%, Grad Norm=4.3779, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=2.1028, Train Acc=20.86%, Val Loss=2.1501, Val Acc=16.95%, Grad Norm=4.5213, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=2.0979, Train Acc=21.38%, Val Loss=2.1492, Val Acc=16.76%, Grad Norm=4.7067, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=2.0967, Train Acc=21.31%, Val Loss=2.1478, Val Acc=17.17%, Grad Norm=4.8867, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=2.0922, Train Acc=21.77%, Val Loss=2.1476, Val Acc=17.08%, Grad Norm=5.0445, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=2.0893, Train Acc=21.81%, Val Loss=2.1443, Val Acc=17.29%, Grad Norm=5.1959, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=2.0834, Train Acc=22.25%, Val Loss=2.1459, Val Acc=16.83%, Grad Norm=5.3796, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=2.0811, Train Acc=22.30%, Val Loss=2.1453, Val Acc=17.27%, Grad Norm=5.5465, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=2.0817, Train Acc=22.39%, Val Loss=2.1439, Val Acc=17.36%, Grad Norm=5.7017, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=2.0790, Train Acc=22.56%, Val Loss=2.1435, Val Acc=17.27%, Grad Norm=5.8395, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=2.0791, Train Acc=22.50%, Val Loss=2.1425, Val Acc=17.49%, Grad Norm=5.9804, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=2.0739, Train Acc=22.70%, Val Loss=2.1431, Val Acc=17.25%, Grad Norm=6.1111, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=2.0752, Train Acc=22.55%, Val Loss=2.1430, Val Acc=17.20%, Grad Norm=6.2488, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=2.0715, Train Acc=23.10%, Val Loss=2.1430, Val Acc=17.34%, Grad Norm=6.4603, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=2.0715, Train Acc=22.88%, Val Loss=2.1436, Val Acc=17.32%, Grad Norm=6.5848, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=2.0667, Train Acc=23.36%, Val Loss=2.1427, Val Acc=17.38%, Grad Norm=6.7155, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=2.0643, Train Acc=23.31%, Val Loss=2.1412, Val Acc=17.50%, Grad Norm=6.8805, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=2.0637, Train Acc=23.45%, Val Loss=2.1416, Val Acc=17.26%, Grad Norm=7.0122, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=2.0607, Train Acc=23.65%, Val Loss=2.1416, Val Acc=17.27%, Grad Norm=7.1465, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=2.0587, Train Acc=23.64%, Val Loss=2.1427, Val Acc=17.27%, Grad Norm=7.2354, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=2.0595, Train Acc=23.67%, Val Loss=2.1403, Val Acc=17.58%, Grad Norm=7.3269, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=2.0582, Train Acc=23.90%, Val Loss=2.1409, Val Acc=17.77%, Grad Norm=7.4929, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=2.0558, Train Acc=23.94%, Val Loss=2.1403, Val Acc=17.58%, Grad Norm=7.6046, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=2.0533, Train Acc=23.92%, Val Loss=2.1406, Val Acc=17.68%, Grad Norm=7.7276, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=2.0554, Train Acc=23.79%, Val Loss=2.1420, Val Acc=17.66%, Grad Norm=7.8602, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=2.0503, Train Acc=24.02%, Val Loss=2.1399, Val Acc=17.74%, Grad Norm=7.9697, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=2.0487, Train Acc=24.25%, Val Loss=2.1411, Val Acc=17.49%, Grad Norm=8.0376, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=2.0476, Train Acc=24.22%, Val Loss=2.1396, Val Acc=17.72%, Grad Norm=8.1062, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=2.0488, Train Acc=24.18%, Val Loss=2.1405, Val Acc=17.76%, Grad Norm=8.1801, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=2.0444, Train Acc=24.73%, Val Loss=2.1398, Val Acc=17.70%, Grad Norm=8.2711, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=2.0463, Train Acc=24.41%, Val Loss=2.1405, Val Acc=17.66%, Grad Norm=8.3742, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=2.0440, Train Acc=24.48%, Val Loss=2.1401, Val Acc=17.58%, Grad Norm=8.4415, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=2.0452, Train Acc=24.35%, Val Loss=2.1405, Val Acc=17.76%, Grad Norm=8.5123, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=2.0415, Train Acc=24.77%, Val Loss=2.1407, Val Acc=17.78%, Grad Norm=8.6252, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=2.0441, Train Acc=24.44%, Val Loss=2.1407, Val Acc=17.68%, Grad Norm=8.6814, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=2.0403, Train Acc=24.77%, Val Loss=2.1398, Val Acc=17.80%, Grad Norm=8.7426, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=2.0427, Train Acc=24.85%, Val Loss=2.1401, Val Acc=17.57%, Grad Norm=8.7958, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=2.0406, Train Acc=24.71%, Val Loss=2.1398, Val Acc=17.64%, Grad Norm=8.8386, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=2.0393, Train Acc=24.73%, Val Loss=2.1404, Val Acc=17.57%, Grad Norm=8.8854, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=2.0408, Train Acc=24.72%, Val Loss=2.1399, Val Acc=17.76%, Grad Norm=8.9260, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=2.0389, Train Acc=24.83%, Val Loss=2.1402, Val Acc=17.63%, Grad Norm=8.9752, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=2.0414, Train Acc=24.58%, Val Loss=2.1399, Val Acc=17.72%, Grad Norm=9.0101, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=2.0405, Train Acc=24.48%, Val Loss=2.1404, Val Acc=17.87%, Grad Norm=9.0566, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=2.0408, Train Acc=24.84%, Val Loss=2.1403, Val Acc=17.77%, Grad Norm=9.1402, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=2.0405, Train Acc=24.73%, Val Loss=2.1394, Val Acc=17.80%, Grad Norm=9.1641, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=2.0384, Train Acc=24.76%, Val Loss=2.1396, Val Acc=17.76%, Grad Norm=9.1981, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=2.0374, Train Acc=25.18%, Val Loss=2.1397, Val Acc=17.72%, Grad Norm=9.2281, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=2.0381, Train Acc=24.78%, Val Loss=2.1402, Val Acc=17.88%, Grad Norm=9.2523, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=2.0372, Train Acc=25.04%, Val Loss=2.1399, Val Acc=17.77%, Grad Norm=9.2749, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=2.0328, Train Acc=25.14%, Val Loss=2.1403, Val Acc=17.80%, Grad Norm=9.2909, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=2.0402, Train Acc=24.66%, Val Loss=2.1403, Val Acc=17.71%, Grad Norm=9.3445, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=2.0370, Train Acc=24.74%, Val Loss=2.1405, Val Acc=17.68%, Grad Norm=9.3376, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=2.0359, Train Acc=25.02%, Val Loss=2.1398, Val Acc=17.77%, Grad Norm=9.3714, LR=3.90625e-07\n",
      "Fold 4, Epoch 89: Train Loss=2.0316, Train Acc=25.20%, Val Loss=2.1399, Val Acc=17.73%, Grad Norm=9.4065, LR=3.90625e-07\n",
      "Fold 4, Epoch 90: Train Loss=2.0340, Train Acc=25.06%, Val Loss=2.1398, Val Acc=17.84%, Grad Norm=9.4157, LR=3.90625e-07\n",
      "Fold 4, Epoch 91: Train Loss=2.0364, Train Acc=24.96%, Val Loss=2.1397, Val Acc=17.80%, Grad Norm=9.4389, LR=1.95313e-07\n",
      "Fold 4, Epoch 92: Train Loss=2.0340, Train Acc=25.23%, Val Loss=2.1397, Val Acc=17.74%, Grad Norm=9.4340, LR=1.95313e-07\n",
      "Fold 4, Epoch 93: Train Loss=2.0344, Train Acc=25.00%, Val Loss=2.1402, Val Acc=17.58%, Grad Norm=9.4335, LR=1.95313e-07\n",
      "Fold 4, Epoch 94: Train Loss=2.0331, Train Acc=25.07%, Val Loss=2.1397, Val Acc=17.76%, Grad Norm=9.4587, LR=1.95313e-07\n",
      "Fold 4, Epoch 95: Train Loss=2.0349, Train Acc=25.05%, Val Loss=2.1395, Val Acc=17.88%, Grad Norm=9.4596, LR=1.95313e-07\n",
      "Fold 4, Epoch 96: Train Loss=2.0333, Train Acc=25.35%, Val Loss=2.1400, Val Acc=17.85%, Grad Norm=9.4670, LR=1.95313e-07\n",
      "Fold 4, Epoch 97: Train Loss=2.0356, Train Acc=24.68%, Val Loss=2.1396, Val Acc=17.74%, Grad Norm=9.4890, LR=1.95313e-07\n",
      "Fold 4, Epoch 98: Train Loss=2.0320, Train Acc=25.02%, Val Loss=2.1400, Val Acc=17.93%, Grad Norm=9.4996, LR=1.95313e-07\n",
      "Fold 4, Epoch 99: Train Loss=2.0364, Train Acc=25.17%, Val Loss=2.1399, Val Acc=17.82%, Grad Norm=9.5292, LR=1.95313e-07\n",
      "Fold 4, Epoch 100: Train Loss=2.0350, Train Acc=24.98%, Val Loss=2.1398, Val Acc=17.81%, Grad Norm=9.5630, LR=1.95313e-07\n",
      "Fold 4, Epoch 101: Train Loss=2.0330, Train Acc=25.32%, Val Loss=2.1401, Val Acc=17.89%, Grad Norm=9.5660, LR=9.76563e-08\n",
      "Fold 4, Epoch 102: Train Loss=2.0339, Train Acc=25.05%, Val Loss=2.1398, Val Acc=17.98%, Grad Norm=9.5658, LR=9.76563e-08\n",
      "Fold 4, Epoch 103: Train Loss=2.0324, Train Acc=25.41%, Val Loss=2.1401, Val Acc=17.82%, Grad Norm=9.5636, LR=9.76563e-08\n",
      "Fold 4, Epoch 104: Train Loss=2.0334, Train Acc=25.20%, Val Loss=2.1401, Val Acc=17.91%, Grad Norm=9.5743, LR=9.76563e-08\n",
      "Fold 4, Epoch 105: Train Loss=2.0349, Train Acc=25.05%, Val Loss=2.1402, Val Acc=17.76%, Grad Norm=9.5697, LR=9.76563e-08\n",
      "Fold 4, Epoch 106: Train Loss=2.0304, Train Acc=25.45%, Val Loss=2.1404, Val Acc=17.92%, Grad Norm=9.5701, LR=9.76563e-08\n",
      "Fold 4, Epoch 107: Train Loss=2.0333, Train Acc=25.16%, Val Loss=2.1399, Val Acc=17.75%, Grad Norm=9.5953, LR=9.76563e-08\n",
      "Fold 4, Epoch 108: Train Loss=2.0333, Train Acc=25.15%, Val Loss=2.1397, Val Acc=17.84%, Grad Norm=9.6036, LR=9.76563e-08\n",
      "Fold 4, Epoch 109: Train Loss=2.0317, Train Acc=25.13%, Val Loss=2.1396, Val Acc=17.78%, Grad Norm=9.5847, LR=9.76563e-08\n",
      "Fold 4, Epoch 110: Train Loss=2.0342, Train Acc=25.00%, Val Loss=2.1402, Val Acc=17.76%, Grad Norm=9.6444, LR=9.76563e-08\n",
      "Fold 4, Epoch 111: Train Loss=2.0336, Train Acc=25.08%, Val Loss=2.1400, Val Acc=17.76%, Grad Norm=9.6064, LR=4.88281e-08\n",
      "Fold 4, Epoch 112: Train Loss=2.0355, Train Acc=25.01%, Val Loss=2.1397, Val Acc=17.85%, Grad Norm=9.6276, LR=4.88281e-08\n",
      "Fold 4, Epoch 113: Train Loss=2.0314, Train Acc=25.27%, Val Loss=2.1398, Val Acc=17.81%, Grad Norm=9.6212, LR=4.88281e-08\n",
      "Fold 4, Epoch 114: Train Loss=2.0281, Train Acc=25.57%, Val Loss=2.1401, Val Acc=17.96%, Grad Norm=9.6276, LR=4.88281e-08\n",
      "Fold 4, Epoch 115: Train Loss=2.0319, Train Acc=25.52%, Val Loss=2.1398, Val Acc=17.95%, Grad Norm=9.6261, LR=4.88281e-08\n",
      "Fold 4, Epoch 116: Train Loss=2.0328, Train Acc=25.45%, Val Loss=2.1394, Val Acc=17.85%, Grad Norm=9.6237, LR=4.88281e-08\n",
      "Fold 4, Epoch 117: Train Loss=2.0333, Train Acc=25.07%, Val Loss=2.1397, Val Acc=17.91%, Grad Norm=9.6189, LR=4.88281e-08\n",
      "Fold 4, Epoch 118: Train Loss=2.0299, Train Acc=25.36%, Val Loss=2.1403, Val Acc=17.80%, Grad Norm=9.6261, LR=4.88281e-08\n",
      "Fold 4, Epoch 119: Train Loss=2.0350, Train Acc=24.93%, Val Loss=2.1399, Val Acc=17.85%, Grad Norm=9.6286, LR=4.88281e-08\n",
      "Fold 4, Epoch 120: Train Loss=2.0336, Train Acc=25.10%, Val Loss=2.1399, Val Acc=17.83%, Grad Norm=9.6395, LR=4.88281e-08\n",
      "Fold 4, Epoch 121: Train Loss=2.0318, Train Acc=25.07%, Val Loss=2.1397, Val Acc=17.71%, Grad Norm=9.6624, LR=2.44141e-08\n",
      "Fold 4, Epoch 122: Train Loss=2.0346, Train Acc=25.07%, Val Loss=2.1398, Val Acc=17.81%, Grad Norm=9.6499, LR=2.44141e-08\n",
      "Fold 4, Epoch 123: Train Loss=2.0322, Train Acc=25.30%, Val Loss=2.1399, Val Acc=17.87%, Grad Norm=9.6266, LR=2.44141e-08\n",
      "Fold 4, Epoch 124: Train Loss=2.0339, Train Acc=25.02%, Val Loss=2.1403, Val Acc=17.94%, Grad Norm=9.6523, LR=2.44141e-08\n",
      "Fold 4, Epoch 125: Train Loss=2.0342, Train Acc=25.14%, Val Loss=2.1394, Val Acc=17.88%, Grad Norm=9.6663, LR=2.44141e-08\n",
      "Fold 4, Epoch 126: Train Loss=2.0331, Train Acc=25.08%, Val Loss=2.1402, Val Acc=17.82%, Grad Norm=9.6484, LR=2.44141e-08\n",
      "Fold 4, Epoch 127: Train Loss=2.0334, Train Acc=25.26%, Val Loss=2.1401, Val Acc=17.91%, Grad Norm=9.6585, LR=2.44141e-08\n",
      "Fold 4, Epoch 128: Train Loss=2.0334, Train Acc=25.18%, Val Loss=2.1401, Val Acc=17.79%, Grad Norm=9.6595, LR=2.44141e-08\n",
      "Fold 4, Epoch 129: Train Loss=2.0356, Train Acc=24.98%, Val Loss=2.1398, Val Acc=17.77%, Grad Norm=9.6677, LR=2.44141e-08\n",
      "Fold 4, Epoch 130: Train Loss=2.0329, Train Acc=25.15%, Val Loss=2.1399, Val Acc=17.87%, Grad Norm=9.6562, LR=2.44141e-08\n",
      "Fold 4, Epoch 131: Train Loss=2.0312, Train Acc=25.33%, Val Loss=2.1401, Val Acc=17.87%, Grad Norm=9.6518, LR=1.2207e-08\n",
      "Fold 4, Epoch 132: Train Loss=2.0318, Train Acc=25.29%, Val Loss=2.1402, Val Acc=17.90%, Grad Norm=9.6589, LR=1.2207e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=17.98%）\n",
      "Fold 4 DONE | Best Val Acc≈17.98% | Final Val Acc=17.98% | Test Acc=18.48%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2235, Train Acc=10.82%, Val Loss=2.2318, Val Acc=11.33%, Grad Norm=6.8881, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2209, Train Acc=11.22%, Val Loss=2.2385, Val Acc=11.02%, Grad Norm=6.5338, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2163, Train Acc=11.02%, Val Loss=2.2246, Val Acc=11.12%, Grad Norm=5.6541, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2119, Train Acc=10.87%, Val Loss=2.2070, Val Acc=11.25%, Grad Norm=4.3476, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2059, Train Acc=11.20%, Val Loss=2.2285, Val Acc=10.93%, Grad Norm=3.5223, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2040, Train Acc=11.37%, Val Loss=2.2126, Val Acc=10.42%, Grad Norm=3.0730, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2032, Train Acc=11.43%, Val Loss=2.2040, Val Acc=11.31%, Grad Norm=2.7270, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2012, Train Acc=11.60%, Val Loss=2.2071, Val Acc=10.75%, Grad Norm=2.3898, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.1995, Train Acc=12.03%, Val Loss=2.1984, Val Acc=12.41%, Grad Norm=2.1433, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.1968, Train Acc=12.37%, Val Loss=2.2054, Val Acc=11.40%, Grad Norm=1.8418, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1917, Train Acc=13.30%, Val Loss=2.2001, Val Acc=12.38%, Grad Norm=1.6751, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1892, Train Acc=13.70%, Val Loss=2.1957, Val Acc=12.62%, Grad Norm=1.7016, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1870, Train Acc=14.07%, Val Loss=2.1938, Val Acc=13.18%, Grad Norm=1.7273, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1835, Train Acc=14.68%, Val Loss=2.1939, Val Acc=13.26%, Grad Norm=1.7472, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1815, Train Acc=14.78%, Val Loss=2.1936, Val Acc=13.61%, Grad Norm=1.7789, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1779, Train Acc=15.33%, Val Loss=2.1909, Val Acc=14.14%, Grad Norm=1.8824, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1740, Train Acc=15.72%, Val Loss=2.1856, Val Acc=14.43%, Grad Norm=1.9636, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1715, Train Acc=15.90%, Val Loss=2.1819, Val Acc=14.43%, Grad Norm=1.9994, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1675, Train Acc=16.22%, Val Loss=2.1804, Val Acc=14.88%, Grad Norm=2.0582, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1649, Train Acc=16.30%, Val Loss=2.1769, Val Acc=14.83%, Grad Norm=2.0670, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1557, Train Acc=17.20%, Val Loss=2.1708, Val Acc=15.09%, Grad Norm=2.1752, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1508, Train Acc=17.60%, Val Loss=2.1700, Val Acc=15.28%, Grad Norm=2.3884, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1478, Train Acc=17.81%, Val Loss=2.1658, Val Acc=15.53%, Grad Norm=2.5192, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1454, Train Acc=17.93%, Val Loss=2.1638, Val Acc=15.80%, Grad Norm=2.6318, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1414, Train Acc=18.28%, Val Loss=2.1625, Val Acc=16.09%, Grad Norm=2.7593, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1371, Train Acc=18.83%, Val Loss=2.1613, Val Acc=16.21%, Grad Norm=2.9259, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1356, Train Acc=18.70%, Val Loss=2.1595, Val Acc=16.29%, Grad Norm=3.0390, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1346, Train Acc=18.93%, Val Loss=2.1575, Val Acc=16.42%, Grad Norm=3.1213, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1308, Train Acc=19.11%, Val Loss=2.1559, Val Acc=16.70%, Grad Norm=3.2695, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1263, Train Acc=19.51%, Val Loss=2.1523, Val Acc=16.99%, Grad Norm=3.4131, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1210, Train Acc=19.77%, Val Loss=2.1552, Val Acc=16.63%, Grad Norm=3.5277, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1133, Train Acc=20.53%, Val Loss=2.1503, Val Acc=16.94%, Grad Norm=3.7311, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1151, Train Acc=20.27%, Val Loss=2.1498, Val Acc=17.25%, Grad Norm=3.9085, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1112, Train Acc=20.61%, Val Loss=2.1515, Val Acc=16.91%, Grad Norm=4.0501, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1064, Train Acc=20.86%, Val Loss=2.1488, Val Acc=17.20%, Grad Norm=4.2074, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1050, Train Acc=20.95%, Val Loss=2.1492, Val Acc=17.04%, Grad Norm=4.3796, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1030, Train Acc=20.96%, Val Loss=2.1430, Val Acc=17.75%, Grad Norm=4.5727, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=2.0992, Train Acc=21.10%, Val Loss=2.1458, Val Acc=17.54%, Grad Norm=4.7460, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=2.0980, Train Acc=21.42%, Val Loss=2.1436, Val Acc=17.69%, Grad Norm=4.8741, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=2.0940, Train Acc=21.70%, Val Loss=2.1424, Val Acc=17.61%, Grad Norm=5.0337, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=2.0920, Train Acc=21.78%, Val Loss=2.1430, Val Acc=17.76%, Grad Norm=5.1896, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=2.0873, Train Acc=22.27%, Val Loss=2.1431, Val Acc=17.47%, Grad Norm=5.3436, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=2.0847, Train Acc=22.25%, Val Loss=2.1427, Val Acc=17.47%, Grad Norm=5.5546, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=2.0811, Train Acc=22.41%, Val Loss=2.1412, Val Acc=17.62%, Grad Norm=5.7425, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=2.0777, Train Acc=22.67%, Val Loss=2.1391, Val Acc=17.97%, Grad Norm=5.8536, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=2.0794, Train Acc=22.37%, Val Loss=2.1384, Val Acc=18.04%, Grad Norm=6.0384, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=2.0756, Train Acc=22.93%, Val Loss=2.1397, Val Acc=17.75%, Grad Norm=6.2014, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=2.0742, Train Acc=22.97%, Val Loss=2.1411, Val Acc=17.64%, Grad Norm=6.3503, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=2.0728, Train Acc=22.81%, Val Loss=2.1404, Val Acc=17.69%, Grad Norm=6.5249, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=2.0717, Train Acc=23.09%, Val Loss=2.1387, Val Acc=18.06%, Grad Norm=6.6694, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=2.0672, Train Acc=23.34%, Val Loss=2.1383, Val Acc=18.08%, Grad Norm=6.8242, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=2.0665, Train Acc=23.16%, Val Loss=2.1388, Val Acc=18.02%, Grad Norm=6.9251, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=2.0648, Train Acc=23.52%, Val Loss=2.1401, Val Acc=17.77%, Grad Norm=7.0417, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=2.0615, Train Acc=23.76%, Val Loss=2.1402, Val Acc=18.06%, Grad Norm=7.1317, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=2.0629, Train Acc=23.62%, Val Loss=2.1389, Val Acc=18.03%, Grad Norm=7.2651, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=2.0590, Train Acc=24.04%, Val Loss=2.1404, Val Acc=17.86%, Grad Norm=7.3869, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=2.0563, Train Acc=23.90%, Val Loss=2.1385, Val Acc=17.91%, Grad Norm=7.5162, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=2.0565, Train Acc=23.97%, Val Loss=2.1395, Val Acc=17.88%, Grad Norm=7.6649, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=2.0532, Train Acc=24.04%, Val Loss=2.1390, Val Acc=17.79%, Grad Norm=7.7500, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=2.0565, Train Acc=23.75%, Val Loss=2.1387, Val Acc=18.01%, Grad Norm=7.8734, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=2.0518, Train Acc=24.34%, Val Loss=2.1388, Val Acc=17.84%, Grad Norm=8.0009, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=2.0492, Train Acc=24.33%, Val Loss=2.1379, Val Acc=17.78%, Grad Norm=8.1004, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=2.0496, Train Acc=24.38%, Val Loss=2.1379, Val Acc=17.71%, Grad Norm=8.1846, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=2.0510, Train Acc=24.00%, Val Loss=2.1375, Val Acc=18.02%, Grad Norm=8.2233, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=2.0478, Train Acc=24.35%, Val Loss=2.1371, Val Acc=17.86%, Grad Norm=8.3079, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=2.0525, Train Acc=24.24%, Val Loss=2.1382, Val Acc=17.74%, Grad Norm=8.3959, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=2.0483, Train Acc=24.22%, Val Loss=2.1365, Val Acc=18.13%, Grad Norm=8.4666, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=2.0454, Train Acc=24.49%, Val Loss=2.1374, Val Acc=17.87%, Grad Norm=8.5462, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=2.0448, Train Acc=24.50%, Val Loss=2.1390, Val Acc=18.06%, Grad Norm=8.6072, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=2.0480, Train Acc=24.70%, Val Loss=2.1375, Val Acc=18.21%, Grad Norm=8.6982, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=2.0442, Train Acc=24.66%, Val Loss=2.1379, Val Acc=17.96%, Grad Norm=8.7794, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=2.0440, Train Acc=24.53%, Val Loss=2.1381, Val Acc=17.93%, Grad Norm=8.7881, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=2.0434, Train Acc=24.47%, Val Loss=2.1381, Val Acc=17.91%, Grad Norm=8.8313, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=2.0429, Train Acc=24.91%, Val Loss=2.1378, Val Acc=17.94%, Grad Norm=8.8723, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=2.0436, Train Acc=24.80%, Val Loss=2.1383, Val Acc=17.89%, Grad Norm=8.9296, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=2.0418, Train Acc=25.08%, Val Loss=2.1388, Val Acc=17.95%, Grad Norm=9.0026, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=2.0408, Train Acc=24.87%, Val Loss=2.1383, Val Acc=18.02%, Grad Norm=9.0239, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=2.0398, Train Acc=24.99%, Val Loss=2.1382, Val Acc=17.94%, Grad Norm=9.0803, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=2.0393, Train Acc=25.08%, Val Loss=2.1387, Val Acc=17.99%, Grad Norm=9.1036, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=2.0390, Train Acc=24.88%, Val Loss=2.1392, Val Acc=17.97%, Grad Norm=9.1359, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=2.0359, Train Acc=25.25%, Val Loss=2.1387, Val Acc=17.97%, Grad Norm=9.1887, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=2.0383, Train Acc=25.17%, Val Loss=2.1384, Val Acc=17.91%, Grad Norm=9.2418, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=2.0385, Train Acc=24.89%, Val Loss=2.1382, Val Acc=17.99%, Grad Norm=9.2582, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=2.0378, Train Acc=25.13%, Val Loss=2.1385, Val Acc=17.96%, Grad Norm=9.2396, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=2.0376, Train Acc=24.94%, Val Loss=2.1383, Val Acc=17.96%, Grad Norm=9.3009, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=2.0375, Train Acc=25.06%, Val Loss=2.1385, Val Acc=18.03%, Grad Norm=9.3249, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=2.0385, Train Acc=24.90%, Val Loss=2.1389, Val Acc=18.19%, Grad Norm=9.3386, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=2.0392, Train Acc=25.02%, Val Loss=2.1386, Val Acc=18.14%, Grad Norm=9.3839, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=2.0381, Train Acc=24.92%, Val Loss=2.1385, Val Acc=18.01%, Grad Norm=9.4000, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=2.0341, Train Acc=25.23%, Val Loss=2.1387, Val Acc=17.99%, Grad Norm=9.4361, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=2.0343, Train Acc=25.13%, Val Loss=2.1380, Val Acc=17.97%, Grad Norm=9.4335, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=2.0390, Train Acc=25.13%, Val Loss=2.1384, Val Acc=18.08%, Grad Norm=9.4938, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=2.0368, Train Acc=25.20%, Val Loss=2.1386, Val Acc=18.06%, Grad Norm=9.4619, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=2.0371, Train Acc=25.16%, Val Loss=2.1388, Val Acc=18.22%, Grad Norm=9.5106, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=2.0341, Train Acc=25.17%, Val Loss=2.1384, Val Acc=17.99%, Grad Norm=9.4955, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=2.0372, Train Acc=24.95%, Val Loss=2.1390, Val Acc=17.85%, Grad Norm=9.4983, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=2.0379, Train Acc=24.81%, Val Loss=2.1382, Val Acc=18.01%, Grad Norm=9.5278, LR=1.95313e-07\n",
      "Fold 5, Epoch 98: Train Loss=2.0347, Train Acc=25.26%, Val Loss=2.1385, Val Acc=18.03%, Grad Norm=9.5446, LR=1.95313e-07\n",
      "Fold 5, Epoch 99: Train Loss=2.0363, Train Acc=25.07%, Val Loss=2.1383, Val Acc=18.03%, Grad Norm=9.5517, LR=1.95313e-07\n",
      "Fold 5, Epoch 100: Train Loss=2.0357, Train Acc=25.25%, Val Loss=2.1387, Val Acc=17.90%, Grad Norm=9.5778, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=18.21%）\n",
      "Fold 5 DONE | Best Val Acc≈18.21% | Final Val Acc=18.21% | Test Acc=18.52%\n",
      "[INFO] SNR=-15 dB | Mean Test Acc: 18.19% ± 0.40%\n",
      "[INFO] SNR -15 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-15dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -20 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2239, Train Acc=11.29%, Val Loss=2.2287, Val Acc=10.98%, Grad Norm=6.8396, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2223, Train Acc=11.00%, Val Loss=2.2382, Val Acc=11.28%, Grad Norm=6.5141, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2194, Train Acc=11.08%, Val Loss=2.2502, Val Acc=11.11%, Grad Norm=5.8165, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2134, Train Acc=11.23%, Val Loss=2.2829, Val Acc=11.11%, Grad Norm=4.9804, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2098, Train Acc=11.32%, Val Loss=2.2460, Val Acc=11.11%, Grad Norm=4.0728, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2073, Train Acc=11.03%, Val Loss=2.2049, Val Acc=11.03%, Grad Norm=3.4315, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2050, Train Acc=11.32%, Val Loss=2.2074, Val Acc=11.42%, Grad Norm=3.0728, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2034, Train Acc=11.23%, Val Loss=2.2232, Val Acc=11.14%, Grad Norm=2.7804, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2038, Train Acc=11.06%, Val Loss=2.2581, Val Acc=11.12%, Grad Norm=2.4834, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2019, Train Acc=11.45%, Val Loss=2.2425, Val Acc=11.15%, Grad Norm=2.2733, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.1996, Train Acc=11.45%, Val Loss=2.2052, Val Acc=11.20%, Grad Norm=1.9858, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.2000, Train Acc=11.17%, Val Loss=2.2017, Val Acc=11.09%, Grad Norm=1.8847, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.1985, Train Acc=11.49%, Val Loss=2.2003, Val Acc=11.17%, Grad Norm=1.8298, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1989, Train Acc=11.37%, Val Loss=2.2035, Val Acc=11.02%, Grad Norm=1.7505, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1987, Train Acc=11.64%, Val Loss=2.2090, Val Acc=11.15%, Grad Norm=1.7135, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1985, Train Acc=11.42%, Val Loss=2.2075, Val Acc=10.94%, Grad Norm=1.6070, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1975, Train Acc=11.81%, Val Loss=2.1997, Val Acc=11.05%, Grad Norm=1.5927, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1982, Train Acc=11.46%, Val Loss=2.2008, Val Acc=11.37%, Grad Norm=1.4622, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1975, Train Acc=11.80%, Val Loss=2.2028, Val Acc=11.20%, Grad Norm=1.3720, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1971, Train Acc=11.82%, Val Loss=2.2013, Val Acc=11.21%, Grad Norm=1.2836, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1960, Train Acc=12.20%, Val Loss=2.1989, Val Acc=11.46%, Grad Norm=1.2466, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1957, Train Acc=12.34%, Val Loss=2.1992, Val Acc=11.20%, Grad Norm=1.2709, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1957, Train Acc=12.24%, Val Loss=2.1989, Val Acc=11.38%, Grad Norm=1.2906, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1952, Train Acc=12.49%, Val Loss=2.2014, Val Acc=11.26%, Grad Norm=1.3075, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1947, Train Acc=12.23%, Val Loss=2.2001, Val Acc=11.40%, Grad Norm=1.3716, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1945, Train Acc=12.47%, Val Loss=2.1986, Val Acc=11.57%, Grad Norm=1.3557, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1945, Train Acc=12.47%, Val Loss=2.1995, Val Acc=11.42%, Grad Norm=1.3985, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1936, Train Acc=12.86%, Val Loss=2.2006, Val Acc=11.32%, Grad Norm=1.4648, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1936, Train Acc=12.88%, Val Loss=2.2005, Val Acc=11.31%, Grad Norm=1.5174, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1931, Train Acc=12.87%, Val Loss=2.1993, Val Acc=11.57%, Grad Norm=1.5062, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1918, Train Acc=13.24%, Val Loss=2.1999, Val Acc=11.49%, Grad Norm=1.6738, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1902, Train Acc=13.46%, Val Loss=2.2028, Val Acc=11.08%, Grad Norm=1.9256, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1915, Train Acc=12.99%, Val Loss=2.2019, Val Acc=11.50%, Grad Norm=1.9713, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1900, Train Acc=13.53%, Val Loss=2.2014, Val Acc=11.42%, Grad Norm=2.1246, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1903, Train Acc=13.42%, Val Loss=2.2014, Val Acc=11.48%, Grad Norm=2.1415, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1898, Train Acc=13.41%, Val Loss=2.2017, Val Acc=11.30%, Grad Norm=2.2504, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1896, Train Acc=13.70%, Val Loss=2.2012, Val Acc=11.36%, Grad Norm=2.2555, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1888, Train Acc=14.01%, Val Loss=2.2012, Val Acc=11.55%, Grad Norm=2.2684, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1883, Train Acc=13.74%, Val Loss=2.2008, Val Acc=11.63%, Grad Norm=2.4057, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1873, Train Acc=14.00%, Val Loss=2.2012, Val Acc=11.65%, Grad Norm=2.4970, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1860, Train Acc=14.27%, Val Loss=2.2015, Val Acc=11.64%, Grad Norm=2.5259, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.1851, Train Acc=14.34%, Val Loss=2.2022, Val Acc=11.53%, Grad Norm=2.6351, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=2.1849, Train Acc=14.41%, Val Loss=2.2014, Val Acc=11.65%, Grad Norm=2.6962, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=2.1847, Train Acc=14.15%, Val Loss=2.2013, Val Acc=11.58%, Grad Norm=2.7330, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=2.1847, Train Acc=14.25%, Val Loss=2.2015, Val Acc=11.40%, Grad Norm=2.7697, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=2.1836, Train Acc=14.66%, Val Loss=2.2002, Val Acc=11.69%, Grad Norm=2.8096, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=2.1846, Train Acc=14.53%, Val Loss=2.2003, Val Acc=11.57%, Grad Norm=2.8088, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=2.1837, Train Acc=14.71%, Val Loss=2.2006, Val Acc=11.52%, Grad Norm=2.8529, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=2.1830, Train Acc=14.82%, Val Loss=2.2013, Val Acc=11.47%, Grad Norm=2.9037, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=2.1828, Train Acc=14.94%, Val Loss=2.2005, Val Acc=11.54%, Grad Norm=2.9168, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=2.1811, Train Acc=14.97%, Val Loss=2.2009, Val Acc=11.66%, Grad Norm=2.9814, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=2.1817, Train Acc=15.01%, Val Loss=2.2010, Val Acc=11.51%, Grad Norm=3.0565, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=2.1809, Train Acc=14.76%, Val Loss=2.2007, Val Acc=11.58%, Grad Norm=3.1131, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=2.1807, Train Acc=14.98%, Val Loss=2.2008, Val Acc=11.58%, Grad Norm=3.1602, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=2.1806, Train Acc=15.02%, Val Loss=2.2007, Val Acc=11.63%, Grad Norm=3.1781, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=2.1801, Train Acc=15.14%, Val Loss=2.2009, Val Acc=11.57%, Grad Norm=3.2098, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=2.1787, Train Acc=15.34%, Val Loss=2.2010, Val Acc=11.60%, Grad Norm=3.2469, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=2.1800, Train Acc=14.99%, Val Loss=2.2009, Val Acc=11.60%, Grad Norm=3.2693, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=2.1782, Train Acc=15.41%, Val Loss=2.2012, Val Acc=11.59%, Grad Norm=3.3335, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=2.1795, Train Acc=15.31%, Val Loss=2.2010, Val Acc=11.61%, Grad Norm=3.3772, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=2.1794, Train Acc=15.28%, Val Loss=2.2008, Val Acc=11.60%, Grad Norm=3.4064, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=2.1775, Train Acc=15.54%, Val Loss=2.2009, Val Acc=11.66%, Grad Norm=3.4201, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=2.1776, Train Acc=15.61%, Val Loss=2.2011, Val Acc=11.66%, Grad Norm=3.4347, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=2.1783, Train Acc=15.63%, Val Loss=2.2014, Val Acc=11.71%, Grad Norm=3.4633, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=2.1781, Train Acc=15.58%, Val Loss=2.2013, Val Acc=11.64%, Grad Norm=3.4777, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=2.1768, Train Acc=15.69%, Val Loss=2.2010, Val Acc=11.58%, Grad Norm=3.5008, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=2.1778, Train Acc=15.62%, Val Loss=2.2010, Val Acc=11.52%, Grad Norm=3.5197, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=2.1772, Train Acc=15.81%, Val Loss=2.2009, Val Acc=11.63%, Grad Norm=3.5459, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=2.1777, Train Acc=15.45%, Val Loss=2.2010, Val Acc=11.52%, Grad Norm=3.5570, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=2.1757, Train Acc=16.02%, Val Loss=2.2014, Val Acc=11.52%, Grad Norm=3.5882, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=2.1768, Train Acc=15.56%, Val Loss=2.2012, Val Acc=11.55%, Grad Norm=3.5978, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=2.1756, Train Acc=15.95%, Val Loss=2.2010, Val Acc=11.58%, Grad Norm=3.6090, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=2.1759, Train Acc=15.85%, Val Loss=2.2011, Val Acc=11.58%, Grad Norm=3.6268, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=2.1767, Train Acc=15.80%, Val Loss=2.2010, Val Acc=11.49%, Grad Norm=3.6510, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=2.1764, Train Acc=15.56%, Val Loss=2.2011, Val Acc=11.46%, Grad Norm=3.6536, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=2.1764, Train Acc=15.72%, Val Loss=2.2011, Val Acc=11.59%, Grad Norm=3.6710, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=2.1756, Train Acc=15.70%, Val Loss=2.2010, Val Acc=11.56%, Grad Norm=3.6823, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=2.1752, Train Acc=16.00%, Val Loss=2.2011, Val Acc=11.69%, Grad Norm=3.7067, LR=7.8125e-07\n",
      "Fold 1, Epoch 79: Train Loss=2.1765, Train Acc=15.70%, Val Loss=2.2011, Val Acc=11.62%, Grad Norm=3.7114, LR=7.8125e-07\n",
      "Fold 1, Epoch 80: Train Loss=2.1753, Train Acc=15.71%, Val Loss=2.2011, Val Acc=11.69%, Grad Norm=3.7191, LR=7.8125e-07\n",
      "Fold 1, Epoch 81: Train Loss=2.1760, Train Acc=15.54%, Val Loss=2.2012, Val Acc=11.71%, Grad Norm=3.7277, LR=3.90625e-07\n",
      "Fold 1, Epoch 82: Train Loss=2.1765, Train Acc=15.56%, Val Loss=2.2011, Val Acc=11.67%, Grad Norm=3.7395, LR=3.90625e-07\n",
      "Fold 1, Epoch 83: Train Loss=2.1762, Train Acc=15.77%, Val Loss=2.2011, Val Acc=11.70%, Grad Norm=3.7450, LR=3.90625e-07\n",
      "Fold 1, Epoch 84: Train Loss=2.1754, Train Acc=15.71%, Val Loss=2.2010, Val Acc=11.80%, Grad Norm=3.7514, LR=3.90625e-07\n",
      "Fold 1, Epoch 85: Train Loss=2.1755, Train Acc=15.86%, Val Loss=2.2010, Val Acc=11.65%, Grad Norm=3.7513, LR=3.90625e-07\n",
      "Fold 1, Epoch 86: Train Loss=2.1757, Train Acc=15.81%, Val Loss=2.2012, Val Acc=11.71%, Grad Norm=3.7700, LR=3.90625e-07\n",
      "Fold 1, Epoch 87: Train Loss=2.1756, Train Acc=15.89%, Val Loss=2.2012, Val Acc=11.66%, Grad Norm=3.7736, LR=3.90625e-07\n",
      "Fold 1, Epoch 88: Train Loss=2.1760, Train Acc=15.78%, Val Loss=2.2010, Val Acc=11.60%, Grad Norm=3.7792, LR=3.90625e-07\n",
      "Fold 1, Epoch 89: Train Loss=2.1744, Train Acc=15.93%, Val Loss=2.2010, Val Acc=11.67%, Grad Norm=3.7884, LR=3.90625e-07\n",
      "Fold 1, Epoch 90: Train Loss=2.1746, Train Acc=15.72%, Val Loss=2.2009, Val Acc=11.65%, Grad Norm=3.8026, LR=3.90625e-07\n",
      "Fold 1, Epoch 91: Train Loss=2.1746, Train Acc=15.96%, Val Loss=2.2009, Val Acc=11.61%, Grad Norm=3.8098, LR=1.95313e-07\n",
      "Fold 1, Epoch 92: Train Loss=2.1750, Train Acc=15.77%, Val Loss=2.2010, Val Acc=11.62%, Grad Norm=3.8156, LR=1.95313e-07\n",
      "Fold 1, Epoch 93: Train Loss=2.1736, Train Acc=16.18%, Val Loss=2.2009, Val Acc=11.61%, Grad Norm=3.8152, LR=1.95313e-07\n",
      "Fold 1, Epoch 94: Train Loss=2.1755, Train Acc=15.88%, Val Loss=2.2009, Val Acc=11.64%, Grad Norm=3.8204, LR=1.95313e-07\n",
      "Fold 1, Epoch 95: Train Loss=2.1746, Train Acc=15.84%, Val Loss=2.2008, Val Acc=11.75%, Grad Norm=3.8242, LR=1.95313e-07\n",
      "Fold 1, Epoch 96: Train Loss=2.1749, Train Acc=15.83%, Val Loss=2.2009, Val Acc=11.66%, Grad Norm=3.8297, LR=1.95313e-07\n",
      "Fold 1, Epoch 97: Train Loss=2.1737, Train Acc=16.12%, Val Loss=2.2008, Val Acc=11.71%, Grad Norm=3.8283, LR=1.95313e-07\n",
      "Fold 1, Epoch 98: Train Loss=2.1755, Train Acc=15.79%, Val Loss=2.2008, Val Acc=11.73%, Grad Norm=3.8346, LR=1.95313e-07\n",
      "Fold 1, Epoch 99: Train Loss=2.1746, Train Acc=16.06%, Val Loss=2.2007, Val Acc=11.78%, Grad Norm=3.8396, LR=1.95313e-07\n",
      "Fold 1, Epoch 100: Train Loss=2.1751, Train Acc=16.00%, Val Loss=2.2009, Val Acc=11.72%, Grad Norm=3.8526, LR=1.95313e-07\n",
      "Fold 1, Epoch 101: Train Loss=2.1740, Train Acc=16.42%, Val Loss=2.2008, Val Acc=11.75%, Grad Norm=3.8512, LR=9.76563e-08\n",
      "Fold 1, Epoch 102: Train Loss=2.1752, Train Acc=16.06%, Val Loss=2.2008, Val Acc=11.69%, Grad Norm=3.8563, LR=9.76563e-08\n",
      "Fold 1, Epoch 103: Train Loss=2.1740, Train Acc=16.16%, Val Loss=2.2008, Val Acc=11.66%, Grad Norm=3.8575, LR=9.76563e-08\n",
      "Fold 1, Epoch 104: Train Loss=2.1747, Train Acc=15.92%, Val Loss=2.2007, Val Acc=11.70%, Grad Norm=3.8573, LR=9.76563e-08\n",
      "Fold 1, Epoch 105: Train Loss=2.1750, Train Acc=15.91%, Val Loss=2.2009, Val Acc=11.67%, Grad Norm=3.8597, LR=9.76563e-08\n",
      "Fold 1, Epoch 106: Train Loss=2.1742, Train Acc=16.00%, Val Loss=2.2008, Val Acc=11.68%, Grad Norm=3.8617, LR=9.76563e-08\n",
      "Fold 1, Epoch 107: Train Loss=2.1745, Train Acc=15.90%, Val Loss=2.2009, Val Acc=11.68%, Grad Norm=3.8642, LR=9.76563e-08\n",
      "Fold 1, Epoch 108: Train Loss=2.1747, Train Acc=16.17%, Val Loss=2.2009, Val Acc=11.73%, Grad Norm=3.8629, LR=9.76563e-08\n",
      "Fold 1, Epoch 109: Train Loss=2.1744, Train Acc=16.05%, Val Loss=2.2009, Val Acc=11.71%, Grad Norm=3.8700, LR=9.76563e-08\n",
      "Fold 1, Epoch 110: Train Loss=2.1746, Train Acc=15.98%, Val Loss=2.2010, Val Acc=11.68%, Grad Norm=3.8662, LR=9.76563e-08\n",
      "Fold 1, Epoch 111: Train Loss=2.1745, Train Acc=15.90%, Val Loss=2.2009, Val Acc=11.63%, Grad Norm=3.8700, LR=4.88281e-08\n",
      "Fold 1, Epoch 112: Train Loss=2.1746, Train Acc=15.83%, Val Loss=2.2008, Val Acc=11.70%, Grad Norm=3.8757, LR=4.88281e-08\n",
      "Fold 1, Epoch 113: Train Loss=2.1745, Train Acc=15.95%, Val Loss=2.2008, Val Acc=11.69%, Grad Norm=3.8726, LR=4.88281e-08\n",
      "Fold 1, Epoch 114: Train Loss=2.1743, Train Acc=15.80%, Val Loss=2.2009, Val Acc=11.64%, Grad Norm=3.8784, LR=4.88281e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.80%）\n",
      "Fold 1 DONE | Best Val Acc≈11.80% | Final Val Acc=11.80% | Test Acc=11.84%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2258, Train Acc=11.14%, Val Loss=2.2795, Val Acc=11.12%, Grad Norm=6.9081, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2230, Train Acc=11.21%, Val Loss=2.2544, Val Acc=11.08%, Grad Norm=6.6293, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2202, Train Acc=10.98%, Val Loss=2.2467, Val Acc=11.11%, Grad Norm=6.0148, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2138, Train Acc=11.13%, Val Loss=2.2159, Val Acc=11.10%, Grad Norm=5.0454, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2105, Train Acc=10.98%, Val Loss=2.2201, Val Acc=11.24%, Grad Norm=4.0525, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2065, Train Acc=11.13%, Val Loss=2.2211, Val Acc=11.21%, Grad Norm=3.4006, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2048, Train Acc=11.13%, Val Loss=2.2058, Val Acc=10.88%, Grad Norm=3.1060, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2037, Train Acc=11.27%, Val Loss=2.2124, Val Acc=11.14%, Grad Norm=2.8323, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2039, Train Acc=10.95%, Val Loss=2.2062, Val Acc=11.05%, Grad Norm=2.5082, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.2016, Train Acc=11.30%, Val Loss=2.2109, Val Acc=11.34%, Grad Norm=2.2567, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.2007, Train Acc=11.25%, Val Loss=2.2009, Val Acc=11.18%, Grad Norm=1.9922, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.1992, Train Acc=11.51%, Val Loss=2.2057, Val Acc=11.10%, Grad Norm=1.8387, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.1989, Train Acc=11.51%, Val Loss=2.2026, Val Acc=11.15%, Grad Norm=1.8130, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1986, Train Acc=11.63%, Val Loss=2.2051, Val Acc=11.08%, Grad Norm=1.7826, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1985, Train Acc=11.36%, Val Loss=2.2002, Val Acc=11.03%, Grad Norm=1.7310, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1978, Train Acc=11.72%, Val Loss=2.2010, Val Acc=11.52%, Grad Norm=1.6822, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1978, Train Acc=11.76%, Val Loss=2.2001, Val Acc=11.20%, Grad Norm=1.5554, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1974, Train Acc=11.89%, Val Loss=2.2011, Val Acc=11.45%, Grad Norm=1.5152, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1972, Train Acc=11.95%, Val Loss=2.1997, Val Acc=11.41%, Grad Norm=1.4088, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1959, Train Acc=12.14%, Val Loss=2.2001, Val Acc=11.22%, Grad Norm=1.4233, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1952, Train Acc=12.53%, Val Loss=2.1988, Val Acc=11.48%, Grad Norm=1.3494, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1946, Train Acc=12.49%, Val Loss=2.1997, Val Acc=11.35%, Grad Norm=1.4073, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1941, Train Acc=12.75%, Val Loss=2.1998, Val Acc=11.35%, Grad Norm=1.4253, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1940, Train Acc=12.63%, Val Loss=2.2010, Val Acc=11.36%, Grad Norm=1.4414, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1943, Train Acc=12.50%, Val Loss=2.1989, Val Acc=11.72%, Grad Norm=1.5165, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1935, Train Acc=12.74%, Val Loss=2.1986, Val Acc=11.28%, Grad Norm=1.5074, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1929, Train Acc=12.97%, Val Loss=2.1989, Val Acc=11.67%, Grad Norm=1.5532, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1919, Train Acc=13.20%, Val Loss=2.1998, Val Acc=11.81%, Grad Norm=1.6476, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1918, Train Acc=12.92%, Val Loss=2.1994, Val Acc=11.59%, Grad Norm=1.6851, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1914, Train Acc=13.13%, Val Loss=2.2004, Val Acc=11.62%, Grad Norm=1.7538, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1900, Train Acc=13.43%, Val Loss=2.1998, Val Acc=11.64%, Grad Norm=1.8261, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1888, Train Acc=13.84%, Val Loss=2.1993, Val Acc=11.85%, Grad Norm=2.0821, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1885, Train Acc=13.65%, Val Loss=2.1995, Val Acc=11.88%, Grad Norm=2.1435, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1887, Train Acc=13.81%, Val Loss=2.2003, Val Acc=11.82%, Grad Norm=2.2358, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1872, Train Acc=13.80%, Val Loss=2.2005, Val Acc=11.92%, Grad Norm=2.3837, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1874, Train Acc=13.72%, Val Loss=2.2004, Val Acc=11.75%, Grad Norm=2.4285, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1865, Train Acc=14.09%, Val Loss=2.2011, Val Acc=11.74%, Grad Norm=2.4761, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1868, Train Acc=14.02%, Val Loss=2.2007, Val Acc=11.95%, Grad Norm=2.5664, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1859, Train Acc=14.58%, Val Loss=2.2000, Val Acc=12.06%, Grad Norm=2.5574, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1839, Train Acc=14.19%, Val Loss=2.2004, Val Acc=11.82%, Grad Norm=2.6682, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1829, Train Acc=14.44%, Val Loss=2.2008, Val Acc=11.93%, Grad Norm=2.7324, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1839, Train Acc=14.54%, Val Loss=2.2000, Val Acc=12.01%, Grad Norm=2.8089, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1819, Train Acc=14.85%, Val Loss=2.2001, Val Acc=12.10%, Grad Norm=2.8590, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1815, Train Acc=14.79%, Val Loss=2.2001, Val Acc=11.98%, Grad Norm=2.9280, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1814, Train Acc=14.82%, Val Loss=2.1997, Val Acc=12.05%, Grad Norm=2.9668, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1809, Train Acc=15.03%, Val Loss=2.1998, Val Acc=12.12%, Grad Norm=3.0347, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1804, Train Acc=15.01%, Val Loss=2.1995, Val Acc=12.30%, Grad Norm=3.1003, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.1807, Train Acc=14.88%, Val Loss=2.1995, Val Acc=12.19%, Grad Norm=3.1339, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.1795, Train Acc=15.09%, Val Loss=2.1999, Val Acc=12.02%, Grad Norm=3.1714, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.1795, Train Acc=15.22%, Val Loss=2.1996, Val Acc=12.13%, Grad Norm=3.2282, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.1776, Train Acc=15.58%, Val Loss=2.1996, Val Acc=12.02%, Grad Norm=3.2806, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.1776, Train Acc=15.58%, Val Loss=2.1996, Val Acc=12.04%, Grad Norm=3.3128, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.1767, Train Acc=15.80%, Val Loss=2.1998, Val Acc=12.00%, Grad Norm=3.3602, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.1769, Train Acc=15.25%, Val Loss=2.2000, Val Acc=12.02%, Grad Norm=3.4122, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.1767, Train Acc=15.37%, Val Loss=2.2001, Val Acc=12.03%, Grad Norm=3.4529, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.1754, Train Acc=15.70%, Val Loss=2.1997, Val Acc=12.01%, Grad Norm=3.4891, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.1758, Train Acc=15.71%, Val Loss=2.1992, Val Acc=12.02%, Grad Norm=3.5250, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.1740, Train Acc=15.95%, Val Loss=2.1995, Val Acc=11.93%, Grad Norm=3.5620, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.1754, Train Acc=15.70%, Val Loss=2.1998, Val Acc=11.98%, Grad Norm=3.6146, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.1746, Train Acc=15.98%, Val Loss=2.1995, Val Acc=12.10%, Grad Norm=3.6345, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.1741, Train Acc=16.05%, Val Loss=2.1997, Val Acc=12.11%, Grad Norm=3.6749, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.1745, Train Acc=15.56%, Val Loss=2.1994, Val Acc=12.06%, Grad Norm=3.7000, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=2.1744, Train Acc=15.58%, Val Loss=2.1996, Val Acc=12.16%, Grad Norm=3.7310, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=2.1741, Train Acc=16.02%, Val Loss=2.1998, Val Acc=12.17%, Grad Norm=3.7488, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=2.1731, Train Acc=15.79%, Val Loss=2.2000, Val Acc=12.19%, Grad Norm=3.7668, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=2.1730, Train Acc=15.82%, Val Loss=2.2001, Val Acc=12.13%, Grad Norm=3.7912, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=2.1723, Train Acc=16.22%, Val Loss=2.2001, Val Acc=12.03%, Grad Norm=3.8171, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=2.1739, Train Acc=15.89%, Val Loss=2.2000, Val Acc=12.10%, Grad Norm=3.8465, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=2.1737, Train Acc=15.96%, Val Loss=2.1998, Val Acc=12.00%, Grad Norm=3.8740, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=2.1723, Train Acc=16.02%, Val Loss=2.1998, Val Acc=12.14%, Grad Norm=3.8941, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=2.1722, Train Acc=16.06%, Val Loss=2.1998, Val Acc=12.12%, Grad Norm=3.9171, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=2.1723, Train Acc=16.23%, Val Loss=2.1998, Val Acc=12.10%, Grad Norm=3.9269, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=2.1709, Train Acc=16.21%, Val Loss=2.1995, Val Acc=12.14%, Grad Norm=3.9418, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=2.1722, Train Acc=16.23%, Val Loss=2.1998, Val Acc=12.18%, Grad Norm=3.9718, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=2.1715, Train Acc=16.36%, Val Loss=2.1998, Val Acc=12.09%, Grad Norm=3.9811, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=2.1710, Train Acc=16.20%, Val Loss=2.1997, Val Acc=12.17%, Grad Norm=3.9966, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=2.1707, Train Acc=16.37%, Val Loss=2.1997, Val Acc=12.17%, Grad Norm=4.0191, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=12.30%）\n",
      "Fold 2 DONE | Best Val Acc≈12.30% | Final Val Acc=12.30% | Test Acc=12.02%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2222, Train Acc=11.48%, Val Loss=2.2329, Val Acc=11.11%, Grad Norm=6.7902, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2219, Train Acc=11.11%, Val Loss=2.2830, Val Acc=11.37%, Grad Norm=6.5081, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2197, Train Acc=11.23%, Val Loss=2.2337, Val Acc=11.18%, Grad Norm=5.8145, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2127, Train Acc=11.20%, Val Loss=2.2345, Val Acc=11.14%, Grad Norm=4.8589, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2089, Train Acc=11.37%, Val Loss=2.2278, Val Acc=10.89%, Grad Norm=3.8737, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2054, Train Acc=11.01%, Val Loss=2.2162, Val Acc=11.11%, Grad Norm=3.3144, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2051, Train Acc=11.42%, Val Loss=2.2096, Val Acc=11.17%, Grad Norm=2.9493, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2040, Train Acc=11.27%, Val Loss=2.2079, Val Acc=11.02%, Grad Norm=2.6566, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2039, Train Acc=10.96%, Val Loss=2.2141, Val Acc=11.10%, Grad Norm=2.2743, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.2018, Train Acc=11.48%, Val Loss=2.2091, Val Acc=11.13%, Grad Norm=1.9966, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.1992, Train Acc=11.55%, Val Loss=2.2080, Val Acc=10.88%, Grad Norm=1.8403, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.1983, Train Acc=11.71%, Val Loss=2.2027, Val Acc=11.08%, Grad Norm=1.7828, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1982, Train Acc=11.73%, Val Loss=2.2013, Val Acc=11.22%, Grad Norm=1.7604, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1984, Train Acc=11.68%, Val Loss=2.2039, Val Acc=11.30%, Grad Norm=1.6395, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1979, Train Acc=11.99%, Val Loss=2.2054, Val Acc=11.02%, Grad Norm=1.5551, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1974, Train Acc=11.87%, Val Loss=2.2005, Val Acc=11.12%, Grad Norm=1.5100, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1975, Train Acc=11.84%, Val Loss=2.1990, Val Acc=11.33%, Grad Norm=1.4393, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1966, Train Acc=12.21%, Val Loss=2.2015, Val Acc=11.08%, Grad Norm=1.3773, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1961, Train Acc=12.14%, Val Loss=2.1988, Val Acc=11.39%, Grad Norm=1.3932, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1961, Train Acc=12.28%, Val Loss=2.1991, Val Acc=11.28%, Grad Norm=1.2667, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1948, Train Acc=12.72%, Val Loss=2.1996, Val Acc=11.60%, Grad Norm=1.2397, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1943, Train Acc=12.59%, Val Loss=2.1996, Val Acc=11.41%, Grad Norm=1.2898, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1940, Train Acc=12.69%, Val Loss=2.1999, Val Acc=11.54%, Grad Norm=1.3280, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1933, Train Acc=12.96%, Val Loss=2.1999, Val Acc=11.38%, Grad Norm=1.4157, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1933, Train Acc=12.86%, Val Loss=2.1997, Val Acc=11.58%, Grad Norm=1.4466, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1927, Train Acc=13.11%, Val Loss=2.1999, Val Acc=11.46%, Grad Norm=1.4742, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1917, Train Acc=13.06%, Val Loss=2.2018, Val Acc=11.55%, Grad Norm=1.5508, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1917, Train Acc=13.28%, Val Loss=2.2002, Val Acc=11.61%, Grad Norm=1.6811, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1911, Train Acc=13.49%, Val Loss=2.2006, Val Acc=11.55%, Grad Norm=1.6474, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1906, Train Acc=13.31%, Val Loss=2.2005, Val Acc=11.42%, Grad Norm=1.7362, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1901, Train Acc=13.70%, Val Loss=2.2006, Val Acc=11.48%, Grad Norm=1.8165, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1885, Train Acc=13.80%, Val Loss=2.2006, Val Acc=11.54%, Grad Norm=2.0158, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1883, Train Acc=13.94%, Val Loss=2.2015, Val Acc=11.41%, Grad Norm=2.0760, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1873, Train Acc=14.03%, Val Loss=2.2019, Val Acc=11.51%, Grad Norm=2.2644, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1871, Train Acc=13.65%, Val Loss=2.2016, Val Acc=11.58%, Grad Norm=2.3225, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1858, Train Acc=14.02%, Val Loss=2.2011, Val Acc=11.49%, Grad Norm=2.3940, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1844, Train Acc=14.34%, Val Loss=2.2022, Val Acc=11.34%, Grad Norm=2.5462, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1851, Train Acc=14.51%, Val Loss=2.2023, Val Acc=11.51%, Grad Norm=2.5724, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1838, Train Acc=14.54%, Val Loss=2.2025, Val Acc=11.44%, Grad Norm=2.6398, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.1833, Train Acc=14.73%, Val Loss=2.2023, Val Acc=11.71%, Grad Norm=2.7311, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.1825, Train Acc=14.78%, Val Loss=2.2022, Val Acc=11.59%, Grad Norm=2.7617, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.1816, Train Acc=14.66%, Val Loss=2.2014, Val Acc=11.72%, Grad Norm=2.8229, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.1812, Train Acc=14.95%, Val Loss=2.2012, Val Acc=11.66%, Grad Norm=2.8957, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.1804, Train Acc=15.02%, Val Loss=2.2015, Val Acc=11.80%, Grad Norm=2.9507, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.1789, Train Acc=15.03%, Val Loss=2.2012, Val Acc=11.75%, Grad Norm=3.0154, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.1798, Train Acc=14.99%, Val Loss=2.2014, Val Acc=11.68%, Grad Norm=3.0611, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.1793, Train Acc=14.87%, Val Loss=2.2020, Val Acc=11.68%, Grad Norm=3.0870, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.1787, Train Acc=14.95%, Val Loss=2.2008, Val Acc=11.80%, Grad Norm=3.1339, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.1787, Train Acc=15.20%, Val Loss=2.2013, Val Acc=11.56%, Grad Norm=3.1640, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.1772, Train Acc=15.54%, Val Loss=2.2017, Val Acc=11.69%, Grad Norm=3.2072, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.1767, Train Acc=15.53%, Val Loss=2.2013, Val Acc=11.75%, Grad Norm=3.2620, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.1770, Train Acc=15.16%, Val Loss=2.2015, Val Acc=11.69%, Grad Norm=3.3081, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=2.1761, Train Acc=15.72%, Val Loss=2.2011, Val Acc=11.76%, Grad Norm=3.3357, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=2.1764, Train Acc=15.69%, Val Loss=2.2015, Val Acc=11.85%, Grad Norm=3.3683, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=2.1760, Train Acc=15.59%, Val Loss=2.2012, Val Acc=11.77%, Grad Norm=3.4287, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=2.1746, Train Acc=15.94%, Val Loss=2.2011, Val Acc=11.81%, Grad Norm=3.4879, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=2.1750, Train Acc=15.95%, Val Loss=2.2013, Val Acc=11.95%, Grad Norm=3.5240, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=2.1739, Train Acc=15.96%, Val Loss=2.2013, Val Acc=11.83%, Grad Norm=3.5719, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=2.1750, Train Acc=15.80%, Val Loss=2.2007, Val Acc=11.86%, Grad Norm=3.5884, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=2.1735, Train Acc=15.82%, Val Loss=2.2014, Val Acc=11.78%, Grad Norm=3.6324, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=2.1724, Train Acc=16.34%, Val Loss=2.2011, Val Acc=11.84%, Grad Norm=3.6598, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=2.1720, Train Acc=16.49%, Val Loss=2.2012, Val Acc=11.88%, Grad Norm=3.7084, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=2.1733, Train Acc=15.94%, Val Loss=2.2015, Val Acc=11.86%, Grad Norm=3.7268, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=2.1738, Train Acc=15.92%, Val Loss=2.2013, Val Acc=11.84%, Grad Norm=3.7539, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=2.1719, Train Acc=16.13%, Val Loss=2.2013, Val Acc=12.04%, Grad Norm=3.7759, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=2.1733, Train Acc=16.17%, Val Loss=2.2013, Val Acc=11.93%, Grad Norm=3.8059, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=2.1713, Train Acc=16.12%, Val Loss=2.2017, Val Acc=11.86%, Grad Norm=3.8336, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=2.1708, Train Acc=16.16%, Val Loss=2.2013, Val Acc=11.88%, Grad Norm=3.8743, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=2.1703, Train Acc=16.38%, Val Loss=2.2016, Val Acc=11.92%, Grad Norm=3.8961, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=2.1708, Train Acc=16.13%, Val Loss=2.2016, Val Acc=12.01%, Grad Norm=3.9250, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=2.1709, Train Acc=16.31%, Val Loss=2.2014, Val Acc=12.01%, Grad Norm=3.9489, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=2.1711, Train Acc=16.20%, Val Loss=2.2013, Val Acc=11.95%, Grad Norm=3.9651, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=2.1698, Train Acc=16.51%, Val Loss=2.2015, Val Acc=11.99%, Grad Norm=3.9803, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=2.1700, Train Acc=16.13%, Val Loss=2.2014, Val Acc=12.00%, Grad Norm=4.0228, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=2.1710, Train Acc=16.08%, Val Loss=2.2017, Val Acc=11.96%, Grad Norm=4.0237, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=2.1702, Train Acc=16.47%, Val Loss=2.2016, Val Acc=12.02%, Grad Norm=4.0533, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=2.1695, Train Acc=16.49%, Val Loss=2.2018, Val Acc=11.94%, Grad Norm=4.0697, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=2.1691, Train Acc=16.64%, Val Loss=2.2016, Val Acc=12.07%, Grad Norm=4.0921, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=2.1692, Train Acc=16.42%, Val Loss=2.2017, Val Acc=12.01%, Grad Norm=4.1140, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=2.1705, Train Acc=16.44%, Val Loss=2.2015, Val Acc=11.92%, Grad Norm=4.1439, LR=7.8125e-07\n",
      "Fold 3, Epoch 81: Train Loss=2.1692, Train Acc=16.45%, Val Loss=2.2016, Val Acc=12.00%, Grad Norm=4.1594, LR=3.90625e-07\n",
      "Fold 3, Epoch 82: Train Loss=2.1700, Train Acc=16.42%, Val Loss=2.2016, Val Acc=12.00%, Grad Norm=4.1724, LR=3.90625e-07\n",
      "Fold 3, Epoch 83: Train Loss=2.1688, Train Acc=16.66%, Val Loss=2.2015, Val Acc=11.98%, Grad Norm=4.1720, LR=3.90625e-07\n",
      "Fold 3, Epoch 84: Train Loss=2.1694, Train Acc=16.68%, Val Loss=2.2015, Val Acc=11.93%, Grad Norm=4.1771, LR=3.90625e-07\n",
      "Fold 3, Epoch 85: Train Loss=2.1678, Train Acc=16.76%, Val Loss=2.2017, Val Acc=11.91%, Grad Norm=4.1835, LR=3.90625e-07\n",
      "Fold 3, Epoch 86: Train Loss=2.1698, Train Acc=16.28%, Val Loss=2.2016, Val Acc=11.87%, Grad Norm=4.1945, LR=3.90625e-07\n",
      "Fold 3, Epoch 87: Train Loss=2.1682, Train Acc=16.54%, Val Loss=2.2016, Val Acc=11.94%, Grad Norm=4.2114, LR=3.90625e-07\n",
      "Fold 3, Epoch 88: Train Loss=2.1689, Train Acc=16.66%, Val Loss=2.2018, Val Acc=11.90%, Grad Norm=4.2134, LR=3.90625e-07\n",
      "Fold 3, Epoch 89: Train Loss=2.1696, Train Acc=16.62%, Val Loss=2.2015, Val Acc=11.88%, Grad Norm=4.2205, LR=3.90625e-07\n",
      "Fold 3, Epoch 90: Train Loss=2.1678, Train Acc=16.65%, Val Loss=2.2016, Val Acc=11.92%, Grad Norm=4.2260, LR=3.90625e-07\n",
      "Fold 3, Epoch 91: Train Loss=2.1681, Train Acc=16.56%, Val Loss=2.2016, Val Acc=11.89%, Grad Norm=4.2352, LR=1.95313e-07\n",
      "Fold 3, Epoch 92: Train Loss=2.1685, Train Acc=16.46%, Val Loss=2.2015, Val Acc=11.89%, Grad Norm=4.2432, LR=1.95313e-07\n",
      "Fold 3, Epoch 93: Train Loss=2.1670, Train Acc=16.79%, Val Loss=2.2014, Val Acc=11.88%, Grad Norm=4.2566, LR=1.95313e-07\n",
      "Fold 3, Epoch 94: Train Loss=2.1693, Train Acc=16.64%, Val Loss=2.2016, Val Acc=11.90%, Grad Norm=4.2549, LR=1.95313e-07\n",
      "Fold 3, Epoch 95: Train Loss=2.1689, Train Acc=16.58%, Val Loss=2.2015, Val Acc=11.86%, Grad Norm=4.2566, LR=1.95313e-07\n",
      "Fold 3, Epoch 96: Train Loss=2.1680, Train Acc=16.65%, Val Loss=2.2014, Val Acc=11.97%, Grad Norm=4.2593, LR=1.95313e-07\n",
      "Fold 3, Epoch 97: Train Loss=2.1684, Train Acc=16.39%, Val Loss=2.2014, Val Acc=11.98%, Grad Norm=4.2742, LR=1.95313e-07\n",
      "Fold 3, Epoch 98: Train Loss=2.1685, Train Acc=16.69%, Val Loss=2.2016, Val Acc=11.95%, Grad Norm=4.2712, LR=1.95313e-07\n",
      "Fold 3, Epoch 99: Train Loss=2.1691, Train Acc=16.21%, Val Loss=2.2015, Val Acc=11.93%, Grad Norm=4.2824, LR=1.95313e-07\n",
      "Fold 3, Epoch 100: Train Loss=2.1689, Train Acc=16.67%, Val Loss=2.2015, Val Acc=11.89%, Grad Norm=4.2868, LR=1.95313e-07\n",
      "Fold 3, Epoch 101: Train Loss=2.1690, Train Acc=16.64%, Val Loss=2.2015, Val Acc=11.96%, Grad Norm=4.2860, LR=9.76563e-08\n",
      "Fold 3, Epoch 102: Train Loss=2.1692, Train Acc=16.58%, Val Loss=2.2016, Val Acc=11.92%, Grad Norm=4.2931, LR=9.76563e-08\n",
      "Fold 3, Epoch 103: Train Loss=2.1687, Train Acc=16.77%, Val Loss=2.2014, Val Acc=11.93%, Grad Norm=4.2969, LR=9.76563e-08\n",
      "Fold 3, Epoch 104: Train Loss=2.1704, Train Acc=16.21%, Val Loss=2.2015, Val Acc=11.88%, Grad Norm=4.2935, LR=9.76563e-08\n",
      "Fold 3, Epoch 105: Train Loss=2.1672, Train Acc=16.70%, Val Loss=2.2015, Val Acc=11.88%, Grad Norm=4.3027, LR=9.76563e-08\n",
      "Fold 3, Epoch 106: Train Loss=2.1693, Train Acc=16.45%, Val Loss=2.2015, Val Acc=11.92%, Grad Norm=4.3009, LR=9.76563e-08\n",
      "Fold 3, Epoch 107: Train Loss=2.1681, Train Acc=16.65%, Val Loss=2.2014, Val Acc=11.93%, Grad Norm=4.3081, LR=9.76563e-08\n",
      "Fold 3, Epoch 108: Train Loss=2.1670, Train Acc=16.46%, Val Loss=2.2015, Val Acc=11.87%, Grad Norm=4.3020, LR=9.76563e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=12.07%）\n",
      "Fold 3 DONE | Best Val Acc≈12.07% | Final Val Acc=12.07% | Test Acc=12.02%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2246, Train Acc=11.02%, Val Loss=2.2805, Val Acc=11.08%, Grad Norm=6.8768, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2210, Train Acc=11.19%, Val Loss=2.2256, Val Acc=11.11%, Grad Norm=6.5055, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2171, Train Acc=10.95%, Val Loss=2.2272, Val Acc=11.23%, Grad Norm=5.6416, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2100, Train Acc=11.12%, Val Loss=2.2266, Val Acc=11.37%, Grad Norm=4.3377, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2059, Train Acc=11.20%, Val Loss=2.2176, Val Acc=11.19%, Grad Norm=3.3813, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2053, Train Acc=11.00%, Val Loss=2.2063, Val Acc=11.11%, Grad Norm=2.9844, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2033, Train Acc=11.50%, Val Loss=2.2055, Val Acc=11.23%, Grad Norm=2.6353, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.2029, Train Acc=11.24%, Val Loss=2.2198, Val Acc=11.09%, Grad Norm=2.2803, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.2018, Train Acc=11.07%, Val Loss=2.2037, Val Acc=11.10%, Grad Norm=1.9236, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.2011, Train Acc=11.27%, Val Loss=2.2021, Val Acc=11.13%, Grad Norm=1.6272, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1989, Train Acc=11.65%, Val Loss=2.1993, Val Acc=11.28%, Grad Norm=1.3975, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1983, Train Acc=11.53%, Val Loss=2.2007, Val Acc=10.69%, Grad Norm=1.3523, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1987, Train Acc=11.53%, Val Loss=2.1984, Val Acc=11.18%, Grad Norm=1.3264, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1977, Train Acc=11.70%, Val Loss=2.2017, Val Acc=11.23%, Grad Norm=1.2804, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1981, Train Acc=11.44%, Val Loss=2.1994, Val Acc=11.06%, Grad Norm=1.1495, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1976, Train Acc=11.47%, Val Loss=2.1985, Val Acc=11.28%, Grad Norm=1.1330, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1972, Train Acc=11.62%, Val Loss=2.1982, Val Acc=11.37%, Grad Norm=1.0507, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1969, Train Acc=11.73%, Val Loss=2.2021, Val Acc=11.28%, Grad Norm=1.0319, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1968, Train Acc=11.79%, Val Loss=2.1988, Val Acc=11.20%, Grad Norm=0.9299, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1965, Train Acc=11.99%, Val Loss=2.1985, Val Acc=11.36%, Grad Norm=0.8555, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1960, Train Acc=11.90%, Val Loss=2.1983, Val Acc=11.27%, Grad Norm=0.8674, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1955, Train Acc=12.14%, Val Loss=2.1984, Val Acc=11.58%, Grad Norm=0.9911, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1950, Train Acc=12.60%, Val Loss=2.1977, Val Acc=11.77%, Grad Norm=1.0879, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1950, Train Acc=12.41%, Val Loss=2.1988, Val Acc=11.04%, Grad Norm=1.0570, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1948, Train Acc=12.60%, Val Loss=2.1989, Val Acc=11.18%, Grad Norm=1.0935, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1945, Train Acc=12.55%, Val Loss=2.1971, Val Acc=11.76%, Grad Norm=1.1924, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1939, Train Acc=12.58%, Val Loss=2.1998, Val Acc=11.38%, Grad Norm=1.2481, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1943, Train Acc=12.70%, Val Loss=2.1987, Val Acc=11.25%, Grad Norm=1.2049, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1937, Train Acc=13.02%, Val Loss=2.1979, Val Acc=11.59%, Grad Norm=1.2324, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1940, Train Acc=12.79%, Val Loss=2.1988, Val Acc=11.19%, Grad Norm=1.2454, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1930, Train Acc=13.11%, Val Loss=2.1988, Val Acc=11.56%, Grad Norm=1.2030, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1919, Train Acc=13.24%, Val Loss=2.1985, Val Acc=11.62%, Grad Norm=1.3673, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=2.1917, Train Acc=13.26%, Val Loss=2.1992, Val Acc=11.26%, Grad Norm=1.4576, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=2.1914, Train Acc=13.45%, Val Loss=2.1983, Val Acc=11.44%, Grad Norm=1.4879, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=2.1907, Train Acc=13.43%, Val Loss=2.1980, Val Acc=11.71%, Grad Norm=1.5204, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=2.1910, Train Acc=13.51%, Val Loss=2.1980, Val Acc=11.62%, Grad Norm=1.5077, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=2.1901, Train Acc=13.55%, Val Loss=2.1978, Val Acc=11.51%, Grad Norm=1.6010, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=2.1903, Train Acc=13.62%, Val Loss=2.1982, Val Acc=11.72%, Grad Norm=1.6501, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=2.1900, Train Acc=13.60%, Val Loss=2.1984, Val Acc=11.43%, Grad Norm=1.7002, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=2.1895, Train Acc=13.81%, Val Loss=2.1981, Val Acc=11.74%, Grad Norm=1.7509, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=2.1888, Train Acc=13.96%, Val Loss=2.1980, Val Acc=11.64%, Grad Norm=1.8347, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=2.1885, Train Acc=13.99%, Val Loss=2.1978, Val Acc=11.59%, Grad Norm=1.8745, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=2.1880, Train Acc=13.90%, Val Loss=2.1979, Val Acc=11.62%, Grad Norm=1.8952, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=2.1874, Train Acc=14.13%, Val Loss=2.1978, Val Acc=11.95%, Grad Norm=2.0096, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=2.1872, Train Acc=14.18%, Val Loss=2.1981, Val Acc=11.39%, Grad Norm=2.0935, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=2.1870, Train Acc=14.34%, Val Loss=2.1981, Val Acc=11.90%, Grad Norm=2.1591, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=2.1868, Train Acc=14.35%, Val Loss=2.1981, Val Acc=11.75%, Grad Norm=2.2499, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=2.1864, Train Acc=14.27%, Val Loss=2.1981, Val Acc=11.82%, Grad Norm=2.3119, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=2.1864, Train Acc=14.53%, Val Loss=2.1984, Val Acc=11.83%, Grad Norm=2.3648, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=2.1853, Train Acc=14.66%, Val Loss=2.1984, Val Acc=11.96%, Grad Norm=2.4190, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=2.1849, Train Acc=14.75%, Val Loss=2.1983, Val Acc=11.88%, Grad Norm=2.4942, LR=3.125e-06\n",
      "Fold 4, Epoch 52: Train Loss=2.1840, Train Acc=14.78%, Val Loss=2.1984, Val Acc=11.98%, Grad Norm=2.5659, LR=3.125e-06\n",
      "Fold 4, Epoch 53: Train Loss=2.1846, Train Acc=14.69%, Val Loss=2.1983, Val Acc=11.87%, Grad Norm=2.6126, LR=3.125e-06\n",
      "Fold 4, Epoch 54: Train Loss=2.1842, Train Acc=14.49%, Val Loss=2.1985, Val Acc=11.89%, Grad Norm=2.6569, LR=3.125e-06\n",
      "Fold 4, Epoch 55: Train Loss=2.1839, Train Acc=14.86%, Val Loss=2.1985, Val Acc=11.88%, Grad Norm=2.7015, LR=3.125e-06\n",
      "Fold 4, Epoch 56: Train Loss=2.1843, Train Acc=14.92%, Val Loss=2.1982, Val Acc=11.66%, Grad Norm=2.7633, LR=3.125e-06\n",
      "Fold 4, Epoch 57: Train Loss=2.1825, Train Acc=14.97%, Val Loss=2.1983, Val Acc=11.88%, Grad Norm=2.8130, LR=3.125e-06\n",
      "Fold 4, Epoch 58: Train Loss=2.1828, Train Acc=14.85%, Val Loss=2.1988, Val Acc=12.06%, Grad Norm=2.8654, LR=3.125e-06\n",
      "Fold 4, Epoch 59: Train Loss=2.1829, Train Acc=15.03%, Val Loss=2.1984, Val Acc=11.89%, Grad Norm=2.9397, LR=3.125e-06\n",
      "Fold 4, Epoch 60: Train Loss=2.1832, Train Acc=14.55%, Val Loss=2.1987, Val Acc=11.80%, Grad Norm=2.9637, LR=3.125e-06\n",
      "Fold 4, Epoch 61: Train Loss=2.1821, Train Acc=15.10%, Val Loss=2.1988, Val Acc=12.01%, Grad Norm=3.0045, LR=1.5625e-06\n",
      "Fold 4, Epoch 62: Train Loss=2.1816, Train Acc=15.01%, Val Loss=2.1987, Val Acc=12.00%, Grad Norm=3.0646, LR=1.5625e-06\n",
      "Fold 4, Epoch 63: Train Loss=2.1818, Train Acc=15.11%, Val Loss=2.1987, Val Acc=11.87%, Grad Norm=3.1189, LR=1.5625e-06\n",
      "Fold 4, Epoch 64: Train Loss=2.1820, Train Acc=14.84%, Val Loss=2.1986, Val Acc=11.82%, Grad Norm=3.1484, LR=1.5625e-06\n",
      "Fold 4, Epoch 65: Train Loss=2.1819, Train Acc=15.14%, Val Loss=2.1987, Val Acc=11.93%, Grad Norm=3.1755, LR=1.5625e-06\n",
      "Fold 4, Epoch 66: Train Loss=2.1817, Train Acc=14.92%, Val Loss=2.1987, Val Acc=11.85%, Grad Norm=3.2023, LR=1.5625e-06\n",
      "Fold 4, Epoch 67: Train Loss=2.1805, Train Acc=15.20%, Val Loss=2.1986, Val Acc=11.76%, Grad Norm=3.2495, LR=1.5625e-06\n",
      "Fold 4, Epoch 68: Train Loss=2.1812, Train Acc=14.99%, Val Loss=2.1985, Val Acc=11.92%, Grad Norm=3.2968, LR=1.5625e-06\n",
      "Fold 4, Epoch 69: Train Loss=2.1807, Train Acc=15.14%, Val Loss=2.1986, Val Acc=11.84%, Grad Norm=3.3394, LR=1.5625e-06\n",
      "Fold 4, Epoch 70: Train Loss=2.1800, Train Acc=15.29%, Val Loss=2.1988, Val Acc=11.87%, Grad Norm=3.3707, LR=1.5625e-06\n",
      "Fold 4, Epoch 71: Train Loss=2.1804, Train Acc=15.29%, Val Loss=2.1988, Val Acc=11.84%, Grad Norm=3.4062, LR=7.8125e-07\n",
      "Fold 4, Epoch 72: Train Loss=2.1795, Train Acc=15.40%, Val Loss=2.1987, Val Acc=11.92%, Grad Norm=3.4414, LR=7.8125e-07\n",
      "Fold 4, Epoch 73: Train Loss=2.1802, Train Acc=15.32%, Val Loss=2.1988, Val Acc=11.87%, Grad Norm=3.4573, LR=7.8125e-07\n",
      "Fold 4, Epoch 74: Train Loss=2.1804, Train Acc=15.11%, Val Loss=2.1989, Val Acc=11.74%, Grad Norm=3.4857, LR=7.8125e-07\n",
      "Fold 4, Epoch 75: Train Loss=2.1796, Train Acc=15.57%, Val Loss=2.1990, Val Acc=11.83%, Grad Norm=3.5257, LR=7.8125e-07\n",
      "Fold 4, Epoch 76: Train Loss=2.1807, Train Acc=15.19%, Val Loss=2.1989, Val Acc=11.81%, Grad Norm=3.5267, LR=7.8125e-07\n",
      "Fold 4, Epoch 77: Train Loss=2.1803, Train Acc=15.06%, Val Loss=2.1989, Val Acc=11.75%, Grad Norm=3.5544, LR=7.8125e-07\n",
      "Fold 4, Epoch 78: Train Loss=2.1800, Train Acc=14.89%, Val Loss=2.1990, Val Acc=11.84%, Grad Norm=3.5757, LR=7.8125e-07\n",
      "Fold 4, Epoch 79: Train Loss=2.1798, Train Acc=15.26%, Val Loss=2.1991, Val Acc=11.76%, Grad Norm=3.5907, LR=7.8125e-07\n",
      "Fold 4, Epoch 80: Train Loss=2.1787, Train Acc=15.30%, Val Loss=2.1989, Val Acc=11.78%, Grad Norm=3.6283, LR=7.8125e-07\n",
      "Fold 4, Epoch 81: Train Loss=2.1793, Train Acc=15.44%, Val Loss=2.1990, Val Acc=11.89%, Grad Norm=3.6562, LR=3.90625e-07\n",
      "Fold 4, Epoch 82: Train Loss=2.1782, Train Acc=15.45%, Val Loss=2.1990, Val Acc=11.82%, Grad Norm=3.6710, LR=3.90625e-07\n",
      "Fold 4, Epoch 83: Train Loss=2.1788, Train Acc=15.53%, Val Loss=2.1989, Val Acc=11.90%, Grad Norm=3.6930, LR=3.90625e-07\n",
      "Fold 4, Epoch 84: Train Loss=2.1793, Train Acc=15.15%, Val Loss=2.1989, Val Acc=11.82%, Grad Norm=3.7046, LR=3.90625e-07\n",
      "Fold 4, Epoch 85: Train Loss=2.1792, Train Acc=15.33%, Val Loss=2.1989, Val Acc=11.82%, Grad Norm=3.7052, LR=3.90625e-07\n",
      "Fold 4, Epoch 86: Train Loss=2.1778, Train Acc=15.54%, Val Loss=2.1990, Val Acc=11.71%, Grad Norm=3.7228, LR=3.90625e-07\n",
      "Fold 4, Epoch 87: Train Loss=2.1792, Train Acc=15.07%, Val Loss=2.1990, Val Acc=11.83%, Grad Norm=3.7337, LR=3.90625e-07\n",
      "Fold 4, Epoch 88: Train Loss=2.1791, Train Acc=15.34%, Val Loss=2.1990, Val Acc=11.81%, Grad Norm=3.7525, LR=3.90625e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=12.06%）\n",
      "Fold 4 DONE | Best Val Acc≈12.06% | Final Val Acc=12.06% | Test Acc=11.93%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2233, Train Acc=11.18%, Val Loss=2.2156, Val Acc=11.20%, Grad Norm=6.7724, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2217, Train Acc=11.19%, Val Loss=2.2552, Val Acc=11.09%, Grad Norm=6.4136, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2150, Train Acc=11.42%, Val Loss=2.2388, Val Acc=11.00%, Grad Norm=5.5157, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2099, Train Acc=11.27%, Val Loss=2.2076, Val Acc=11.46%, Grad Norm=4.2124, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2067, Train Acc=11.25%, Val Loss=2.2148, Val Acc=11.07%, Grad Norm=3.4042, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2048, Train Acc=11.22%, Val Loss=2.2129, Val Acc=11.02%, Grad Norm=2.9533, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2034, Train Acc=11.46%, Val Loss=2.2117, Val Acc=10.82%, Grad Norm=2.6101, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2028, Train Acc=11.31%, Val Loss=2.2066, Val Acc=11.30%, Grad Norm=2.2934, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.2017, Train Acc=11.16%, Val Loss=2.2039, Val Acc=10.72%, Grad Norm=2.0210, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.2010, Train Acc=11.34%, Val Loss=2.2020, Val Acc=11.41%, Grad Norm=1.6795, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1988, Train Acc=11.44%, Val Loss=2.1999, Val Acc=11.46%, Grad Norm=1.5066, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1984, Train Acc=11.43%, Val Loss=2.2062, Val Acc=11.05%, Grad Norm=1.4155, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1974, Train Acc=11.70%, Val Loss=2.2017, Val Acc=11.25%, Grad Norm=1.4221, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1976, Train Acc=11.93%, Val Loss=2.2015, Val Acc=10.97%, Grad Norm=1.3689, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1974, Train Acc=11.64%, Val Loss=2.2009, Val Acc=11.48%, Grad Norm=1.2708, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1970, Train Acc=11.96%, Val Loss=2.2014, Val Acc=10.74%, Grad Norm=1.2118, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1967, Train Acc=11.81%, Val Loss=2.2000, Val Acc=10.74%, Grad Norm=1.1509, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1964, Train Acc=11.94%, Val Loss=2.1995, Val Acc=11.19%, Grad Norm=1.0834, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1961, Train Acc=11.93%, Val Loss=2.1999, Val Acc=11.43%, Grad Norm=1.0584, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1962, Train Acc=12.21%, Val Loss=2.1981, Val Acc=11.25%, Grad Norm=0.9985, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1949, Train Acc=12.65%, Val Loss=2.1998, Val Acc=11.63%, Grad Norm=1.0092, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1943, Train Acc=12.72%, Val Loss=2.1995, Val Acc=11.38%, Grad Norm=1.2426, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1937, Train Acc=12.76%, Val Loss=2.1999, Val Acc=11.43%, Grad Norm=1.2290, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1930, Train Acc=12.94%, Val Loss=2.1998, Val Acc=11.08%, Grad Norm=1.3703, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1935, Train Acc=12.71%, Val Loss=2.1993, Val Acc=11.38%, Grad Norm=1.3376, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1933, Train Acc=12.77%, Val Loss=2.1990, Val Acc=11.56%, Grad Norm=1.3406, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1930, Train Acc=12.78%, Val Loss=2.1995, Val Acc=11.11%, Grad Norm=1.3517, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1923, Train Acc=13.24%, Val Loss=2.1994, Val Acc=11.16%, Grad Norm=1.4329, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1924, Train Acc=13.18%, Val Loss=2.1981, Val Acc=11.36%, Grad Norm=1.4149, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1921, Train Acc=13.00%, Val Loss=2.1991, Val Acc=11.37%, Grad Norm=1.3725, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1910, Train Acc=13.38%, Val Loss=2.1984, Val Acc=11.57%, Grad Norm=1.3813, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1904, Train Acc=13.75%, Val Loss=2.1984, Val Acc=11.50%, Grad Norm=1.4836, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1900, Train Acc=13.41%, Val Loss=2.1987, Val Acc=11.45%, Grad Norm=1.5590, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1894, Train Acc=13.95%, Val Loss=2.1981, Val Acc=11.32%, Grad Norm=1.5814, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1893, Train Acc=13.92%, Val Loss=2.1987, Val Acc=11.28%, Grad Norm=1.6823, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1890, Train Acc=13.64%, Val Loss=2.1986, Val Acc=11.53%, Grad Norm=1.7316, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1889, Train Acc=13.99%, Val Loss=2.1984, Val Acc=11.55%, Grad Norm=1.7731, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=2.1883, Train Acc=14.10%, Val Loss=2.1987, Val Acc=11.65%, Grad Norm=1.8181, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=2.1881, Train Acc=14.05%, Val Loss=2.1987, Val Acc=11.62%, Grad Norm=1.8314, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=2.1876, Train Acc=14.57%, Val Loss=2.1988, Val Acc=11.57%, Grad Norm=1.9019, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=2.1863, Train Acc=14.53%, Val Loss=2.1987, Val Acc=11.65%, Grad Norm=1.9693, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=2.1862, Train Acc=14.35%, Val Loss=2.1992, Val Acc=11.65%, Grad Norm=2.0727, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=2.1856, Train Acc=14.59%, Val Loss=2.1988, Val Acc=11.69%, Grad Norm=2.1537, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=2.1851, Train Acc=14.72%, Val Loss=2.1990, Val Acc=11.37%, Grad Norm=2.2292, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=2.1854, Train Acc=14.41%, Val Loss=2.1985, Val Acc=11.61%, Grad Norm=2.2799, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=2.1842, Train Acc=14.77%, Val Loss=2.1988, Val Acc=11.45%, Grad Norm=2.3319, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=2.1840, Train Acc=14.66%, Val Loss=2.1988, Val Acc=11.29%, Grad Norm=2.4269, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=2.1837, Train Acc=14.91%, Val Loss=2.1995, Val Acc=11.40%, Grad Norm=2.4900, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=2.1834, Train Acc=14.78%, Val Loss=2.1993, Val Acc=11.56%, Grad Norm=2.5814, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=2.1823, Train Acc=14.92%, Val Loss=2.1996, Val Acc=11.31%, Grad Norm=2.6786, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=2.1826, Train Acc=14.86%, Val Loss=2.1994, Val Acc=11.29%, Grad Norm=2.7466, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=2.1823, Train Acc=14.78%, Val Loss=2.1995, Val Acc=11.33%, Grad Norm=2.8097, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=2.1816, Train Acc=15.04%, Val Loss=2.1993, Val Acc=11.56%, Grad Norm=2.8553, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=2.1812, Train Acc=15.11%, Val Loss=2.1997, Val Acc=11.43%, Grad Norm=2.9005, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=2.1815, Train Acc=15.00%, Val Loss=2.1998, Val Acc=11.49%, Grad Norm=2.9461, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=2.1805, Train Acc=15.31%, Val Loss=2.1994, Val Acc=11.50%, Grad Norm=3.0016, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=2.1809, Train Acc=15.22%, Val Loss=2.1994, Val Acc=11.61%, Grad Norm=3.0773, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=2.1800, Train Acc=15.29%, Val Loss=2.1994, Val Acc=11.66%, Grad Norm=3.1071, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=2.1794, Train Acc=15.36%, Val Loss=2.1997, Val Acc=11.66%, Grad Norm=3.1888, LR=3.125e-06\n",
      "Fold 5, Epoch 60: Train Loss=2.1799, Train Acc=15.34%, Val Loss=2.1993, Val Acc=11.63%, Grad Norm=3.2687, LR=3.125e-06\n",
      "Fold 5, Epoch 61: Train Loss=2.1792, Train Acc=15.46%, Val Loss=2.1993, Val Acc=11.40%, Grad Norm=3.3134, LR=1.5625e-06\n",
      "Fold 5, Epoch 62: Train Loss=2.1781, Train Acc=15.53%, Val Loss=2.1996, Val Acc=11.58%, Grad Norm=3.3578, LR=1.5625e-06\n",
      "Fold 5, Epoch 63: Train Loss=2.1789, Train Acc=15.30%, Val Loss=2.1996, Val Acc=11.43%, Grad Norm=3.4016, LR=1.5625e-06\n",
      "Fold 5, Epoch 64: Train Loss=2.1783, Train Acc=15.50%, Val Loss=2.1997, Val Acc=11.68%, Grad Norm=3.4404, LR=1.5625e-06\n",
      "Fold 5, Epoch 65: Train Loss=2.1774, Train Acc=15.57%, Val Loss=2.1999, Val Acc=11.52%, Grad Norm=3.4831, LR=1.5625e-06\n",
      "Fold 5, Epoch 66: Train Loss=2.1777, Train Acc=15.51%, Val Loss=2.1999, Val Acc=11.57%, Grad Norm=3.5204, LR=1.5625e-06\n",
      "Fold 5, Epoch 67: Train Loss=2.1773, Train Acc=15.82%, Val Loss=2.1998, Val Acc=11.51%, Grad Norm=3.5793, LR=1.5625e-06\n",
      "Fold 5, Epoch 68: Train Loss=2.1769, Train Acc=15.59%, Val Loss=2.1999, Val Acc=11.58%, Grad Norm=3.6524, LR=1.5625e-06\n",
      "Fold 5, Epoch 69: Train Loss=2.1777, Train Acc=15.59%, Val Loss=2.1999, Val Acc=11.59%, Grad Norm=3.6772, LR=1.5625e-06\n",
      "Fold 5, Epoch 70: Train Loss=2.1769, Train Acc=15.65%, Val Loss=2.2000, Val Acc=11.75%, Grad Norm=3.7222, LR=1.5625e-06\n",
      "Fold 5, Epoch 71: Train Loss=2.1766, Train Acc=15.70%, Val Loss=2.2001, Val Acc=11.58%, Grad Norm=3.7719, LR=7.8125e-07\n",
      "Fold 5, Epoch 72: Train Loss=2.1762, Train Acc=15.74%, Val Loss=2.2002, Val Acc=11.51%, Grad Norm=3.7784, LR=7.8125e-07\n",
      "Fold 5, Epoch 73: Train Loss=2.1758, Train Acc=15.94%, Val Loss=2.2001, Val Acc=11.50%, Grad Norm=3.8000, LR=7.8125e-07\n",
      "Fold 5, Epoch 74: Train Loss=2.1773, Train Acc=15.81%, Val Loss=2.2003, Val Acc=11.59%, Grad Norm=3.8070, LR=7.8125e-07\n",
      "Fold 5, Epoch 75: Train Loss=2.1762, Train Acc=15.71%, Val Loss=2.2002, Val Acc=11.47%, Grad Norm=3.8163, LR=7.8125e-07\n",
      "Fold 5, Epoch 76: Train Loss=2.1771, Train Acc=15.49%, Val Loss=2.2002, Val Acc=11.63%, Grad Norm=3.8599, LR=7.8125e-07\n",
      "Fold 5, Epoch 77: Train Loss=2.1753, Train Acc=15.79%, Val Loss=2.2004, Val Acc=11.50%, Grad Norm=3.9072, LR=7.8125e-07\n",
      "Fold 5, Epoch 78: Train Loss=2.1756, Train Acc=15.79%, Val Loss=2.2002, Val Acc=11.46%, Grad Norm=3.9298, LR=7.8125e-07\n",
      "Fold 5, Epoch 79: Train Loss=2.1761, Train Acc=15.52%, Val Loss=2.2002, Val Acc=11.52%, Grad Norm=3.9538, LR=7.8125e-07\n",
      "Fold 5, Epoch 80: Train Loss=2.1761, Train Acc=15.71%, Val Loss=2.2003, Val Acc=11.56%, Grad Norm=3.9838, LR=7.8125e-07\n",
      "Fold 5, Epoch 81: Train Loss=2.1756, Train Acc=15.98%, Val Loss=2.2005, Val Acc=11.70%, Grad Norm=3.9884, LR=3.90625e-07\n",
      "Fold 5, Epoch 82: Train Loss=2.1750, Train Acc=15.79%, Val Loss=2.2007, Val Acc=11.49%, Grad Norm=4.0031, LR=3.90625e-07\n",
      "Fold 5, Epoch 83: Train Loss=2.1748, Train Acc=16.10%, Val Loss=2.2007, Val Acc=11.49%, Grad Norm=4.0265, LR=3.90625e-07\n",
      "Fold 5, Epoch 84: Train Loss=2.1757, Train Acc=15.86%, Val Loss=2.2005, Val Acc=11.62%, Grad Norm=4.0226, LR=3.90625e-07\n",
      "Fold 5, Epoch 85: Train Loss=2.1752, Train Acc=15.91%, Val Loss=2.2006, Val Acc=11.57%, Grad Norm=4.0407, LR=3.90625e-07\n",
      "Fold 5, Epoch 86: Train Loss=2.1755, Train Acc=15.67%, Val Loss=2.2007, Val Acc=11.62%, Grad Norm=4.0627, LR=3.90625e-07\n",
      "Fold 5, Epoch 87: Train Loss=2.1755, Train Acc=15.95%, Val Loss=2.2006, Val Acc=11.62%, Grad Norm=4.0632, LR=3.90625e-07\n",
      "Fold 5, Epoch 88: Train Loss=2.1742, Train Acc=16.04%, Val Loss=2.2008, Val Acc=11.58%, Grad Norm=4.0818, LR=3.90625e-07\n",
      "Fold 5, Epoch 89: Train Loss=2.1744, Train Acc=15.79%, Val Loss=2.2005, Val Acc=11.75%, Grad Norm=4.0915, LR=3.90625e-07\n",
      "Fold 5, Epoch 90: Train Loss=2.1741, Train Acc=16.19%, Val Loss=2.2005, Val Acc=11.65%, Grad Norm=4.1029, LR=3.90625e-07\n",
      "Fold 5, Epoch 91: Train Loss=2.1744, Train Acc=16.01%, Val Loss=2.2007, Val Acc=11.61%, Grad Norm=4.1124, LR=1.95313e-07\n",
      "Fold 5, Epoch 92: Train Loss=2.1757, Train Acc=15.89%, Val Loss=2.2007, Val Acc=11.56%, Grad Norm=4.1099, LR=1.95313e-07\n",
      "Fold 5, Epoch 93: Train Loss=2.1741, Train Acc=16.16%, Val Loss=2.2006, Val Acc=11.66%, Grad Norm=4.1177, LR=1.95313e-07\n",
      "Fold 5, Epoch 94: Train Loss=2.1745, Train Acc=15.87%, Val Loss=2.2007, Val Acc=11.58%, Grad Norm=4.1268, LR=1.95313e-07\n",
      "Fold 5, Epoch 95: Train Loss=2.1754, Train Acc=15.74%, Val Loss=2.2007, Val Acc=11.61%, Grad Norm=4.1468, LR=1.95313e-07\n",
      "Fold 5, Epoch 96: Train Loss=2.1758, Train Acc=15.74%, Val Loss=2.2007, Val Acc=11.57%, Grad Norm=4.1364, LR=1.95313e-07\n",
      "Fold 5, Epoch 97: Train Loss=2.1747, Train Acc=15.96%, Val Loss=2.2008, Val Acc=11.65%, Grad Norm=4.1456, LR=1.95313e-07\n",
      "Fold 5, Epoch 98: Train Loss=2.1749, Train Acc=15.74%, Val Loss=2.2008, Val Acc=11.65%, Grad Norm=4.1531, LR=1.95313e-07\n",
      "Fold 5, Epoch 99: Train Loss=2.1745, Train Acc=15.91%, Val Loss=2.2007, Val Acc=11.67%, Grad Norm=4.1537, LR=1.95313e-07\n",
      "Fold 5, Epoch 100: Train Loss=2.1748, Train Acc=15.95%, Val Loss=2.2006, Val Acc=11.61%, Grad Norm=4.1712, LR=1.95313e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.75%）\n",
      "Fold 5 DONE | Best Val Acc≈11.75% | Final Val Acc=11.75% | Test Acc=12.19%\n",
      "[INFO] SNR=-20 dB | Mean Test Acc: 12.00% ± 0.11%\n",
      "[INFO] SNR -20 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-20dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -25 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2244, Train Acc=11.14%, Val Loss=2.2577, Val Acc=11.12%, Grad Norm=6.7667, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2221, Train Acc=11.09%, Val Loss=2.2741, Val Acc=11.11%, Grad Norm=6.4599, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2183, Train Acc=11.27%, Val Loss=2.2734, Val Acc=11.03%, Grad Norm=5.8532, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2139, Train Acc=11.06%, Val Loss=2.2505, Val Acc=11.26%, Grad Norm=4.9506, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2088, Train Acc=11.11%, Val Loss=2.2200, Val Acc=11.06%, Grad Norm=3.9146, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2071, Train Acc=11.10%, Val Loss=2.2112, Val Acc=11.15%, Grad Norm=3.3273, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2047, Train Acc=11.28%, Val Loss=2.2139, Val Acc=10.99%, Grad Norm=2.9822, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2045, Train Acc=11.09%, Val Loss=2.2055, Val Acc=10.92%, Grad Norm=2.6850, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2029, Train Acc=11.32%, Val Loss=2.2130, Val Acc=11.07%, Grad Norm=2.4211, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2023, Train Acc=10.99%, Val Loss=2.2038, Val Acc=11.20%, Grad Norm=2.0838, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.2002, Train Acc=11.42%, Val Loss=2.2035, Val Acc=11.02%, Grad Norm=1.8426, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.1994, Train Acc=11.30%, Val Loss=2.2027, Val Acc=11.13%, Grad Norm=1.7201, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.1997, Train Acc=11.24%, Val Loss=2.2110, Val Acc=11.10%, Grad Norm=1.6555, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1991, Train Acc=11.20%, Val Loss=2.2180, Val Acc=11.12%, Grad Norm=1.5902, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1990, Train Acc=11.34%, Val Loss=2.2006, Val Acc=11.12%, Grad Norm=1.5542, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1984, Train Acc=11.58%, Val Loss=2.2035, Val Acc=10.87%, Grad Norm=1.5268, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1987, Train Acc=11.38%, Val Loss=2.1993, Val Acc=11.18%, Grad Norm=1.3957, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1978, Train Acc=11.70%, Val Loss=2.2022, Val Acc=11.30%, Grad Norm=1.3232, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1978, Train Acc=11.41%, Val Loss=2.1997, Val Acc=11.00%, Grad Norm=1.2593, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1979, Train Acc=11.45%, Val Loss=2.1989, Val Acc=10.98%, Grad Norm=1.1675, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1967, Train Acc=11.78%, Val Loss=2.1985, Val Acc=11.13%, Grad Norm=1.0915, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1966, Train Acc=12.07%, Val Loss=2.2011, Val Acc=11.14%, Grad Norm=1.1172, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1962, Train Acc=12.16%, Val Loss=2.1989, Val Acc=11.13%, Grad Norm=1.2367, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1961, Train Acc=11.91%, Val Loss=2.2003, Val Acc=11.04%, Grad Norm=1.2929, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1962, Train Acc=11.70%, Val Loss=2.2003, Val Acc=11.21%, Grad Norm=1.2077, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1958, Train Acc=12.09%, Val Loss=2.1990, Val Acc=11.11%, Grad Norm=1.1998, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1959, Train Acc=12.04%, Val Loss=2.2002, Val Acc=11.19%, Grad Norm=1.2396, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1953, Train Acc=12.13%, Val Loss=2.2021, Val Acc=11.21%, Grad Norm=1.2820, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1956, Train Acc=12.03%, Val Loss=2.2012, Val Acc=11.22%, Grad Norm=1.2184, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1956, Train Acc=12.39%, Val Loss=2.1989, Val Acc=11.23%, Grad Norm=1.2429, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1939, Train Acc=12.75%, Val Loss=2.2018, Val Acc=11.34%, Grad Norm=1.3446, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1938, Train Acc=12.48%, Val Loss=2.2030, Val Acc=11.14%, Grad Norm=1.6377, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1937, Train Acc=12.47%, Val Loss=2.2032, Val Acc=11.20%, Grad Norm=1.5754, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1935, Train Acc=12.61%, Val Loss=2.2004, Val Acc=11.03%, Grad Norm=1.7682, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1929, Train Acc=12.92%, Val Loss=2.2018, Val Acc=10.98%, Grad Norm=1.7831, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1922, Train Acc=12.94%, Val Loss=2.2004, Val Acc=11.52%, Grad Norm=2.0276, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1922, Train Acc=12.96%, Val Loss=2.2024, Val Acc=11.15%, Grad Norm=2.0117, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1926, Train Acc=12.96%, Val Loss=2.2013, Val Acc=11.08%, Grad Norm=2.0393, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1919, Train Acc=13.20%, Val Loss=2.2021, Val Acc=11.06%, Grad Norm=2.1301, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1911, Train Acc=13.23%, Val Loss=2.2033, Val Acc=10.96%, Grad Norm=2.2827, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1904, Train Acc=13.42%, Val Loss=2.2028, Val Acc=11.05%, Grad Norm=2.3723, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.1903, Train Acc=12.96%, Val Loss=2.2027, Val Acc=11.09%, Grad Norm=2.4138, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=2.1895, Train Acc=13.59%, Val Loss=2.2027, Val Acc=11.22%, Grad Norm=2.4502, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=2.1892, Train Acc=13.44%, Val Loss=2.2027, Val Acc=11.19%, Grad Norm=2.5786, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=2.1890, Train Acc=13.44%, Val Loss=2.2028, Val Acc=11.05%, Grad Norm=2.6129, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=2.1890, Train Acc=13.57%, Val Loss=2.2036, Val Acc=10.95%, Grad Norm=2.6468, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=2.1885, Train Acc=13.56%, Val Loss=2.2033, Val Acc=11.20%, Grad Norm=2.6562, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=2.1867, Train Acc=13.86%, Val Loss=2.2037, Val Acc=11.02%, Grad Norm=2.7366, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=2.1879, Train Acc=13.65%, Val Loss=2.2036, Val Acc=10.99%, Grad Norm=2.7859, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=2.1875, Train Acc=13.83%, Val Loss=2.2040, Val Acc=11.24%, Grad Norm=2.8298, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=2.1872, Train Acc=14.06%, Val Loss=2.2031, Val Acc=11.08%, Grad Norm=2.8465, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=2.1868, Train Acc=14.04%, Val Loss=2.2035, Val Acc=11.06%, Grad Norm=2.8562, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=2.1872, Train Acc=13.76%, Val Loss=2.2033, Val Acc=11.11%, Grad Norm=2.8912, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=2.1857, Train Acc=14.19%, Val Loss=2.2033, Val Acc=11.11%, Grad Norm=2.9045, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=2.1862, Train Acc=14.07%, Val Loss=2.2034, Val Acc=11.04%, Grad Norm=2.9444, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=2.1859, Train Acc=14.17%, Val Loss=2.2032, Val Acc=10.97%, Grad Norm=2.9501, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=2.1854, Train Acc=14.15%, Val Loss=2.2036, Val Acc=11.17%, Grad Norm=2.9945, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=2.1849, Train Acc=14.25%, Val Loss=2.2038, Val Acc=11.07%, Grad Norm=3.0261, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=2.1854, Train Acc=14.20%, Val Loss=2.2035, Val Acc=10.99%, Grad Norm=3.0267, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=2.1853, Train Acc=14.24%, Val Loss=2.2034, Val Acc=11.05%, Grad Norm=3.0743, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=2.1843, Train Acc=14.21%, Val Loss=2.2037, Val Acc=11.06%, Grad Norm=3.0977, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=2.1846, Train Acc=14.33%, Val Loss=2.2035, Val Acc=11.01%, Grad Norm=3.1150, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=2.1843, Train Acc=14.54%, Val Loss=2.2036, Val Acc=11.04%, Grad Norm=3.1178, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=2.1846, Train Acc=14.45%, Val Loss=2.2034, Val Acc=10.97%, Grad Norm=3.1438, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=2.1836, Train Acc=14.87%, Val Loss=2.2034, Val Acc=11.09%, Grad Norm=3.1615, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=2.1842, Train Acc=14.55%, Val Loss=2.2035, Val Acc=11.03%, Grad Norm=3.1753, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.52%）\n",
      "Fold 1 DONE | Best Val Acc≈11.52% | Final Val Acc=11.52% | Test Acc=10.80%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2232, Train Acc=11.31%, Val Loss=2.2333, Val Acc=10.96%, Grad Norm=6.7420, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2236, Train Acc=10.86%, Val Loss=2.2403, Val Acc=10.95%, Grad Norm=6.4543, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2181, Train Acc=11.09%, Val Loss=2.2344, Val Acc=11.13%, Grad Norm=5.8387, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2138, Train Acc=11.07%, Val Loss=2.2292, Val Acc=11.06%, Grad Norm=4.9113, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2103, Train Acc=10.98%, Val Loss=2.2351, Val Acc=11.11%, Grad Norm=3.9928, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2071, Train Acc=11.00%, Val Loss=2.2289, Val Acc=11.02%, Grad Norm=3.5114, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2048, Train Acc=11.09%, Val Loss=2.2120, Val Acc=11.10%, Grad Norm=3.1009, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2033, Train Acc=11.60%, Val Loss=2.2205, Val Acc=10.92%, Grad Norm=2.7634, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2035, Train Acc=11.34%, Val Loss=2.2085, Val Acc=11.06%, Grad Norm=2.4693, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.2023, Train Acc=11.15%, Val Loss=2.2183, Val Acc=11.23%, Grad Norm=2.1602, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.2004, Train Acc=11.28%, Val Loss=2.2079, Val Acc=11.20%, Grad Norm=1.9689, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.2000, Train Acc=11.06%, Val Loss=2.2001, Val Acc=11.17%, Grad Norm=1.8425, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.1996, Train Acc=11.30%, Val Loss=2.2019, Val Acc=11.02%, Grad Norm=1.7144, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1988, Train Acc=11.60%, Val Loss=2.2057, Val Acc=11.28%, Grad Norm=1.6725, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1989, Train Acc=11.56%, Val Loss=2.2021, Val Acc=11.13%, Grad Norm=1.5716, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1982, Train Acc=11.53%, Val Loss=2.2067, Val Acc=11.09%, Grad Norm=1.5823, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1983, Train Acc=11.58%, Val Loss=2.2030, Val Acc=10.80%, Grad Norm=1.4957, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1985, Train Acc=11.18%, Val Loss=2.1982, Val Acc=11.16%, Grad Norm=1.3841, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1979, Train Acc=11.60%, Val Loss=2.2008, Val Acc=11.06%, Grad Norm=1.3294, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1976, Train Acc=11.70%, Val Loss=2.1987, Val Acc=11.33%, Grad Norm=1.2752, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1969, Train Acc=11.72%, Val Loss=2.1985, Val Acc=11.04%, Grad Norm=1.2484, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1964, Train Acc=11.96%, Val Loss=2.1987, Val Acc=11.02%, Grad Norm=1.2364, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1963, Train Acc=11.85%, Val Loss=2.2000, Val Acc=11.33%, Grad Norm=1.2810, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1965, Train Acc=11.92%, Val Loss=2.1983, Val Acc=11.37%, Grad Norm=1.3152, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1965, Train Acc=11.97%, Val Loss=2.1999, Val Acc=11.20%, Grad Norm=1.2736, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1961, Train Acc=11.90%, Val Loss=2.1997, Val Acc=11.25%, Grad Norm=1.2547, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1959, Train Acc=12.31%, Val Loss=2.2007, Val Acc=11.42%, Grad Norm=1.3152, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1953, Train Acc=12.14%, Val Loss=2.2017, Val Acc=11.24%, Grad Norm=1.3711, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1954, Train Acc=11.96%, Val Loss=2.1997, Val Acc=11.37%, Grad Norm=1.5254, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1955, Train Acc=12.22%, Val Loss=2.1995, Val Acc=11.00%, Grad Norm=1.3129, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1947, Train Acc=12.46%, Val Loss=2.2000, Val Acc=11.28%, Grad Norm=1.3537, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1943, Train Acc=12.59%, Val Loss=2.2007, Val Acc=11.29%, Grad Norm=1.5367, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1940, Train Acc=12.57%, Val Loss=2.1999, Val Acc=11.34%, Grad Norm=1.6921, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1935, Train Acc=12.39%, Val Loss=2.2013, Val Acc=11.30%, Grad Norm=1.8272, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1927, Train Acc=12.93%, Val Loss=2.2021, Val Acc=11.36%, Grad Norm=1.9482, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1929, Train Acc=13.06%, Val Loss=2.2021, Val Acc=11.45%, Grad Norm=1.9953, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1929, Train Acc=12.85%, Val Loss=2.2029, Val Acc=11.52%, Grad Norm=1.9833, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1922, Train Acc=12.94%, Val Loss=2.2027, Val Acc=11.63%, Grad Norm=2.1600, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1923, Train Acc=12.90%, Val Loss=2.2034, Val Acc=11.49%, Grad Norm=2.1496, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1925, Train Acc=13.02%, Val Loss=2.2048, Val Acc=11.44%, Grad Norm=2.1628, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1915, Train Acc=12.91%, Val Loss=2.2039, Val Acc=11.68%, Grad Norm=2.1806, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1911, Train Acc=13.43%, Val Loss=2.2034, Val Acc=11.57%, Grad Norm=2.3064, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1909, Train Acc=13.24%, Val Loss=2.2054, Val Acc=11.45%, Grad Norm=2.3668, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1893, Train Acc=13.97%, Val Loss=2.2032, Val Acc=11.46%, Grad Norm=2.4398, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1898, Train Acc=13.44%, Val Loss=2.2021, Val Acc=11.40%, Grad Norm=2.5279, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1902, Train Acc=13.59%, Val Loss=2.2010, Val Acc=11.60%, Grad Norm=2.4845, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1902, Train Acc=13.50%, Val Loss=2.2024, Val Acc=11.43%, Grad Norm=2.5135, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.1897, Train Acc=13.51%, Val Loss=2.2023, Val Acc=11.73%, Grad Norm=2.5195, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.1896, Train Acc=13.62%, Val Loss=2.2026, Val Acc=11.60%, Grad Norm=2.5033, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.1883, Train Acc=13.60%, Val Loss=2.2023, Val Acc=11.62%, Grad Norm=2.5808, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.1886, Train Acc=13.78%, Val Loss=2.2030, Val Acc=11.51%, Grad Norm=2.6109, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.1878, Train Acc=13.92%, Val Loss=2.2028, Val Acc=11.51%, Grad Norm=2.6357, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.1877, Train Acc=14.14%, Val Loss=2.2029, Val Acc=11.52%, Grad Norm=2.6695, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.1869, Train Acc=14.10%, Val Loss=2.2029, Val Acc=11.62%, Grad Norm=2.7094, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.1864, Train Acc=14.21%, Val Loss=2.2025, Val Acc=11.62%, Grad Norm=2.7665, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.1868, Train Acc=14.25%, Val Loss=2.2020, Val Acc=11.71%, Grad Norm=2.7895, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.1866, Train Acc=14.25%, Val Loss=2.2023, Val Acc=11.69%, Grad Norm=2.8163, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.1858, Train Acc=14.22%, Val Loss=2.2032, Val Acc=11.63%, Grad Norm=2.8568, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.1864, Train Acc=14.08%, Val Loss=2.2036, Val Acc=11.51%, Grad Norm=2.8798, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.1863, Train Acc=14.04%, Val Loss=2.2032, Val Acc=11.57%, Grad Norm=2.8860, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.1864, Train Acc=13.68%, Val Loss=2.2028, Val Acc=11.77%, Grad Norm=2.9041, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.1855, Train Acc=14.21%, Val Loss=2.2027, Val Acc=11.80%, Grad Norm=2.9139, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=2.1865, Train Acc=14.22%, Val Loss=2.2026, Val Acc=11.74%, Grad Norm=2.9237, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=2.1854, Train Acc=14.06%, Val Loss=2.2025, Val Acc=11.73%, Grad Norm=2.9368, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=2.1853, Train Acc=14.34%, Val Loss=2.2030, Val Acc=11.51%, Grad Norm=2.9584, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=2.1850, Train Acc=14.22%, Val Loss=2.2024, Val Acc=11.70%, Grad Norm=2.9653, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=2.1851, Train Acc=14.52%, Val Loss=2.2028, Val Acc=11.73%, Grad Norm=2.9893, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=2.1851, Train Acc=14.07%, Val Loss=2.2030, Val Acc=11.69%, Grad Norm=3.0159, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=2.1848, Train Acc=14.29%, Val Loss=2.2029, Val Acc=11.71%, Grad Norm=3.0290, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=2.1844, Train Acc=14.52%, Val Loss=2.2033, Val Acc=11.52%, Grad Norm=3.0474, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=2.1843, Train Acc=14.47%, Val Loss=2.2030, Val Acc=11.56%, Grad Norm=3.0697, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=2.1847, Train Acc=14.57%, Val Loss=2.2030, Val Acc=11.63%, Grad Norm=3.0864, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=2.1851, Train Acc=14.34%, Val Loss=2.2031, Val Acc=11.63%, Grad Norm=3.0795, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=2.1839, Train Acc=14.88%, Val Loss=2.2032, Val Acc=11.60%, Grad Norm=3.0957, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=2.1850, Train Acc=14.48%, Val Loss=2.2033, Val Acc=11.56%, Grad Norm=3.1135, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=2.1846, Train Acc=14.35%, Val Loss=2.2033, Val Acc=11.66%, Grad Norm=3.1199, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=2.1846, Train Acc=14.55%, Val Loss=2.2033, Val Acc=11.65%, Grad Norm=3.1293, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=2.1853, Train Acc=14.33%, Val Loss=2.2031, Val Acc=11.82%, Grad Norm=3.1392, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=2.1839, Train Acc=14.93%, Val Loss=2.2027, Val Acc=11.77%, Grad Norm=3.1573, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=2.1838, Train Acc=14.56%, Val Loss=2.2026, Val Acc=11.70%, Grad Norm=3.1534, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=2.1841, Train Acc=14.56%, Val Loss=2.2027, Val Acc=11.69%, Grad Norm=3.1626, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=2.1842, Train Acc=14.39%, Val Loss=2.2025, Val Acc=11.77%, Grad Norm=3.1655, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=2.1848, Train Acc=14.29%, Val Loss=2.2027, Val Acc=11.80%, Grad Norm=3.1723, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=2.1850, Train Acc=14.45%, Val Loss=2.2029, Val Acc=11.78%, Grad Norm=3.1773, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=2.1843, Train Acc=14.66%, Val Loss=2.2029, Val Acc=11.78%, Grad Norm=3.1827, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=2.1841, Train Acc=14.64%, Val Loss=2.2029, Val Acc=11.74%, Grad Norm=3.1842, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=2.1840, Train Acc=14.65%, Val Loss=2.2028, Val Acc=11.91%, Grad Norm=3.1914, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=2.1843, Train Acc=14.60%, Val Loss=2.2029, Val Acc=11.87%, Grad Norm=3.1888, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=2.1833, Train Acc=14.64%, Val Loss=2.2030, Val Acc=11.80%, Grad Norm=3.1994, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=2.1829, Train Acc=14.88%, Val Loss=2.2030, Val Acc=11.80%, Grad Norm=3.2066, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=2.1833, Train Acc=14.88%, Val Loss=2.2032, Val Acc=11.71%, Grad Norm=3.2120, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=2.1837, Train Acc=14.40%, Val Loss=2.2030, Val Acc=11.72%, Grad Norm=3.2132, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=2.1841, Train Acc=14.44%, Val Loss=2.2032, Val Acc=11.76%, Grad Norm=3.2169, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=2.1838, Train Acc=14.59%, Val Loss=2.2032, Val Acc=11.76%, Grad Norm=3.2189, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=2.1844, Train Acc=14.37%, Val Loss=2.2030, Val Acc=11.77%, Grad Norm=3.2216, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=2.1833, Train Acc=14.62%, Val Loss=2.2029, Val Acc=11.72%, Grad Norm=3.2248, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=2.1841, Train Acc=14.56%, Val Loss=2.2030, Val Acc=11.68%, Grad Norm=3.2290, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=2.1841, Train Acc=14.49%, Val Loss=2.2031, Val Acc=11.65%, Grad Norm=3.2292, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=2.1839, Train Acc=14.69%, Val Loss=2.2030, Val Acc=11.73%, Grad Norm=3.2315, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=2.1835, Train Acc=14.73%, Val Loss=2.2030, Val Acc=11.71%, Grad Norm=3.2361, LR=1.95313e-07\n",
      "Fold 2, Epoch 101: Train Loss=2.1831, Train Acc=14.63%, Val Loss=2.2028, Val Acc=11.72%, Grad Norm=3.2380, LR=9.76563e-08\n",
      "Fold 2, Epoch 102: Train Loss=2.1839, Train Acc=14.78%, Val Loss=2.2028, Val Acc=11.68%, Grad Norm=3.2442, LR=9.76563e-08\n",
      "Fold 2, Epoch 103: Train Loss=2.1832, Train Acc=14.87%, Val Loss=2.2029, Val Acc=11.71%, Grad Norm=3.2434, LR=9.76563e-08\n",
      "Fold 2, Epoch 104: Train Loss=2.1836, Train Acc=14.70%, Val Loss=2.2031, Val Acc=11.74%, Grad Norm=3.2456, LR=9.76563e-08\n",
      "Fold 2, Epoch 105: Train Loss=2.1838, Train Acc=14.53%, Val Loss=2.2029, Val Acc=11.71%, Grad Norm=3.2414, LR=9.76563e-08\n",
      "Fold 2, Epoch 106: Train Loss=2.1841, Train Acc=14.56%, Val Loss=2.2030, Val Acc=11.71%, Grad Norm=3.2498, LR=9.76563e-08\n",
      "Fold 2, Epoch 107: Train Loss=2.1834, Train Acc=14.77%, Val Loss=2.2028, Val Acc=11.68%, Grad Norm=3.2432, LR=9.76563e-08\n",
      "Fold 2, Epoch 108: Train Loss=2.1839, Train Acc=14.58%, Val Loss=2.2029, Val Acc=11.67%, Grad Norm=3.2446, LR=9.76563e-08\n",
      "Fold 2, Epoch 109: Train Loss=2.1836, Train Acc=14.58%, Val Loss=2.2029, Val Acc=11.69%, Grad Norm=3.2482, LR=9.76563e-08\n",
      "Fold 2, Epoch 110: Train Loss=2.1832, Train Acc=14.95%, Val Loss=2.2030, Val Acc=11.74%, Grad Norm=3.2504, LR=9.76563e-08\n",
      "Fold 2, Epoch 111: Train Loss=2.1839, Train Acc=14.56%, Val Loss=2.2028, Val Acc=11.73%, Grad Norm=3.2502, LR=4.88281e-08\n",
      "Fold 2, Epoch 112: Train Loss=2.1839, Train Acc=14.60%, Val Loss=2.2029, Val Acc=11.72%, Grad Norm=3.2499, LR=4.88281e-08\n",
      "Fold 2, Epoch 113: Train Loss=2.1837, Train Acc=14.56%, Val Loss=2.2029, Val Acc=11.71%, Grad Norm=3.2484, LR=4.88281e-08\n",
      "Fold 2, Epoch 114: Train Loss=2.1834, Train Acc=14.62%, Val Loss=2.2031, Val Acc=11.70%, Grad Norm=3.2499, LR=4.88281e-08\n",
      "Fold 2, Epoch 115: Train Loss=2.1824, Train Acc=14.81%, Val Loss=2.2028, Val Acc=11.72%, Grad Norm=3.2530, LR=4.88281e-08\n",
      "Fold 2, Epoch 116: Train Loss=2.1836, Train Acc=14.43%, Val Loss=2.2029, Val Acc=11.77%, Grad Norm=3.2524, LR=4.88281e-08\n",
      "Fold 2, Epoch 117: Train Loss=2.1835, Train Acc=14.83%, Val Loss=2.2030, Val Acc=11.74%, Grad Norm=3.2594, LR=4.88281e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.91%）\n",
      "Fold 2 DONE | Best Val Acc≈11.91% | Final Val Acc=11.91% | Test Acc=11.11%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2232, Train Acc=11.08%, Val Loss=2.2707, Val Acc=11.12%, Grad Norm=6.7869, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2219, Train Acc=10.91%, Val Loss=2.2367, Val Acc=11.27%, Grad Norm=6.5025, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2196, Train Acc=11.03%, Val Loss=2.2284, Val Acc=10.91%, Grad Norm=5.8098, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2133, Train Acc=10.90%, Val Loss=2.2342, Val Acc=11.09%, Grad Norm=4.8348, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2094, Train Acc=11.20%, Val Loss=2.2072, Val Acc=11.04%, Grad Norm=3.9750, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2061, Train Acc=11.25%, Val Loss=2.2481, Val Acc=11.03%, Grad Norm=3.3462, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2049, Train Acc=11.25%, Val Loss=2.2104, Val Acc=11.09%, Grad Norm=2.9903, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2033, Train Acc=11.31%, Val Loss=2.2225, Val Acc=11.05%, Grad Norm=2.6684, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2029, Train Acc=11.15%, Val Loss=2.2065, Val Acc=11.12%, Grad Norm=2.3920, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.2020, Train Acc=11.39%, Val Loss=2.2055, Val Acc=11.04%, Grad Norm=2.0969, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.1997, Train Acc=11.43%, Val Loss=2.2056, Val Acc=11.09%, Grad Norm=1.9009, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.1990, Train Acc=11.62%, Val Loss=2.2130, Val Acc=11.13%, Grad Norm=1.7716, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1987, Train Acc=11.41%, Val Loss=2.2044, Val Acc=11.04%, Grad Norm=1.6877, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1990, Train Acc=11.28%, Val Loss=2.2021, Val Acc=11.09%, Grad Norm=1.6139, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1986, Train Acc=11.29%, Val Loss=2.2033, Val Acc=11.18%, Grad Norm=1.5930, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1984, Train Acc=11.31%, Val Loss=2.2011, Val Acc=11.12%, Grad Norm=1.4621, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1983, Train Acc=11.40%, Val Loss=2.2018, Val Acc=11.17%, Grad Norm=1.3642, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1979, Train Acc=11.69%, Val Loss=2.1989, Val Acc=11.07%, Grad Norm=1.2883, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1978, Train Acc=11.66%, Val Loss=2.1992, Val Acc=11.18%, Grad Norm=1.2805, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1973, Train Acc=11.73%, Val Loss=2.1993, Val Acc=11.21%, Grad Norm=1.1666, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1964, Train Acc=11.96%, Val Loss=2.1989, Val Acc=11.17%, Grad Norm=1.1004, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1965, Train Acc=11.90%, Val Loss=2.1986, Val Acc=11.21%, Grad Norm=1.1868, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1961, Train Acc=12.00%, Val Loss=2.1995, Val Acc=11.00%, Grad Norm=1.1944, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1958, Train Acc=12.12%, Val Loss=2.1994, Val Acc=11.30%, Grad Norm=1.2507, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1958, Train Acc=12.33%, Val Loss=2.1983, Val Acc=11.28%, Grad Norm=1.2983, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1957, Train Acc=12.02%, Val Loss=2.1993, Val Acc=11.11%, Grad Norm=1.2928, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1955, Train Acc=12.08%, Val Loss=2.1996, Val Acc=11.00%, Grad Norm=1.2738, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1954, Train Acc=12.28%, Val Loss=2.1995, Val Acc=11.34%, Grad Norm=1.2810, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1950, Train Acc=11.94%, Val Loss=2.1989, Val Acc=11.25%, Grad Norm=1.3267, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1946, Train Acc=12.40%, Val Loss=2.1988, Val Acc=11.19%, Grad Norm=1.3484, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1931, Train Acc=12.81%, Val Loss=2.2013, Val Acc=11.12%, Grad Norm=1.4657, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1939, Train Acc=12.75%, Val Loss=2.2000, Val Acc=11.16%, Grad Norm=1.6281, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1935, Train Acc=12.70%, Val Loss=2.2011, Val Acc=11.17%, Grad Norm=1.5984, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1923, Train Acc=12.97%, Val Loss=2.2011, Val Acc=11.27%, Grad Norm=1.8435, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1920, Train Acc=12.87%, Val Loss=2.2013, Val Acc=11.28%, Grad Norm=2.0374, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1914, Train Acc=12.96%, Val Loss=2.2017, Val Acc=11.37%, Grad Norm=2.1278, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1912, Train Acc=13.61%, Val Loss=2.2015, Val Acc=11.11%, Grad Norm=2.2928, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1912, Train Acc=13.18%, Val Loss=2.2052, Val Acc=11.23%, Grad Norm=2.3072, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1902, Train Acc=13.54%, Val Loss=2.2025, Val Acc=11.18%, Grad Norm=2.3393, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.1905, Train Acc=13.50%, Val Loss=2.2027, Val Acc=11.31%, Grad Norm=2.4359, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.1888, Train Acc=13.78%, Val Loss=2.2030, Val Acc=11.23%, Grad Norm=2.5279, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.1878, Train Acc=13.78%, Val Loss=2.2033, Val Acc=11.25%, Grad Norm=2.6439, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.1883, Train Acc=13.74%, Val Loss=2.2037, Val Acc=11.24%, Grad Norm=2.7204, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.1874, Train Acc=13.89%, Val Loss=2.2036, Val Acc=11.33%, Grad Norm=2.7489, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.1870, Train Acc=13.80%, Val Loss=2.2041, Val Acc=11.13%, Grad Norm=2.7944, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.1858, Train Acc=14.17%, Val Loss=2.2033, Val Acc=11.32%, Grad Norm=2.8495, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.1878, Train Acc=13.66%, Val Loss=2.2037, Val Acc=11.25%, Grad Norm=2.8478, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.1864, Train Acc=14.17%, Val Loss=2.2027, Val Acc=11.21%, Grad Norm=2.9139, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.1856, Train Acc=14.08%, Val Loss=2.2030, Val Acc=11.22%, Grad Norm=2.9773, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.1859, Train Acc=14.21%, Val Loss=2.2029, Val Acc=11.45%, Grad Norm=2.9884, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.1845, Train Acc=14.51%, Val Loss=2.2027, Val Acc=11.21%, Grad Norm=3.0257, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.1845, Train Acc=14.27%, Val Loss=2.2032, Val Acc=11.36%, Grad Norm=3.0872, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=2.1850, Train Acc=14.44%, Val Loss=2.2029, Val Acc=11.33%, Grad Norm=3.1013, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=2.1847, Train Acc=14.31%, Val Loss=2.2030, Val Acc=11.28%, Grad Norm=3.1176, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=2.1850, Train Acc=14.32%, Val Loss=2.2027, Val Acc=11.28%, Grad Norm=3.1462, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=2.1847, Train Acc=14.37%, Val Loss=2.2029, Val Acc=11.29%, Grad Norm=3.1801, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=2.1848, Train Acc=14.56%, Val Loss=2.2027, Val Acc=11.36%, Grad Norm=3.1935, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=2.1838, Train Acc=14.26%, Val Loss=2.2028, Val Acc=11.35%, Grad Norm=3.1997, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=2.1837, Train Acc=14.48%, Val Loss=2.2025, Val Acc=11.41%, Grad Norm=3.2409, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=2.1827, Train Acc=14.81%, Val Loss=2.2024, Val Acc=11.43%, Grad Norm=3.2774, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=2.1824, Train Acc=14.75%, Val Loss=2.2026, Val Acc=11.34%, Grad Norm=3.2873, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=2.1837, Train Acc=14.66%, Val Loss=2.2028, Val Acc=11.39%, Grad Norm=3.3109, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=2.1820, Train Acc=14.52%, Val Loss=2.2027, Val Acc=11.38%, Grad Norm=3.3252, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=2.1818, Train Acc=14.86%, Val Loss=2.2027, Val Acc=11.29%, Grad Norm=3.3534, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=2.1829, Train Acc=14.73%, Val Loss=2.2024, Val Acc=11.40%, Grad Norm=3.3744, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=2.1819, Train Acc=14.89%, Val Loss=2.2025, Val Acc=11.27%, Grad Norm=3.3904, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=2.1817, Train Acc=14.95%, Val Loss=2.2027, Val Acc=11.30%, Grad Norm=3.4055, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=2.1816, Train Acc=14.85%, Val Loss=2.2029, Val Acc=11.23%, Grad Norm=3.4318, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=2.1818, Train Acc=14.90%, Val Loss=2.2028, Val Acc=11.32%, Grad Norm=3.4461, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=2.1824, Train Acc=15.01%, Val Loss=2.2029, Val Acc=11.35%, Grad Norm=3.4716, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=2.1818, Train Acc=14.74%, Val Loss=2.2029, Val Acc=11.42%, Grad Norm=3.4900, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=2.1807, Train Acc=15.06%, Val Loss=2.2028, Val Acc=11.28%, Grad Norm=3.4996, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=2.1806, Train Acc=15.09%, Val Loss=2.2028, Val Acc=11.30%, Grad Norm=3.5140, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=2.1812, Train Acc=15.06%, Val Loss=2.2028, Val Acc=11.39%, Grad Norm=3.5277, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=2.1820, Train Acc=15.15%, Val Loss=2.2027, Val Acc=11.31%, Grad Norm=3.5358, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=2.1800, Train Acc=14.97%, Val Loss=2.2027, Val Acc=11.27%, Grad Norm=3.5424, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=2.1807, Train Acc=14.89%, Val Loss=2.2027, Val Acc=11.28%, Grad Norm=3.5606, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=2.1816, Train Acc=15.00%, Val Loss=2.2026, Val Acc=11.19%, Grad Norm=3.5690, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=2.1796, Train Acc=15.25%, Val Loss=2.2026, Val Acc=11.21%, Grad Norm=3.5773, LR=7.8125e-07\n",
      "Fold 3, Epoch 80: Train Loss=2.1809, Train Acc=14.72%, Val Loss=2.2027, Val Acc=11.21%, Grad Norm=3.5945, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.45%）\n",
      "Fold 3 DONE | Best Val Acc≈11.45% | Final Val Acc=11.45% | Test Acc=11.62%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2258, Train Acc=10.86%, Val Loss=2.2213, Val Acc=11.41%, Grad Norm=6.7694, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2213, Train Acc=11.20%, Val Loss=2.2456, Val Acc=11.12%, Grad Norm=6.3987, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2161, Train Acc=10.99%, Val Loss=2.2269, Val Acc=11.02%, Grad Norm=5.3988, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2115, Train Acc=10.87%, Val Loss=2.2230, Val Acc=11.08%, Grad Norm=4.1190, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2073, Train Acc=10.96%, Val Loss=2.2143, Val Acc=11.18%, Grad Norm=3.3793, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2052, Train Acc=11.28%, Val Loss=2.2100, Val Acc=11.05%, Grad Norm=2.9783, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2039, Train Acc=11.22%, Val Loss=2.2112, Val Acc=11.33%, Grad Norm=2.6724, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.2032, Train Acc=11.24%, Val Loss=2.2017, Val Acc=10.94%, Grad Norm=2.3365, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.2025, Train Acc=11.03%, Val Loss=2.2051, Val Acc=11.02%, Grad Norm=1.9580, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.2009, Train Acc=11.20%, Val Loss=2.2051, Val Acc=11.06%, Grad Norm=1.6552, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1991, Train Acc=11.14%, Val Loss=2.1999, Val Acc=11.33%, Grad Norm=1.4284, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1990, Train Acc=11.23%, Val Loss=2.1984, Val Acc=11.22%, Grad Norm=1.3415, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1985, Train Acc=11.22%, Val Loss=2.1993, Val Acc=10.96%, Grad Norm=1.2551, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1983, Train Acc=11.49%, Val Loss=2.2073, Val Acc=11.10%, Grad Norm=1.2741, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1984, Train Acc=11.24%, Val Loss=2.1981, Val Acc=11.25%, Grad Norm=1.1600, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1977, Train Acc=11.47%, Val Loss=2.2002, Val Acc=11.31%, Grad Norm=1.1551, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1979, Train Acc=11.58%, Val Loss=2.1982, Val Acc=11.15%, Grad Norm=1.0537, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1977, Train Acc=11.62%, Val Loss=2.1983, Val Acc=10.94%, Grad Norm=0.9618, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1973, Train Acc=11.57%, Val Loss=2.1982, Val Acc=11.45%, Grad Norm=0.9606, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1974, Train Acc=11.58%, Val Loss=2.1981, Val Acc=11.12%, Grad Norm=0.8423, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1966, Train Acc=11.75%, Val Loss=2.1977, Val Acc=11.36%, Grad Norm=0.7716, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1968, Train Acc=11.62%, Val Loss=2.1981, Val Acc=11.36%, Grad Norm=0.8421, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1966, Train Acc=11.67%, Val Loss=2.1979, Val Acc=10.77%, Grad Norm=0.8459, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1963, Train Acc=11.89%, Val Loss=2.1989, Val Acc=10.91%, Grad Norm=0.8729, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1963, Train Acc=12.03%, Val Loss=2.1993, Val Acc=10.68%, Grad Norm=0.9188, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1959, Train Acc=12.06%, Val Loss=2.1984, Val Acc=11.21%, Grad Norm=0.9951, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1964, Train Acc=11.62%, Val Loss=2.1982, Val Acc=11.31%, Grad Norm=0.8646, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1960, Train Acc=11.92%, Val Loss=2.1985, Val Acc=10.47%, Grad Norm=0.9443, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1957, Train Acc=12.25%, Val Loss=2.1993, Val Acc=10.79%, Grad Norm=1.0418, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1959, Train Acc=12.24%, Val Loss=2.1989, Val Acc=11.34%, Grad Norm=0.9299, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1951, Train Acc=12.30%, Val Loss=2.1986, Val Acc=11.18%, Grad Norm=1.0775, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1949, Train Acc=12.44%, Val Loss=2.1985, Val Acc=11.05%, Grad Norm=1.1761, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=2.1948, Train Acc=12.34%, Val Loss=2.1987, Val Acc=11.02%, Grad Norm=1.1400, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=2.1944, Train Acc=12.55%, Val Loss=2.1986, Val Acc=11.31%, Grad Norm=1.1566, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=2.1947, Train Acc=12.31%, Val Loss=2.1989, Val Acc=11.11%, Grad Norm=1.1681, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=2.1942, Train Acc=12.61%, Val Loss=2.1985, Val Acc=10.84%, Grad Norm=1.1871, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=2.1942, Train Acc=13.14%, Val Loss=2.1987, Val Acc=11.10%, Grad Norm=1.1769, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=2.1939, Train Acc=12.67%, Val Loss=2.1989, Val Acc=11.02%, Grad Norm=1.1958, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=2.1938, Train Acc=12.83%, Val Loss=2.1989, Val Acc=11.07%, Grad Norm=1.2744, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=2.1937, Train Acc=12.81%, Val Loss=2.1989, Val Acc=11.29%, Grad Norm=1.2897, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=2.1938, Train Acc=12.56%, Val Loss=2.1989, Val Acc=10.89%, Grad Norm=1.2636, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=2.1936, Train Acc=12.81%, Val Loss=2.1990, Val Acc=11.38%, Grad Norm=1.2770, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=2.1933, Train Acc=12.73%, Val Loss=2.1990, Val Acc=11.08%, Grad Norm=1.3006, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=2.1930, Train Acc=13.09%, Val Loss=2.1989, Val Acc=10.87%, Grad Norm=1.3342, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=2.1927, Train Acc=12.98%, Val Loss=2.1989, Val Acc=11.23%, Grad Norm=1.3801, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=2.1927, Train Acc=12.98%, Val Loss=2.1988, Val Acc=11.27%, Grad Norm=1.4291, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=2.1932, Train Acc=12.91%, Val Loss=2.1989, Val Acc=11.22%, Grad Norm=1.4573, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=2.1925, Train Acc=12.94%, Val Loss=2.1992, Val Acc=11.26%, Grad Norm=1.5096, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=2.1924, Train Acc=13.10%, Val Loss=2.1994, Val Acc=11.00%, Grad Norm=1.5549, LR=6.25e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.45%）\n",
      "Fold 4 DONE | Best Val Acc≈11.45% | Final Val Acc=11.45% | Test Acc=11.31%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2243, Train Acc=11.09%, Val Loss=2.2398, Val Acc=11.07%, Grad Norm=6.6981, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2218, Train Acc=11.07%, Val Loss=2.2830, Val Acc=11.10%, Grad Norm=6.3462, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2156, Train Acc=11.38%, Val Loss=2.3151, Val Acc=11.11%, Grad Norm=5.3591, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2099, Train Acc=11.34%, Val Loss=2.2229, Val Acc=11.11%, Grad Norm=4.1769, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2068, Train Acc=11.01%, Val Loss=2.2396, Val Acc=11.20%, Grad Norm=3.3535, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2039, Train Acc=11.31%, Val Loss=2.2071, Val Acc=10.89%, Grad Norm=2.9415, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2044, Train Acc=11.22%, Val Loss=2.2202, Val Acc=11.30%, Grad Norm=2.5836, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2030, Train Acc=11.12%, Val Loss=2.2143, Val Acc=11.08%, Grad Norm=2.2526, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.2023, Train Acc=10.97%, Val Loss=2.2038, Val Acc=11.12%, Grad Norm=1.9721, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.2012, Train Acc=11.15%, Val Loss=2.2060, Val Acc=10.87%, Grad Norm=1.7321, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1988, Train Acc=11.39%, Val Loss=2.2024, Val Acc=11.15%, Grad Norm=1.5162, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1991, Train Acc=11.12%, Val Loss=2.2004, Val Acc=11.24%, Grad Norm=1.4030, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1985, Train Acc=11.35%, Val Loss=2.2001, Val Acc=11.25%, Grad Norm=1.3184, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1983, Train Acc=11.39%, Val Loss=2.2014, Val Acc=11.08%, Grad Norm=1.2348, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1983, Train Acc=11.35%, Val Loss=2.2006, Val Acc=10.90%, Grad Norm=1.1601, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1977, Train Acc=11.26%, Val Loss=2.1986, Val Acc=11.05%, Grad Norm=1.0940, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1980, Train Acc=11.47%, Val Loss=2.1991, Val Acc=10.98%, Grad Norm=1.0117, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1974, Train Acc=11.55%, Val Loss=2.1983, Val Acc=11.00%, Grad Norm=0.9494, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1975, Train Acc=11.28%, Val Loss=2.1981, Val Acc=11.24%, Grad Norm=0.8930, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1974, Train Acc=11.51%, Val Loss=2.1982, Val Acc=11.11%, Grad Norm=0.8454, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1967, Train Acc=11.66%, Val Loss=2.1980, Val Acc=10.91%, Grad Norm=0.7626, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1965, Train Acc=11.90%, Val Loss=2.1982, Val Acc=11.17%, Grad Norm=0.9384, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1968, Train Acc=11.76%, Val Loss=2.1979, Val Acc=10.82%, Grad Norm=0.7834, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1959, Train Acc=12.15%, Val Loss=2.1989, Val Acc=11.18%, Grad Norm=1.0087, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1962, Train Acc=12.05%, Val Loss=2.1979, Val Acc=10.99%, Grad Norm=0.9385, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1965, Train Acc=11.80%, Val Loss=2.1979, Val Acc=11.14%, Grad Norm=0.8324, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1962, Train Acc=12.04%, Val Loss=2.1979, Val Acc=10.82%, Grad Norm=0.9253, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1962, Train Acc=11.94%, Val Loss=2.1992, Val Acc=11.10%, Grad Norm=0.8619, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1958, Train Acc=11.99%, Val Loss=2.1984, Val Acc=10.88%, Grad Norm=1.0052, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1959, Train Acc=12.06%, Val Loss=2.1986, Val Acc=10.80%, Grad Norm=0.9417, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1954, Train Acc=12.30%, Val Loss=2.1982, Val Acc=10.86%, Grad Norm=1.0328, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1948, Train Acc=12.40%, Val Loss=2.1987, Val Acc=10.70%, Grad Norm=1.0627, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1947, Train Acc=12.54%, Val Loss=2.1989, Val Acc=10.81%, Grad Norm=1.1256, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1948, Train Acc=12.25%, Val Loss=2.1984, Val Acc=10.66%, Grad Norm=1.1535, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1942, Train Acc=12.63%, Val Loss=2.1985, Val Acc=10.89%, Grad Norm=1.1615, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1942, Train Acc=12.45%, Val Loss=2.1984, Val Acc=10.80%, Grad Norm=1.1898, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1944, Train Acc=12.47%, Val Loss=2.1986, Val Acc=11.16%, Grad Norm=1.1795, LR=1.25e-05\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.30%）\n",
      "Fold 5 DONE | Best Val Acc≈11.30% | Final Val Acc=11.30% | Test Acc=10.85%\n",
      "[INFO] SNR=-25 dB | Mean Test Acc: 11.14% ± 0.30%\n",
      "[INFO] SNR -25 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-25dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -30 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2239, Train Acc=11.02%, Val Loss=2.2714, Val Acc=11.11%, Grad Norm=6.7601, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2220, Train Acc=11.24%, Val Loss=2.2159, Val Acc=11.22%, Grad Norm=6.5546, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2193, Train Acc=10.94%, Val Loss=2.2589, Val Acc=11.01%, Grad Norm=5.8874, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2124, Train Acc=11.31%, Val Loss=2.2235, Val Acc=10.99%, Grad Norm=4.8085, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2094, Train Acc=11.05%, Val Loss=2.2213, Val Acc=11.11%, Grad Norm=3.7951, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2061, Train Acc=11.09%, Val Loss=2.2453, Val Acc=10.98%, Grad Norm=3.1981, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2048, Train Acc=11.21%, Val Loss=2.2192, Val Acc=11.11%, Grad Norm=2.8579, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2032, Train Acc=11.36%, Val Loss=2.2084, Val Acc=11.16%, Grad Norm=2.6227, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2031, Train Acc=11.27%, Val Loss=2.2042, Val Acc=11.08%, Grad Norm=2.3124, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2027, Train Acc=11.15%, Val Loss=2.2053, Val Acc=11.08%, Grad Norm=1.9991, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.2001, Train Acc=11.41%, Val Loss=2.1998, Val Acc=11.11%, Grad Norm=1.7751, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.1990, Train Acc=11.29%, Val Loss=2.2039, Val Acc=11.06%, Grad Norm=1.6882, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.1991, Train Acc=11.32%, Val Loss=2.2059, Val Acc=11.04%, Grad Norm=1.6414, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1994, Train Acc=11.16%, Val Loss=2.2022, Val Acc=10.91%, Grad Norm=1.5402, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1978, Train Acc=11.65%, Val Loss=2.2012, Val Acc=11.15%, Grad Norm=1.5095, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1991, Train Acc=11.38%, Val Loss=2.2023, Val Acc=10.89%, Grad Norm=1.4069, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1983, Train Acc=11.46%, Val Loss=2.2028, Val Acc=11.14%, Grad Norm=1.3535, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1983, Train Acc=11.42%, Val Loss=2.2036, Val Acc=11.14%, Grad Norm=1.2491, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1980, Train Acc=11.54%, Val Loss=2.2016, Val Acc=11.02%, Grad Norm=1.2269, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1977, Train Acc=11.50%, Val Loss=2.1984, Val Acc=11.07%, Grad Norm=1.1804, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1971, Train Acc=11.43%, Val Loss=2.1983, Val Acc=11.19%, Grad Norm=1.1592, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1972, Train Acc=11.60%, Val Loss=2.1989, Val Acc=10.94%, Grad Norm=1.1121, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1968, Train Acc=11.56%, Val Loss=2.1984, Val Acc=11.20%, Grad Norm=1.1530, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1966, Train Acc=11.75%, Val Loss=2.2001, Val Acc=11.13%, Grad Norm=1.2446, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1966, Train Acc=11.80%, Val Loss=2.1993, Val Acc=11.18%, Grad Norm=1.2726, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1961, Train Acc=11.97%, Val Loss=2.2012, Val Acc=11.00%, Grad Norm=1.2745, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1961, Train Acc=12.24%, Val Loss=2.2008, Val Acc=11.04%, Grad Norm=1.2135, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1958, Train Acc=12.09%, Val Loss=2.2004, Val Acc=11.08%, Grad Norm=1.2455, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1954, Train Acc=12.24%, Val Loss=2.2011, Val Acc=11.03%, Grad Norm=1.3122, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1953, Train Acc=12.16%, Val Loss=2.2012, Val Acc=11.01%, Grad Norm=1.3673, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1953, Train Acc=12.19%, Val Loss=2.1996, Val Acc=11.27%, Grad Norm=1.3144, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1947, Train Acc=12.12%, Val Loss=2.2003, Val Acc=11.10%, Grad Norm=1.4488, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1939, Train Acc=12.60%, Val Loss=2.2041, Val Acc=11.06%, Grad Norm=1.6423, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1935, Train Acc=12.87%, Val Loss=2.2007, Val Acc=11.18%, Grad Norm=1.7604, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1936, Train Acc=12.62%, Val Loss=2.2008, Val Acc=11.41%, Grad Norm=1.8608, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1933, Train Acc=13.00%, Val Loss=2.2009, Val Acc=11.24%, Grad Norm=1.8319, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1935, Train Acc=12.93%, Val Loss=2.2020, Val Acc=11.22%, Grad Norm=1.8024, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1931, Train Acc=12.59%, Val Loss=2.2026, Val Acc=11.13%, Grad Norm=1.8778, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1931, Train Acc=12.83%, Val Loss=2.2016, Val Acc=11.43%, Grad Norm=2.0001, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1927, Train Acc=12.90%, Val Loss=2.2012, Val Acc=11.17%, Grad Norm=2.0756, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1913, Train Acc=13.20%, Val Loss=2.2035, Val Acc=11.26%, Grad Norm=2.2057, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.1917, Train Acc=13.20%, Val Loss=2.2025, Val Acc=11.19%, Grad Norm=2.3097, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=2.1908, Train Acc=13.47%, Val Loss=2.2029, Val Acc=11.04%, Grad Norm=2.3973, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=2.1909, Train Acc=13.05%, Val Loss=2.2030, Val Acc=10.97%, Grad Norm=2.4809, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=2.1909, Train Acc=13.44%, Val Loss=2.2027, Val Acc=11.27%, Grad Norm=2.5151, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=2.1902, Train Acc=13.45%, Val Loss=2.2036, Val Acc=11.05%, Grad Norm=2.5512, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=2.1899, Train Acc=13.58%, Val Loss=2.2036, Val Acc=11.15%, Grad Norm=2.5970, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=2.1895, Train Acc=13.58%, Val Loss=2.2029, Val Acc=11.34%, Grad Norm=2.6205, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=2.1896, Train Acc=13.50%, Val Loss=2.2030, Val Acc=11.33%, Grad Norm=2.6567, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=2.1895, Train Acc=13.51%, Val Loss=2.2034, Val Acc=11.30%, Grad Norm=2.7005, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=2.1894, Train Acc=13.81%, Val Loss=2.2035, Val Acc=11.24%, Grad Norm=2.7635, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=2.1883, Train Acc=13.81%, Val Loss=2.2038, Val Acc=11.39%, Grad Norm=2.7762, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=2.1887, Train Acc=13.56%, Val Loss=2.2034, Val Acc=11.30%, Grad Norm=2.7753, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=2.1875, Train Acc=13.88%, Val Loss=2.2035, Val Acc=11.26%, Grad Norm=2.8029, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=2.1880, Train Acc=13.87%, Val Loss=2.2033, Val Acc=11.24%, Grad Norm=2.8446, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=2.1885, Train Acc=13.80%, Val Loss=2.2027, Val Acc=11.23%, Grad Norm=2.8591, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=2.1873, Train Acc=13.79%, Val Loss=2.2028, Val Acc=11.14%, Grad Norm=2.8718, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=2.1876, Train Acc=14.04%, Val Loss=2.2027, Val Acc=11.23%, Grad Norm=2.8811, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=2.1874, Train Acc=13.93%, Val Loss=2.2039, Val Acc=11.42%, Grad Norm=2.9001, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=2.1877, Train Acc=13.96%, Val Loss=2.2032, Val Acc=11.37%, Grad Norm=2.8976, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=2.1866, Train Acc=13.99%, Val Loss=2.2034, Val Acc=11.39%, Grad Norm=2.9243, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=2.1868, Train Acc=13.96%, Val Loss=2.2035, Val Acc=11.25%, Grad Norm=2.9460, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=2.1862, Train Acc=14.09%, Val Loss=2.2038, Val Acc=11.34%, Grad Norm=2.9594, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=2.1869, Train Acc=14.20%, Val Loss=2.2038, Val Acc=11.27%, Grad Norm=2.9814, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=2.1866, Train Acc=13.94%, Val Loss=2.2042, Val Acc=11.24%, Grad Norm=2.9885, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=2.1873, Train Acc=13.67%, Val Loss=2.2036, Val Acc=11.24%, Grad Norm=2.9934, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=2.1870, Train Acc=13.83%, Val Loss=2.2033, Val Acc=11.18%, Grad Norm=2.9949, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=2.1864, Train Acc=14.21%, Val Loss=2.2035, Val Acc=11.18%, Grad Norm=3.0047, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=2.1869, Train Acc=13.99%, Val Loss=2.2035, Val Acc=11.11%, Grad Norm=3.0176, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.43%）\n",
      "Fold 1 DONE | Best Val Acc≈11.43% | Final Val Acc=11.43% | Test Acc=10.95%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2235, Train Acc=10.89%, Val Loss=2.2778, Val Acc=11.19%, Grad Norm=6.7083, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2202, Train Acc=11.10%, Val Loss=2.2750, Val Acc=11.11%, Grad Norm=6.5384, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2190, Train Acc=11.16%, Val Loss=2.2407, Val Acc=11.15%, Grad Norm=5.9516, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2135, Train Acc=11.14%, Val Loss=2.2287, Val Acc=11.10%, Grad Norm=4.9507, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2082, Train Acc=11.13%, Val Loss=2.2175, Val Acc=11.15%, Grad Norm=3.9441, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2066, Train Acc=10.98%, Val Loss=2.2229, Val Acc=11.29%, Grad Norm=3.3447, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2043, Train Acc=11.09%, Val Loss=2.2080, Val Acc=11.22%, Grad Norm=2.9819, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2045, Train Acc=11.03%, Val Loss=2.2207, Val Acc=11.12%, Grad Norm=2.6957, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2029, Train Acc=11.16%, Val Loss=2.2127, Val Acc=11.28%, Grad Norm=2.3819, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.2022, Train Acc=11.16%, Val Loss=2.2185, Val Acc=11.11%, Grad Norm=2.1258, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.2002, Train Acc=11.19%, Val Loss=2.2070, Val Acc=11.12%, Grad Norm=1.9060, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.2001, Train Acc=11.17%, Val Loss=2.2012, Val Acc=11.06%, Grad Norm=1.7698, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.2001, Train Acc=11.08%, Val Loss=2.2020, Val Acc=11.19%, Grad Norm=1.6803, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1994, Train Acc=11.13%, Val Loss=2.2019, Val Acc=11.10%, Grad Norm=1.5856, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1990, Train Acc=11.14%, Val Loss=2.2028, Val Acc=11.12%, Grad Norm=1.5305, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1990, Train Acc=11.43%, Val Loss=2.2020, Val Acc=11.21%, Grad Norm=1.5081, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1989, Train Acc=11.39%, Val Loss=2.2025, Val Acc=11.09%, Grad Norm=1.3685, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1984, Train Acc=11.12%, Val Loss=2.2003, Val Acc=11.14%, Grad Norm=1.2783, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1980, Train Acc=11.71%, Val Loss=2.2005, Val Acc=11.18%, Grad Norm=1.2706, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1977, Train Acc=11.51%, Val Loss=2.2027, Val Acc=11.31%, Grad Norm=1.2351, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1975, Train Acc=11.58%, Val Loss=2.1988, Val Acc=11.08%, Grad Norm=1.1562, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1970, Train Acc=11.86%, Val Loss=2.1982, Val Acc=11.21%, Grad Norm=1.1110, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1968, Train Acc=11.66%, Val Loss=2.2011, Val Acc=11.29%, Grad Norm=1.1456, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1967, Train Acc=11.91%, Val Loss=2.1987, Val Acc=11.19%, Grad Norm=1.2514, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1967, Train Acc=11.79%, Val Loss=2.1988, Val Acc=11.04%, Grad Norm=1.2426, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1965, Train Acc=12.04%, Val Loss=2.1999, Val Acc=11.07%, Grad Norm=1.2094, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1966, Train Acc=11.90%, Val Loss=2.2030, Val Acc=11.23%, Grad Norm=1.2115, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1960, Train Acc=12.15%, Val Loss=2.1992, Val Acc=10.99%, Grad Norm=1.2791, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1957, Train Acc=12.12%, Val Loss=2.1990, Val Acc=11.15%, Grad Norm=1.2980, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1961, Train Acc=12.10%, Val Loss=2.2001, Val Acc=11.11%, Grad Norm=1.2682, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1950, Train Acc=12.35%, Val Loss=2.1992, Val Acc=11.26%, Grad Norm=1.2822, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1946, Train Acc=12.65%, Val Loss=2.1998, Val Acc=11.38%, Grad Norm=1.4275, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1949, Train Acc=12.46%, Val Loss=2.1997, Val Acc=11.27%, Grad Norm=1.5580, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1940, Train Acc=13.05%, Val Loss=2.2022, Val Acc=11.19%, Grad Norm=1.7089, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1941, Train Acc=12.85%, Val Loss=2.1992, Val Acc=11.33%, Grad Norm=1.7600, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1940, Train Acc=12.55%, Val Loss=2.2009, Val Acc=11.08%, Grad Norm=1.8162, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1935, Train Acc=12.81%, Val Loss=2.2006, Val Acc=11.02%, Grad Norm=1.9267, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1932, Train Acc=12.88%, Val Loss=2.2014, Val Acc=11.16%, Grad Norm=2.0430, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1932, Train Acc=12.68%, Val Loss=2.2012, Val Acc=11.22%, Grad Norm=1.9580, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1928, Train Acc=13.07%, Val Loss=2.2020, Val Acc=10.96%, Grad Norm=2.1683, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1921, Train Acc=13.04%, Val Loss=2.2019, Val Acc=11.25%, Grad Norm=2.1998, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1919, Train Acc=13.16%, Val Loss=2.2023, Val Acc=10.87%, Grad Norm=2.2997, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1910, Train Acc=13.26%, Val Loss=2.2040, Val Acc=10.77%, Grad Norm=2.3974, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1918, Train Acc=13.01%, Val Loss=2.2015, Val Acc=10.95%, Grad Norm=2.4215, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1907, Train Acc=13.38%, Val Loss=2.2036, Val Acc=10.97%, Grad Norm=2.4738, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1900, Train Acc=13.44%, Val Loss=2.2042, Val Acc=10.87%, Grad Norm=2.5346, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1905, Train Acc=13.12%, Val Loss=2.2033, Val Acc=10.98%, Grad Norm=2.5864, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.1903, Train Acc=13.61%, Val Loss=2.2027, Val Acc=11.04%, Grad Norm=2.5657, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.1903, Train Acc=13.61%, Val Loss=2.2021, Val Acc=11.16%, Grad Norm=2.5576, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.1896, Train Acc=13.58%, Val Loss=2.2026, Val Acc=11.20%, Grad Norm=2.5961, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.1898, Train Acc=13.48%, Val Loss=2.2024, Val Acc=11.12%, Grad Norm=2.6046, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.1892, Train Acc=13.37%, Val Loss=2.2027, Val Acc=11.16%, Grad Norm=2.6276, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.1895, Train Acc=13.59%, Val Loss=2.2028, Val Acc=11.08%, Grad Norm=2.6486, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.1884, Train Acc=13.65%, Val Loss=2.2026, Val Acc=10.98%, Grad Norm=2.6813, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.1899, Train Acc=13.36%, Val Loss=2.2014, Val Acc=11.22%, Grad Norm=2.7082, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.1882, Train Acc=13.88%, Val Loss=2.2020, Val Acc=11.07%, Grad Norm=2.7374, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.1877, Train Acc=13.84%, Val Loss=2.2019, Val Acc=11.20%, Grad Norm=2.7745, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.1885, Train Acc=13.87%, Val Loss=2.2022, Val Acc=11.06%, Grad Norm=2.7889, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.1889, Train Acc=13.59%, Val Loss=2.2023, Val Acc=11.19%, Grad Norm=2.8129, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.1875, Train Acc=14.12%, Val Loss=2.2024, Val Acc=11.21%, Grad Norm=2.8010, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.1874, Train Acc=14.12%, Val Loss=2.2021, Val Acc=11.20%, Grad Norm=2.8125, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.1873, Train Acc=14.07%, Val Loss=2.2024, Val Acc=11.20%, Grad Norm=2.8425, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.38%）\n",
      "Fold 2 DONE | Best Val Acc≈11.38% | Final Val Acc=11.38% | Test Acc=11.12%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2248, Train Acc=11.11%, Val Loss=2.2176, Val Acc=11.14%, Grad Norm=6.7626, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2224, Train Acc=11.23%, Val Loss=2.2181, Val Acc=11.21%, Grad Norm=6.4795, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2181, Train Acc=11.23%, Val Loss=2.2305, Val Acc=11.11%, Grad Norm=5.8275, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2148, Train Acc=11.12%, Val Loss=2.2142, Val Acc=10.95%, Grad Norm=4.8358, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2101, Train Acc=11.20%, Val Loss=2.2612, Val Acc=11.05%, Grad Norm=3.9821, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2069, Train Acc=11.29%, Val Loss=2.2332, Val Acc=11.09%, Grad Norm=3.5132, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2059, Train Acc=10.89%, Val Loss=2.2128, Val Acc=11.19%, Grad Norm=3.0334, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2046, Train Acc=11.12%, Val Loss=2.2395, Val Acc=11.11%, Grad Norm=2.7529, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2028, Train Acc=11.21%, Val Loss=2.2155, Val Acc=10.99%, Grad Norm=2.4925, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.2025, Train Acc=11.17%, Val Loss=2.2125, Val Acc=11.15%, Grad Norm=2.1974, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.2001, Train Acc=11.51%, Val Loss=2.2009, Val Acc=11.03%, Grad Norm=1.9331, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.2004, Train Acc=11.28%, Val Loss=2.2033, Val Acc=11.04%, Grad Norm=1.7628, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1996, Train Acc=11.02%, Val Loss=2.2019, Val Acc=10.85%, Grad Norm=1.7253, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1994, Train Acc=11.47%, Val Loss=2.2043, Val Acc=11.16%, Grad Norm=1.6571, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1991, Train Acc=11.18%, Val Loss=2.2037, Val Acc=11.40%, Grad Norm=1.5469, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1988, Train Acc=11.61%, Val Loss=2.2023, Val Acc=11.20%, Grad Norm=1.4891, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1988, Train Acc=11.50%, Val Loss=2.2001, Val Acc=11.09%, Grad Norm=1.4242, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1984, Train Acc=11.38%, Val Loss=2.2067, Val Acc=11.07%, Grad Norm=1.2786, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1978, Train Acc=11.58%, Val Loss=2.1982, Val Acc=11.23%, Grad Norm=1.3333, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1979, Train Acc=11.38%, Val Loss=2.2005, Val Acc=11.21%, Grad Norm=1.1451, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1974, Train Acc=11.49%, Val Loss=2.1994, Val Acc=11.24%, Grad Norm=1.0925, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1972, Train Acc=11.65%, Val Loss=2.1980, Val Acc=11.47%, Grad Norm=1.0659, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1968, Train Acc=11.70%, Val Loss=2.1990, Val Acc=11.21%, Grad Norm=1.1384, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1967, Train Acc=11.64%, Val Loss=2.1993, Val Acc=11.22%, Grad Norm=1.1465, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1963, Train Acc=12.02%, Val Loss=2.1988, Val Acc=11.04%, Grad Norm=1.2061, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1961, Train Acc=11.91%, Val Loss=2.1986, Val Acc=10.94%, Grad Norm=1.3408, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1965, Train Acc=11.94%, Val Loss=2.1985, Val Acc=11.14%, Grad Norm=1.1371, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1962, Train Acc=11.86%, Val Loss=2.1991, Val Acc=11.15%, Grad Norm=1.1324, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1961, Train Acc=11.88%, Val Loss=2.1985, Val Acc=11.17%, Grad Norm=1.2091, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1958, Train Acc=12.08%, Val Loss=2.1984, Val Acc=11.26%, Grad Norm=1.2442, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1954, Train Acc=12.27%, Val Loss=2.1982, Val Acc=11.43%, Grad Norm=1.2280, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1947, Train Acc=12.65%, Val Loss=2.1993, Val Acc=11.22%, Grad Norm=1.3755, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1948, Train Acc=12.26%, Val Loss=2.1988, Val Acc=11.11%, Grad Norm=1.4414, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1949, Train Acc=12.43%, Val Loss=2.1990, Val Acc=11.30%, Grad Norm=1.4530, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1942, Train Acc=12.65%, Val Loss=2.1993, Val Acc=11.40%, Grad Norm=1.6050, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1939, Train Acc=12.84%, Val Loss=2.2007, Val Acc=11.28%, Grad Norm=1.6694, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1937, Train Acc=12.53%, Val Loss=2.1998, Val Acc=11.34%, Grad Norm=1.8018, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1940, Train Acc=12.55%, Val Loss=2.1992, Val Acc=11.39%, Grad Norm=1.8061, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1930, Train Acc=12.67%, Val Loss=2.2002, Val Acc=11.34%, Grad Norm=2.0184, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.1932, Train Acc=12.89%, Val Loss=2.1998, Val Acc=11.24%, Grad Norm=2.0680, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.1921, Train Acc=13.16%, Val Loss=2.2001, Val Acc=11.21%, Grad Norm=2.1101, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.1921, Train Acc=13.08%, Val Loss=2.2000, Val Acc=11.05%, Grad Norm=2.1630, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.1911, Train Acc=13.40%, Val Loss=2.2005, Val Acc=11.10%, Grad Norm=2.3347, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.1907, Train Acc=12.98%, Val Loss=2.2013, Val Acc=11.17%, Grad Norm=2.4650, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.1899, Train Acc=13.56%, Val Loss=2.2018, Val Acc=11.10%, Grad Norm=2.5134, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.1904, Train Acc=13.27%, Val Loss=2.2014, Val Acc=11.08%, Grad Norm=2.5547, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.1906, Train Acc=13.26%, Val Loss=2.2011, Val Acc=11.05%, Grad Norm=2.5880, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.1897, Train Acc=13.29%, Val Loss=2.2011, Val Acc=11.24%, Grad Norm=2.6746, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.1899, Train Acc=13.40%, Val Loss=2.2007, Val Acc=11.11%, Grad Norm=2.6736, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.1888, Train Acc=13.50%, Val Loss=2.2014, Val Acc=11.14%, Grad Norm=2.6669, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.1892, Train Acc=13.48%, Val Loss=2.2012, Val Acc=11.15%, Grad Norm=2.7405, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.1886, Train Acc=13.99%, Val Loss=2.2009, Val Acc=11.10%, Grad Norm=2.7254, LR=3.125e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.47%）\n",
      "Fold 3 DONE | Best Val Acc≈11.47% | Final Val Acc=11.47% | Test Acc=11.24%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2238, Train Acc=11.08%, Val Loss=2.2219, Val Acc=11.12%, Grad Norm=6.7962, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2217, Train Acc=11.25%, Val Loss=2.2180, Val Acc=11.02%, Grad Norm=6.3997, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2163, Train Acc=11.27%, Val Loss=2.2589, Val Acc=11.08%, Grad Norm=5.5190, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2099, Train Acc=10.90%, Val Loss=2.2061, Val Acc=11.13%, Grad Norm=4.2365, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2078, Train Acc=10.88%, Val Loss=2.2195, Val Acc=11.11%, Grad Norm=3.4447, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2046, Train Acc=11.34%, Val Loss=2.2109, Val Acc=11.21%, Grad Norm=3.0489, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2046, Train Acc=10.90%, Val Loss=2.2200, Val Acc=10.99%, Grad Norm=2.6627, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.2023, Train Acc=11.30%, Val Loss=2.2183, Val Acc=11.09%, Grad Norm=2.3516, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.2024, Train Acc=11.25%, Val Loss=2.2087, Val Acc=11.21%, Grad Norm=2.0219, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.2009, Train Acc=11.37%, Val Loss=2.2003, Val Acc=11.26%, Grad Norm=1.6720, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1992, Train Acc=11.34%, Val Loss=2.2014, Val Acc=11.14%, Grad Norm=1.4457, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1985, Train Acc=11.50%, Val Loss=2.1986, Val Acc=11.21%, Grad Norm=1.3820, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1987, Train Acc=11.37%, Val Loss=2.2029, Val Acc=11.08%, Grad Norm=1.2807, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1983, Train Acc=11.49%, Val Loss=2.1999, Val Acc=11.03%, Grad Norm=1.2572, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1984, Train Acc=11.38%, Val Loss=2.2025, Val Acc=11.29%, Grad Norm=1.1688, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1980, Train Acc=11.34%, Val Loss=2.1987, Val Acc=11.11%, Grad Norm=1.1583, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1978, Train Acc=11.47%, Val Loss=2.1986, Val Acc=11.01%, Grad Norm=0.9980, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1975, Train Acc=11.37%, Val Loss=2.1983, Val Acc=11.15%, Grad Norm=1.0195, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1974, Train Acc=11.86%, Val Loss=2.1995, Val Acc=11.26%, Grad Norm=0.8858, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1971, Train Acc=11.66%, Val Loss=2.1985, Val Acc=11.15%, Grad Norm=0.8551, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1967, Train Acc=11.62%, Val Loss=2.1997, Val Acc=10.83%, Grad Norm=0.7674, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1968, Train Acc=11.89%, Val Loss=2.1987, Val Acc=10.91%, Grad Norm=0.8502, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1960, Train Acc=12.02%, Val Loss=2.2014, Val Acc=10.80%, Grad Norm=0.9100, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1964, Train Acc=11.88%, Val Loss=2.1982, Val Acc=11.12%, Grad Norm=0.9224, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1965, Train Acc=11.69%, Val Loss=2.1991, Val Acc=10.80%, Grad Norm=0.8566, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1959, Train Acc=12.06%, Val Loss=2.1989, Val Acc=10.95%, Grad Norm=0.9949, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1959, Train Acc=12.01%, Val Loss=2.1988, Val Acc=10.54%, Grad Norm=0.9337, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1957, Train Acc=11.97%, Val Loss=2.1993, Val Acc=10.85%, Grad Norm=1.0307, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1959, Train Acc=12.19%, Val Loss=2.1989, Val Acc=11.21%, Grad Norm=0.9971, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1954, Train Acc=12.30%, Val Loss=2.1995, Val Acc=10.72%, Grad Norm=1.1008, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1949, Train Acc=12.43%, Val Loss=2.1993, Val Acc=11.02%, Grad Norm=1.1898, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1946, Train Acc=12.38%, Val Loss=2.1995, Val Acc=11.06%, Grad Norm=1.2677, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=2.1943, Train Acc=12.62%, Val Loss=2.1993, Val Acc=10.70%, Grad Norm=1.2421, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=2.1938, Train Acc=12.95%, Val Loss=2.1988, Val Acc=10.95%, Grad Norm=1.2446, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=2.1937, Train Acc=12.63%, Val Loss=2.1992, Val Acc=10.78%, Grad Norm=1.3102, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=2.1940, Train Acc=12.84%, Val Loss=2.1988, Val Acc=10.75%, Grad Norm=1.2956, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=2.1941, Train Acc=12.79%, Val Loss=2.1990, Val Acc=10.93%, Grad Norm=1.3207, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=2.1940, Train Acc=12.90%, Val Loss=2.1994, Val Acc=10.74%, Grad Norm=1.2968, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=2.1936, Train Acc=13.07%, Val Loss=2.1995, Val Acc=10.73%, Grad Norm=1.3205, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=2.1931, Train Acc=12.81%, Val Loss=2.1998, Val Acc=11.13%, Grad Norm=1.3294, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=2.1930, Train Acc=13.17%, Val Loss=2.1991, Val Acc=10.92%, Grad Norm=1.3560, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=2.1929, Train Acc=13.03%, Val Loss=2.1992, Val Acc=11.09%, Grad Norm=1.4226, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=2.1931, Train Acc=13.02%, Val Loss=2.1993, Val Acc=11.01%, Grad Norm=1.4506, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=2.1927, Train Acc=13.14%, Val Loss=2.1992, Val Acc=10.77%, Grad Norm=1.4507, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=2.1926, Train Acc=13.07%, Val Loss=2.1994, Val Acc=10.81%, Grad Norm=1.4920, LR=6.25e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.29%）\n",
      "Fold 4 DONE | Best Val Acc≈11.29% | Final Val Acc=11.29% | Test Acc=11.12%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2258, Train Acc=11.02%, Val Loss=2.2730, Val Acc=11.11%, Grad Norm=6.7027, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2222, Train Acc=11.01%, Val Loss=2.2573, Val Acc=11.12%, Grad Norm=6.3836, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2181, Train Acc=10.89%, Val Loss=2.2259, Val Acc=11.07%, Grad Norm=5.4565, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2111, Train Acc=11.11%, Val Loss=2.2124, Val Acc=11.33%, Grad Norm=4.3222, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2070, Train Acc=11.12%, Val Loss=2.2280, Val Acc=11.05%, Grad Norm=3.5327, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2052, Train Acc=11.09%, Val Loss=2.2267, Val Acc=11.12%, Grad Norm=3.0106, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2043, Train Acc=11.07%, Val Loss=2.2079, Val Acc=11.17%, Grad Norm=2.7001, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2023, Train Acc=11.34%, Val Loss=2.2300, Val Acc=11.11%, Grad Norm=2.4305, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.2022, Train Acc=11.03%, Val Loss=2.2295, Val Acc=11.11%, Grad Norm=2.1037, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.2013, Train Acc=11.19%, Val Loss=2.2055, Val Acc=10.85%, Grad Norm=1.7601, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1987, Train Acc=11.44%, Val Loss=2.2038, Val Acc=11.19%, Grad Norm=1.5042, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1991, Train Acc=11.20%, Val Loss=2.2015, Val Acc=11.18%, Grad Norm=1.4320, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1988, Train Acc=11.46%, Val Loss=2.2030, Val Acc=11.06%, Grad Norm=1.3213, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1986, Train Acc=11.33%, Val Loss=2.2002, Val Acc=11.29%, Grad Norm=1.2634, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1982, Train Acc=11.19%, Val Loss=2.1993, Val Acc=11.24%, Grad Norm=1.1727, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1982, Train Acc=11.43%, Val Loss=2.2006, Val Acc=11.22%, Grad Norm=1.0978, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1978, Train Acc=11.28%, Val Loss=2.1984, Val Acc=11.17%, Grad Norm=1.0639, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1979, Train Acc=11.28%, Val Loss=2.1983, Val Acc=11.26%, Grad Norm=0.8574, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1978, Train Acc=11.41%, Val Loss=2.1975, Val Acc=11.40%, Grad Norm=0.8389, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1979, Train Acc=11.18%, Val Loss=2.1977, Val Acc=11.37%, Grad Norm=0.7349, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1971, Train Acc=11.39%, Val Loss=2.1977, Val Acc=10.87%, Grad Norm=0.7522, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1967, Train Acc=11.59%, Val Loss=2.1978, Val Acc=11.31%, Grad Norm=0.8671, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1966, Train Acc=11.79%, Val Loss=2.1981, Val Acc=11.12%, Grad Norm=0.8407, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1968, Train Acc=11.63%, Val Loss=2.1982, Val Acc=11.10%, Grad Norm=0.8268, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1968, Train Acc=11.46%, Val Loss=2.1979, Val Acc=11.40%, Grad Norm=0.7379, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1965, Train Acc=11.82%, Val Loss=2.1978, Val Acc=11.04%, Grad Norm=0.8627, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1969, Train Acc=11.55%, Val Loss=2.1977, Val Acc=11.18%, Grad Norm=0.7665, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1964, Train Acc=11.78%, Val Loss=2.1982, Val Acc=11.24%, Grad Norm=0.9085, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1966, Train Acc=12.01%, Val Loss=2.1979, Val Acc=11.72%, Grad Norm=0.8199, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1964, Train Acc=12.12%, Val Loss=2.1977, Val Acc=11.26%, Grad Norm=0.9595, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1962, Train Acc=12.03%, Val Loss=2.1977, Val Acc=11.17%, Grad Norm=0.8994, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1954, Train Acc=12.11%, Val Loss=2.1981, Val Acc=11.12%, Grad Norm=1.0565, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1954, Train Acc=12.09%, Val Loss=2.1982, Val Acc=11.05%, Grad Norm=1.1610, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1955, Train Acc=12.40%, Val Loss=2.1979, Val Acc=11.02%, Grad Norm=1.0703, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1950, Train Acc=12.57%, Val Loss=2.1981, Val Acc=11.25%, Grad Norm=1.0659, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1949, Train Acc=12.62%, Val Loss=2.1978, Val Acc=11.18%, Grad Norm=1.1285, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1952, Train Acc=12.32%, Val Loss=2.1980, Val Acc=11.31%, Grad Norm=1.0916, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=2.1948, Train Acc=12.64%, Val Loss=2.1980, Val Acc=11.24%, Grad Norm=1.0979, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=2.1947, Train Acc=12.46%, Val Loss=2.1983, Val Acc=11.05%, Grad Norm=1.1166, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=2.1947, Train Acc=12.41%, Val Loss=2.1980, Val Acc=11.23%, Grad Norm=1.1291, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=2.1946, Train Acc=12.45%, Val Loss=2.1979, Val Acc=11.14%, Grad Norm=1.1673, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=2.1945, Train Acc=12.66%, Val Loss=2.1981, Val Acc=11.28%, Grad Norm=1.1582, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=2.1944, Train Acc=12.63%, Val Loss=2.1981, Val Acc=11.32%, Grad Norm=1.1888, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=2.1944, Train Acc=12.87%, Val Loss=2.1980, Val Acc=11.50%, Grad Norm=1.2041, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=2.1941, Train Acc=12.82%, Val Loss=2.1981, Val Acc=11.19%, Grad Norm=1.2160, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=2.1936, Train Acc=12.74%, Val Loss=2.1983, Val Acc=11.26%, Grad Norm=1.2499, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=2.1940, Train Acc=12.86%, Val Loss=2.1982, Val Acc=11.26%, Grad Norm=1.2830, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=2.1935, Train Acc=12.76%, Val Loss=2.1980, Val Acc=11.32%, Grad Norm=1.3333, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=2.1941, Train Acc=12.74%, Val Loss=2.1981, Val Acc=11.51%, Grad Norm=1.3555, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=2.1939, Train Acc=12.84%, Val Loss=2.1981, Val Acc=11.12%, Grad Norm=1.3816, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=2.1938, Train Acc=12.83%, Val Loss=2.1981, Val Acc=11.08%, Grad Norm=1.4019, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=2.1935, Train Acc=13.02%, Val Loss=2.1983, Val Acc=11.12%, Grad Norm=1.4090, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=2.1933, Train Acc=13.08%, Val Loss=2.1984, Val Acc=11.29%, Grad Norm=1.4130, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=2.1933, Train Acc=13.02%, Val Loss=2.1984, Val Acc=11.42%, Grad Norm=1.4567, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=2.1932, Train Acc=12.96%, Val Loss=2.1984, Val Acc=11.05%, Grad Norm=1.4737, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=2.1932, Train Acc=13.22%, Val Loss=2.1983, Val Acc=11.14%, Grad Norm=1.5051, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=2.1930, Train Acc=13.15%, Val Loss=2.1983, Val Acc=11.13%, Grad Norm=1.5062, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=2.1932, Train Acc=13.04%, Val Loss=2.1982, Val Acc=11.14%, Grad Norm=1.5298, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=2.1930, Train Acc=13.12%, Val Loss=2.1983, Val Acc=11.09%, Grad Norm=1.5563, LR=3.125e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.72%）\n",
      "Fold 5 DONE | Best Val Acc≈11.72% | Final Val Acc=11.72% | Test Acc=11.16%\n",
      "[INFO] SNR=-30 dB | Mean Test Acc: 11.12% ± 0.10%\n",
      "[INFO] SNR -30 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-30dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -35 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2237, Train Acc=11.16%, Val Loss=2.2225, Val Acc=11.25%, Grad Norm=6.8705, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2224, Train Acc=11.16%, Val Loss=2.2223, Val Acc=11.22%, Grad Norm=6.6268, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2186, Train Acc=11.01%, Val Loss=2.2356, Val Acc=11.10%, Grad Norm=5.9391, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2146, Train Acc=10.98%, Val Loss=2.2247, Val Acc=11.09%, Grad Norm=4.8453, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2080, Train Acc=11.33%, Val Loss=2.2217, Val Acc=11.10%, Grad Norm=3.9216, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2062, Train Acc=11.04%, Val Loss=2.2117, Val Acc=11.19%, Grad Norm=3.2713, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2047, Train Acc=11.30%, Val Loss=2.2229, Val Acc=11.20%, Grad Norm=2.9307, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2042, Train Acc=11.10%, Val Loss=2.2214, Val Acc=11.17%, Grad Norm=2.6122, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2031, Train Acc=11.34%, Val Loss=2.2345, Val Acc=11.11%, Grad Norm=2.3992, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2017, Train Acc=11.31%, Val Loss=2.2042, Val Acc=11.11%, Grad Norm=2.1293, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.2011, Train Acc=11.19%, Val Loss=2.2004, Val Acc=11.28%, Grad Norm=1.8569, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.1991, Train Acc=11.56%, Val Loss=2.2044, Val Acc=11.08%, Grad Norm=1.7261, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.2001, Train Acc=11.13%, Val Loss=2.2029, Val Acc=11.12%, Grad Norm=1.6497, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1991, Train Acc=11.38%, Val Loss=2.2049, Val Acc=11.03%, Grad Norm=1.5898, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1991, Train Acc=11.26%, Val Loss=2.2006, Val Acc=11.12%, Grad Norm=1.5351, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1991, Train Acc=11.02%, Val Loss=2.2004, Val Acc=11.11%, Grad Norm=1.4204, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1985, Train Acc=11.31%, Val Loss=2.1988, Val Acc=11.05%, Grad Norm=1.3944, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1982, Train Acc=11.43%, Val Loss=2.1986, Val Acc=11.15%, Grad Norm=1.3148, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1976, Train Acc=11.35%, Val Loss=2.1988, Val Acc=11.08%, Grad Norm=1.2579, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1982, Train Acc=11.44%, Val Loss=2.1993, Val Acc=11.17%, Grad Norm=1.1975, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1973, Train Acc=11.69%, Val Loss=2.1988, Val Acc=11.26%, Grad Norm=1.0775, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1971, Train Acc=11.62%, Val Loss=2.1985, Val Acc=11.09%, Grad Norm=1.1459, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1968, Train Acc=11.97%, Val Loss=2.1986, Val Acc=11.18%, Grad Norm=1.1807, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1967, Train Acc=11.77%, Val Loss=2.1993, Val Acc=11.04%, Grad Norm=1.2490, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1958, Train Acc=12.12%, Val Loss=2.1990, Val Acc=11.05%, Grad Norm=1.4411, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1965, Train Acc=11.99%, Val Loss=2.1987, Val Acc=11.25%, Grad Norm=1.2908, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1962, Train Acc=11.97%, Val Loss=2.1990, Val Acc=11.09%, Grad Norm=1.3218, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1956, Train Acc=12.23%, Val Loss=2.1989, Val Acc=11.10%, Grad Norm=1.4226, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1958, Train Acc=11.99%, Val Loss=2.1987, Val Acc=11.16%, Grad Norm=1.3343, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1955, Train Acc=12.22%, Val Loss=2.1986, Val Acc=11.35%, Grad Norm=1.3136, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1956, Train Acc=12.18%, Val Loss=2.1987, Val Acc=10.95%, Grad Norm=1.2537, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1948, Train Acc=12.37%, Val Loss=2.1992, Val Acc=11.06%, Grad Norm=1.3814, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1947, Train Acc=12.34%, Val Loss=2.2001, Val Acc=11.02%, Grad Norm=1.5634, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1942, Train Acc=12.35%, Val Loss=2.1999, Val Acc=11.22%, Grad Norm=1.6381, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1940, Train Acc=12.75%, Val Loss=2.1995, Val Acc=11.31%, Grad Norm=1.7331, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1935, Train Acc=12.65%, Val Loss=2.2011, Val Acc=11.31%, Grad Norm=1.8475, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1931, Train Acc=12.69%, Val Loss=2.2015, Val Acc=11.27%, Grad Norm=1.9500, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1926, Train Acc=12.89%, Val Loss=2.2017, Val Acc=11.27%, Grad Norm=2.0071, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1933, Train Acc=12.64%, Val Loss=2.2011, Val Acc=11.27%, Grad Norm=2.1330, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1925, Train Acc=12.96%, Val Loss=2.2017, Val Acc=11.28%, Grad Norm=2.1822, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1922, Train Acc=13.13%, Val Loss=2.2023, Val Acc=11.42%, Grad Norm=2.1946, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.1910, Train Acc=13.05%, Val Loss=2.2025, Val Acc=11.18%, Grad Norm=2.3856, LR=6.25e-06\n",
      "Fold 1, Epoch 43: Train Loss=2.1910, Train Acc=13.22%, Val Loss=2.2026, Val Acc=11.41%, Grad Norm=2.4960, LR=6.25e-06\n",
      "Fold 1, Epoch 44: Train Loss=2.1907, Train Acc=13.14%, Val Loss=2.2025, Val Acc=11.12%, Grad Norm=2.6431, LR=6.25e-06\n",
      "Fold 1, Epoch 45: Train Loss=2.1900, Train Acc=13.24%, Val Loss=2.2026, Val Acc=10.89%, Grad Norm=2.7052, LR=6.25e-06\n",
      "Fold 1, Epoch 46: Train Loss=2.1911, Train Acc=13.08%, Val Loss=2.2035, Val Acc=11.34%, Grad Norm=2.6839, LR=6.25e-06\n",
      "Fold 1, Epoch 47: Train Loss=2.1902, Train Acc=13.40%, Val Loss=2.2029, Val Acc=11.40%, Grad Norm=2.7062, LR=6.25e-06\n",
      "Fold 1, Epoch 48: Train Loss=2.1898, Train Acc=13.62%, Val Loss=2.2021, Val Acc=11.52%, Grad Norm=2.6959, LR=6.25e-06\n",
      "Fold 1, Epoch 49: Train Loss=2.1901, Train Acc=13.41%, Val Loss=2.2023, Val Acc=11.24%, Grad Norm=2.7206, LR=6.25e-06\n",
      "Fold 1, Epoch 50: Train Loss=2.1896, Train Acc=13.58%, Val Loss=2.2020, Val Acc=11.16%, Grad Norm=2.7436, LR=6.25e-06\n",
      "Fold 1, Epoch 51: Train Loss=2.1891, Train Acc=13.63%, Val Loss=2.2020, Val Acc=11.32%, Grad Norm=2.7618, LR=3.125e-06\n",
      "Fold 1, Epoch 52: Train Loss=2.1893, Train Acc=13.58%, Val Loss=2.2018, Val Acc=11.31%, Grad Norm=2.7728, LR=3.125e-06\n",
      "Fold 1, Epoch 53: Train Loss=2.1882, Train Acc=13.79%, Val Loss=2.2023, Val Acc=11.24%, Grad Norm=2.8022, LR=3.125e-06\n",
      "Fold 1, Epoch 54: Train Loss=2.1889, Train Acc=13.53%, Val Loss=2.2019, Val Acc=11.21%, Grad Norm=2.8262, LR=3.125e-06\n",
      "Fold 1, Epoch 55: Train Loss=2.1884, Train Acc=13.74%, Val Loss=2.2021, Val Acc=11.27%, Grad Norm=2.8436, LR=3.125e-06\n",
      "Fold 1, Epoch 56: Train Loss=2.1886, Train Acc=13.64%, Val Loss=2.2026, Val Acc=11.32%, Grad Norm=2.8699, LR=3.125e-06\n",
      "Fold 1, Epoch 57: Train Loss=2.1876, Train Acc=14.02%, Val Loss=2.2023, Val Acc=11.26%, Grad Norm=2.8867, LR=3.125e-06\n",
      "Fold 1, Epoch 58: Train Loss=2.1873, Train Acc=14.18%, Val Loss=2.2023, Val Acc=11.13%, Grad Norm=2.9107, LR=3.125e-06\n",
      "Fold 1, Epoch 59: Train Loss=2.1877, Train Acc=13.99%, Val Loss=2.2018, Val Acc=11.27%, Grad Norm=2.9443, LR=3.125e-06\n",
      "Fold 1, Epoch 60: Train Loss=2.1875, Train Acc=14.10%, Val Loss=2.2025, Val Acc=11.34%, Grad Norm=2.9638, LR=3.125e-06\n",
      "Fold 1, Epoch 61: Train Loss=2.1873, Train Acc=13.85%, Val Loss=2.2022, Val Acc=11.16%, Grad Norm=2.9801, LR=1.5625e-06\n",
      "Fold 1, Epoch 62: Train Loss=2.1874, Train Acc=14.13%, Val Loss=2.2022, Val Acc=11.33%, Grad Norm=2.9923, LR=1.5625e-06\n",
      "Fold 1, Epoch 63: Train Loss=2.1866, Train Acc=14.09%, Val Loss=2.2024, Val Acc=11.26%, Grad Norm=2.9929, LR=1.5625e-06\n",
      "Fold 1, Epoch 64: Train Loss=2.1870, Train Acc=13.93%, Val Loss=2.2021, Val Acc=11.20%, Grad Norm=3.0212, LR=1.5625e-06\n",
      "Fold 1, Epoch 65: Train Loss=2.1867, Train Acc=14.05%, Val Loss=2.2023, Val Acc=11.30%, Grad Norm=3.0291, LR=1.5625e-06\n",
      "Fold 1, Epoch 66: Train Loss=2.1878, Train Acc=13.81%, Val Loss=2.2024, Val Acc=11.31%, Grad Norm=3.0315, LR=1.5625e-06\n",
      "Fold 1, Epoch 67: Train Loss=2.1863, Train Acc=13.99%, Val Loss=2.2025, Val Acc=11.26%, Grad Norm=3.0489, LR=1.5625e-06\n",
      "Fold 1, Epoch 68: Train Loss=2.1869, Train Acc=14.09%, Val Loss=2.2021, Val Acc=11.25%, Grad Norm=3.0759, LR=1.5625e-06\n",
      "Fold 1, Epoch 69: Train Loss=2.1869, Train Acc=13.98%, Val Loss=2.2020, Val Acc=11.14%, Grad Norm=3.0918, LR=1.5625e-06\n",
      "Fold 1, Epoch 70: Train Loss=2.1862, Train Acc=14.07%, Val Loss=2.2020, Val Acc=11.22%, Grad Norm=3.0848, LR=1.5625e-06\n",
      "Fold 1, Epoch 71: Train Loss=2.1859, Train Acc=14.20%, Val Loss=2.2021, Val Acc=11.19%, Grad Norm=3.1009, LR=7.8125e-07\n",
      "Fold 1, Epoch 72: Train Loss=2.1856, Train Acc=14.61%, Val Loss=2.2022, Val Acc=11.32%, Grad Norm=3.1121, LR=7.8125e-07\n",
      "Fold 1, Epoch 73: Train Loss=2.1857, Train Acc=14.34%, Val Loss=2.2021, Val Acc=11.27%, Grad Norm=3.1256, LR=7.8125e-07\n",
      "Fold 1, Epoch 74: Train Loss=2.1856, Train Acc=14.16%, Val Loss=2.2023, Val Acc=11.27%, Grad Norm=3.1302, LR=7.8125e-07\n",
      "Fold 1, Epoch 75: Train Loss=2.1856, Train Acc=14.20%, Val Loss=2.2020, Val Acc=11.15%, Grad Norm=3.1373, LR=7.8125e-07\n",
      "Fold 1, Epoch 76: Train Loss=2.1857, Train Acc=14.43%, Val Loss=2.2021, Val Acc=11.13%, Grad Norm=3.1456, LR=7.8125e-07\n",
      "Fold 1, Epoch 77: Train Loss=2.1859, Train Acc=14.12%, Val Loss=2.2021, Val Acc=11.25%, Grad Norm=3.1511, LR=7.8125e-07\n",
      "Fold 1, Epoch 78: Train Loss=2.1852, Train Acc=14.48%, Val Loss=2.2021, Val Acc=11.22%, Grad Norm=3.1616, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.52%）\n",
      "Fold 1 DONE | Best Val Acc≈11.52% | Final Val Acc=11.52% | Test Acc=11.16%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2253, Train Acc=11.10%, Val Loss=2.2448, Val Acc=11.14%, Grad Norm=6.7725, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2230, Train Acc=10.96%, Val Loss=2.2291, Val Acc=11.09%, Grad Norm=6.4485, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2192, Train Acc=11.04%, Val Loss=2.2437, Val Acc=11.15%, Grad Norm=5.7201, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2132, Train Acc=11.15%, Val Loss=2.2448, Val Acc=11.11%, Grad Norm=4.7881, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2088, Train Acc=11.00%, Val Loss=2.2516, Val Acc=11.15%, Grad Norm=3.8632, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2068, Train Acc=11.32%, Val Loss=2.2460, Val Acc=11.11%, Grad Norm=3.3415, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2050, Train Acc=11.28%, Val Loss=2.2372, Val Acc=11.11%, Grad Norm=2.9849, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2040, Train Acc=11.27%, Val Loss=2.2205, Val Acc=11.23%, Grad Norm=2.6792, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2028, Train Acc=11.46%, Val Loss=2.2010, Val Acc=11.14%, Grad Norm=2.3876, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.2022, Train Acc=11.33%, Val Loss=2.2051, Val Acc=11.15%, Grad Norm=2.1175, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.2006, Train Acc=11.33%, Val Loss=2.2074, Val Acc=11.01%, Grad Norm=1.8477, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.1998, Train Acc=11.19%, Val Loss=2.2074, Val Acc=11.13%, Grad Norm=1.7543, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.1999, Train Acc=11.34%, Val Loss=2.2021, Val Acc=11.13%, Grad Norm=1.6793, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1989, Train Acc=11.23%, Val Loss=2.2013, Val Acc=11.09%, Grad Norm=1.6372, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1994, Train Acc=11.27%, Val Loss=2.1990, Val Acc=11.11%, Grad Norm=1.5847, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1989, Train Acc=11.24%, Val Loss=2.2006, Val Acc=11.47%, Grad Norm=1.4613, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1984, Train Acc=11.41%, Val Loss=2.2046, Val Acc=11.15%, Grad Norm=1.4093, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1986, Train Acc=11.32%, Val Loss=2.1990, Val Acc=11.17%, Grad Norm=1.3592, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1980, Train Acc=11.32%, Val Loss=2.1989, Val Acc=11.23%, Grad Norm=1.2527, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1982, Train Acc=11.28%, Val Loss=2.1985, Val Acc=11.09%, Grad Norm=1.2105, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1971, Train Acc=11.55%, Val Loss=2.1979, Val Acc=11.16%, Grad Norm=1.0839, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1965, Train Acc=11.80%, Val Loss=2.1984, Val Acc=11.15%, Grad Norm=1.1804, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1969, Train Acc=11.70%, Val Loss=2.1997, Val Acc=11.05%, Grad Norm=1.2041, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1968, Train Acc=11.72%, Val Loss=2.1984, Val Acc=11.15%, Grad Norm=1.1671, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1963, Train Acc=11.81%, Val Loss=2.1981, Val Acc=11.34%, Grad Norm=1.2176, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1963, Train Acc=11.73%, Val Loss=2.1981, Val Acc=11.39%, Grad Norm=1.2081, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1964, Train Acc=12.05%, Val Loss=2.2010, Val Acc=11.38%, Grad Norm=1.2317, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1960, Train Acc=12.14%, Val Loss=2.2008, Val Acc=11.25%, Grad Norm=1.2618, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1957, Train Acc=12.17%, Val Loss=2.1990, Val Acc=11.36%, Grad Norm=1.2899, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1954, Train Acc=12.27%, Val Loss=2.1990, Val Acc=11.18%, Grad Norm=1.3205, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1953, Train Acc=12.02%, Val Loss=2.1985, Val Acc=11.53%, Grad Norm=1.3997, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1944, Train Acc=12.75%, Val Loss=2.1990, Val Acc=11.31%, Grad Norm=1.4692, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1945, Train Acc=12.47%, Val Loss=2.1987, Val Acc=11.35%, Grad Norm=1.5659, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1940, Train Acc=12.51%, Val Loss=2.1995, Val Acc=11.38%, Grad Norm=1.6626, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1936, Train Acc=12.45%, Val Loss=2.1995, Val Acc=11.55%, Grad Norm=1.8669, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1934, Train Acc=12.65%, Val Loss=2.1988, Val Acc=11.50%, Grad Norm=1.9465, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1933, Train Acc=12.86%, Val Loss=2.1987, Val Acc=11.36%, Grad Norm=1.9110, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1932, Train Acc=12.57%, Val Loss=2.1994, Val Acc=11.20%, Grad Norm=1.9800, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1930, Train Acc=12.96%, Val Loss=2.2010, Val Acc=11.68%, Grad Norm=1.9996, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1923, Train Acc=13.12%, Val Loss=2.2010, Val Acc=11.49%, Grad Norm=2.2024, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1920, Train Acc=13.33%, Val Loss=2.2000, Val Acc=11.34%, Grad Norm=2.2662, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1914, Train Acc=13.13%, Val Loss=2.2004, Val Acc=11.44%, Grad Norm=2.3835, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1908, Train Acc=13.10%, Val Loss=2.2005, Val Acc=11.24%, Grad Norm=2.4833, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1911, Train Acc=13.24%, Val Loss=2.2006, Val Acc=11.41%, Grad Norm=2.4912, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1904, Train Acc=13.18%, Val Loss=2.2005, Val Acc=11.57%, Grad Norm=2.5816, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1907, Train Acc=13.28%, Val Loss=2.2007, Val Acc=11.42%, Grad Norm=2.5789, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1899, Train Acc=13.40%, Val Loss=2.2005, Val Acc=11.33%, Grad Norm=2.6153, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.1900, Train Acc=13.41%, Val Loss=2.2006, Val Acc=11.42%, Grad Norm=2.6660, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.1895, Train Acc=13.57%, Val Loss=2.2005, Val Acc=11.41%, Grad Norm=2.7423, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.1896, Train Acc=13.45%, Val Loss=2.2003, Val Acc=11.48%, Grad Norm=2.7325, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.1888, Train Acc=13.89%, Val Loss=2.2006, Val Acc=11.46%, Grad Norm=2.7306, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.1888, Train Acc=13.61%, Val Loss=2.2005, Val Acc=11.55%, Grad Norm=2.7806, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.1890, Train Acc=13.79%, Val Loss=2.2006, Val Acc=11.38%, Grad Norm=2.7993, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.1878, Train Acc=14.02%, Val Loss=2.2012, Val Acc=11.36%, Grad Norm=2.8282, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.1888, Train Acc=13.74%, Val Loss=2.2009, Val Acc=11.31%, Grad Norm=2.8552, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.1877, Train Acc=14.04%, Val Loss=2.2008, Val Acc=11.33%, Grad Norm=2.8673, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.1882, Train Acc=13.77%, Val Loss=2.2007, Val Acc=11.26%, Grad Norm=2.8924, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.1877, Train Acc=13.85%, Val Loss=2.2006, Val Acc=11.23%, Grad Norm=2.9263, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.1873, Train Acc=14.01%, Val Loss=2.2010, Val Acc=11.36%, Grad Norm=2.9381, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.1876, Train Acc=13.91%, Val Loss=2.2007, Val Acc=11.40%, Grad Norm=2.9414, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.1873, Train Acc=13.93%, Val Loss=2.2007, Val Acc=11.40%, Grad Norm=2.9383, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.1873, Train Acc=14.04%, Val Loss=2.2006, Val Acc=11.54%, Grad Norm=2.9621, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=2.1871, Train Acc=13.95%, Val Loss=2.2007, Val Acc=11.40%, Grad Norm=2.9791, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=2.1868, Train Acc=14.03%, Val Loss=2.2010, Val Acc=11.52%, Grad Norm=2.9947, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=2.1870, Train Acc=13.94%, Val Loss=2.2008, Val Acc=11.45%, Grad Norm=3.0167, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=2.1869, Train Acc=13.86%, Val Loss=2.2011, Val Acc=11.43%, Grad Norm=3.0218, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=2.1864, Train Acc=14.13%, Val Loss=2.2010, Val Acc=11.32%, Grad Norm=3.0378, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=2.1858, Train Acc=14.10%, Val Loss=2.2010, Val Acc=11.39%, Grad Norm=3.0628, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=2.1868, Train Acc=14.05%, Val Loss=2.2009, Val Acc=11.39%, Grad Norm=3.0800, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.68%）\n",
      "Fold 2 DONE | Best Val Acc≈11.68% | Final Val Acc=11.68% | Test Acc=11.16%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2224, Train Acc=11.19%, Val Loss=2.2201, Val Acc=11.03%, Grad Norm=6.8143, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2217, Train Acc=11.07%, Val Loss=2.2540, Val Acc=10.94%, Grad Norm=6.6396, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2195, Train Acc=10.93%, Val Loss=2.2280, Val Acc=11.12%, Grad Norm=6.0252, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2148, Train Acc=11.33%, Val Loss=2.2549, Val Acc=11.15%, Grad Norm=5.0759, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2101, Train Acc=10.77%, Val Loss=2.2067, Val Acc=10.95%, Grad Norm=4.1454, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2065, Train Acc=11.30%, Val Loss=2.2155, Val Acc=11.11%, Grad Norm=3.4488, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2040, Train Acc=11.20%, Val Loss=2.2448, Val Acc=11.05%, Grad Norm=3.0925, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2041, Train Acc=11.00%, Val Loss=2.2076, Val Acc=11.21%, Grad Norm=2.7635, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2031, Train Acc=10.89%, Val Loss=2.2108, Val Acc=11.05%, Grad Norm=2.4196, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.2019, Train Acc=11.31%, Val Loss=2.2038, Val Acc=11.14%, Grad Norm=2.1209, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.2007, Train Acc=11.14%, Val Loss=2.2066, Val Acc=11.15%, Grad Norm=1.9249, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.2001, Train Acc=11.15%, Val Loss=2.2050, Val Acc=11.10%, Grad Norm=1.7690, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1993, Train Acc=11.27%, Val Loss=2.2025, Val Acc=11.11%, Grad Norm=1.7086, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1989, Train Acc=11.34%, Val Loss=2.2023, Val Acc=11.09%, Grad Norm=1.6332, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1987, Train Acc=11.61%, Val Loss=2.2020, Val Acc=10.84%, Grad Norm=1.5674, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1986, Train Acc=11.32%, Val Loss=2.2004, Val Acc=11.02%, Grad Norm=1.5425, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1985, Train Acc=11.23%, Val Loss=2.2005, Val Acc=11.00%, Grad Norm=1.4495, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1983, Train Acc=11.45%, Val Loss=2.2002, Val Acc=10.98%, Grad Norm=1.3973, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1982, Train Acc=11.57%, Val Loss=2.2008, Val Acc=11.15%, Grad Norm=1.2481, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1979, Train Acc=11.69%, Val Loss=2.1997, Val Acc=10.87%, Grad Norm=1.1639, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1977, Train Acc=11.52%, Val Loss=2.1978, Val Acc=11.14%, Grad Norm=1.0695, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1974, Train Acc=11.55%, Val Loss=2.1989, Val Acc=11.02%, Grad Norm=1.0618, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1973, Train Acc=11.56%, Val Loss=2.2008, Val Acc=11.04%, Grad Norm=1.1282, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1967, Train Acc=11.77%, Val Loss=2.1990, Val Acc=11.09%, Grad Norm=1.0913, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1968, Train Acc=11.74%, Val Loss=2.1987, Val Acc=10.81%, Grad Norm=1.2279, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1965, Train Acc=11.79%, Val Loss=2.1989, Val Acc=11.05%, Grad Norm=1.2252, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1961, Train Acc=12.10%, Val Loss=2.1994, Val Acc=10.90%, Grad Norm=1.3045, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1966, Train Acc=11.87%, Val Loss=2.1989, Val Acc=11.08%, Grad Norm=1.1685, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1964, Train Acc=11.76%, Val Loss=2.1988, Val Acc=10.95%, Grad Norm=1.1805, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1963, Train Acc=11.92%, Val Loss=2.1986, Val Acc=11.23%, Grad Norm=1.1373, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1958, Train Acc=11.94%, Val Loss=2.1988, Val Acc=11.07%, Grad Norm=1.2278, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1948, Train Acc=12.43%, Val Loss=2.1991, Val Acc=11.01%, Grad Norm=1.3660, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1950, Train Acc=12.57%, Val Loss=2.1995, Val Acc=11.02%, Grad Norm=1.4774, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1951, Train Acc=12.25%, Val Loss=2.1991, Val Acc=11.03%, Grad Norm=1.4438, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1942, Train Acc=12.61%, Val Loss=2.1992, Val Acc=11.18%, Grad Norm=1.6459, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1946, Train Acc=12.43%, Val Loss=2.1992, Val Acc=11.12%, Grad Norm=1.6677, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1943, Train Acc=12.64%, Val Loss=2.1992, Val Acc=11.16%, Grad Norm=1.6932, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1934, Train Acc=12.85%, Val Loss=2.1998, Val Acc=11.05%, Grad Norm=1.9019, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1942, Train Acc=12.49%, Val Loss=2.1995, Val Acc=10.88%, Grad Norm=1.8327, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.1935, Train Acc=12.87%, Val Loss=2.2003, Val Acc=11.11%, Grad Norm=1.7909, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.1932, Train Acc=12.85%, Val Loss=2.2003, Val Acc=11.02%, Grad Norm=1.9366, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.1928, Train Acc=13.12%, Val Loss=2.2007, Val Acc=11.11%, Grad Norm=2.0820, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.1926, Train Acc=12.92%, Val Loss=2.2008, Val Acc=10.95%, Grad Norm=2.1876, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.1925, Train Acc=13.06%, Val Loss=2.2010, Val Acc=11.15%, Grad Norm=2.2310, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.1929, Train Acc=12.71%, Val Loss=2.2008, Val Acc=10.95%, Grad Norm=2.2129, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.1919, Train Acc=12.94%, Val Loss=2.2012, Val Acc=10.86%, Grad Norm=2.2540, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.1913, Train Acc=13.14%, Val Loss=2.2014, Val Acc=10.98%, Grad Norm=2.3459, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.1920, Train Acc=13.09%, Val Loss=2.2016, Val Acc=11.01%, Grad Norm=2.3651, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.1910, Train Acc=13.21%, Val Loss=2.2015, Val Acc=11.26%, Grad Norm=2.3780, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.1910, Train Acc=13.38%, Val Loss=2.2013, Val Acc=11.19%, Grad Norm=2.4086, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.1908, Train Acc=13.29%, Val Loss=2.2015, Val Acc=11.05%, Grad Norm=2.4456, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.1909, Train Acc=13.17%, Val Loss=2.2010, Val Acc=11.10%, Grad Norm=2.4771, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=2.1908, Train Acc=13.30%, Val Loss=2.2009, Val Acc=11.14%, Grad Norm=2.4808, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=2.1903, Train Acc=13.41%, Val Loss=2.2013, Val Acc=11.01%, Grad Norm=2.4879, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=2.1901, Train Acc=13.54%, Val Loss=2.2012, Val Acc=11.11%, Grad Norm=2.5290, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=2.1899, Train Acc=13.48%, Val Loss=2.2012, Val Acc=10.93%, Grad Norm=2.5395, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=2.1901, Train Acc=13.59%, Val Loss=2.2010, Val Acc=11.03%, Grad Norm=2.5519, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=2.1894, Train Acc=13.81%, Val Loss=2.2013, Val Acc=11.09%, Grad Norm=2.5690, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=2.1891, Train Acc=13.67%, Val Loss=2.2014, Val Acc=11.14%, Grad Norm=2.6131, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=2.1893, Train Acc=13.44%, Val Loss=2.2015, Val Acc=11.17%, Grad Norm=2.6283, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=2.1889, Train Acc=13.66%, Val Loss=2.2016, Val Acc=11.16%, Grad Norm=2.6638, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=2.1886, Train Acc=13.91%, Val Loss=2.2014, Val Acc=11.10%, Grad Norm=2.6663, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=2.1893, Train Acc=13.62%, Val Loss=2.2013, Val Acc=11.12%, Grad Norm=2.6902, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=2.1893, Train Acc=14.01%, Val Loss=2.2012, Val Acc=11.14%, Grad Norm=2.6946, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=2.1895, Train Acc=13.73%, Val Loss=2.2011, Val Acc=11.05%, Grad Norm=2.7028, LR=1.5625e-06\n",
      "Fold 3, Epoch 66: Train Loss=2.1884, Train Acc=14.16%, Val Loss=2.2011, Val Acc=11.12%, Grad Norm=2.7159, LR=1.5625e-06\n",
      "Fold 3, Epoch 67: Train Loss=2.1891, Train Acc=13.76%, Val Loss=2.2011, Val Acc=11.14%, Grad Norm=2.7342, LR=1.5625e-06\n",
      "Fold 3, Epoch 68: Train Loss=2.1879, Train Acc=13.87%, Val Loss=2.2012, Val Acc=11.10%, Grad Norm=2.7368, LR=1.5625e-06\n",
      "Fold 3, Epoch 69: Train Loss=2.1889, Train Acc=13.69%, Val Loss=2.2011, Val Acc=11.00%, Grad Norm=2.7480, LR=1.5625e-06\n",
      "Fold 3, Epoch 70: Train Loss=2.1881, Train Acc=13.86%, Val Loss=2.2011, Val Acc=11.11%, Grad Norm=2.7535, LR=1.5625e-06\n",
      "Fold 3, Epoch 71: Train Loss=2.1886, Train Acc=13.92%, Val Loss=2.2011, Val Acc=11.12%, Grad Norm=2.7730, LR=7.8125e-07\n",
      "Fold 3, Epoch 72: Train Loss=2.1874, Train Acc=14.00%, Val Loss=2.2012, Val Acc=11.07%, Grad Norm=2.7774, LR=7.8125e-07\n",
      "Fold 3, Epoch 73: Train Loss=2.1887, Train Acc=13.86%, Val Loss=2.2012, Val Acc=11.08%, Grad Norm=2.7842, LR=7.8125e-07\n",
      "Fold 3, Epoch 74: Train Loss=2.1888, Train Acc=13.71%, Val Loss=2.2012, Val Acc=11.09%, Grad Norm=2.7875, LR=7.8125e-07\n",
      "Fold 3, Epoch 75: Train Loss=2.1884, Train Acc=13.58%, Val Loss=2.2011, Val Acc=11.08%, Grad Norm=2.7834, LR=7.8125e-07\n",
      "Fold 3, Epoch 76: Train Loss=2.1888, Train Acc=13.75%, Val Loss=2.2011, Val Acc=11.07%, Grad Norm=2.7886, LR=7.8125e-07\n",
      "Fold 3, Epoch 77: Train Loss=2.1877, Train Acc=14.06%, Val Loss=2.2012, Val Acc=11.03%, Grad Norm=2.7932, LR=7.8125e-07\n",
      "Fold 3, Epoch 78: Train Loss=2.1880, Train Acc=13.57%, Val Loss=2.2012, Val Acc=11.08%, Grad Norm=2.8090, LR=7.8125e-07\n",
      "Fold 3, Epoch 79: Train Loss=2.1885, Train Acc=13.86%, Val Loss=2.2012, Val Acc=11.09%, Grad Norm=2.8165, LR=7.8125e-07\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.26%）\n",
      "Fold 3 DONE | Best Val Acc≈11.26% | Final Val Acc=11.26% | Test Acc=11.44%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2259, Train Acc=10.79%, Val Loss=2.2100, Val Acc=11.05%, Grad Norm=6.6871, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2207, Train Acc=11.01%, Val Loss=2.2245, Val Acc=11.06%, Grad Norm=6.2293, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2172, Train Acc=10.90%, Val Loss=2.2290, Val Acc=10.99%, Grad Norm=5.2581, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2114, Train Acc=11.23%, Val Loss=2.2201, Val Acc=11.32%, Grad Norm=4.2187, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2069, Train Acc=11.21%, Val Loss=2.2218, Val Acc=11.14%, Grad Norm=3.3997, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2052, Train Acc=10.94%, Val Loss=2.2077, Val Acc=11.05%, Grad Norm=2.9827, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2042, Train Acc=11.21%, Val Loss=2.2074, Val Acc=11.11%, Grad Norm=2.6375, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.2030, Train Acc=11.32%, Val Loss=2.2023, Val Acc=10.94%, Grad Norm=2.3091, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.2027, Train Acc=11.02%, Val Loss=2.2032, Val Acc=11.04%, Grad Norm=1.9945, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.2014, Train Acc=11.20%, Val Loss=2.2173, Val Acc=11.05%, Grad Norm=1.7356, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1995, Train Acc=11.23%, Val Loss=2.2004, Val Acc=11.11%, Grad Norm=1.4988, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1989, Train Acc=11.18%, Val Loss=2.2005, Val Acc=11.38%, Grad Norm=1.4287, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1989, Train Acc=11.18%, Val Loss=2.2000, Val Acc=11.19%, Grad Norm=1.3708, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1989, Train Acc=11.21%, Val Loss=2.2055, Val Acc=11.21%, Grad Norm=1.2284, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1981, Train Acc=11.65%, Val Loss=2.1998, Val Acc=11.39%, Grad Norm=1.1848, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1983, Train Acc=11.35%, Val Loss=2.1983, Val Acc=10.96%, Grad Norm=1.0816, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1980, Train Acc=11.32%, Val Loss=2.1982, Val Acc=11.20%, Grad Norm=0.9730, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1980, Train Acc=11.21%, Val Loss=2.1985, Val Acc=11.30%, Grad Norm=0.8281, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1979, Train Acc=11.29%, Val Loss=2.1979, Val Acc=11.04%, Grad Norm=0.7970, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1979, Train Acc=11.04%, Val Loss=2.1978, Val Acc=11.06%, Grad Norm=0.7205, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1973, Train Acc=11.44%, Val Loss=2.1975, Val Acc=11.42%, Grad Norm=0.7744, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1971, Train Acc=11.38%, Val Loss=2.1978, Val Acc=11.00%, Grad Norm=0.7628, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1970, Train Acc=11.66%, Val Loss=2.1980, Val Acc=11.20%, Grad Norm=0.7368, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1968, Train Acc=11.71%, Val Loss=2.1977, Val Acc=11.10%, Grad Norm=0.7749, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1969, Train Acc=11.55%, Val Loss=2.1978, Val Acc=10.90%, Grad Norm=0.7573, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1969, Train Acc=11.59%, Val Loss=2.1974, Val Acc=11.11%, Grad Norm=0.7135, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1970, Train Acc=11.57%, Val Loss=2.1977, Val Acc=11.39%, Grad Norm=0.6185, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1969, Train Acc=11.68%, Val Loss=2.1976, Val Acc=11.23%, Grad Norm=0.6541, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1969, Train Acc=11.55%, Val Loss=2.1975, Val Acc=11.09%, Grad Norm=0.6356, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1966, Train Acc=11.83%, Val Loss=2.1981, Val Acc=11.25%, Grad Norm=0.7178, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1963, Train Acc=11.83%, Val Loss=2.1981, Val Acc=11.19%, Grad Norm=0.8567, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1962, Train Acc=11.74%, Val Loss=2.1980, Val Acc=11.00%, Grad Norm=0.9586, LR=1.25e-05\n",
      "Fold 4, Epoch 33: Train Loss=2.1962, Train Acc=12.12%, Val Loss=2.1982, Val Acc=11.37%, Grad Norm=0.8931, LR=1.25e-05\n",
      "Fold 4, Epoch 34: Train Loss=2.1961, Train Acc=12.07%, Val Loss=2.1980, Val Acc=11.21%, Grad Norm=0.8739, LR=1.25e-05\n",
      "Fold 4, Epoch 35: Train Loss=2.1957, Train Acc=12.16%, Val Loss=2.1984, Val Acc=10.97%, Grad Norm=0.8741, LR=1.25e-05\n",
      "Fold 4, Epoch 36: Train Loss=2.1956, Train Acc=12.27%, Val Loss=2.1980, Val Acc=11.36%, Grad Norm=0.9478, LR=1.25e-05\n",
      "Fold 4, Epoch 37: Train Loss=2.1955, Train Acc=12.29%, Val Loss=2.1981, Val Acc=10.95%, Grad Norm=0.9140, LR=1.25e-05\n",
      "Fold 4, Epoch 38: Train Loss=2.1954, Train Acc=12.32%, Val Loss=2.1981, Val Acc=10.92%, Grad Norm=0.9429, LR=1.25e-05\n",
      "Fold 4, Epoch 39: Train Loss=2.1956, Train Acc=12.36%, Val Loss=2.1978, Val Acc=11.38%, Grad Norm=0.9409, LR=1.25e-05\n",
      "Fold 4, Epoch 40: Train Loss=2.1952, Train Acc=12.08%, Val Loss=2.1982, Val Acc=11.01%, Grad Norm=0.9604, LR=1.25e-05\n",
      "Fold 4, Epoch 41: Train Loss=2.1951, Train Acc=12.62%, Val Loss=2.1981, Val Acc=10.81%, Grad Norm=1.0169, LR=6.25e-06\n",
      "Fold 4, Epoch 42: Train Loss=2.1949, Train Acc=12.34%, Val Loss=2.1983, Val Acc=10.95%, Grad Norm=1.0387, LR=6.25e-06\n",
      "Fold 4, Epoch 43: Train Loss=2.1947, Train Acc=12.77%, Val Loss=2.1982, Val Acc=10.99%, Grad Norm=1.0620, LR=6.25e-06\n",
      "Fold 4, Epoch 44: Train Loss=2.1949, Train Acc=12.44%, Val Loss=2.1982, Val Acc=10.89%, Grad Norm=1.0754, LR=6.25e-06\n",
      "Fold 4, Epoch 45: Train Loss=2.1949, Train Acc=12.48%, Val Loss=2.1982, Val Acc=11.05%, Grad Norm=1.0983, LR=6.25e-06\n",
      "Fold 4, Epoch 46: Train Loss=2.1949, Train Acc=12.55%, Val Loss=2.1982, Val Acc=11.19%, Grad Norm=1.1137, LR=6.25e-06\n",
      "Fold 4, Epoch 47: Train Loss=2.1946, Train Acc=12.61%, Val Loss=2.1981, Val Acc=11.12%, Grad Norm=1.1269, LR=6.25e-06\n",
      "Fold 4, Epoch 48: Train Loss=2.1945, Train Acc=12.75%, Val Loss=2.1983, Val Acc=11.30%, Grad Norm=1.1638, LR=6.25e-06\n",
      "Fold 4, Epoch 49: Train Loss=2.1940, Train Acc=12.64%, Val Loss=2.1984, Val Acc=11.05%, Grad Norm=1.2220, LR=6.25e-06\n",
      "Fold 4, Epoch 50: Train Loss=2.1944, Train Acc=12.49%, Val Loss=2.1985, Val Acc=11.01%, Grad Norm=1.2575, LR=6.25e-06\n",
      "Fold 4, Epoch 51: Train Loss=2.1941, Train Acc=12.66%, Val Loss=2.1987, Val Acc=11.14%, Grad Norm=1.3048, LR=3.125e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.42%）\n",
      "Fold 4 DONE | Best Val Acc≈11.42% | Final Val Acc=11.42% | Test Acc=11.40%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2234, Train Acc=11.16%, Val Loss=2.2809, Val Acc=11.02%, Grad Norm=6.6970, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2206, Train Acc=11.49%, Val Loss=2.2439, Val Acc=11.01%, Grad Norm=6.3005, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2173, Train Acc=11.05%, Val Loss=2.2372, Val Acc=11.12%, Grad Norm=5.4380, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2104, Train Acc=11.11%, Val Loss=2.2089, Val Acc=11.12%, Grad Norm=4.1602, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2065, Train Acc=11.24%, Val Loss=2.2309, Val Acc=10.87%, Grad Norm=3.4194, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2051, Train Acc=11.21%, Val Loss=2.2367, Val Acc=11.11%, Grad Norm=2.8970, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2046, Train Acc=10.79%, Val Loss=2.2094, Val Acc=11.15%, Grad Norm=2.5303, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2032, Train Acc=11.06%, Val Loss=2.2066, Val Acc=11.07%, Grad Norm=2.2345, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.2018, Train Acc=11.20%, Val Loss=2.2127, Val Acc=11.32%, Grad Norm=1.9484, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.2013, Train Acc=11.13%, Val Loss=2.2022, Val Acc=11.13%, Grad Norm=1.6736, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1992, Train Acc=11.14%, Val Loss=2.2047, Val Acc=11.17%, Grad Norm=1.4592, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1993, Train Acc=11.10%, Val Loss=2.1992, Val Acc=10.98%, Grad Norm=1.3248, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1985, Train Acc=11.26%, Val Loss=2.1995, Val Acc=11.20%, Grad Norm=1.2637, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1983, Train Acc=11.30%, Val Loss=2.2003, Val Acc=11.00%, Grad Norm=1.2446, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1980, Train Acc=11.41%, Val Loss=2.2011, Val Acc=11.24%, Grad Norm=1.1958, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1982, Train Acc=11.37%, Val Loss=2.1990, Val Acc=11.05%, Grad Norm=1.1421, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1979, Train Acc=11.36%, Val Loss=2.1989, Val Acc=10.98%, Grad Norm=0.9716, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1981, Train Acc=11.32%, Val Loss=2.1986, Val Acc=11.17%, Grad Norm=0.9313, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1976, Train Acc=11.24%, Val Loss=2.1980, Val Acc=10.95%, Grad Norm=0.8014, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1977, Train Acc=11.07%, Val Loss=2.1979, Val Acc=11.24%, Grad Norm=0.7983, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1972, Train Acc=11.47%, Val Loss=2.1979, Val Acc=11.18%, Grad Norm=0.6305, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1971, Train Acc=11.41%, Val Loss=2.1980, Val Acc=11.09%, Grad Norm=0.7638, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1969, Train Acc=11.78%, Val Loss=2.1979, Val Acc=11.11%, Grad Norm=0.6838, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1970, Train Acc=11.59%, Val Loss=2.1980, Val Acc=10.83%, Grad Norm=0.7662, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1968, Train Acc=11.68%, Val Loss=2.1978, Val Acc=10.99%, Grad Norm=0.7877, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1968, Train Acc=11.68%, Val Loss=2.1978, Val Acc=11.17%, Grad Norm=0.7025, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1969, Train Acc=11.66%, Val Loss=2.1981, Val Acc=10.60%, Grad Norm=0.7272, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1962, Train Acc=11.97%, Val Loss=2.1982, Val Acc=11.24%, Grad Norm=0.8989, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1967, Train Acc=11.86%, Val Loss=2.1977, Val Acc=11.36%, Grad Norm=0.8364, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1965, Train Acc=11.82%, Val Loss=2.1979, Val Acc=11.30%, Grad Norm=0.8416, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1961, Train Acc=11.99%, Val Loss=2.1981, Val Acc=10.75%, Grad Norm=0.8801, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1956, Train Acc=12.14%, Val Loss=2.1984, Val Acc=11.07%, Grad Norm=1.0327, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1956, Train Acc=12.22%, Val Loss=2.1986, Val Acc=11.10%, Grad Norm=1.0581, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1957, Train Acc=11.96%, Val Loss=2.1985, Val Acc=10.81%, Grad Norm=1.0341, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1954, Train Acc=12.21%, Val Loss=2.1990, Val Acc=10.89%, Grad Norm=1.0707, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1949, Train Acc=12.33%, Val Loss=2.1982, Val Acc=11.05%, Grad Norm=1.0569, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1949, Train Acc=12.28%, Val Loss=2.1986, Val Acc=10.94%, Grad Norm=1.0886, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=2.1952, Train Acc=12.05%, Val Loss=2.1983, Val Acc=10.97%, Grad Norm=1.1010, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=2.1948, Train Acc=12.45%, Val Loss=2.1985, Val Acc=11.13%, Grad Norm=1.1117, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=2.1945, Train Acc=12.84%, Val Loss=2.1988, Val Acc=10.86%, Grad Norm=1.1647, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=2.1942, Train Acc=12.79%, Val Loss=2.1989, Val Acc=10.94%, Grad Norm=1.2047, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=2.1943, Train Acc=12.74%, Val Loss=2.1989, Val Acc=10.81%, Grad Norm=1.2549, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=2.1944, Train Acc=12.58%, Val Loss=2.1991, Val Acc=10.67%, Grad Norm=1.2565, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=2.1946, Train Acc=12.56%, Val Loss=2.1989, Val Acc=10.73%, Grad Norm=1.2352, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=2.1944, Train Acc=12.71%, Val Loss=2.1989, Val Acc=10.76%, Grad Norm=1.2518, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=2.1940, Train Acc=12.88%, Val Loss=2.1987, Val Acc=10.94%, Grad Norm=1.3045, LR=6.25e-06\n",
      "Fold 5, Epoch 47: Train Loss=2.1938, Train Acc=12.57%, Val Loss=2.1991, Val Acc=10.92%, Grad Norm=1.3468, LR=6.25e-06\n",
      "Fold 5, Epoch 48: Train Loss=2.1936, Train Acc=12.67%, Val Loss=2.1994, Val Acc=10.80%, Grad Norm=1.3883, LR=6.25e-06\n",
      "Fold 5, Epoch 49: Train Loss=2.1938, Train Acc=12.70%, Val Loss=2.1994, Val Acc=10.80%, Grad Norm=1.4524, LR=6.25e-06\n",
      "Fold 5, Epoch 50: Train Loss=2.1935, Train Acc=12.88%, Val Loss=2.1993, Val Acc=10.90%, Grad Norm=1.4937, LR=6.25e-06\n",
      "Fold 5, Epoch 51: Train Loss=2.1935, Train Acc=12.80%, Val Loss=2.1993, Val Acc=10.89%, Grad Norm=1.5208, LR=3.125e-06\n",
      "Fold 5, Epoch 52: Train Loss=2.1936, Train Acc=12.80%, Val Loss=2.1994, Val Acc=10.72%, Grad Norm=1.5536, LR=3.125e-06\n",
      "Fold 5, Epoch 53: Train Loss=2.1934, Train Acc=12.69%, Val Loss=2.1994, Val Acc=10.93%, Grad Norm=1.5656, LR=3.125e-06\n",
      "Fold 5, Epoch 54: Train Loss=2.1933, Train Acc=12.94%, Val Loss=2.1995, Val Acc=10.84%, Grad Norm=1.5785, LR=3.125e-06\n",
      "Fold 5, Epoch 55: Train Loss=2.1928, Train Acc=12.97%, Val Loss=2.1993, Val Acc=10.91%, Grad Norm=1.6181, LR=3.125e-06\n",
      "Fold 5, Epoch 56: Train Loss=2.1929, Train Acc=12.94%, Val Loss=2.1994, Val Acc=10.81%, Grad Norm=1.6593, LR=3.125e-06\n",
      "Fold 5, Epoch 57: Train Loss=2.1925, Train Acc=13.01%, Val Loss=2.1997, Val Acc=10.76%, Grad Norm=1.6974, LR=3.125e-06\n",
      "Fold 5, Epoch 58: Train Loss=2.1928, Train Acc=13.03%, Val Loss=2.1994, Val Acc=10.75%, Grad Norm=1.7202, LR=3.125e-06\n",
      "Fold 5, Epoch 59: Train Loss=2.1927, Train Acc=13.24%, Val Loss=2.1995, Val Acc=10.77%, Grad Norm=1.7563, LR=3.125e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.36%）\n",
      "Fold 5 DONE | Best Val Acc≈11.36% | Final Val Acc=11.36% | Test Acc=11.37%\n",
      "[INFO] SNR=-35 dB | Mean Test Acc: 11.31% ± 0.12%\n",
      "[INFO] SNR -35 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-35dB\n",
      "\n",
      "============================================================\n",
      "开始训练：SNR = -40 dB\n",
      "============================================================\n",
      "[INFO] 使用设备: cuda\n",
      "共找到 72 个 .mat 文件\n",
      "目标速度 120 km/h，多普勒频移 655.56 Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] target_sample_len = 256\n",
      "[INFO] 生成 block 数: 787 | 每 block 样本数(=group_size): 256 | 每样本长度(=sample_len): 256\n",
      "[INFO] 类别数: 9 | 类别映射: {'001': 0, '002': 1, '003': 2, '004': 3, '005': 4, '006': 5, '007': 6, '008': 7, '009': 8}\n",
      "[INFO] 总 block 数: 787\n",
      "[INFO] Train blocks: 576 | Test blocks: 211\n",
      "\n",
      "====== Fold 1/5 ======\n",
      "Fold 1, Epoch 1: Train Loss=2.2246, Train Acc=11.35%, Val Loss=2.2419, Val Acc=11.16%, Grad Norm=6.8573, LR=0.0001\n",
      "Fold 1, Epoch 2: Train Loss=2.2237, Train Acc=10.70%, Val Loss=2.2606, Val Acc=11.11%, Grad Norm=6.5194, LR=0.0001\n",
      "Fold 1, Epoch 3: Train Loss=2.2172, Train Acc=11.47%, Val Loss=2.2211, Val Acc=11.11%, Grad Norm=5.8810, LR=0.0001\n",
      "Fold 1, Epoch 4: Train Loss=2.2143, Train Acc=11.10%, Val Loss=2.2209, Val Acc=11.03%, Grad Norm=4.9171, LR=0.0001\n",
      "Fold 1, Epoch 5: Train Loss=2.2091, Train Acc=11.13%, Val Loss=2.2146, Val Acc=11.19%, Grad Norm=3.9393, LR=0.0001\n",
      "Fold 1, Epoch 6: Train Loss=2.2061, Train Acc=11.40%, Val Loss=2.2287, Val Acc=11.09%, Grad Norm=3.2733, LR=0.0001\n",
      "Fold 1, Epoch 7: Train Loss=2.2054, Train Acc=11.09%, Val Loss=2.2153, Val Acc=11.12%, Grad Norm=2.9208, LR=0.0001\n",
      "Fold 1, Epoch 8: Train Loss=2.2041, Train Acc=11.04%, Val Loss=2.2216, Val Acc=11.12%, Grad Norm=2.6671, LR=0.0001\n",
      "Fold 1, Epoch 9: Train Loss=2.2035, Train Acc=11.27%, Val Loss=2.2230, Val Acc=11.27%, Grad Norm=2.3811, LR=0.0001\n",
      "Fold 1, Epoch 10: Train Loss=2.2018, Train Acc=11.34%, Val Loss=2.2185, Val Acc=10.96%, Grad Norm=2.1552, LR=0.0001\n",
      "Fold 1, Epoch 11: Train Loss=2.2005, Train Acc=11.19%, Val Loss=2.2076, Val Acc=11.07%, Grad Norm=1.8794, LR=5e-05\n",
      "Fold 1, Epoch 12: Train Loss=2.1998, Train Acc=11.18%, Val Loss=2.2028, Val Acc=11.37%, Grad Norm=1.7016, LR=5e-05\n",
      "Fold 1, Epoch 13: Train Loss=2.1996, Train Acc=11.15%, Val Loss=2.2015, Val Acc=11.17%, Grad Norm=1.6845, LR=5e-05\n",
      "Fold 1, Epoch 14: Train Loss=2.1989, Train Acc=11.40%, Val Loss=2.2033, Val Acc=11.15%, Grad Norm=1.6037, LR=5e-05\n",
      "Fold 1, Epoch 15: Train Loss=2.1992, Train Acc=11.25%, Val Loss=2.2007, Val Acc=11.19%, Grad Norm=1.5179, LR=5e-05\n",
      "Fold 1, Epoch 16: Train Loss=2.1988, Train Acc=11.29%, Val Loss=2.1993, Val Acc=11.01%, Grad Norm=1.3818, LR=5e-05\n",
      "Fold 1, Epoch 17: Train Loss=2.1986, Train Acc=11.46%, Val Loss=2.2008, Val Acc=11.17%, Grad Norm=1.3120, LR=5e-05\n",
      "Fold 1, Epoch 18: Train Loss=2.1984, Train Acc=11.11%, Val Loss=2.2000, Val Acc=11.04%, Grad Norm=1.2334, LR=5e-05\n",
      "Fold 1, Epoch 19: Train Loss=2.1983, Train Acc=11.27%, Val Loss=2.2009, Val Acc=11.06%, Grad Norm=1.2523, LR=5e-05\n",
      "Fold 1, Epoch 20: Train Loss=2.1977, Train Acc=11.35%, Val Loss=2.1995, Val Acc=11.01%, Grad Norm=1.1028, LR=5e-05\n",
      "Fold 1, Epoch 21: Train Loss=2.1969, Train Acc=11.62%, Val Loss=2.1985, Val Acc=11.08%, Grad Norm=1.0999, LR=2.5e-05\n",
      "Fold 1, Epoch 22: Train Loss=2.1966, Train Acc=11.76%, Val Loss=2.1999, Val Acc=11.03%, Grad Norm=1.2116, LR=2.5e-05\n",
      "Fold 1, Epoch 23: Train Loss=2.1965, Train Acc=11.44%, Val Loss=2.1991, Val Acc=11.10%, Grad Norm=1.1693, LR=2.5e-05\n",
      "Fold 1, Epoch 24: Train Loss=2.1967, Train Acc=11.77%, Val Loss=2.1996, Val Acc=11.12%, Grad Norm=1.1655, LR=2.5e-05\n",
      "Fold 1, Epoch 25: Train Loss=2.1964, Train Acc=11.78%, Val Loss=2.1985, Val Acc=11.12%, Grad Norm=1.1806, LR=2.5e-05\n",
      "Fold 1, Epoch 26: Train Loss=2.1961, Train Acc=11.87%, Val Loss=2.2010, Val Acc=11.18%, Grad Norm=1.1871, LR=2.5e-05\n",
      "Fold 1, Epoch 27: Train Loss=2.1961, Train Acc=11.88%, Val Loss=2.1985, Val Acc=10.98%, Grad Norm=1.2375, LR=2.5e-05\n",
      "Fold 1, Epoch 28: Train Loss=2.1956, Train Acc=12.48%, Val Loss=2.2018, Val Acc=10.86%, Grad Norm=1.2730, LR=2.5e-05\n",
      "Fold 1, Epoch 29: Train Loss=2.1958, Train Acc=12.17%, Val Loss=2.1992, Val Acc=10.98%, Grad Norm=1.3452, LR=2.5e-05\n",
      "Fold 1, Epoch 30: Train Loss=2.1954, Train Acc=12.13%, Val Loss=2.2003, Val Acc=10.80%, Grad Norm=1.3007, LR=2.5e-05\n",
      "Fold 1, Epoch 31: Train Loss=2.1947, Train Acc=12.59%, Val Loss=2.2009, Val Acc=10.88%, Grad Norm=1.3534, LR=1.25e-05\n",
      "Fold 1, Epoch 32: Train Loss=2.1944, Train Acc=12.46%, Val Loss=2.2001, Val Acc=10.91%, Grad Norm=1.5130, LR=1.25e-05\n",
      "Fold 1, Epoch 33: Train Loss=2.1944, Train Acc=12.43%, Val Loss=2.2014, Val Acc=10.89%, Grad Norm=1.5012, LR=1.25e-05\n",
      "Fold 1, Epoch 34: Train Loss=2.1937, Train Acc=12.47%, Val Loss=2.2018, Val Acc=11.20%, Grad Norm=1.6293, LR=1.25e-05\n",
      "Fold 1, Epoch 35: Train Loss=2.1941, Train Acc=12.75%, Val Loss=2.1998, Val Acc=11.02%, Grad Norm=1.7381, LR=1.25e-05\n",
      "Fold 1, Epoch 36: Train Loss=2.1935, Train Acc=12.75%, Val Loss=2.2000, Val Acc=11.04%, Grad Norm=1.6502, LR=1.25e-05\n",
      "Fold 1, Epoch 37: Train Loss=2.1930, Train Acc=12.74%, Val Loss=2.2023, Val Acc=11.15%, Grad Norm=1.9406, LR=1.25e-05\n",
      "Fold 1, Epoch 38: Train Loss=2.1926, Train Acc=12.72%, Val Loss=2.2024, Val Acc=11.23%, Grad Norm=2.0775, LR=1.25e-05\n",
      "Fold 1, Epoch 39: Train Loss=2.1929, Train Acc=13.12%, Val Loss=2.2018, Val Acc=11.14%, Grad Norm=2.0964, LR=1.25e-05\n",
      "Fold 1, Epoch 40: Train Loss=2.1924, Train Acc=12.86%, Val Loss=2.2012, Val Acc=10.98%, Grad Norm=2.1391, LR=1.25e-05\n",
      "Fold 1, Epoch 41: Train Loss=2.1912, Train Acc=13.35%, Val Loss=2.2019, Val Acc=10.83%, Grad Norm=2.1943, LR=6.25e-06\n",
      "Fold 1, Epoch 42: Train Loss=2.1914, Train Acc=13.18%, Val Loss=2.2029, Val Acc=10.98%, Grad Norm=2.3834, LR=6.25e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.37%）\n",
      "Fold 1 DONE | Best Val Acc≈11.37% | Final Val Acc=11.37% | Test Acc=11.49%\n",
      "\n",
      "====== Fold 2/5 ======\n",
      "Fold 2, Epoch 1: Train Loss=2.2254, Train Acc=10.97%, Val Loss=2.2446, Val Acc=11.11%, Grad Norm=6.8055, LR=0.0001\n",
      "Fold 2, Epoch 2: Train Loss=2.2226, Train Acc=11.06%, Val Loss=2.2325, Val Acc=11.17%, Grad Norm=6.5159, LR=0.0001\n",
      "Fold 2, Epoch 3: Train Loss=2.2185, Train Acc=10.94%, Val Loss=2.2754, Val Acc=11.08%, Grad Norm=5.8345, LR=0.0001\n",
      "Fold 2, Epoch 4: Train Loss=2.2136, Train Acc=11.15%, Val Loss=2.2381, Val Acc=11.15%, Grad Norm=4.7820, LR=0.0001\n",
      "Fold 2, Epoch 5: Train Loss=2.2094, Train Acc=11.15%, Val Loss=2.2373, Val Acc=11.12%, Grad Norm=3.7619, LR=0.0001\n",
      "Fold 2, Epoch 6: Train Loss=2.2058, Train Acc=11.06%, Val Loss=2.2214, Val Acc=11.12%, Grad Norm=3.2530, LR=0.0001\n",
      "Fold 2, Epoch 7: Train Loss=2.2044, Train Acc=11.44%, Val Loss=2.2253, Val Acc=11.13%, Grad Norm=2.9503, LR=0.0001\n",
      "Fold 2, Epoch 8: Train Loss=2.2045, Train Acc=11.18%, Val Loss=2.2127, Val Acc=11.11%, Grad Norm=2.6678, LR=0.0001\n",
      "Fold 2, Epoch 9: Train Loss=2.2025, Train Acc=11.40%, Val Loss=2.2061, Val Acc=11.10%, Grad Norm=2.3890, LR=0.0001\n",
      "Fold 2, Epoch 10: Train Loss=2.2028, Train Acc=11.05%, Val Loss=2.2036, Val Acc=11.13%, Grad Norm=2.0675, LR=0.0001\n",
      "Fold 2, Epoch 11: Train Loss=2.1996, Train Acc=11.48%, Val Loss=2.2035, Val Acc=10.98%, Grad Norm=1.8245, LR=5e-05\n",
      "Fold 2, Epoch 12: Train Loss=2.1996, Train Acc=11.41%, Val Loss=2.2025, Val Acc=10.84%, Grad Norm=1.7117, LR=5e-05\n",
      "Fold 2, Epoch 13: Train Loss=2.1995, Train Acc=11.40%, Val Loss=2.2054, Val Acc=11.12%, Grad Norm=1.6736, LR=5e-05\n",
      "Fold 2, Epoch 14: Train Loss=2.1993, Train Acc=11.44%, Val Loss=2.2050, Val Acc=11.11%, Grad Norm=1.6171, LR=5e-05\n",
      "Fold 2, Epoch 15: Train Loss=2.1993, Train Acc=11.32%, Val Loss=2.2030, Val Acc=10.90%, Grad Norm=1.5032, LR=5e-05\n",
      "Fold 2, Epoch 16: Train Loss=2.1990, Train Acc=11.29%, Val Loss=2.1996, Val Acc=11.11%, Grad Norm=1.3912, LR=5e-05\n",
      "Fold 2, Epoch 17: Train Loss=2.1982, Train Acc=11.46%, Val Loss=2.1995, Val Acc=11.11%, Grad Norm=1.3744, LR=5e-05\n",
      "Fold 2, Epoch 18: Train Loss=2.1983, Train Acc=11.44%, Val Loss=2.2002, Val Acc=10.99%, Grad Norm=1.3131, LR=5e-05\n",
      "Fold 2, Epoch 19: Train Loss=2.1977, Train Acc=11.67%, Val Loss=2.2009, Val Acc=11.24%, Grad Norm=1.2608, LR=5e-05\n",
      "Fold 2, Epoch 20: Train Loss=2.1980, Train Acc=11.41%, Val Loss=2.2010, Val Acc=10.92%, Grad Norm=1.1980, LR=5e-05\n",
      "Fold 2, Epoch 21: Train Loss=2.1974, Train Acc=11.81%, Val Loss=2.1984, Val Acc=10.95%, Grad Norm=1.0612, LR=2.5e-05\n",
      "Fold 2, Epoch 22: Train Loss=2.1971, Train Acc=11.70%, Val Loss=2.1987, Val Acc=10.91%, Grad Norm=1.1350, LR=2.5e-05\n",
      "Fold 2, Epoch 23: Train Loss=2.1969, Train Acc=11.64%, Val Loss=2.1999, Val Acc=11.03%, Grad Norm=1.1139, LR=2.5e-05\n",
      "Fold 2, Epoch 24: Train Loss=2.1970, Train Acc=11.57%, Val Loss=2.2005, Val Acc=11.02%, Grad Norm=1.1704, LR=2.5e-05\n",
      "Fold 2, Epoch 25: Train Loss=2.1968, Train Acc=11.75%, Val Loss=2.1984, Val Acc=11.24%, Grad Norm=1.1584, LR=2.5e-05\n",
      "Fold 2, Epoch 26: Train Loss=2.1962, Train Acc=11.90%, Val Loss=2.1989, Val Acc=11.04%, Grad Norm=1.2391, LR=2.5e-05\n",
      "Fold 2, Epoch 27: Train Loss=2.1959, Train Acc=12.08%, Val Loss=2.2002, Val Acc=10.98%, Grad Norm=1.2542, LR=2.5e-05\n",
      "Fold 2, Epoch 28: Train Loss=2.1962, Train Acc=11.93%, Val Loss=2.2001, Val Acc=10.98%, Grad Norm=1.2651, LR=2.5e-05\n",
      "Fold 2, Epoch 29: Train Loss=2.1961, Train Acc=12.05%, Val Loss=2.2001, Val Acc=10.84%, Grad Norm=1.2567, LR=2.5e-05\n",
      "Fold 2, Epoch 30: Train Loss=2.1963, Train Acc=11.94%, Val Loss=2.1982, Val Acc=11.06%, Grad Norm=1.2248, LR=2.5e-05\n",
      "Fold 2, Epoch 31: Train Loss=2.1956, Train Acc=12.16%, Val Loss=2.1994, Val Acc=11.08%, Grad Norm=1.1409, LR=1.25e-05\n",
      "Fold 2, Epoch 32: Train Loss=2.1955, Train Acc=12.30%, Val Loss=2.1987, Val Acc=11.26%, Grad Norm=1.1811, LR=1.25e-05\n",
      "Fold 2, Epoch 33: Train Loss=2.1953, Train Acc=12.34%, Val Loss=2.1991, Val Acc=11.15%, Grad Norm=1.2844, LR=1.25e-05\n",
      "Fold 2, Epoch 34: Train Loss=2.1946, Train Acc=12.26%, Val Loss=2.1994, Val Acc=10.73%, Grad Norm=1.4472, LR=1.25e-05\n",
      "Fold 2, Epoch 35: Train Loss=2.1947, Train Acc=12.50%, Val Loss=2.1994, Val Acc=11.04%, Grad Norm=1.6004, LR=1.25e-05\n",
      "Fold 2, Epoch 36: Train Loss=2.1940, Train Acc=12.29%, Val Loss=2.2009, Val Acc=11.06%, Grad Norm=1.6930, LR=1.25e-05\n",
      "Fold 2, Epoch 37: Train Loss=2.1943, Train Acc=12.46%, Val Loss=2.1992, Val Acc=10.90%, Grad Norm=1.8058, LR=1.25e-05\n",
      "Fold 2, Epoch 38: Train Loss=2.1942, Train Acc=12.67%, Val Loss=2.2000, Val Acc=10.86%, Grad Norm=1.7623, LR=1.25e-05\n",
      "Fold 2, Epoch 39: Train Loss=2.1936, Train Acc=12.63%, Val Loss=2.2020, Val Acc=10.97%, Grad Norm=1.9642, LR=1.25e-05\n",
      "Fold 2, Epoch 40: Train Loss=2.1935, Train Acc=12.62%, Val Loss=2.2010, Val Acc=11.10%, Grad Norm=2.0148, LR=1.25e-05\n",
      "Fold 2, Epoch 41: Train Loss=2.1928, Train Acc=12.95%, Val Loss=2.2012, Val Acc=11.12%, Grad Norm=2.0365, LR=6.25e-06\n",
      "Fold 2, Epoch 42: Train Loss=2.1929, Train Acc=12.71%, Val Loss=2.2010, Val Acc=10.98%, Grad Norm=2.1090, LR=6.25e-06\n",
      "Fold 2, Epoch 43: Train Loss=2.1919, Train Acc=13.09%, Val Loss=2.2013, Val Acc=10.88%, Grad Norm=2.2408, LR=6.25e-06\n",
      "Fold 2, Epoch 44: Train Loss=2.1922, Train Acc=12.76%, Val Loss=2.2007, Val Acc=11.06%, Grad Norm=2.3418, LR=6.25e-06\n",
      "Fold 2, Epoch 45: Train Loss=2.1912, Train Acc=13.03%, Val Loss=2.2013, Val Acc=10.93%, Grad Norm=2.4127, LR=6.25e-06\n",
      "Fold 2, Epoch 46: Train Loss=2.1923, Train Acc=12.99%, Val Loss=2.2006, Val Acc=10.94%, Grad Norm=2.3800, LR=6.25e-06\n",
      "Fold 2, Epoch 47: Train Loss=2.1905, Train Acc=13.35%, Val Loss=2.2007, Val Acc=10.87%, Grad Norm=2.4905, LR=6.25e-06\n",
      "Fold 2, Epoch 48: Train Loss=2.1913, Train Acc=13.08%, Val Loss=2.2010, Val Acc=10.91%, Grad Norm=2.4951, LR=6.25e-06\n",
      "Fold 2, Epoch 49: Train Loss=2.1899, Train Acc=13.36%, Val Loss=2.2010, Val Acc=10.89%, Grad Norm=2.5608, LR=6.25e-06\n",
      "Fold 2, Epoch 50: Train Loss=2.1912, Train Acc=13.04%, Val Loss=2.2019, Val Acc=11.06%, Grad Norm=2.6032, LR=6.25e-06\n",
      "Fold 2, Epoch 51: Train Loss=2.1900, Train Acc=13.34%, Val Loss=2.2014, Val Acc=11.20%, Grad Norm=2.5992, LR=3.125e-06\n",
      "Fold 2, Epoch 52: Train Loss=2.1898, Train Acc=13.38%, Val Loss=2.2015, Val Acc=11.21%, Grad Norm=2.6305, LR=3.125e-06\n",
      "Fold 2, Epoch 53: Train Loss=2.1897, Train Acc=13.65%, Val Loss=2.2016, Val Acc=11.26%, Grad Norm=2.6491, LR=3.125e-06\n",
      "Fold 2, Epoch 54: Train Loss=2.1898, Train Acc=13.58%, Val Loss=2.2017, Val Acc=11.02%, Grad Norm=2.6598, LR=3.125e-06\n",
      "Fold 2, Epoch 55: Train Loss=2.1892, Train Acc=13.59%, Val Loss=2.2016, Val Acc=11.08%, Grad Norm=2.6720, LR=3.125e-06\n",
      "Fold 2, Epoch 56: Train Loss=2.1885, Train Acc=13.49%, Val Loss=2.2017, Val Acc=11.22%, Grad Norm=2.7236, LR=3.125e-06\n",
      "Fold 2, Epoch 57: Train Loss=2.1892, Train Acc=13.50%, Val Loss=2.2016, Val Acc=11.20%, Grad Norm=2.7442, LR=3.125e-06\n",
      "Fold 2, Epoch 58: Train Loss=2.1892, Train Acc=13.44%, Val Loss=2.2018, Val Acc=11.23%, Grad Norm=2.7691, LR=3.125e-06\n",
      "Fold 2, Epoch 59: Train Loss=2.1892, Train Acc=13.50%, Val Loss=2.2016, Val Acc=11.28%, Grad Norm=2.7927, LR=3.125e-06\n",
      "Fold 2, Epoch 60: Train Loss=2.1894, Train Acc=13.62%, Val Loss=2.2024, Val Acc=11.26%, Grad Norm=2.8054, LR=3.125e-06\n",
      "Fold 2, Epoch 61: Train Loss=2.1885, Train Acc=13.66%, Val Loss=2.2018, Val Acc=11.35%, Grad Norm=2.8363, LR=1.5625e-06\n",
      "Fold 2, Epoch 62: Train Loss=2.1882, Train Acc=14.06%, Val Loss=2.2016, Val Acc=11.32%, Grad Norm=2.8495, LR=1.5625e-06\n",
      "Fold 2, Epoch 63: Train Loss=2.1883, Train Acc=14.03%, Val Loss=2.2016, Val Acc=11.31%, Grad Norm=2.8650, LR=1.5625e-06\n",
      "Fold 2, Epoch 64: Train Loss=2.1879, Train Acc=13.93%, Val Loss=2.2017, Val Acc=11.32%, Grad Norm=2.8796, LR=1.5625e-06\n",
      "Fold 2, Epoch 65: Train Loss=2.1874, Train Acc=14.04%, Val Loss=2.2019, Val Acc=11.31%, Grad Norm=2.8884, LR=1.5625e-06\n",
      "Fold 2, Epoch 66: Train Loss=2.1878, Train Acc=13.77%, Val Loss=2.2015, Val Acc=11.25%, Grad Norm=2.8876, LR=1.5625e-06\n",
      "Fold 2, Epoch 67: Train Loss=2.1876, Train Acc=13.89%, Val Loss=2.2018, Val Acc=11.30%, Grad Norm=2.9100, LR=1.5625e-06\n",
      "Fold 2, Epoch 68: Train Loss=2.1871, Train Acc=13.93%, Val Loss=2.2018, Val Acc=11.24%, Grad Norm=2.9196, LR=1.5625e-06\n",
      "Fold 2, Epoch 69: Train Loss=2.1872, Train Acc=14.26%, Val Loss=2.2020, Val Acc=11.18%, Grad Norm=2.9251, LR=1.5625e-06\n",
      "Fold 2, Epoch 70: Train Loss=2.1873, Train Acc=13.87%, Val Loss=2.2017, Val Acc=11.07%, Grad Norm=2.9324, LR=1.5625e-06\n",
      "Fold 2, Epoch 71: Train Loss=2.1885, Train Acc=13.82%, Val Loss=2.2019, Val Acc=11.15%, Grad Norm=2.9463, LR=7.8125e-07\n",
      "Fold 2, Epoch 72: Train Loss=2.1875, Train Acc=13.92%, Val Loss=2.2020, Val Acc=11.18%, Grad Norm=2.9481, LR=7.8125e-07\n",
      "Fold 2, Epoch 73: Train Loss=2.1868, Train Acc=14.10%, Val Loss=2.2017, Val Acc=11.09%, Grad Norm=2.9612, LR=7.8125e-07\n",
      "Fold 2, Epoch 74: Train Loss=2.1875, Train Acc=13.91%, Val Loss=2.2018, Val Acc=11.08%, Grad Norm=2.9730, LR=7.8125e-07\n",
      "Fold 2, Epoch 75: Train Loss=2.1878, Train Acc=14.07%, Val Loss=2.2017, Val Acc=11.14%, Grad Norm=2.9814, LR=7.8125e-07\n",
      "Fold 2, Epoch 76: Train Loss=2.1876, Train Acc=14.22%, Val Loss=2.2019, Val Acc=11.15%, Grad Norm=2.9846, LR=7.8125e-07\n",
      "Fold 2, Epoch 77: Train Loss=2.1869, Train Acc=13.89%, Val Loss=2.2017, Val Acc=11.25%, Grad Norm=3.0013, LR=7.8125e-07\n",
      "Fold 2, Epoch 78: Train Loss=2.1866, Train Acc=14.23%, Val Loss=2.2018, Val Acc=11.27%, Grad Norm=3.0205, LR=7.8125e-07\n",
      "Fold 2, Epoch 79: Train Loss=2.1874, Train Acc=14.07%, Val Loss=2.2017, Val Acc=11.25%, Grad Norm=3.0188, LR=7.8125e-07\n",
      "Fold 2, Epoch 80: Train Loss=2.1869, Train Acc=14.19%, Val Loss=2.2015, Val Acc=11.34%, Grad Norm=3.0224, LR=7.8125e-07\n",
      "Fold 2, Epoch 81: Train Loss=2.1878, Train Acc=14.28%, Val Loss=2.2015, Val Acc=11.34%, Grad Norm=3.0270, LR=3.90625e-07\n",
      "Fold 2, Epoch 82: Train Loss=2.1858, Train Acc=14.64%, Val Loss=2.2017, Val Acc=11.34%, Grad Norm=3.0374, LR=3.90625e-07\n",
      "Fold 2, Epoch 83: Train Loss=2.1867, Train Acc=14.39%, Val Loss=2.2015, Val Acc=11.36%, Grad Norm=3.0376, LR=3.90625e-07\n",
      "Fold 2, Epoch 84: Train Loss=2.1879, Train Acc=13.79%, Val Loss=2.2016, Val Acc=11.30%, Grad Norm=3.0429, LR=3.90625e-07\n",
      "Fold 2, Epoch 85: Train Loss=2.1867, Train Acc=14.34%, Val Loss=2.2015, Val Acc=11.38%, Grad Norm=3.0508, LR=3.90625e-07\n",
      "Fold 2, Epoch 86: Train Loss=2.1865, Train Acc=14.32%, Val Loss=2.2016, Val Acc=11.35%, Grad Norm=3.0546, LR=3.90625e-07\n",
      "Fold 2, Epoch 87: Train Loss=2.1878, Train Acc=13.96%, Val Loss=2.2017, Val Acc=11.28%, Grad Norm=3.0593, LR=3.90625e-07\n",
      "Fold 2, Epoch 88: Train Loss=2.1863, Train Acc=14.19%, Val Loss=2.2017, Val Acc=11.34%, Grad Norm=3.0584, LR=3.90625e-07\n",
      "Fold 2, Epoch 89: Train Loss=2.1865, Train Acc=14.47%, Val Loss=2.2016, Val Acc=11.36%, Grad Norm=3.0629, LR=3.90625e-07\n",
      "Fold 2, Epoch 90: Train Loss=2.1867, Train Acc=14.08%, Val Loss=2.2018, Val Acc=11.33%, Grad Norm=3.0719, LR=3.90625e-07\n",
      "Fold 2, Epoch 91: Train Loss=2.1867, Train Acc=14.05%, Val Loss=2.2016, Val Acc=11.34%, Grad Norm=3.0725, LR=1.95313e-07\n",
      "Fold 2, Epoch 92: Train Loss=2.1870, Train Acc=14.06%, Val Loss=2.2017, Val Acc=11.39%, Grad Norm=3.0760, LR=1.95313e-07\n",
      "Fold 2, Epoch 93: Train Loss=2.1865, Train Acc=13.97%, Val Loss=2.2017, Val Acc=11.33%, Grad Norm=3.0790, LR=1.95313e-07\n",
      "Fold 2, Epoch 94: Train Loss=2.1861, Train Acc=14.32%, Val Loss=2.2017, Val Acc=11.32%, Grad Norm=3.0776, LR=1.95313e-07\n",
      "Fold 2, Epoch 95: Train Loss=2.1864, Train Acc=14.16%, Val Loss=2.2018, Val Acc=11.37%, Grad Norm=3.0816, LR=1.95313e-07\n",
      "Fold 2, Epoch 96: Train Loss=2.1871, Train Acc=14.06%, Val Loss=2.2017, Val Acc=11.31%, Grad Norm=3.0794, LR=1.95313e-07\n",
      "Fold 2, Epoch 97: Train Loss=2.1875, Train Acc=13.92%, Val Loss=2.2018, Val Acc=11.30%, Grad Norm=3.0841, LR=1.95313e-07\n",
      "Fold 2, Epoch 98: Train Loss=2.1866, Train Acc=14.23%, Val Loss=2.2018, Val Acc=11.34%, Grad Norm=3.0892, LR=1.95313e-07\n",
      "Fold 2, Epoch 99: Train Loss=2.1864, Train Acc=14.20%, Val Loss=2.2017, Val Acc=11.35%, Grad Norm=3.0853, LR=1.95313e-07\n",
      "Fold 2, Epoch 100: Train Loss=2.1865, Train Acc=14.41%, Val Loss=2.2017, Val Acc=11.40%, Grad Norm=3.0911, LR=1.95313e-07\n",
      "Fold 2, Epoch 101: Train Loss=2.1858, Train Acc=14.44%, Val Loss=2.2017, Val Acc=11.36%, Grad Norm=3.0941, LR=9.76563e-08\n",
      "Fold 2, Epoch 102: Train Loss=2.1861, Train Acc=14.33%, Val Loss=2.2017, Val Acc=11.31%, Grad Norm=3.0949, LR=9.76563e-08\n",
      "Fold 2, Epoch 103: Train Loss=2.1869, Train Acc=13.98%, Val Loss=2.2017, Val Acc=11.34%, Grad Norm=3.0956, LR=9.76563e-08\n",
      "Fold 2, Epoch 104: Train Loss=2.1863, Train Acc=14.13%, Val Loss=2.2015, Val Acc=11.33%, Grad Norm=3.0972, LR=9.76563e-08\n",
      "Fold 2, Epoch 105: Train Loss=2.1870, Train Acc=13.90%, Val Loss=2.2016, Val Acc=11.34%, Grad Norm=3.1022, LR=9.76563e-08\n",
      "Fold 2, Epoch 106: Train Loss=2.1867, Train Acc=14.30%, Val Loss=2.2016, Val Acc=11.36%, Grad Norm=3.1007, LR=9.76563e-08\n",
      "Fold 2, Epoch 107: Train Loss=2.1860, Train Acc=14.39%, Val Loss=2.2016, Val Acc=11.29%, Grad Norm=3.1005, LR=9.76563e-08\n",
      "Fold 2, Epoch 108: Train Loss=2.1864, Train Acc=13.96%, Val Loss=2.2016, Val Acc=11.39%, Grad Norm=3.0992, LR=9.76563e-08\n",
      "Fold 2, Epoch 109: Train Loss=2.1859, Train Acc=14.19%, Val Loss=2.2016, Val Acc=11.36%, Grad Norm=3.0994, LR=9.76563e-08\n",
      "Fold 2, Epoch 110: Train Loss=2.1861, Train Acc=14.39%, Val Loss=2.2016, Val Acc=11.36%, Grad Norm=3.1084, LR=9.76563e-08\n",
      "Fold 2, Epoch 111: Train Loss=2.1858, Train Acc=14.44%, Val Loss=2.2016, Val Acc=11.38%, Grad Norm=3.1070, LR=4.88281e-08\n",
      "Fold 2, Epoch 112: Train Loss=2.1870, Train Acc=14.08%, Val Loss=2.2016, Val Acc=11.35%, Grad Norm=3.1067, LR=4.88281e-08\n",
      "Fold 2, Epoch 113: Train Loss=2.1860, Train Acc=14.37%, Val Loss=2.2015, Val Acc=11.38%, Grad Norm=3.1028, LR=4.88281e-08\n",
      "Fold 2, Epoch 114: Train Loss=2.1866, Train Acc=14.16%, Val Loss=2.2017, Val Acc=11.28%, Grad Norm=3.1045, LR=4.88281e-08\n",
      "Fold 2, Epoch 115: Train Loss=2.1860, Train Acc=14.28%, Val Loss=2.2017, Val Acc=11.37%, Grad Norm=3.1059, LR=4.88281e-08\n",
      "Fold 2, Epoch 116: Train Loss=2.1870, Train Acc=14.14%, Val Loss=2.2016, Val Acc=11.33%, Grad Norm=3.1054, LR=4.88281e-08\n",
      "Fold 2, Epoch 117: Train Loss=2.1861, Train Acc=14.10%, Val Loss=2.2016, Val Acc=11.27%, Grad Norm=3.1025, LR=4.88281e-08\n",
      "Fold 2, Epoch 118: Train Loss=2.1866, Train Acc=14.07%, Val Loss=2.2017, Val Acc=11.37%, Grad Norm=3.1043, LR=4.88281e-08\n",
      "Fold 2, Epoch 119: Train Loss=2.1864, Train Acc=14.11%, Val Loss=2.2016, Val Acc=11.31%, Grad Norm=3.1076, LR=4.88281e-08\n",
      "Fold 2, Epoch 120: Train Loss=2.1863, Train Acc=14.46%, Val Loss=2.2016, Val Acc=11.33%, Grad Norm=3.1034, LR=4.88281e-08\n",
      "Fold 2, Epoch 121: Train Loss=2.1861, Train Acc=14.31%, Val Loss=2.2017, Val Acc=11.37%, Grad Norm=3.1087, LR=2.44141e-08\n",
      "Fold 2, Epoch 122: Train Loss=2.1860, Train Acc=14.20%, Val Loss=2.2017, Val Acc=11.33%, Grad Norm=3.1083, LR=2.44141e-08\n",
      "Fold 2, Epoch 123: Train Loss=2.1856, Train Acc=14.13%, Val Loss=2.2015, Val Acc=11.33%, Grad Norm=3.1073, LR=2.44141e-08\n",
      "Fold 2, Epoch 124: Train Loss=2.1855, Train Acc=14.46%, Val Loss=2.2016, Val Acc=11.28%, Grad Norm=3.1132, LR=2.44141e-08\n",
      "Fold 2, Epoch 125: Train Loss=2.1861, Train Acc=13.96%, Val Loss=2.2016, Val Acc=11.32%, Grad Norm=3.1106, LR=2.44141e-08\n",
      "Fold 2, Epoch 126: Train Loss=2.1863, Train Acc=14.34%, Val Loss=2.2016, Val Acc=11.32%, Grad Norm=3.1078, LR=2.44141e-08\n",
      "Fold 2, Epoch 127: Train Loss=2.1865, Train Acc=14.13%, Val Loss=2.2017, Val Acc=11.33%, Grad Norm=3.1114, LR=2.44141e-08\n",
      "Fold 2, Epoch 128: Train Loss=2.1871, Train Acc=14.00%, Val Loss=2.2017, Val Acc=11.31%, Grad Norm=3.1067, LR=2.44141e-08\n",
      "Fold 2, Epoch 129: Train Loss=2.1857, Train Acc=14.52%, Val Loss=2.2016, Val Acc=11.33%, Grad Norm=3.1151, LR=2.44141e-08\n",
      "Fold 2, Epoch 130: Train Loss=2.1863, Train Acc=14.21%, Val Loss=2.2015, Val Acc=11.25%, Grad Norm=3.1114, LR=2.44141e-08\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.40%）\n",
      "Fold 2 DONE | Best Val Acc≈11.40% | Final Val Acc=11.40% | Test Acc=11.18%\n",
      "\n",
      "====== Fold 3/5 ======\n",
      "Fold 3, Epoch 1: Train Loss=2.2276, Train Acc=10.86%, Val Loss=2.2076, Val Acc=11.05%, Grad Norm=6.7307, LR=0.0001\n",
      "Fold 3, Epoch 2: Train Loss=2.2212, Train Acc=11.37%, Val Loss=2.2657, Val Acc=11.07%, Grad Norm=6.4016, LR=0.0001\n",
      "Fold 3, Epoch 3: Train Loss=2.2171, Train Acc=11.35%, Val Loss=2.2576, Val Acc=10.98%, Grad Norm=5.7798, LR=0.0001\n",
      "Fold 3, Epoch 4: Train Loss=2.2135, Train Acc=11.11%, Val Loss=2.2251, Val Acc=11.08%, Grad Norm=4.6199, LR=0.0001\n",
      "Fold 3, Epoch 5: Train Loss=2.2083, Train Acc=11.00%, Val Loss=2.2620, Val Acc=11.13%, Grad Norm=3.7519, LR=0.0001\n",
      "Fold 3, Epoch 6: Train Loss=2.2071, Train Acc=11.11%, Val Loss=2.2593, Val Acc=11.14%, Grad Norm=3.2596, LR=0.0001\n",
      "Fold 3, Epoch 7: Train Loss=2.2045, Train Acc=11.45%, Val Loss=2.2982, Val Acc=11.11%, Grad Norm=2.9421, LR=0.0001\n",
      "Fold 3, Epoch 8: Train Loss=2.2042, Train Acc=11.35%, Val Loss=2.2297, Val Acc=11.15%, Grad Norm=2.6710, LR=0.0001\n",
      "Fold 3, Epoch 9: Train Loss=2.2032, Train Acc=11.36%, Val Loss=2.2166, Val Acc=11.11%, Grad Norm=2.3668, LR=0.0001\n",
      "Fold 3, Epoch 10: Train Loss=2.2026, Train Acc=11.25%, Val Loss=2.2100, Val Acc=11.21%, Grad Norm=2.0840, LR=0.0001\n",
      "Fold 3, Epoch 11: Train Loss=2.2004, Train Acc=11.12%, Val Loss=2.2056, Val Acc=11.24%, Grad Norm=1.8237, LR=5e-05\n",
      "Fold 3, Epoch 12: Train Loss=2.2000, Train Acc=11.05%, Val Loss=2.2021, Val Acc=10.97%, Grad Norm=1.7102, LR=5e-05\n",
      "Fold 3, Epoch 13: Train Loss=2.1994, Train Acc=11.30%, Val Loss=2.2009, Val Acc=11.02%, Grad Norm=1.6356, LR=5e-05\n",
      "Fold 3, Epoch 14: Train Loss=2.1994, Train Acc=11.04%, Val Loss=2.2120, Val Acc=11.11%, Grad Norm=1.6082, LR=5e-05\n",
      "Fold 3, Epoch 15: Train Loss=2.1988, Train Acc=11.52%, Val Loss=2.2016, Val Acc=11.12%, Grad Norm=1.4790, LR=5e-05\n",
      "Fold 3, Epoch 16: Train Loss=2.1987, Train Acc=11.40%, Val Loss=2.1987, Val Acc=11.11%, Grad Norm=1.4348, LR=5e-05\n",
      "Fold 3, Epoch 17: Train Loss=2.1989, Train Acc=11.15%, Val Loss=2.2004, Val Acc=11.13%, Grad Norm=1.3781, LR=5e-05\n",
      "Fold 3, Epoch 18: Train Loss=2.1985, Train Acc=11.45%, Val Loss=2.2000, Val Acc=11.03%, Grad Norm=1.2810, LR=5e-05\n",
      "Fold 3, Epoch 19: Train Loss=2.1982, Train Acc=11.64%, Val Loss=2.2012, Val Acc=11.09%, Grad Norm=1.2240, LR=5e-05\n",
      "Fold 3, Epoch 20: Train Loss=2.1977, Train Acc=11.45%, Val Loss=2.1992, Val Acc=11.01%, Grad Norm=1.1561, LR=5e-05\n",
      "Fold 3, Epoch 21: Train Loss=2.1975, Train Acc=11.51%, Val Loss=2.1993, Val Acc=11.11%, Grad Norm=1.0526, LR=2.5e-05\n",
      "Fold 3, Epoch 22: Train Loss=2.1969, Train Acc=11.83%, Val Loss=2.1995, Val Acc=11.12%, Grad Norm=1.1266, LR=2.5e-05\n",
      "Fold 3, Epoch 23: Train Loss=2.1967, Train Acc=11.71%, Val Loss=2.1989, Val Acc=11.11%, Grad Norm=1.1849, LR=2.5e-05\n",
      "Fold 3, Epoch 24: Train Loss=2.1969, Train Acc=11.70%, Val Loss=2.1987, Val Acc=11.21%, Grad Norm=1.1936, LR=2.5e-05\n",
      "Fold 3, Epoch 25: Train Loss=2.1969, Train Acc=11.81%, Val Loss=2.1985, Val Acc=11.01%, Grad Norm=1.2073, LR=2.5e-05\n",
      "Fold 3, Epoch 26: Train Loss=2.1964, Train Acc=11.92%, Val Loss=2.2015, Val Acc=11.17%, Grad Norm=1.1219, LR=2.5e-05\n",
      "Fold 3, Epoch 27: Train Loss=2.1959, Train Acc=11.83%, Val Loss=2.2007, Val Acc=10.94%, Grad Norm=1.2855, LR=2.5e-05\n",
      "Fold 3, Epoch 28: Train Loss=2.1960, Train Acc=12.23%, Val Loss=2.1986, Val Acc=10.89%, Grad Norm=1.3932, LR=2.5e-05\n",
      "Fold 3, Epoch 29: Train Loss=2.1957, Train Acc=12.04%, Val Loss=2.1994, Val Acc=11.03%, Grad Norm=1.2704, LR=2.5e-05\n",
      "Fold 3, Epoch 30: Train Loss=2.1957, Train Acc=12.39%, Val Loss=2.1990, Val Acc=11.04%, Grad Norm=1.2789, LR=2.5e-05\n",
      "Fold 3, Epoch 31: Train Loss=2.1952, Train Acc=12.27%, Val Loss=2.1990, Val Acc=10.88%, Grad Norm=1.3559, LR=1.25e-05\n",
      "Fold 3, Epoch 32: Train Loss=2.1945, Train Acc=12.44%, Val Loss=2.2018, Val Acc=10.98%, Grad Norm=1.5110, LR=1.25e-05\n",
      "Fold 3, Epoch 33: Train Loss=2.1939, Train Acc=12.36%, Val Loss=2.2012, Val Acc=10.93%, Grad Norm=1.7666, LR=1.25e-05\n",
      "Fold 3, Epoch 34: Train Loss=2.1943, Train Acc=12.40%, Val Loss=2.2003, Val Acc=11.08%, Grad Norm=1.7707, LR=1.25e-05\n",
      "Fold 3, Epoch 35: Train Loss=2.1934, Train Acc=12.78%, Val Loss=2.2047, Val Acc=11.29%, Grad Norm=1.8824, LR=1.25e-05\n",
      "Fold 3, Epoch 36: Train Loss=2.1933, Train Acc=12.82%, Val Loss=2.2016, Val Acc=11.14%, Grad Norm=2.0408, LR=1.25e-05\n",
      "Fold 3, Epoch 37: Train Loss=2.1932, Train Acc=12.72%, Val Loss=2.2005, Val Acc=11.04%, Grad Norm=2.0611, LR=1.25e-05\n",
      "Fold 3, Epoch 38: Train Loss=2.1926, Train Acc=13.01%, Val Loss=2.2023, Val Acc=10.94%, Grad Norm=2.2372, LR=1.25e-05\n",
      "Fold 3, Epoch 39: Train Loss=2.1927, Train Acc=12.68%, Val Loss=2.2019, Val Acc=11.04%, Grad Norm=2.3286, LR=1.25e-05\n",
      "Fold 3, Epoch 40: Train Loss=2.1923, Train Acc=12.87%, Val Loss=2.2036, Val Acc=11.08%, Grad Norm=2.3342, LR=1.25e-05\n",
      "Fold 3, Epoch 41: Train Loss=2.1913, Train Acc=13.02%, Val Loss=2.2041, Val Acc=11.16%, Grad Norm=2.4124, LR=6.25e-06\n",
      "Fold 3, Epoch 42: Train Loss=2.1917, Train Acc=13.25%, Val Loss=2.2036, Val Acc=10.89%, Grad Norm=2.5326, LR=6.25e-06\n",
      "Fold 3, Epoch 43: Train Loss=2.1904, Train Acc=13.28%, Val Loss=2.2034, Val Acc=10.96%, Grad Norm=2.5888, LR=6.25e-06\n",
      "Fold 3, Epoch 44: Train Loss=2.1905, Train Acc=13.43%, Val Loss=2.2026, Val Acc=11.14%, Grad Norm=2.6794, LR=6.25e-06\n",
      "Fold 3, Epoch 45: Train Loss=2.1905, Train Acc=13.20%, Val Loss=2.2028, Val Acc=11.05%, Grad Norm=2.7496, LR=6.25e-06\n",
      "Fold 3, Epoch 46: Train Loss=2.1894, Train Acc=13.51%, Val Loss=2.2024, Val Acc=11.00%, Grad Norm=2.8476, LR=6.25e-06\n",
      "Fold 3, Epoch 47: Train Loss=2.1894, Train Acc=13.75%, Val Loss=2.2034, Val Acc=11.20%, Grad Norm=2.8751, LR=6.25e-06\n",
      "Fold 3, Epoch 48: Train Loss=2.1883, Train Acc=13.88%, Val Loss=2.2045, Val Acc=10.93%, Grad Norm=2.9164, LR=6.25e-06\n",
      "Fold 3, Epoch 49: Train Loss=2.1889, Train Acc=13.65%, Val Loss=2.2047, Val Acc=11.17%, Grad Norm=2.9216, LR=6.25e-06\n",
      "Fold 3, Epoch 50: Train Loss=2.1882, Train Acc=13.78%, Val Loss=2.2036, Val Acc=11.09%, Grad Norm=2.9002, LR=6.25e-06\n",
      "Fold 3, Epoch 51: Train Loss=2.1880, Train Acc=13.88%, Val Loss=2.2035, Val Acc=11.09%, Grad Norm=2.9210, LR=3.125e-06\n",
      "Fold 3, Epoch 52: Train Loss=2.1884, Train Acc=13.86%, Val Loss=2.2030, Val Acc=10.90%, Grad Norm=2.9541, LR=3.125e-06\n",
      "Fold 3, Epoch 53: Train Loss=2.1880, Train Acc=14.05%, Val Loss=2.2033, Val Acc=11.05%, Grad Norm=2.9731, LR=3.125e-06\n",
      "Fold 3, Epoch 54: Train Loss=2.1876, Train Acc=13.85%, Val Loss=2.2039, Val Acc=10.98%, Grad Norm=2.9879, LR=3.125e-06\n",
      "Fold 3, Epoch 55: Train Loss=2.1875, Train Acc=13.99%, Val Loss=2.2043, Val Acc=10.95%, Grad Norm=2.9942, LR=3.125e-06\n",
      "Fold 3, Epoch 56: Train Loss=2.1872, Train Acc=13.76%, Val Loss=2.2036, Val Acc=10.94%, Grad Norm=3.0042, LR=3.125e-06\n",
      "Fold 3, Epoch 57: Train Loss=2.1867, Train Acc=14.13%, Val Loss=2.2038, Val Acc=11.02%, Grad Norm=3.0408, LR=3.125e-06\n",
      "Fold 3, Epoch 58: Train Loss=2.1868, Train Acc=13.97%, Val Loss=2.2028, Val Acc=10.97%, Grad Norm=3.0695, LR=3.125e-06\n",
      "Fold 3, Epoch 59: Train Loss=2.1874, Train Acc=13.98%, Val Loss=2.2031, Val Acc=10.93%, Grad Norm=3.0818, LR=3.125e-06\n",
      "Fold 3, Epoch 60: Train Loss=2.1866, Train Acc=14.12%, Val Loss=2.2033, Val Acc=11.11%, Grad Norm=3.0930, LR=3.125e-06\n",
      "Fold 3, Epoch 61: Train Loss=2.1860, Train Acc=13.83%, Val Loss=2.2032, Val Acc=11.03%, Grad Norm=3.1225, LR=1.5625e-06\n",
      "Fold 3, Epoch 62: Train Loss=2.1855, Train Acc=14.42%, Val Loss=2.2030, Val Acc=11.03%, Grad Norm=3.1499, LR=1.5625e-06\n",
      "Fold 3, Epoch 63: Train Loss=2.1854, Train Acc=14.17%, Val Loss=2.2030, Val Acc=11.15%, Grad Norm=3.1742, LR=1.5625e-06\n",
      "Fold 3, Epoch 64: Train Loss=2.1852, Train Acc=14.22%, Val Loss=2.2026, Val Acc=11.08%, Grad Norm=3.2076, LR=1.5625e-06\n",
      "Fold 3, Epoch 65: Train Loss=2.1862, Train Acc=13.93%, Val Loss=2.2031, Val Acc=11.11%, Grad Norm=3.2243, LR=1.5625e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.29%）\n",
      "Fold 3 DONE | Best Val Acc≈11.29% | Final Val Acc=11.29% | Test Acc=11.17%\n",
      "\n",
      "====== Fold 4/5 ======\n",
      "Fold 4, Epoch 1: Train Loss=2.2237, Train Acc=11.15%, Val Loss=2.2315, Val Acc=11.00%, Grad Norm=6.8729, LR=0.0001\n",
      "Fold 4, Epoch 2: Train Loss=2.2197, Train Acc=11.23%, Val Loss=2.2168, Val Acc=11.39%, Grad Norm=6.4872, LR=0.0001\n",
      "Fold 4, Epoch 3: Train Loss=2.2170, Train Acc=11.46%, Val Loss=2.2854, Val Acc=11.13%, Grad Norm=5.5313, LR=0.0001\n",
      "Fold 4, Epoch 4: Train Loss=2.2102, Train Acc=11.10%, Val Loss=2.2138, Val Acc=11.24%, Grad Norm=4.2397, LR=0.0001\n",
      "Fold 4, Epoch 5: Train Loss=2.2077, Train Acc=11.19%, Val Loss=2.2157, Val Acc=11.13%, Grad Norm=3.4178, LR=0.0001\n",
      "Fold 4, Epoch 6: Train Loss=2.2043, Train Acc=11.20%, Val Loss=2.2052, Val Acc=11.04%, Grad Norm=2.9574, LR=0.0001\n",
      "Fold 4, Epoch 7: Train Loss=2.2038, Train Acc=11.21%, Val Loss=2.2080, Val Acc=11.06%, Grad Norm=2.6249, LR=0.0001\n",
      "Fold 4, Epoch 8: Train Loss=2.2032, Train Acc=11.26%, Val Loss=2.2090, Val Acc=11.11%, Grad Norm=2.2856, LR=0.0001\n",
      "Fold 4, Epoch 9: Train Loss=2.2026, Train Acc=11.01%, Val Loss=2.2067, Val Acc=11.05%, Grad Norm=1.9601, LR=0.0001\n",
      "Fold 4, Epoch 10: Train Loss=2.2007, Train Acc=11.31%, Val Loss=2.2113, Val Acc=10.94%, Grad Norm=1.8241, LR=0.0001\n",
      "Fold 4, Epoch 11: Train Loss=2.1996, Train Acc=11.27%, Val Loss=2.1997, Val Acc=10.66%, Grad Norm=1.5758, LR=5e-05\n",
      "Fold 4, Epoch 12: Train Loss=2.1994, Train Acc=11.05%, Val Loss=2.2016, Val Acc=11.17%, Grad Norm=1.4221, LR=5e-05\n",
      "Fold 4, Epoch 13: Train Loss=2.1985, Train Acc=11.33%, Val Loss=2.2018, Val Acc=11.14%, Grad Norm=1.3480, LR=5e-05\n",
      "Fold 4, Epoch 14: Train Loss=2.1986, Train Acc=11.42%, Val Loss=2.2005, Val Acc=11.15%, Grad Norm=1.2649, LR=5e-05\n",
      "Fold 4, Epoch 15: Train Loss=2.1981, Train Acc=11.29%, Val Loss=2.1993, Val Acc=11.09%, Grad Norm=1.1756, LR=5e-05\n",
      "Fold 4, Epoch 16: Train Loss=2.1979, Train Acc=11.47%, Val Loss=2.1991, Val Acc=10.54%, Grad Norm=1.0958, LR=5e-05\n",
      "Fold 4, Epoch 17: Train Loss=2.1980, Train Acc=11.37%, Val Loss=2.1977, Val Acc=11.26%, Grad Norm=1.0243, LR=5e-05\n",
      "Fold 4, Epoch 18: Train Loss=2.1976, Train Acc=11.49%, Val Loss=2.1984, Val Acc=11.21%, Grad Norm=0.8668, LR=5e-05\n",
      "Fold 4, Epoch 19: Train Loss=2.1978, Train Acc=11.27%, Val Loss=2.2001, Val Acc=10.55%, Grad Norm=0.8038, LR=5e-05\n",
      "Fold 4, Epoch 20: Train Loss=2.1977, Train Acc=11.41%, Val Loss=2.1982, Val Acc=11.07%, Grad Norm=0.7538, LR=5e-05\n",
      "Fold 4, Epoch 21: Train Loss=2.1970, Train Acc=11.52%, Val Loss=2.1987, Val Acc=10.82%, Grad Norm=0.7326, LR=2.5e-05\n",
      "Fold 4, Epoch 22: Train Loss=2.1969, Train Acc=11.56%, Val Loss=2.1986, Val Acc=10.82%, Grad Norm=0.8016, LR=2.5e-05\n",
      "Fold 4, Epoch 23: Train Loss=2.1964, Train Acc=11.80%, Val Loss=2.1986, Val Acc=10.93%, Grad Norm=0.9563, LR=2.5e-05\n",
      "Fold 4, Epoch 24: Train Loss=2.1963, Train Acc=12.00%, Val Loss=2.1985, Val Acc=10.99%, Grad Norm=0.9120, LR=2.5e-05\n",
      "Fold 4, Epoch 25: Train Loss=2.1963, Train Acc=11.79%, Val Loss=2.1983, Val Acc=11.18%, Grad Norm=0.9079, LR=2.5e-05\n",
      "Fold 4, Epoch 26: Train Loss=2.1967, Train Acc=11.76%, Val Loss=2.1984, Val Acc=11.32%, Grad Norm=0.7793, LR=2.5e-05\n",
      "Fold 4, Epoch 27: Train Loss=2.1964, Train Acc=11.85%, Val Loss=2.1990, Val Acc=11.05%, Grad Norm=0.8556, LR=2.5e-05\n",
      "Fold 4, Epoch 28: Train Loss=2.1966, Train Acc=11.79%, Val Loss=2.1991, Val Acc=10.80%, Grad Norm=0.8943, LR=2.5e-05\n",
      "Fold 4, Epoch 29: Train Loss=2.1964, Train Acc=12.14%, Val Loss=2.1989, Val Acc=11.04%, Grad Norm=0.7983, LR=2.5e-05\n",
      "Fold 4, Epoch 30: Train Loss=2.1962, Train Acc=11.91%, Val Loss=2.2002, Val Acc=10.87%, Grad Norm=0.8670, LR=2.5e-05\n",
      "Fold 4, Epoch 31: Train Loss=2.1956, Train Acc=12.44%, Val Loss=2.1995, Val Acc=11.05%, Grad Norm=0.9497, LR=1.25e-05\n",
      "Fold 4, Epoch 32: Train Loss=2.1956, Train Acc=12.33%, Val Loss=2.1996, Val Acc=10.68%, Grad Norm=1.1288, LR=1.25e-05\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.39%）\n",
      "Fold 4 DONE | Best Val Acc≈11.39% | Final Val Acc=11.39% | Test Acc=11.15%\n",
      "\n",
      "====== Fold 5/5 ======\n",
      "Fold 5, Epoch 1: Train Loss=2.2226, Train Acc=11.40%, Val Loss=2.2200, Val Acc=10.90%, Grad Norm=6.7177, LR=0.0001\n",
      "Fold 5, Epoch 2: Train Loss=2.2213, Train Acc=11.14%, Val Loss=2.2728, Val Acc=11.14%, Grad Norm=6.2037, LR=0.0001\n",
      "Fold 5, Epoch 3: Train Loss=2.2165, Train Acc=11.07%, Val Loss=2.2140, Val Acc=11.04%, Grad Norm=5.2208, LR=0.0001\n",
      "Fold 5, Epoch 4: Train Loss=2.2107, Train Acc=10.97%, Val Loss=2.2262, Val Acc=10.82%, Grad Norm=3.9787, LR=0.0001\n",
      "Fold 5, Epoch 5: Train Loss=2.2059, Train Acc=11.13%, Val Loss=2.2319, Val Acc=11.12%, Grad Norm=3.3328, LR=0.0001\n",
      "Fold 5, Epoch 6: Train Loss=2.2056, Train Acc=10.96%, Val Loss=2.2202, Val Acc=11.09%, Grad Norm=2.8708, LR=0.0001\n",
      "Fold 5, Epoch 7: Train Loss=2.2037, Train Acc=11.59%, Val Loss=2.2131, Val Acc=10.95%, Grad Norm=2.5850, LR=0.0001\n",
      "Fold 5, Epoch 8: Train Loss=2.2029, Train Acc=11.06%, Val Loss=2.2115, Val Acc=11.06%, Grad Norm=2.2824, LR=0.0001\n",
      "Fold 5, Epoch 9: Train Loss=2.2023, Train Acc=11.12%, Val Loss=2.2149, Val Acc=11.11%, Grad Norm=1.9521, LR=0.0001\n",
      "Fold 5, Epoch 10: Train Loss=2.2012, Train Acc=11.06%, Val Loss=2.2133, Val Acc=11.11%, Grad Norm=1.6769, LR=0.0001\n",
      "Fold 5, Epoch 11: Train Loss=2.1994, Train Acc=11.29%, Val Loss=2.2000, Val Acc=11.03%, Grad Norm=1.4515, LR=5e-05\n",
      "Fold 5, Epoch 12: Train Loss=2.1991, Train Acc=11.28%, Val Loss=2.2006, Val Acc=11.28%, Grad Norm=1.3214, LR=5e-05\n",
      "Fold 5, Epoch 13: Train Loss=2.1986, Train Acc=11.42%, Val Loss=2.2027, Val Acc=11.12%, Grad Norm=1.2744, LR=5e-05\n",
      "Fold 5, Epoch 14: Train Loss=2.1982, Train Acc=11.36%, Val Loss=2.2031, Val Acc=11.13%, Grad Norm=1.2337, LR=5e-05\n",
      "Fold 5, Epoch 15: Train Loss=2.1984, Train Acc=11.18%, Val Loss=2.2000, Val Acc=11.26%, Grad Norm=1.1109, LR=5e-05\n",
      "Fold 5, Epoch 16: Train Loss=2.1980, Train Acc=11.53%, Val Loss=2.2000, Val Acc=11.49%, Grad Norm=1.1009, LR=5e-05\n",
      "Fold 5, Epoch 17: Train Loss=2.1980, Train Acc=11.21%, Val Loss=2.1993, Val Acc=11.02%, Grad Norm=0.9212, LR=5e-05\n",
      "Fold 5, Epoch 18: Train Loss=2.1979, Train Acc=11.40%, Val Loss=2.1984, Val Acc=10.85%, Grad Norm=0.9046, LR=5e-05\n",
      "Fold 5, Epoch 19: Train Loss=2.1978, Train Acc=11.25%, Val Loss=2.1989, Val Acc=11.28%, Grad Norm=0.7935, LR=5e-05\n",
      "Fold 5, Epoch 20: Train Loss=2.1974, Train Acc=11.52%, Val Loss=2.1989, Val Acc=11.02%, Grad Norm=0.7835, LR=5e-05\n",
      "Fold 5, Epoch 21: Train Loss=2.1971, Train Acc=11.52%, Val Loss=2.1979, Val Acc=11.04%, Grad Norm=0.7489, LR=2.5e-05\n",
      "Fold 5, Epoch 22: Train Loss=2.1969, Train Acc=11.63%, Val Loss=2.1981, Val Acc=11.02%, Grad Norm=0.8188, LR=2.5e-05\n",
      "Fold 5, Epoch 23: Train Loss=2.1968, Train Acc=11.97%, Val Loss=2.1982, Val Acc=10.84%, Grad Norm=0.8738, LR=2.5e-05\n",
      "Fold 5, Epoch 24: Train Loss=2.1967, Train Acc=11.80%, Val Loss=2.2016, Val Acc=11.09%, Grad Norm=0.8429, LR=2.5e-05\n",
      "Fold 5, Epoch 25: Train Loss=2.1971, Train Acc=11.52%, Val Loss=2.1980, Val Acc=11.44%, Grad Norm=0.7216, LR=2.5e-05\n",
      "Fold 5, Epoch 26: Train Loss=2.1966, Train Acc=11.82%, Val Loss=2.1982, Val Acc=11.37%, Grad Norm=0.8017, LR=2.5e-05\n",
      "Fold 5, Epoch 27: Train Loss=2.1965, Train Acc=11.83%, Val Loss=2.1990, Val Acc=11.09%, Grad Norm=0.7906, LR=2.5e-05\n",
      "Fold 5, Epoch 28: Train Loss=2.1964, Train Acc=11.98%, Val Loss=2.1984, Val Acc=11.15%, Grad Norm=0.9038, LR=2.5e-05\n",
      "Fold 5, Epoch 29: Train Loss=2.1965, Train Acc=11.83%, Val Loss=2.1982, Val Acc=10.66%, Grad Norm=0.9092, LR=2.5e-05\n",
      "Fold 5, Epoch 30: Train Loss=2.1964, Train Acc=11.99%, Val Loss=2.1994, Val Acc=11.13%, Grad Norm=1.0389, LR=2.5e-05\n",
      "Fold 5, Epoch 31: Train Loss=2.1958, Train Acc=12.03%, Val Loss=2.1997, Val Acc=11.33%, Grad Norm=0.9617, LR=1.25e-05\n",
      "Fold 5, Epoch 32: Train Loss=2.1955, Train Acc=11.99%, Val Loss=2.1994, Val Acc=11.20%, Grad Norm=1.0789, LR=1.25e-05\n",
      "Fold 5, Epoch 33: Train Loss=2.1952, Train Acc=12.38%, Val Loss=2.2000, Val Acc=11.03%, Grad Norm=1.1296, LR=1.25e-05\n",
      "Fold 5, Epoch 34: Train Loss=2.1951, Train Acc=12.34%, Val Loss=2.1989, Val Acc=10.76%, Grad Norm=1.2086, LR=1.25e-05\n",
      "Fold 5, Epoch 35: Train Loss=2.1950, Train Acc=12.32%, Val Loss=2.1997, Val Acc=11.14%, Grad Norm=1.2003, LR=1.25e-05\n",
      "Fold 5, Epoch 36: Train Loss=2.1953, Train Acc=12.24%, Val Loss=2.1996, Val Acc=11.44%, Grad Norm=1.1447, LR=1.25e-05\n",
      "Fold 5, Epoch 37: Train Loss=2.1949, Train Acc=12.26%, Val Loss=2.1989, Val Acc=11.23%, Grad Norm=1.1566, LR=1.25e-05\n",
      "Fold 5, Epoch 38: Train Loss=2.1947, Train Acc=12.52%, Val Loss=2.2002, Val Acc=10.88%, Grad Norm=1.1511, LR=1.25e-05\n",
      "Fold 5, Epoch 39: Train Loss=2.1945, Train Acc=12.72%, Val Loss=2.1992, Val Acc=11.06%, Grad Norm=1.2023, LR=1.25e-05\n",
      "Fold 5, Epoch 40: Train Loss=2.1948, Train Acc=12.53%, Val Loss=2.1991, Val Acc=11.17%, Grad Norm=1.1638, LR=1.25e-05\n",
      "Fold 5, Epoch 41: Train Loss=2.1944, Train Acc=12.62%, Val Loss=2.1993, Val Acc=10.93%, Grad Norm=1.2011, LR=6.25e-06\n",
      "Fold 5, Epoch 42: Train Loss=2.1944, Train Acc=12.71%, Val Loss=2.1996, Val Acc=11.12%, Grad Norm=1.2187, LR=6.25e-06\n",
      "Fold 5, Epoch 43: Train Loss=2.1941, Train Acc=12.69%, Val Loss=2.1993, Val Acc=11.20%, Grad Norm=1.2139, LR=6.25e-06\n",
      "Fold 5, Epoch 44: Train Loss=2.1943, Train Acc=12.55%, Val Loss=2.1989, Val Acc=11.06%, Grad Norm=1.2432, LR=6.25e-06\n",
      "Fold 5, Epoch 45: Train Loss=2.1939, Train Acc=12.68%, Val Loss=2.1998, Val Acc=10.84%, Grad Norm=1.2649, LR=6.25e-06\n",
      "Fold 5, Epoch 46: Train Loss=2.1940, Train Acc=12.62%, Val Loss=2.1997, Val Acc=10.82%, Grad Norm=1.2931, LR=6.25e-06\n",
      "早停：连续 30 个 epoch 验证集未提升（best_val_acc=11.49%）\n",
      "Fold 5 DONE | Best Val Acc≈11.49% | Final Val Acc=11.49% | Test Acc=11.37%\n",
      "[INFO] SNR=-40 dB | Mean Test Acc: 11.27% ± 0.13%\n",
      "[INFO] SNR -40 dB -> results: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR-40dB\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Sweep folder: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\n",
      "[INFO] Sweep summary CSV: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR_sweep_summary.csv\n",
      "[INFO] SNR curve saved: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-26_13-54-02_LTE-V_XFR_FileBlockBalanced_fd655_group256_ResNet_SNRsweep\\SNR_vs_accuracy.png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# LTE-V XFR (File-Block Balanced Split) — ResNet18_1D SNR Sweep\n",
    "# + Per-Block Row Subsampling (each epoch, each block draws different K rows)\n",
    "# ==========================================================\n",
    "# 目标：\n",
    "# 1) XFR block 构造：同一文件内顺序抽取 group_size 帧组成一个 block，不跨文件拼接\n",
    "#    - 每个 block: (group_size, sample_len, 2) -> transpose -> (sample_len, group_size, 2)\n",
    "#    - 文件内不足一个 block 的剩余帧丢弃\n",
    "# 2) 允许同一文件出现在多个集合，但要求“每个文件的 block 按比例”进入：\n",
    "#    - train/test：按文件分别切分（例如 75/25）\n",
    "#    - train 内 KFold：按文件分别均匀分桶到 n_splits 折（每折 val 约占每文件 train-block 的 1/n_splits）\n",
    "# 3) SNR sweep：20, 15, ..., -40（步长 -5）\n",
    "# 4) 网络：ResNet18_1D\n",
    "# 5) 输出：本次 sweep 一个总文件夹；每个 SNR 一个子文件夹，保存 results.txt / metrics.csv / confusion matrices / best models / loss curves / grad norms\n",
    "#    + 总的 SNR_vs_accuracy 曲线与 CSV（放在 sweep 总文件夹）\n",
    "# 6) 新增：训练集每个 epoch 对每个 block 独立抽 K 行（每个 block 行索引不同），降低行冗余；val/test 仍用全行\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# ================= 基础参数 =================\n",
    "data_path = \"E:/rf_datasets_IQ_raw/\"   # 存放 .mat 的文件夹\n",
    "fs = 1.4e6\n",
    "fc = 5.9e9\n",
    "v_kmh = 120                           # km/h\n",
    "\n",
    "apply_doppler = True\n",
    "apply_awgn = True\n",
    "\n",
    "# XFR block 参数\n",
    "group_size = 256                      # 一个 block 内帧数（time axis after XFR sample length）\n",
    "expected_sample_len = None            # None: 用首个有效文件长度；否则强制对齐到该长度（crop/pad）\n",
    "align_mode = \"crop_right\"             # \"crop_right\" | \"crop_center\" | \"pad_right\"\n",
    "skip_if_short = False                 # True: dmrs 短于 target 直接跳过文件；False: pad\n",
    "\n",
    "# ===== 新增：训练集每 epoch 每 block 抽 K 行 =====\n",
    "train_rows_per_block = 96             # K；None 或 >= sample_len 则等价全行训练\n",
    "\n",
    "# 训练超参数\n",
    "batch_size = 64\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 3e-3\n",
    "in_planes = 32\n",
    "dropout = 0.5\n",
    "patience = 30\n",
    "n_splits = 5\n",
    "test_size = 0.25\n",
    "\n",
    "# 复现实验\n",
    "seed = 42\n",
    "\n",
    "# 输出根目录\n",
    "out_root = os.path.join(os.getcwd(), \"training_results\")\n",
    "\n",
    "\n",
    "# ================= 工具：随机种子 =================\n",
    "def seed_everything(seed_: int = 42):\n",
    "    random.seed(seed_)\n",
    "    np.random.seed(seed_)\n",
    "    torch.manual_seed(seed_)\n",
    "    torch.cuda.manual_seed_all(seed_)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ================= 信道处理函数 =================\n",
    "def compute_doppler_shift(v_kmh_, fc_hz):\n",
    "    c = 3e8\n",
    "    v = v_kmh_ / 3.6\n",
    "    return (v / c) * fc_hz\n",
    "\n",
    "def apply_doppler_shift(signal, fd, fs_):\n",
    "    t = np.arange(signal.shape[-1], dtype=np.float64) / fs_\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "def add_awgn(signal, snr_db):\n",
    "    sig_power = np.mean(np.abs(signal) ** 2)\n",
    "    noise_power = sig_power / (10 ** (snr_db / 10))\n",
    "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
    "    return signal + noise\n",
    "\n",
    "def power_normalize(sig):\n",
    "    return sig / (np.sqrt(np.mean(np.abs(sig) ** 2)) + 1e-12)\n",
    "\n",
    "\n",
    "# ================= H5 读取：dmrs / txID（兼容两种存储形态） =================\n",
    "def read_dmrs_complex(rfDataset):\n",
    "    \"\"\"\n",
    "    支持：\n",
    "    - dmrs 是 compound dataset，字段 real/imag\n",
    "    - dmrs 是 group，内部 datasets real/imag\n",
    "    返回 dmrs_complex: (num_frames, sample_len) complex\n",
    "    \"\"\"\n",
    "    dmrs_obj = rfDataset[\"dmrs\"]\n",
    "    if isinstance(dmrs_obj, h5py.Dataset):\n",
    "        arr = dmrs_obj[:]\n",
    "        if hasattr(arr.dtype, \"names\") and arr.dtype.names is not None and (\"real\" in arr.dtype.names) and (\"imag\" in arr.dtype.names):\n",
    "            dmrs_complex = arr[\"real\"] + 1j * arr[\"imag\"]\n",
    "            return dmrs_complex\n",
    "        raise RuntimeError(\"dmrs dataset 不是预期的 compound(real/imag) 格式。\")\n",
    "    else:\n",
    "        real = dmrs_obj[\"real\"][:]\n",
    "        imag = dmrs_obj[\"imag\"][:]\n",
    "        return real + 1j * imag\n",
    "\n",
    "def read_txid_str(rfDataset):\n",
    "    \"\"\"\n",
    "    txID: uint16 array -> string\n",
    "    \"\"\"\n",
    "    txID_uint16 = rfDataset[\"txID\"][:].flatten()\n",
    "    chars = []\n",
    "    for c in txID_uint16:\n",
    "        ci = int(c)\n",
    "        if ci != 0:\n",
    "            chars.append(chr(ci))\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "# ================= dmrs 长度对齐 =================\n",
    "def align_1d_complex(sig_1d, target_len, mode=\"crop_right\"):\n",
    "    L = sig_1d.shape[0]\n",
    "    if L == target_len:\n",
    "        return sig_1d\n",
    "\n",
    "    if L > target_len:\n",
    "        if mode == \"crop_right\":\n",
    "            return sig_1d[:target_len]\n",
    "        if mode == \"crop_center\":\n",
    "            start = (L - target_len) // 2\n",
    "            return sig_1d[start:start + target_len]\n",
    "        return sig_1d[:target_len]\n",
    "\n",
    "    # L < target_len\n",
    "    if skip_if_short:\n",
    "        return None\n",
    "\n",
    "    # pad_right\n",
    "    out = np.zeros((target_len,), dtype=sig_1d.dtype)\n",
    "    out[:L] = sig_1d\n",
    "    return out\n",
    "\n",
    "\n",
    "# ================= XFR block 构造（同一文件内） =================\n",
    "def load_and_preprocess_with_file_blocks(\n",
    "    mat_folder,\n",
    "    group_size_=256,\n",
    "    apply_doppler_=False,\n",
    "    target_velocity_kmh_=120,\n",
    "    apply_awgn_=False,\n",
    "    snr_db_=20,\n",
    "    fs_=1.4e6,\n",
    "    fc_=5.9e9,\n",
    "    expected_sample_len_=None,\n",
    "    align_mode_=\"crop_right\",\n",
    "):\n",
    "    \"\"\"\n",
    "    返回：\n",
    "      X_blocks: (num_blocks, sample_len, group_size, 2)  float32\n",
    "      y_blocks: (num_blocks,) class idx\n",
    "      label_to_idx: dict(tx_id -> class idx)\n",
    "      file_ids: (num_blocks,) 每个 block 的 file_id\n",
    "      meta: dict\n",
    "    \"\"\"\n",
    "    mat_files = sorted(glob.glob(os.path.join(mat_folder, \"*.mat\")))\n",
    "    print(f\"共找到 {len(mat_files)} 个 .mat 文件\")\n",
    "\n",
    "    fd = compute_doppler_shift(target_velocity_kmh_, fc_)\n",
    "    print(f\"目标速度 {target_velocity_kmh_} km/h，多普勒频移 {fd:.2f} Hz\")\n",
    "\n",
    "    X_blocks_list = []\n",
    "    y_blocks_str_list = []\n",
    "    file_id_list = []\n",
    "    label_set = set()\n",
    "\n",
    "    skipped_no_rf = 0\n",
    "    skipped_missing_keys = 0\n",
    "    skipped_bad_tx = 0\n",
    "    skipped_no_block = 0\n",
    "    skipped_len_mismatch = 0\n",
    "\n",
    "    global_target_len = expected_sample_len_\n",
    "\n",
    "    for file in tqdm(mat_files, desc=\"读取数据\"):\n",
    "        file_id = os.path.basename(file)\n",
    "\n",
    "        try:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                if \"rfDataset\" not in f:\n",
    "                    skipped_no_rf += 1\n",
    "                    continue\n",
    "                rfDataset = f[\"rfDataset\"]\n",
    "                if (\"dmrs\" not in rfDataset) or (\"txID\" not in rfDataset):\n",
    "                    skipped_missing_keys += 1\n",
    "                    continue\n",
    "\n",
    "                tx_id = read_txid_str(rfDataset)\n",
    "                if tx_id == \"\":\n",
    "                    skipped_bad_tx += 1\n",
    "                    continue\n",
    "\n",
    "                dmrs_complex = read_dmrs_complex(rfDataset)  # (num_frames, sample_len)\n",
    "        except Exception:\n",
    "            skipped_missing_keys += 1\n",
    "            continue\n",
    "\n",
    "        num_frames = dmrs_complex.shape[0]\n",
    "        sample_len = dmrs_complex.shape[1]\n",
    "\n",
    "        if global_target_len is None:\n",
    "            global_target_len = int(sample_len)\n",
    "\n",
    "        processed = []\n",
    "        for i in range(num_frames):\n",
    "            sig = dmrs_complex[i, :]\n",
    "\n",
    "            sig = align_1d_complex(sig, global_target_len, mode=align_mode_)\n",
    "            if sig is None:\n",
    "                skipped_len_mismatch += 1\n",
    "                processed = None\n",
    "                break\n",
    "\n",
    "            sig = power_normalize(sig)\n",
    "\n",
    "            if apply_doppler_:\n",
    "                sig = apply_doppler_shift(sig, fd, fs_)\n",
    "            if apply_awgn_:\n",
    "                sig = add_awgn(sig, snr_db_)\n",
    "\n",
    "            iq = np.stack((sig.real, sig.imag), axis=-1)  # (target_len, 2)\n",
    "            processed.append(iq)\n",
    "\n",
    "        if processed is None:\n",
    "            continue\n",
    "\n",
    "        processed = np.asarray(processed, dtype=np.float32)  # (num_frames, target_len, 2)\n",
    "        num_frames_eff = processed.shape[0]\n",
    "\n",
    "        num_full_blocks = num_frames_eff // group_size_\n",
    "        if num_full_blocks == 0:\n",
    "            skipped_no_block += 1\n",
    "            continue\n",
    "\n",
    "        for b in range(num_full_blocks):\n",
    "            s = b * group_size_\n",
    "            e = s + group_size_\n",
    "            big_block = processed[s:e]  # (group_size, target_len, 2)\n",
    "            big_block = np.transpose(big_block, (1, 0, 2))  # (target_len, group_size, 2)\n",
    "\n",
    "            X_blocks_list.append(big_block)\n",
    "            y_blocks_str_list.append(tx_id)\n",
    "            file_id_list.append(file_id)\n",
    "            label_set.add(tx_id)\n",
    "\n",
    "    if len(X_blocks_list) == 0:\n",
    "        raise RuntimeError(\"没有生成任何 block（请检查数据路径、group_size、dmrs长度对齐策略）。\")\n",
    "\n",
    "    label_list = sorted(list(label_set))\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(label_list)}\n",
    "    y_blocks = np.array([label_to_idx[s] for s in y_blocks_str_list], dtype=np.int64)\n",
    "\n",
    "    X_blocks = np.stack(X_blocks_list, axis=0).astype(np.float32)\n",
    "    file_ids = np.array(file_id_list, dtype=object)\n",
    "\n",
    "    print(f\"[INFO] target_sample_len = {X_blocks.shape[1]}\")\n",
    "    print(f\"[INFO] 生成 block 数: {X_blocks.shape[0]} | 每 block 样本数(=group_size): {X_blocks.shape[2]} | 每样本长度(=sample_len): {X_blocks.shape[1]}\")\n",
    "    print(f\"[INFO] 类别数: {len(label_to_idx)} | 类别映射: {label_to_idx}\")\n",
    "\n",
    "    meta = {\n",
    "        \"global_target_len\": global_target_len,\n",
    "        \"skipped_no_rf\": skipped_no_rf,\n",
    "        \"skipped_missing_keys\": skipped_missing_keys,\n",
    "        \"skipped_bad_tx\": skipped_bad_tx,\n",
    "        \"skipped_no_block\": skipped_no_block,\n",
    "        \"skipped_len_mismatch\": skipped_len_mismatch,\n",
    "    }\n",
    "    if any(meta[k] > 0 for k in meta if k.startswith(\"skipped_\")):\n",
    "        print(f\"[INFO] 跳过统计: {meta}\")\n",
    "\n",
    "    return X_blocks, y_blocks, label_to_idx, file_ids, meta\n",
    "\n",
    "\n",
    "# ================= 文件均衡划分：train/test =================\n",
    "def filewise_train_test_split(file_ids, test_size_=0.25, seed_=42):\n",
    "    \"\"\"\n",
    "    对每个文件：其 block 索引单独 shuffle 后按比例切分，保证 train/test 都尽量非空（n>=2）。\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed_)\n",
    "    train_idx, test_idx = [], []\n",
    "\n",
    "    for fid in np.unique(file_ids):\n",
    "        idx = np.where(file_ids == fid)[0]\n",
    "        rng.shuffle(idx)\n",
    "        n = len(idx)\n",
    "\n",
    "        if n == 1:\n",
    "            train_idx.append(idx[0])\n",
    "            continue\n",
    "\n",
    "        n_test = int(np.round(n * test_size_))\n",
    "        n_test = max(1, min(n_test, n - 1))\n",
    "        test_idx.extend(idx[:n_test])\n",
    "        train_idx.extend(idx[n_test:])\n",
    "\n",
    "    return np.array(train_idx, dtype=int), np.array(test_idx, dtype=int)\n",
    "\n",
    "\n",
    "# ================= 文件均衡 KFold：train 内 -> train/val =================\n",
    "def filewise_kfold_indices(train_idx, file_ids, n_splits_=5, seed_=42):\n",
    "    \"\"\"\n",
    "    将 train_idx 内各文件的 block 均匀分桶到 n_splits 个折的 val 中。\n",
    "    第 k 折：val = union_over_files(chunk_k(file_train_blocks))\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed_)\n",
    "    folds_val = [[] for _ in range(n_splits_)]\n",
    "\n",
    "    train_files = np.unique(file_ids[train_idx])\n",
    "    for fid in train_files:\n",
    "        idx = train_idx[file_ids[train_idx] == fid].copy()\n",
    "        rng.shuffle(idx)\n",
    "        chunks = np.array_split(idx, n_splits_)\n",
    "        for k in range(n_splits_):\n",
    "            folds_val[k].extend(chunks[k].tolist())\n",
    "\n",
    "    for k in range(n_splits_):\n",
    "        val_idx = np.array(folds_val[k], dtype=int)\n",
    "        tr_idx = np.setdiff1d(train_idx, val_idx, assume_unique=False)\n",
    "        yield tr_idx, val_idx\n",
    "\n",
    "\n",
    "# ================= ResNet18_1D =================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes_, planes, stride=1, downsample=None, dropout_=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes_, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout_)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes_=64, dropout_=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes_\n",
    "        self.conv1 = nn.Conv1d(2, in_planes_, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes_)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout_=dropout_)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout_=dropout_)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout_=dropout_)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout_=dropout_)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout_):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes),\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout_=dropout_)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout_=dropout_))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, 2) where T=group_size after reshape\n",
    "        x = x.permute(0, 2, 1)  # (B,2,T)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ================= 训练辅助 =================\n",
    "def compute_grad_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            total_norm += (p.grad.data.norm(2).item()) ** 2\n",
    "    return total_norm ** 0.5\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    if len(x) == 0:\n",
    "        return np.array([])\n",
    "    w = max(1, min(int(w), len(x)))\n",
    "    return np.convolve(x, np.ones(w), \"valid\") / w\n",
    "\n",
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel(\"Reference\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_curves(fold_results, save_folder):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i, res in enumerate(fold_results):\n",
    "        plt.plot(moving_average(res[\"train_loss\"]), label=f\"Fold{i+1} Train Loss\")\n",
    "        plt.plot(moving_average(res[\"val_loss\"]), label=f\"Fold{i+1} Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"训练与验证 Loss 曲线（滑动平均）\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, \"loss_curves.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_grad_norms(avg_grad_norms, save_folder):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(range(1, len(avg_grad_norms) + 1), avg_grad_norms)\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"平均梯度范数\")\n",
    "    plt.title(\"各 Fold 平均梯度范数\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, \"avg_grad_norms.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def write_split_report(file_ids, y_blocks, train_idx, val_idx, test_idx, label_to_idx, save_path):\n",
    "    inv_label = {v: k for k, v in label_to_idx.items()}\n",
    "    files = np.unique(file_ids)\n",
    "\n",
    "    def class_hist(idxs):\n",
    "        h = {}\n",
    "        for c in y_blocks[idxs]:\n",
    "            h[int(c)] = h.get(int(c), 0) + 1\n",
    "        return {inv_label[k]: h.get(k, 0) for k in sorted(inv_label.keys())}\n",
    "\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=== Split Report (block-level) ===\\n\")\n",
    "        f.write(f\"Total blocks: {len(file_ids)}\\n\")\n",
    "        f.write(f\"Train blocks: {len(train_idx)} | Val blocks: {len(val_idx)} | Test blocks: {len(test_idx)}\\n\\n\")\n",
    "\n",
    "        f.write(\"=== Class distribution (blocks) ===\\n\")\n",
    "        f.write(f\"Train: {class_hist(train_idx)}\\n\")\n",
    "        f.write(f\"Val  : {class_hist(val_idx)}\\n\")\n",
    "        f.write(f\"Test : {class_hist(test_idx)}\\n\\n\")\n",
    "\n",
    "        f.write(\"=== Per-file block counts ===\\n\")\n",
    "        f.write(\"file_id\\ttrain\\tval\\ttest\\ttotal\\ttrain%\\tval%\\ttest%\\n\")\n",
    "        for fid in files:\n",
    "            idx = np.where(file_ids == fid)[0]\n",
    "            total = len(idx)\n",
    "            tr = int(np.sum(np.isin(idx, train_idx)))\n",
    "            va = int(np.sum(np.isin(idx, val_idx)))\n",
    "            te = int(np.sum(np.isin(idx, test_idx)))\n",
    "            f.write(\n",
    "                f\"{fid}\\t{tr}\\t{va}\\t{te}\\t{total}\\t\"\n",
    "                f\"{(tr/total*100 if total else 0):.1f}\\t{(va/total*100 if total else 0):.1f}\\t{(te/total*100 if total else 0):.1f}\\n\"\n",
    "            )\n",
    "\n",
    "\n",
    "# ================= 训练集每 epoch 每 block 独立抽 K 行 =================\n",
    "def sample_rows_per_block_epoch(X_train_blocks, y_train_blocks, K, rng):\n",
    "    \"\"\"\n",
    "    X_train_blocks: (n_blocks, sample_len, group_size, 2)\n",
    "    y_train_blocks: (n_blocks,)\n",
    "    返回：\n",
    "      X_train: (n_blocks*K, group_size, 2)\n",
    "      y_train: (n_blocks*K,)\n",
    "    规则：每个 block 独立抽 K 行（不放回）；K>=sample_len 则取全行。\n",
    "    \"\"\"\n",
    "    n_blocks, sample_len, group_size_, ch = X_train_blocks.shape\n",
    "    if (K is None) or (K >= sample_len):\n",
    "        X_train = X_train_blocks.reshape(-1, group_size_, ch)\n",
    "        y_train = np.repeat(y_train_blocks, sample_len)\n",
    "        return X_train, y_train\n",
    "\n",
    "    # 为每个 block 生成不同的行索引（不放回）\n",
    "    # idx_mat: (n_blocks, K)\n",
    "    idx_mat = np.empty((n_blocks, K), dtype=np.int64)\n",
    "    for b in range(n_blocks):\n",
    "        idx_mat[b] = rng.choice(sample_len, size=K, replace=False)\n",
    "\n",
    "    # 高效 gather：先把 block 维和行维合并取样\n",
    "    # 使用 np.take_along_axis 需要对齐维度：\n",
    "    # X_train_blocks: (B, L, G, C)\n",
    "    # idx_mat -> (B, K, 1, 1) broadcast 到 (B, K, G, C)\n",
    "    gather_idx = idx_mat[:, :, None, None]\n",
    "    X_sel = np.take_along_axis(X_train_blocks, gather_idx, axis=1)  # (B, K, G, C)\n",
    "\n",
    "    X_train = X_sel.reshape(-1, group_size_, ch)  # (B*K, G, C)\n",
    "    y_train = np.repeat(y_train_blocks, K)\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "# ================= 单个 SNR 训练（含文件均衡切分） =================\n",
    "def train_for_snr(SNR_dB, save_folder, group_size_=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] 使用设备: {device}\")\n",
    "\n",
    "    # ---------- 1) 构造 blocks ----------\n",
    "    X_blocks, y_blocks, label_to_idx, file_ids, meta = load_and_preprocess_with_file_blocks(\n",
    "        data_path,\n",
    "        group_size_=group_size_,\n",
    "        apply_doppler_=apply_doppler,\n",
    "        target_velocity_kmh_=v_kmh,\n",
    "        apply_awgn_=apply_awgn,\n",
    "        snr_db_=SNR_dB,\n",
    "        fs_=fs,\n",
    "        fc_=fc,\n",
    "        expected_sample_len_=expected_sample_len,\n",
    "        align_mode_=align_mode,\n",
    "    )\n",
    "    num_blocks = X_blocks.shape[0]\n",
    "    num_classes = len(label_to_idx)\n",
    "    print(f\"[INFO] 总 block 数: {num_blocks}\")\n",
    "\n",
    "    # ---------- 2) 文件均衡 train/test ----------\n",
    "    train_idx, test_idx = filewise_train_test_split(file_ids, test_size_=test_size, seed_=seed)\n",
    "\n",
    "    # test set (展开为样本，全行)\n",
    "    X_test_blocks = X_blocks[test_idx]\n",
    "    y_test_blocks = y_blocks[test_idx]\n",
    "    X_test = X_test_blocks.reshape(-1, X_test_blocks.shape[2], X_test_blocks.shape[3])\n",
    "    y_test = np.repeat(y_test_blocks, X_test_blocks.shape[1])\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    # metrics.csv 记录每个 epoch\n",
    "    metrics_csv = os.path.join(save_folder, \"metrics.csv\")\n",
    "    with open(metrics_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"snr_db,fold,epoch,train_loss,train_acc,val_loss,val_acc,grad_norm,lr\\n\")\n",
    "\n",
    "    results_txt = os.path.join(save_folder, \"results.txt\")\n",
    "    with open(results_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=== 实验总结 ===\\n\")\n",
    "        f.write(f\"timestamp: {os.path.basename(save_folder)}\\n\")\n",
    "        f.write(f\"SNR_dB: {SNR_dB}\\n\")\n",
    "        f.write(f\"fs: {fs}\\n\")\n",
    "        f.write(f\"fc: {fc}\\n\")\n",
    "        f.write(f\"v_kmh: {v_kmh}\\n\")\n",
    "        f.write(f\"fd: {compute_doppler_shift(v_kmh, fc):.2f}\\n\")\n",
    "        f.write(f\"group_size: {group_size_}\\n\")\n",
    "        f.write(f\"expected_sample_len: {expected_sample_len}\\n\")\n",
    "        f.write(f\"align_mode: {align_mode}\\n\")\n",
    "        f.write(f\"train_rows_per_block(K): {train_rows_per_block}\\n\")\n",
    "        f.write(f\"num_blocks: {num_blocks}\\n\")\n",
    "        f.write(f\"num_classes: {num_classes}\\n\")\n",
    "        f.write(f\"label_to_idx: {label_to_idx}\\n\")\n",
    "        f.write(f\"meta: {meta}\\n\\n\")\n",
    "\n",
    "    print(f\"[INFO] Train blocks: {len(train_idx)} | Test blocks: {len(test_idx)}\")\n",
    "\n",
    "    # ---------- 3) 文件均衡 KFold ----------\n",
    "    fold_results = []\n",
    "    fold_test_accs = []\n",
    "    avg_grad_norms_per_fold = []\n",
    "\n",
    "    fold_generator = list(filewise_kfold_indices(train_idx, file_ids, n_splits_=n_splits, seed_=seed))\n",
    "\n",
    "    if len(fold_generator) > 0:\n",
    "        tr0, va0 = fold_generator[0]\n",
    "        write_split_report(\n",
    "            file_ids=file_ids,\n",
    "            y_blocks=y_blocks,\n",
    "            train_idx=tr0,\n",
    "            val_idx=va0,\n",
    "            test_idx=test_idx,\n",
    "            label_to_idx=label_to_idx,\n",
    "            save_path=os.path.join(save_folder, \"split_report_fold1.txt\"),\n",
    "        )\n",
    "\n",
    "    for fold, (tr_idx_fold, va_idx_fold) in enumerate(fold_generator):\n",
    "        print(f\"\\n====== Fold {fold+1}/{n_splits} ======\")\n",
    "\n",
    "        # 训练 blocks（epoch 内抽样）\n",
    "        X_train_blocks = X_blocks[tr_idx_fold]  # (Btr, L, G, 2)\n",
    "        y_train_blocks = y_blocks[tr_idx_fold]  # (Btr,)\n",
    "\n",
    "        # 验证 blocks（全行）\n",
    "        X_val_blocks = X_blocks[va_idx_fold]\n",
    "        y_val_blocks = y_blocks[va_idx_fold]\n",
    "        X_val = X_val_blocks.reshape(-1, X_val_blocks.shape[2], X_val_blocks.shape[3])\n",
    "        y_val = np.repeat(y_val_blocks, X_val_blocks.shape[1])\n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # 模型\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes_=in_planes, dropout_=dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        best_val_acc = -1.0\n",
    "        patience_counter = 0\n",
    "        best_model_wts = None\n",
    "\n",
    "        train_losses, val_losses, grad_norms = [], [], []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train, total_train = 0, 0\n",
    "            batch_grad_norms = []\n",
    "\n",
    "            # ===== 每个 epoch：每个 block 独立抽 K 行，构建本 epoch 训练集 =====\n",
    "            rng = np.random.default_rng(seed + 100000 * (fold + 1) + (epoch + 1))\n",
    "            X_train_ep, y_train_ep = sample_rows_per_block_epoch(\n",
    "                X_train_blocks, y_train_blocks, train_rows_per_block, rng\n",
    "            )\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                TensorDataset(torch.tensor(X_train_ep, dtype=torch.float32),\n",
    "                              torch.tensor(y_train_ep, dtype=torch.long)),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                gn = compute_grad_norm(model)\n",
    "                batch_grad_norms.append(gn)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, pred = torch.max(outputs, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (pred == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / max(1, len(train_loader))\n",
    "            train_acc = 100.0 * correct_train / max(1, total_train)\n",
    "            avg_gn = float(np.mean(batch_grad_norms)) if len(batch_grad_norms) else 0.0\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            grad_norms.append(avg_gn)\n",
    "\n",
    "            # 验证\n",
    "            model.eval()\n",
    "            running_val_loss = 0.0\n",
    "            correct_val, total_val = 0, 0\n",
    "            all_val_labels, all_val_preds = [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for vinputs, vlabels in val_loader:\n",
    "                    vinputs = vinputs.to(device)\n",
    "                    vlabels = vlabels.to(device)\n",
    "                    voutputs = model(vinputs)\n",
    "                    vloss = criterion(voutputs, vlabels)\n",
    "                    running_val_loss += vloss.item()\n",
    "                    _, vpred = torch.max(voutputs, 1)\n",
    "                    total_val += vlabels.size(0)\n",
    "                    correct_val += (vpred == vlabels).sum().item()\n",
    "                    all_val_labels.extend(vlabels.cpu().numpy())\n",
    "                    all_val_preds.extend(vpred.cpu().numpy())\n",
    "\n",
    "            val_loss = running_val_loss / max(1, len(val_loader))\n",
    "            val_acc = 100.0 * correct_val / max(1, total_val)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "            log_msg = (\n",
    "                f\"Fold {fold+1}, Epoch {epoch+1}: \"\n",
    "                f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
    "                f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%, \"\n",
    "                f\"Grad Norm={avg_gn:.4f}, LR={lr_now:.6g}\"\n",
    "            )\n",
    "            print(log_msg)\n",
    "\n",
    "            with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(log_msg + \"\\n\")\n",
    "\n",
    "            with open(metrics_csv, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{SNR_dB},{fold+1},{epoch+1},{train_loss:.6f},{train_acc:.4f},{val_loss:.6f},{val_acc:.4f},{avg_gn:.6f},{lr_now:.10f}\\n\")\n",
    "\n",
    "            # early stopping on val_acc\n",
    "            if val_acc > best_val_acc + 0.01:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                best_model_wts = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    msg = f\"早停：连续 {patience} 个 epoch 验证集未提升（best_val_acc={best_val_acc:.2f}%）\"\n",
    "                    print(msg)\n",
    "                    with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(msg + \"\\n\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # 评估与保存\n",
    "        if best_model_wts is None:\n",
    "            best_model_wts = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        model.load_state_dict(best_model_wts, strict=True)\n",
    "        model.to(device)\n",
    "\n",
    "        val_acc_final, val_cm_final = evaluate_model(model, val_loader, device, num_classes)\n",
    "        test_acc, test_cm = evaluate_model(model, test_loader, device, num_classes)\n",
    "\n",
    "        fold_test_accs.append(test_acc)\n",
    "        avg_grad_norms_per_fold.append(float(np.mean(grad_norms)) if len(grad_norms) else 0.0)\n",
    "\n",
    "        fold_results.append({\n",
    "            \"train_loss\": train_losses,\n",
    "            \"val_loss\": val_losses,\n",
    "            \"grad_norms\": grad_norms,\n",
    "        })\n",
    "\n",
    "        plot_confusion_matrix(val_cm_final, os.path.join(save_folder, f\"confusion_matrix_val_fold{fold+1}.png\"))\n",
    "        plot_confusion_matrix(test_cm, os.path.join(save_folder, f\"confusion_matrix_test_fold{fold+1}.png\"))\n",
    "        torch.save(best_model_wts, os.path.join(save_folder, f\"best_model_fold{fold+1}.pth\"))\n",
    "\n",
    "        msg2 = f\"Fold {fold+1} DONE | Best Val Acc≈{best_val_acc:.2f}% | Final Val Acc={val_acc_final:.2f}% | Test Acc={test_acc:.2f}%\"\n",
    "        print(msg2)\n",
    "        with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg2 + \"\\n\")\n",
    "\n",
    "    # 汇总\n",
    "    plot_training_curves(fold_results, save_folder)\n",
    "    plot_grad_norms(avg_grad_norms_per_fold, save_folder)\n",
    "\n",
    "    mean_test = float(np.mean(fold_test_accs)) if len(fold_test_accs) else 0.0\n",
    "    std_test = float(np.std(fold_test_accs)) if len(fold_test_accs) else 0.0\n",
    "    with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n=== Summary ===\\n\")\n",
    "        f.write(f\"Fold test accs: {fold_test_accs}\\n\")\n",
    "        f.write(f\"Mean test acc: {mean_test:.2f}% ± {std_test:.2f}%\\n\")\n",
    "\n",
    "    print(f\"[INFO] SNR={SNR_dB} dB | Mean Test Acc: {mean_test:.2f}% ± {std_test:.2f}%\")\n",
    "    return mean_test\n",
    "\n",
    "\n",
    "# ================= 主程序：SNR sweep（一个总文件夹 + 每 SNR 子文件夹） =================\n",
    "def main():\n",
    "    seed_everything(seed)\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    snr_list = list(range(20, -45, -5))  # 20, 15, ..., -40\n",
    "    snr_accs = []\n",
    "\n",
    "    sweep_ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    fd_int = int(compute_doppler_shift(v_kmh, fc))\n",
    "\n",
    "    # sweep 总文件夹\n",
    "    sweep_folder = os.path.join(\n",
    "        out_root,\n",
    "        f\"{sweep_ts}_LTE-V_XFR_FileBlockBalanced_fd{fd_int}_group{group_size}_ResNet_SNRsweep\"\n",
    "    )\n",
    "    os.makedirs(sweep_folder, exist_ok=True)\n",
    "\n",
    "    sweep_csv = os.path.join(sweep_folder, \"SNR_sweep_summary.csv\")\n",
    "    with open(sweep_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"snr_db,mean_test_acc\\n\")\n",
    "\n",
    "    for snr_db in snr_list:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"开始训练：SNR = {snr_db} dB\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        save_folder = os.path.join(sweep_folder, f\"SNR{snr_db}dB\")\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "        mean_test_acc = train_for_snr(snr_db, save_folder, group_size_=group_size)\n",
    "        snr_accs.append(mean_test_acc)\n",
    "\n",
    "        with open(sweep_csv, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{snr_db},{mean_test_acc:.6f}\\n\")\n",
    "\n",
    "        print(f\"[INFO] SNR {snr_db:>3} dB -> results: {save_folder}\")\n",
    "\n",
    "    # 总体曲线放在 sweep_folder\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(snr_list, snr_accs, marker=\"o\", linestyle=\"-\")\n",
    "    plt.xlabel(\"SNR (dB)\")\n",
    "    plt.ylabel(\"Mean Test Accuracy (%)\")\n",
    "    plt.title(\"SNR vs Test Accuracy (File-Block Balanced Split + Per-Block Row Sampling)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    curve_path = os.path.join(sweep_folder, \"SNR_vs_accuracy.png\")\n",
    "    plt.savefig(curve_path, dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[INFO] Sweep folder: {sweep_folder}\")\n",
    "    print(f\"[INFO] Sweep summary CSV: {sweep_csv}\")\n",
    "    print(f\"[INFO] SNR curve saved: {curve_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
