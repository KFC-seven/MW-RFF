{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46fbae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded file idx=0: dev0.mat, shape (after transpose): (7014, 320)\n",
      "Loaded file idx=1: dev1.mat, shape (after transpose): (6632, 320)\n",
      "Loaded file idx=2: dev10.mat, shape (after transpose): (8935, 320)\n",
      "Loaded file idx=3: dev11.mat, shape (after transpose): (7776, 320)\n",
      "Loaded file idx=4: dev13.mat, shape (after transpose): (7410, 320)\n",
      "Loaded file idx=5: dev14.mat, shape (after transpose): (6274, 320)\n",
      "Loaded file idx=6: dev15.mat, shape (after transpose): (5706, 320)\n",
      "Loaded file idx=7: dev16.mat, shape (after transpose): (12968, 320)\n",
      "Loaded file idx=8: dev17.mat, shape (after transpose): (9508, 320)\n",
      "Loaded file idx=9: dev18.mat, shape (after transpose): (3343, 320)\n",
      "Loaded file idx=10: dev19.mat, shape (after transpose): (4756, 320)\n",
      "Loaded file idx=11: dev2.mat, shape (after transpose): (6316, 320)\n",
      "Loaded file idx=12: dev20.mat, shape (after transpose): (5592, 320)\n",
      "Loaded file idx=13: dev3.mat, shape (after transpose): (5536, 320)\n",
      "Loaded file idx=14: dev4.mat, shape (after transpose): (6669, 320)\n",
      "Loaded file idx=15: dev5.mat, shape (after transpose): (5237, 320)\n",
      "Loaded file idx=16: dev6.mat, shape (after transpose): (5460, 320)\n",
      "Loaded file idx=17: dev7.mat, shape (after transpose): (8926, 320)\n",
      "Loaded file idx=18: dev8.mat, shape (after transpose): (7614, 320)\n",
      "Loaded file idx=19: dev9.mat, shape (after transpose): (7232, 320)\n",
      "Total data shape: (138904, 320), labels shape: (138904,)\n",
      "Num classes detected: 20\n",
      "Preprocessing (this may take some time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZY\\.conda\\envs\\MW-RFF\\lib\\site-packages\\pywt\\_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed features shape: torch.Size([138904, 1, 160])\n",
      "Train_val size: 111123, Test size: 27781\n",
      "Param search: mode=grid, total_trials=8. Results base: ./search_results\\2025-11-24_15-16-22_param_search_SNR20dB_fd266_classes_20\n",
      "\n",
      "=== Trial 1/8 | cfg: {'lr': 0.001, 'weight_decay': 1e-05, 'batch_size': 32, 'channels': 16, 'dropout': 0.0, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=65.69% | ValAcc=22.52% | TrainLoss=0.9816 | ValLoss=4.4320\n",
      "Epoch 2/200 | TrainAcc=82.68% | ValAcc=70.44% | TrainLoss=0.4878 | ValLoss=1.0474\n",
      "Epoch 3/200 | TrainAcc=85.21% | ValAcc=31.28% | TrainLoss=0.4079 | ValLoss=3.6358\n",
      "Epoch 4/200 | TrainAcc=86.48% | ValAcc=87.68% | TrainLoss=0.3724 | ValLoss=0.3388\n",
      "Epoch 5/200 | TrainAcc=87.65% | ValAcc=80.66% | TrainLoss=0.3397 | ValLoss=0.5197\n",
      "Epoch 6/200 | TrainAcc=88.61% | ValAcc=75.29% | TrainLoss=0.3189 | ValLoss=0.6357\n",
      "Epoch 7/200 | TrainAcc=89.08% | ValAcc=80.09% | TrainLoss=0.3003 | ValLoss=0.5618\n",
      "Epoch 8/200 | TrainAcc=89.88% | ValAcc=19.47% | TrainLoss=0.2829 | ValLoss=6.6711\n",
      "Epoch 9/200 | TrainAcc=90.36% | ValAcc=78.54% | TrainLoss=0.2685 | ValLoss=0.6929\n",
      "Epoch 10/200 | TrainAcc=90.79% | ValAcc=80.45% | TrainLoss=0.2557 | ValLoss=0.5492\n",
      "Epoch 11/200 | TrainAcc=91.25% | ValAcc=77.86% | TrainLoss=0.2460 | ValLoss=0.6143\n",
      "Epoch 12/200 | TrainAcc=91.54% | ValAcc=71.82% | TrainLoss=0.2376 | ValLoss=0.9317\n",
      "Epoch 13/200 | TrainAcc=91.81% | ValAcc=87.07% | TrainLoss=0.2282 | ValLoss=0.3471\n",
      "Epoch 14/200 | TrainAcc=92.06% | ValAcc=79.14% | TrainLoss=0.2219 | ValLoss=0.6530\n",
      "Early stopping.\n",
      "Trial 1 done. BestValAcc=87.68 | TestAcc=87.49\n",
      "\n",
      "=== Trial 2/8 | cfg: {'lr': 0.0003, 'weight_decay': 1e-05, 'batch_size': 64, 'channels': 16, 'dropout': 0.1, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=33.68% | ValAcc=54.73% | TrainLoss=1.8909 | ValLoss=1.2286\n",
      "Epoch 2/200 | TrainAcc=58.43% | ValAcc=62.82% | TrainLoss=1.1281 | ValLoss=1.0005\n",
      "Epoch 3/200 | TrainAcc=66.71% | ValAcc=70.47% | TrainLoss=0.9189 | ValLoss=0.8024\n",
      "Epoch 4/200 | TrainAcc=71.24% | ValAcc=76.94% | TrainLoss=0.7999 | ValLoss=0.6760\n",
      "Epoch 5/200 | TrainAcc=73.80% | ValAcc=75.49% | TrainLoss=0.7205 | ValLoss=0.6514\n",
      "Epoch 6/200 | TrainAcc=75.82% | ValAcc=76.55% | TrainLoss=0.6635 | ValLoss=0.6140\n",
      "Epoch 7/200 | TrainAcc=77.23% | ValAcc=81.88% | TrainLoss=0.6221 | ValLoss=0.5177\n",
      "Epoch 8/200 | TrainAcc=78.27% | ValAcc=81.81% | TrainLoss=0.5907 | ValLoss=0.4947\n",
      "Epoch 9/200 | TrainAcc=78.94% | ValAcc=78.20% | TrainLoss=0.5684 | ValLoss=0.5668\n",
      "Epoch 10/200 | TrainAcc=79.86% | ValAcc=83.42% | TrainLoss=0.5438 | ValLoss=0.4558\n",
      "Epoch 11/200 | TrainAcc=80.53% | ValAcc=84.27% | TrainLoss=0.5256 | ValLoss=0.4321\n",
      "Epoch 12/200 | TrainAcc=80.98% | ValAcc=80.05% | TrainLoss=0.5136 | ValLoss=0.5286\n",
      "Epoch 13/200 | TrainAcc=81.44% | ValAcc=82.30% | TrainLoss=0.5039 | ValLoss=0.4697\n",
      "Epoch 14/200 | TrainAcc=81.68% | ValAcc=84.91% | TrainLoss=0.4946 | ValLoss=0.4117\n",
      "Epoch 15/200 | TrainAcc=82.21% | ValAcc=86.12% | TrainLoss=0.4776 | ValLoss=0.3793\n",
      "Epoch 16/200 | TrainAcc=82.57% | ValAcc=79.35% | TrainLoss=0.4680 | ValLoss=0.5421\n",
      "Epoch 17/200 | TrainAcc=82.86% | ValAcc=86.33% | TrainLoss=0.4593 | ValLoss=0.3779\n",
      "Epoch 18/200 | TrainAcc=83.07% | ValAcc=87.56% | TrainLoss=0.4547 | ValLoss=0.3481\n",
      "Epoch 19/200 | TrainAcc=83.22% | ValAcc=87.77% | TrainLoss=0.4473 | ValLoss=0.3415\n",
      "Epoch 20/200 | TrainAcc=83.79% | ValAcc=86.30% | TrainLoss=0.4391 | ValLoss=0.3721\n",
      "Epoch 21/200 | TrainAcc=83.75% | ValAcc=88.34% | TrainLoss=0.4347 | ValLoss=0.3231\n",
      "Epoch 22/200 | TrainAcc=84.29% | ValAcc=86.70% | TrainLoss=0.4241 | ValLoss=0.3585\n",
      "Epoch 23/200 | TrainAcc=84.29% | ValAcc=85.86% | TrainLoss=0.4223 | ValLoss=0.3780\n",
      "Epoch 24/200 | TrainAcc=84.40% | ValAcc=88.61% | TrainLoss=0.4181 | ValLoss=0.3144\n",
      "Epoch 25/200 | TrainAcc=84.74% | ValAcc=87.46% | TrainLoss=0.4133 | ValLoss=0.3427\n",
      "Epoch 26/200 | TrainAcc=84.92% | ValAcc=85.42% | TrainLoss=0.4057 | ValLoss=0.3884\n",
      "Epoch 27/200 | TrainAcc=85.22% | ValAcc=86.87% | TrainLoss=0.3994 | ValLoss=0.3530\n",
      "Epoch 28/200 | TrainAcc=85.24% | ValAcc=85.23% | TrainLoss=0.3986 | ValLoss=0.3950\n",
      "Epoch 29/200 | TrainAcc=85.39% | ValAcc=89.85% | TrainLoss=0.3926 | ValLoss=0.2897\n",
      "Epoch 30/200 | TrainAcc=85.60% | ValAcc=89.24% | TrainLoss=0.3899 | ValLoss=0.2974\n",
      "Epoch 31/200 | TrainAcc=86.27% | ValAcc=89.83% | TrainLoss=0.3710 | ValLoss=0.2815\n",
      "Epoch 32/200 | TrainAcc=86.21% | ValAcc=90.46% | TrainLoss=0.3727 | ValLoss=0.2706\n",
      "Epoch 33/200 | TrainAcc=86.23% | ValAcc=89.34% | TrainLoss=0.3712 | ValLoss=0.2917\n",
      "Epoch 34/200 | TrainAcc=86.45% | ValAcc=89.90% | TrainLoss=0.3692 | ValLoss=0.2824\n",
      "Epoch 35/200 | TrainAcc=86.34% | ValAcc=90.35% | TrainLoss=0.3678 | ValLoss=0.2751\n",
      "Epoch 36/200 | TrainAcc=86.49% | ValAcc=90.32% | TrainLoss=0.3663 | ValLoss=0.2706\n",
      "Epoch 37/200 | TrainAcc=86.59% | ValAcc=89.87% | TrainLoss=0.3625 | ValLoss=0.2839\n",
      "Epoch 38/200 | TrainAcc=86.64% | ValAcc=90.41% | TrainLoss=0.3651 | ValLoss=0.2691\n",
      "Epoch 39/200 | TrainAcc=86.80% | ValAcc=89.35% | TrainLoss=0.3608 | ValLoss=0.2935\n",
      "Epoch 40/200 | TrainAcc=86.73% | ValAcc=90.54% | TrainLoss=0.3578 | ValLoss=0.2657\n",
      "Epoch 41/200 | TrainAcc=87.03% | ValAcc=89.93% | TrainLoss=0.3565 | ValLoss=0.2739\n",
      "Epoch 42/200 | TrainAcc=86.91% | ValAcc=90.79% | TrainLoss=0.3579 | ValLoss=0.2621\n",
      "Epoch 43/200 | TrainAcc=87.01% | ValAcc=89.58% | TrainLoss=0.3575 | ValLoss=0.2906\n",
      "Epoch 44/200 | TrainAcc=87.20% | ValAcc=90.32% | TrainLoss=0.3512 | ValLoss=0.2709\n",
      "Epoch 45/200 | TrainAcc=87.06% | ValAcc=90.47% | TrainLoss=0.3498 | ValLoss=0.2694\n",
      "Epoch 46/200 | TrainAcc=87.12% | ValAcc=90.46% | TrainLoss=0.3490 | ValLoss=0.2677\n",
      "Epoch 47/200 | TrainAcc=87.20% | ValAcc=90.83% | TrainLoss=0.3462 | ValLoss=0.2587\n",
      "Epoch 48/200 | TrainAcc=87.05% | ValAcc=89.89% | TrainLoss=0.3498 | ValLoss=0.2786\n",
      "Epoch 49/200 | TrainAcc=87.29% | ValAcc=86.54% | TrainLoss=0.3463 | ValLoss=0.3500\n",
      "Epoch 50/200 | TrainAcc=87.34% | ValAcc=91.06% | TrainLoss=0.3430 | ValLoss=0.2557\n",
      "Epoch 51/200 | TrainAcc=87.33% | ValAcc=90.33% | TrainLoss=0.3424 | ValLoss=0.2726\n",
      "Epoch 52/200 | TrainAcc=87.51% | ValAcc=90.95% | TrainLoss=0.3388 | ValLoss=0.2556\n",
      "Epoch 53/200 | TrainAcc=87.57% | ValAcc=91.37% | TrainLoss=0.3367 | ValLoss=0.2441\n",
      "Epoch 54/200 | TrainAcc=87.64% | ValAcc=90.80% | TrainLoss=0.3377 | ValLoss=0.2596\n",
      "Epoch 55/200 | TrainAcc=87.74% | ValAcc=90.01% | TrainLoss=0.3388 | ValLoss=0.2786\n",
      "Epoch 56/200 | TrainAcc=87.65% | ValAcc=91.24% | TrainLoss=0.3368 | ValLoss=0.2459\n",
      "Epoch 57/200 | TrainAcc=87.70% | ValAcc=91.15% | TrainLoss=0.3361 | ValLoss=0.2540\n",
      "Epoch 58/200 | TrainAcc=87.73% | ValAcc=90.53% | TrainLoss=0.3337 | ValLoss=0.2625\n",
      "Epoch 59/200 | TrainAcc=87.70% | ValAcc=91.42% | TrainLoss=0.3307 | ValLoss=0.2404\n",
      "Epoch 60/200 | TrainAcc=87.91% | ValAcc=91.32% | TrainLoss=0.3326 | ValLoss=0.2511\n",
      "Epoch 61/200 | TrainAcc=88.13% | ValAcc=91.93% | TrainLoss=0.3247 | ValLoss=0.2306\n",
      "Epoch 62/200 | TrainAcc=88.04% | ValAcc=91.16% | TrainLoss=0.3234 | ValLoss=0.2456\n",
      "Epoch 63/200 | TrainAcc=88.20% | ValAcc=92.03% | TrainLoss=0.3234 | ValLoss=0.2288\n",
      "Epoch 64/200 | TrainAcc=88.14% | ValAcc=91.70% | TrainLoss=0.3253 | ValLoss=0.2375\n",
      "Epoch 65/200 | TrainAcc=88.09% | ValAcc=91.47% | TrainLoss=0.3226 | ValLoss=0.2381\n",
      "Epoch 66/200 | TrainAcc=88.21% | ValAcc=91.79% | TrainLoss=0.3221 | ValLoss=0.2332\n",
      "Epoch 67/200 | TrainAcc=88.16% | ValAcc=91.78% | TrainLoss=0.3187 | ValLoss=0.2359\n",
      "Epoch 68/200 | TrainAcc=88.31% | ValAcc=91.79% | TrainLoss=0.3183 | ValLoss=0.2393\n",
      "Epoch 69/200 | TrainAcc=88.37% | ValAcc=91.75% | TrainLoss=0.3186 | ValLoss=0.2358\n",
      "Epoch 70/200 | TrainAcc=88.48% | ValAcc=91.53% | TrainLoss=0.3160 | ValLoss=0.2366\n",
      "Epoch 71/200 | TrainAcc=88.29% | ValAcc=91.94% | TrainLoss=0.3183 | ValLoss=0.2334\n",
      "Early stopping.\n",
      "Trial 2 done. BestValAcc=91.93 | TestAcc=91.72\n",
      "\n",
      "=== Trial 3/8 | cfg: {'lr': 0.0003, 'weight_decay': 0.0001, 'batch_size': 64, 'channels': 32, 'dropout': 0.0, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=64.48% | ValAcc=53.71% | TrainLoss=1.1347 | ValLoss=1.4334\n",
      "Epoch 2/200 | TrainAcc=84.43% | ValAcc=70.86% | TrainLoss=0.4828 | ValLoss=0.7936\n",
      "Epoch 3/200 | TrainAcc=87.68% | ValAcc=39.36% | TrainLoss=0.3628 | ValLoss=3.1026\n",
      "Epoch 4/200 | TrainAcc=89.16% | ValAcc=61.12% | TrainLoss=0.3108 | ValLoss=1.2707\n",
      "Epoch 5/200 | TrainAcc=90.76% | ValAcc=57.32% | TrainLoss=0.2720 | ValLoss=1.4581\n",
      "Epoch 6/200 | TrainAcc=91.57% | ValAcc=37.89% | TrainLoss=0.2427 | ValLoss=3.1382\n",
      "Epoch 7/200 | TrainAcc=92.47% | ValAcc=73.39% | TrainLoss=0.2207 | ValLoss=0.9072\n",
      "Epoch 8/200 | TrainAcc=93.08% | ValAcc=52.67% | TrainLoss=0.2055 | ValLoss=2.2405\n",
      "Epoch 9/200 | TrainAcc=93.50% | ValAcc=48.40% | TrainLoss=0.1948 | ValLoss=2.8628\n",
      "Epoch 10/200 | TrainAcc=93.80% | ValAcc=56.43% | TrainLoss=0.1851 | ValLoss=1.9825\n",
      "Epoch 11/200 | TrainAcc=94.19% | ValAcc=81.59% | TrainLoss=0.1724 | ValLoss=0.5270\n",
      "Epoch 12/200 | TrainAcc=94.26% | ValAcc=50.35% | TrainLoss=0.1670 | ValLoss=2.2444\n",
      "Epoch 13/200 | TrainAcc=94.71% | ValAcc=36.90% | TrainLoss=0.1581 | ValLoss=4.4309\n",
      "Epoch 14/200 | TrainAcc=94.80% | ValAcc=76.65% | TrainLoss=0.1526 | ValLoss=0.7450\n",
      "Epoch 15/200 | TrainAcc=95.06% | ValAcc=80.43% | TrainLoss=0.1452 | ValLoss=0.6153\n",
      "Epoch 16/200 | TrainAcc=95.14% | ValAcc=58.96% | TrainLoss=0.1423 | ValLoss=1.6845\n",
      "Epoch 17/200 | TrainAcc=95.28% | ValAcc=37.01% | TrainLoss=0.1389 | ValLoss=5.5542\n",
      "Epoch 18/200 | TrainAcc=95.23% | ValAcc=59.42% | TrainLoss=0.1382 | ValLoss=1.7057\n",
      "Epoch 19/200 | TrainAcc=95.58% | ValAcc=74.85% | TrainLoss=0.1296 | ValLoss=0.8857\n",
      "Epoch 20/200 | TrainAcc=95.66% | ValAcc=53.32% | TrainLoss=0.1280 | ValLoss=1.9988\n",
      "Epoch 21/200 | TrainAcc=95.79% | ValAcc=22.24% | TrainLoss=0.1224 | ValLoss=8.2883\n",
      "Early stopping.\n",
      "Trial 3 done. BestValAcc=81.59 | TestAcc=82.08\n",
      "\n",
      "=== Trial 4/8 | cfg: {'lr': 0.001, 'weight_decay': 0.0001, 'batch_size': 32, 'channels': 32, 'dropout': 0.5, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=55.85% | ValAcc=73.74% | TrainLoss=1.2020 | ValLoss=0.6773\n",
      "Epoch 2/200 | TrainAcc=73.51% | ValAcc=79.66% | TrainLoss=0.6997 | ValLoss=0.5429\n",
      "Epoch 3/200 | TrainAcc=76.99% | ValAcc=81.79% | TrainLoss=0.6053 | ValLoss=0.4997\n",
      "Epoch 4/200 | TrainAcc=78.67% | ValAcc=83.06% | TrainLoss=0.5616 | ValLoss=0.4551\n",
      "Epoch 5/200 | TrainAcc=79.96% | ValAcc=84.77% | TrainLoss=0.5301 | ValLoss=0.4013\n",
      "Epoch 6/200 | TrainAcc=80.91% | ValAcc=86.87% | TrainLoss=0.5046 | ValLoss=0.3566\n",
      "Epoch 7/200 | TrainAcc=81.58% | ValAcc=80.62% | TrainLoss=0.4867 | ValLoss=0.4818\n",
      "Epoch 8/200 | TrainAcc=82.21% | ValAcc=85.80% | TrainLoss=0.4716 | ValLoss=0.3765\n",
      "Epoch 9/200 | TrainAcc=82.61% | ValAcc=88.55% | TrainLoss=0.4615 | ValLoss=0.3152\n",
      "Epoch 10/200 | TrainAcc=83.19% | ValAcc=83.43% | TrainLoss=0.4521 | ValLoss=0.4183\n",
      "Epoch 11/200 | TrainAcc=83.19% | ValAcc=84.35% | TrainLoss=0.4452 | ValLoss=0.4002\n",
      "Epoch 12/200 | TrainAcc=83.68% | ValAcc=84.10% | TrainLoss=0.4356 | ValLoss=0.4172\n",
      "Epoch 13/200 | TrainAcc=83.77% | ValAcc=89.20% | TrainLoss=0.4320 | ValLoss=0.3060\n",
      "Epoch 14/200 | TrainAcc=83.95% | ValAcc=86.29% | TrainLoss=0.4290 | ValLoss=0.3769\n",
      "Epoch 15/200 | TrainAcc=84.28% | ValAcc=88.05% | TrainLoss=0.4207 | ValLoss=0.3259\n",
      "Epoch 16/200 | TrainAcc=84.32% | ValAcc=89.53% | TrainLoss=0.4178 | ValLoss=0.2955\n",
      "Epoch 17/200 | TrainAcc=84.35% | ValAcc=89.15% | TrainLoss=0.4172 | ValLoss=0.2882\n",
      "Epoch 18/200 | TrainAcc=84.74% | ValAcc=89.30% | TrainLoss=0.4086 | ValLoss=0.3001\n",
      "Epoch 19/200 | TrainAcc=84.84% | ValAcc=87.62% | TrainLoss=0.4064 | ValLoss=0.3313\n",
      "Epoch 20/200 | TrainAcc=84.70% | ValAcc=90.64% | TrainLoss=0.4066 | ValLoss=0.2635\n",
      "Epoch 21/200 | TrainAcc=84.77% | ValAcc=88.56% | TrainLoss=0.4053 | ValLoss=0.3011\n",
      "Epoch 22/200 | TrainAcc=85.03% | ValAcc=90.40% | TrainLoss=0.4000 | ValLoss=0.2702\n",
      "Epoch 23/200 | TrainAcc=85.25% | ValAcc=88.41% | TrainLoss=0.3961 | ValLoss=0.3212\n",
      "Epoch 24/200 | TrainAcc=85.26% | ValAcc=91.24% | TrainLoss=0.3951 | ValLoss=0.2524\n",
      "Epoch 25/200 | TrainAcc=85.50% | ValAcc=91.49% | TrainLoss=0.3894 | ValLoss=0.2421\n",
      "Epoch 26/200 | TrainAcc=85.44% | ValAcc=89.50% | TrainLoss=0.3886 | ValLoss=0.2869\n",
      "Epoch 27/200 | TrainAcc=85.40% | ValAcc=89.76% | TrainLoss=0.3912 | ValLoss=0.2845\n",
      "Epoch 28/200 | TrainAcc=85.57% | ValAcc=89.94% | TrainLoss=0.3876 | ValLoss=0.2738\n",
      "Epoch 29/200 | TrainAcc=85.60% | ValAcc=87.78% | TrainLoss=0.3879 | ValLoss=0.3194\n",
      "Epoch 30/200 | TrainAcc=85.52% | ValAcc=91.66% | TrainLoss=0.3887 | ValLoss=0.2416\n",
      "Epoch 31/200 | TrainAcc=86.69% | ValAcc=91.68% | TrainLoss=0.3585 | ValLoss=0.2404\n",
      "Epoch 32/200 | TrainAcc=86.93% | ValAcc=91.87% | TrainLoss=0.3522 | ValLoss=0.2326\n",
      "Epoch 33/200 | TrainAcc=86.87% | ValAcc=89.84% | TrainLoss=0.3527 | ValLoss=0.2741\n",
      "Epoch 34/200 | TrainAcc=86.87% | ValAcc=90.59% | TrainLoss=0.3505 | ValLoss=0.2547\n",
      "Epoch 35/200 | TrainAcc=86.88% | ValAcc=92.13% | TrainLoss=0.3535 | ValLoss=0.2256\n",
      "Epoch 36/200 | TrainAcc=87.18% | ValAcc=91.97% | TrainLoss=0.3474 | ValLoss=0.2232\n",
      "Epoch 37/200 | TrainAcc=86.99% | ValAcc=91.47% | TrainLoss=0.3493 | ValLoss=0.2408\n",
      "Epoch 38/200 | TrainAcc=87.10% | ValAcc=91.96% | TrainLoss=0.3465 | ValLoss=0.2272\n",
      "Epoch 39/200 | TrainAcc=86.97% | ValAcc=91.16% | TrainLoss=0.3489 | ValLoss=0.2458\n",
      "Epoch 40/200 | TrainAcc=87.19% | ValAcc=91.12% | TrainLoss=0.3459 | ValLoss=0.2454\n",
      "Epoch 41/200 | TrainAcc=87.00% | ValAcc=91.65% | TrainLoss=0.3479 | ValLoss=0.2333\n",
      "Epoch 42/200 | TrainAcc=87.02% | ValAcc=92.22% | TrainLoss=0.3467 | ValLoss=0.2215\n",
      "Epoch 43/200 | TrainAcc=87.06% | ValAcc=90.00% | TrainLoss=0.3448 | ValLoss=0.2668\n",
      "Epoch 44/200 | TrainAcc=87.13% | ValAcc=90.30% | TrainLoss=0.3466 | ValLoss=0.2559\n",
      "Epoch 45/200 | TrainAcc=87.23% | ValAcc=91.80% | TrainLoss=0.3455 | ValLoss=0.2257\n",
      "Early stopping.\n",
      "Trial 4 done. BestValAcc=92.13 | TestAcc=91.82\n",
      "\n",
      "=== Trial 5/8 | cfg: {'lr': 0.001, 'weight_decay': 1e-05, 'batch_size': 32, 'channels': 16, 'dropout': 0.1, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=56.68% | ValAcc=74.96% | TrainLoss=1.1818 | ValLoss=0.6852\n",
      "Epoch 2/200 | TrainAcc=74.91% | ValAcc=69.53% | TrainLoss=0.6745 | ValLoss=0.7522\n",
      "Epoch 3/200 | TrainAcc=78.55% | ValAcc=75.44% | TrainLoss=0.5725 | ValLoss=0.6420\n",
      "Epoch 4/200 | TrainAcc=80.22% | ValAcc=80.69% | TrainLoss=0.5259 | ValLoss=0.4979\n",
      "Epoch 5/200 | TrainAcc=81.43% | ValAcc=83.91% | TrainLoss=0.4928 | ValLoss=0.4284\n",
      "Epoch 6/200 | TrainAcc=82.52% | ValAcc=85.29% | TrainLoss=0.4682 | ValLoss=0.3916\n",
      "Epoch 7/200 | TrainAcc=83.02% | ValAcc=85.68% | TrainLoss=0.4538 | ValLoss=0.3807\n",
      "Epoch 8/200 | TrainAcc=83.69% | ValAcc=87.93% | TrainLoss=0.4296 | ValLoss=0.3304\n",
      "Epoch 9/200 | TrainAcc=84.34% | ValAcc=88.00% | TrainLoss=0.4184 | ValLoss=0.3302\n",
      "Epoch 10/200 | TrainAcc=84.85% | ValAcc=86.25% | TrainLoss=0.4061 | ValLoss=0.3616\n",
      "Epoch 11/200 | TrainAcc=85.16% | ValAcc=88.36% | TrainLoss=0.3998 | ValLoss=0.3144\n",
      "Epoch 12/200 | TrainAcc=85.48% | ValAcc=87.52% | TrainLoss=0.3864 | ValLoss=0.3424\n",
      "Epoch 13/200 | TrainAcc=85.65% | ValAcc=83.64% | TrainLoss=0.3831 | ValLoss=0.4148\n",
      "Epoch 14/200 | TrainAcc=86.08% | ValAcc=88.44% | TrainLoss=0.3738 | ValLoss=0.2991\n",
      "Epoch 15/200 | TrainAcc=86.08% | ValAcc=87.28% | TrainLoss=0.3722 | ValLoss=0.3386\n",
      "Epoch 16/200 | TrainAcc=86.45% | ValAcc=89.28% | TrainLoss=0.3656 | ValLoss=0.2888\n",
      "Epoch 17/200 | TrainAcc=86.65% | ValAcc=87.82% | TrainLoss=0.3556 | ValLoss=0.3240\n",
      "Epoch 18/200 | TrainAcc=86.85% | ValAcc=87.32% | TrainLoss=0.3534 | ValLoss=0.3309\n",
      "Epoch 19/200 | TrainAcc=87.11% | ValAcc=91.24% | TrainLoss=0.3486 | ValLoss=0.2474\n",
      "Epoch 20/200 | TrainAcc=87.17% | ValAcc=89.82% | TrainLoss=0.3449 | ValLoss=0.2686\n",
      "Epoch 21/200 | TrainAcc=87.41% | ValAcc=90.98% | TrainLoss=0.3396 | ValLoss=0.2509\n",
      "Epoch 22/200 | TrainAcc=87.55% | ValAcc=90.06% | TrainLoss=0.3358 | ValLoss=0.2621\n",
      "Epoch 23/200 | TrainAcc=87.58% | ValAcc=91.34% | TrainLoss=0.3323 | ValLoss=0.2416\n",
      "Epoch 24/200 | TrainAcc=87.84% | ValAcc=90.25% | TrainLoss=0.3281 | ValLoss=0.2581\n",
      "Epoch 25/200 | TrainAcc=87.94% | ValAcc=90.68% | TrainLoss=0.3259 | ValLoss=0.2624\n",
      "Epoch 26/200 | TrainAcc=88.06% | ValAcc=90.90% | TrainLoss=0.3207 | ValLoss=0.2480\n",
      "Epoch 27/200 | TrainAcc=88.05% | ValAcc=91.49% | TrainLoss=0.3215 | ValLoss=0.2323\n",
      "Epoch 28/200 | TrainAcc=88.28% | ValAcc=91.04% | TrainLoss=0.3184 | ValLoss=0.2474\n",
      "Epoch 29/200 | TrainAcc=88.40% | ValAcc=91.57% | TrainLoss=0.3152 | ValLoss=0.2350\n",
      "Epoch 30/200 | TrainAcc=88.45% | ValAcc=91.25% | TrainLoss=0.3110 | ValLoss=0.2419\n",
      "Epoch 31/200 | TrainAcc=89.16% | ValAcc=92.14% | TrainLoss=0.2941 | ValLoss=0.2214\n",
      "Epoch 32/200 | TrainAcc=89.34% | ValAcc=92.76% | TrainLoss=0.2866 | ValLoss=0.1999\n",
      "Epoch 33/200 | TrainAcc=89.48% | ValAcc=92.89% | TrainLoss=0.2851 | ValLoss=0.1989\n",
      "Epoch 34/200 | TrainAcc=89.52% | ValAcc=93.13% | TrainLoss=0.2847 | ValLoss=0.1960\n",
      "Epoch 35/200 | TrainAcc=89.40% | ValAcc=92.84% | TrainLoss=0.2852 | ValLoss=0.1976\n",
      "Epoch 36/200 | TrainAcc=89.47% | ValAcc=92.79% | TrainLoss=0.2835 | ValLoss=0.2001\n",
      "Epoch 37/200 | TrainAcc=89.63% | ValAcc=93.09% | TrainLoss=0.2812 | ValLoss=0.1978\n",
      "Epoch 38/200 | TrainAcc=89.69% | ValAcc=93.17% | TrainLoss=0.2798 | ValLoss=0.1968\n",
      "Epoch 39/200 | TrainAcc=89.73% | ValAcc=93.23% | TrainLoss=0.2794 | ValLoss=0.1933\n",
      "Epoch 40/200 | TrainAcc=89.85% | ValAcc=92.62% | TrainLoss=0.2778 | ValLoss=0.2049\n",
      "Epoch 41/200 | TrainAcc=89.65% | ValAcc=93.17% | TrainLoss=0.2787 | ValLoss=0.1956\n",
      "Epoch 42/200 | TrainAcc=89.81% | ValAcc=93.05% | TrainLoss=0.2763 | ValLoss=0.1992\n",
      "Epoch 43/200 | TrainAcc=89.82% | ValAcc=93.30% | TrainLoss=0.2761 | ValLoss=0.1909\n",
      "Epoch 44/200 | TrainAcc=89.96% | ValAcc=93.06% | TrainLoss=0.2729 | ValLoss=0.1975\n",
      "Epoch 45/200 | TrainAcc=89.85% | ValAcc=92.85% | TrainLoss=0.2717 | ValLoss=0.2019\n",
      "Epoch 46/200 | TrainAcc=89.94% | ValAcc=92.95% | TrainLoss=0.2727 | ValLoss=0.1943\n",
      "Epoch 47/200 | TrainAcc=89.92% | ValAcc=93.31% | TrainLoss=0.2762 | ValLoss=0.1916\n",
      "Epoch 48/200 | TrainAcc=90.01% | ValAcc=93.07% | TrainLoss=0.2721 | ValLoss=0.1960\n",
      "Epoch 49/200 | TrainAcc=90.11% | ValAcc=92.94% | TrainLoss=0.2703 | ValLoss=0.1948\n",
      "Early stopping.\n",
      "Trial 5 done. BestValAcc=93.23 | TestAcc=93.44\n",
      "\n",
      "=== Trial 6/8 | cfg: {'lr': 0.0003, 'weight_decay': 0.0001, 'batch_size': 64, 'channels': 16, 'dropout': 0.5, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=22.23% | ValAcc=41.82% | TrainLoss=2.2734 | ValLoss=1.6587\n",
      "Epoch 2/200 | TrainAcc=42.84% | ValAcc=50.39% | TrainLoss=1.5089 | ValLoss=1.2926\n",
      "Epoch 3/200 | TrainAcc=53.30% | ValAcc=58.11% | TrainLoss=1.2232 | ValLoss=1.0624\n",
      "Epoch 4/200 | TrainAcc=58.05% | ValAcc=65.80% | TrainLoss=1.0892 | ValLoss=0.9146\n",
      "Epoch 5/200 | TrainAcc=61.04% | ValAcc=63.80% | TrainLoss=1.0117 | ValLoss=0.8972\n",
      "Epoch 6/200 | TrainAcc=62.84% | ValAcc=60.76% | TrainLoss=0.9566 | ValLoss=0.9385\n",
      "Epoch 7/200 | TrainAcc=64.43% | ValAcc=71.01% | TrainLoss=0.9192 | ValLoss=0.7654\n",
      "Epoch 8/200 | TrainAcc=65.79% | ValAcc=69.34% | TrainLoss=0.8863 | ValLoss=0.7712\n",
      "Epoch 9/200 | TrainAcc=66.92% | ValAcc=67.62% | TrainLoss=0.8572 | ValLoss=0.8274\n",
      "Epoch 10/200 | TrainAcc=67.93% | ValAcc=70.66% | TrainLoss=0.8390 | ValLoss=0.7384\n",
      "Epoch 11/200 | TrainAcc=69.05% | ValAcc=71.96% | TrainLoss=0.8143 | ValLoss=0.7152\n",
      "Epoch 12/200 | TrainAcc=69.39% | ValAcc=75.31% | TrainLoss=0.7986 | ValLoss=0.6621\n",
      "Epoch 13/200 | TrainAcc=70.36% | ValAcc=72.07% | TrainLoss=0.7810 | ValLoss=0.7032\n",
      "Epoch 14/200 | TrainAcc=70.42% | ValAcc=73.21% | TrainLoss=0.7723 | ValLoss=0.6827\n",
      "Epoch 15/200 | TrainAcc=71.28% | ValAcc=72.83% | TrainLoss=0.7578 | ValLoss=0.6884\n",
      "Epoch 16/200 | TrainAcc=71.61% | ValAcc=71.24% | TrainLoss=0.7455 | ValLoss=0.7107\n",
      "Epoch 17/200 | TrainAcc=72.02% | ValAcc=71.24% | TrainLoss=0.7362 | ValLoss=0.7136\n",
      "Epoch 18/200 | TrainAcc=72.30% | ValAcc=73.29% | TrainLoss=0.7280 | ValLoss=0.6706\n",
      "Epoch 19/200 | TrainAcc=72.64% | ValAcc=76.39% | TrainLoss=0.7198 | ValLoss=0.6309\n",
      "Epoch 20/200 | TrainAcc=72.86% | ValAcc=74.04% | TrainLoss=0.7143 | ValLoss=0.6608\n",
      "Epoch 21/200 | TrainAcc=73.14% | ValAcc=75.78% | TrainLoss=0.7060 | ValLoss=0.6313\n",
      "Epoch 22/200 | TrainAcc=73.21% | ValAcc=79.40% | TrainLoss=0.6989 | ValLoss=0.5725\n",
      "Epoch 23/200 | TrainAcc=73.40% | ValAcc=80.26% | TrainLoss=0.6919 | ValLoss=0.5642\n",
      "Epoch 24/200 | TrainAcc=73.86% | ValAcc=75.65% | TrainLoss=0.6880 | ValLoss=0.6420\n",
      "Epoch 25/200 | TrainAcc=73.84% | ValAcc=78.16% | TrainLoss=0.6886 | ValLoss=0.5792\n",
      "Epoch 26/200 | TrainAcc=73.87% | ValAcc=79.81% | TrainLoss=0.6839 | ValLoss=0.5552\n",
      "Epoch 27/200 | TrainAcc=74.16% | ValAcc=77.16% | TrainLoss=0.6793 | ValLoss=0.6220\n",
      "Epoch 28/200 | TrainAcc=74.52% | ValAcc=76.03% | TrainLoss=0.6729 | ValLoss=0.6350\n",
      "Epoch 29/200 | TrainAcc=74.45% | ValAcc=80.08% | TrainLoss=0.6739 | ValLoss=0.5651\n",
      "Epoch 30/200 | TrainAcc=74.41% | ValAcc=81.41% | TrainLoss=0.6705 | ValLoss=0.5236\n",
      "Epoch 31/200 | TrainAcc=74.99% | ValAcc=78.45% | TrainLoss=0.6562 | ValLoss=0.5884\n",
      "Epoch 32/200 | TrainAcc=75.15% | ValAcc=79.67% | TrainLoss=0.6536 | ValLoss=0.5674\n",
      "Epoch 33/200 | TrainAcc=75.31% | ValAcc=79.65% | TrainLoss=0.6497 | ValLoss=0.5519\n",
      "Epoch 34/200 | TrainAcc=75.32% | ValAcc=78.11% | TrainLoss=0.6497 | ValLoss=0.5814\n",
      "Epoch 35/200 | TrainAcc=75.32% | ValAcc=81.53% | TrainLoss=0.6489 | ValLoss=0.5158\n",
      "Epoch 36/200 | TrainAcc=75.17% | ValAcc=79.76% | TrainLoss=0.6526 | ValLoss=0.5575\n",
      "Epoch 37/200 | TrainAcc=75.31% | ValAcc=81.31% | TrainLoss=0.6461 | ValLoss=0.5182\n",
      "Epoch 38/200 | TrainAcc=75.56% | ValAcc=80.95% | TrainLoss=0.6457 | ValLoss=0.5278\n",
      "Epoch 39/200 | TrainAcc=75.56% | ValAcc=78.79% | TrainLoss=0.6400 | ValLoss=0.5710\n",
      "Epoch 40/200 | TrainAcc=75.62% | ValAcc=81.00% | TrainLoss=0.6415 | ValLoss=0.5305\n",
      "Epoch 41/200 | TrainAcc=75.76% | ValAcc=79.79% | TrainLoss=0.6355 | ValLoss=0.5514\n",
      "Epoch 42/200 | TrainAcc=75.74% | ValAcc=81.60% | TrainLoss=0.6370 | ValLoss=0.5063\n",
      "Epoch 43/200 | TrainAcc=75.83% | ValAcc=77.63% | TrainLoss=0.6388 | ValLoss=0.5858\n",
      "Epoch 44/200 | TrainAcc=75.84% | ValAcc=79.38% | TrainLoss=0.6386 | ValLoss=0.5630\n",
      "Epoch 45/200 | TrainAcc=75.85% | ValAcc=78.47% | TrainLoss=0.6319 | ValLoss=0.5785\n",
      "Early stopping.\n",
      "Trial 6 done. BestValAcc=81.53 | TestAcc=81.57\n",
      "\n",
      "=== Trial 7/8 | cfg: {'lr': 0.001, 'weight_decay': 0.0001, 'batch_size': 64, 'channels': 16, 'dropout': 0.3, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=45.76% | ValAcc=66.33% | TrainLoss=1.4764 | ValLoss=0.9104\n",
      "Epoch 2/200 | TrainAcc=65.23% | ValAcc=61.63% | TrainLoss=0.9021 | ValLoss=1.0253\n",
      "Epoch 3/200 | TrainAcc=70.66% | ValAcc=77.70% | TrainLoss=0.7765 | ValLoss=0.6095\n",
      "Epoch 4/200 | TrainAcc=73.20% | ValAcc=75.81% | TrainLoss=0.7078 | ValLoss=0.6447\n",
      "Epoch 5/200 | TrainAcc=74.82% | ValAcc=78.76% | TrainLoss=0.6645 | ValLoss=0.5649\n",
      "Epoch 6/200 | TrainAcc=76.32% | ValAcc=81.96% | TrainLoss=0.6254 | ValLoss=0.4972\n",
      "Epoch 7/200 | TrainAcc=76.94% | ValAcc=83.05% | TrainLoss=0.6099 | ValLoss=0.4870\n",
      "Epoch 8/200 | TrainAcc=77.86% | ValAcc=80.55% | TrainLoss=0.5882 | ValLoss=0.5300\n",
      "Epoch 9/200 | TrainAcc=78.31% | ValAcc=82.58% | TrainLoss=0.5759 | ValLoss=0.4741\n",
      "Epoch 10/200 | TrainAcc=78.69% | ValAcc=82.41% | TrainLoss=0.5632 | ValLoss=0.4731\n",
      "Epoch 11/200 | TrainAcc=79.13% | ValAcc=82.91% | TrainLoss=0.5505 | ValLoss=0.4655\n",
      "Epoch 12/200 | TrainAcc=79.78% | ValAcc=84.76% | TrainLoss=0.5339 | ValLoss=0.4280\n",
      "Epoch 13/200 | TrainAcc=80.14% | ValAcc=83.52% | TrainLoss=0.5286 | ValLoss=0.4547\n",
      "Epoch 14/200 | TrainAcc=80.09% | ValAcc=83.03% | TrainLoss=0.5284 | ValLoss=0.4612\n",
      "Epoch 15/200 | TrainAcc=80.35% | ValAcc=85.25% | TrainLoss=0.5180 | ValLoss=0.4144\n",
      "Epoch 16/200 | TrainAcc=80.65% | ValAcc=85.33% | TrainLoss=0.5135 | ValLoss=0.4053\n",
      "Epoch 17/200 | TrainAcc=80.92% | ValAcc=82.89% | TrainLoss=0.5055 | ValLoss=0.4558\n",
      "Epoch 18/200 | TrainAcc=81.04% | ValAcc=84.15% | TrainLoss=0.5011 | ValLoss=0.4259\n",
      "Epoch 19/200 | TrainAcc=81.10% | ValAcc=86.16% | TrainLoss=0.5003 | ValLoss=0.4034\n",
      "Epoch 20/200 | TrainAcc=81.37% | ValAcc=83.50% | TrainLoss=0.4938 | ValLoss=0.4416\n",
      "Epoch 21/200 | TrainAcc=81.44% | ValAcc=85.44% | TrainLoss=0.4922 | ValLoss=0.3924\n",
      "Epoch 22/200 | TrainAcc=81.55% | ValAcc=85.80% | TrainLoss=0.4881 | ValLoss=0.4020\n",
      "Epoch 23/200 | TrainAcc=81.66% | ValAcc=83.89% | TrainLoss=0.4819 | ValLoss=0.4174\n",
      "Epoch 24/200 | TrainAcc=81.78% | ValAcc=83.38% | TrainLoss=0.4826 | ValLoss=0.4269\n",
      "Epoch 25/200 | TrainAcc=81.91% | ValAcc=84.87% | TrainLoss=0.4846 | ValLoss=0.4178\n",
      "Epoch 26/200 | TrainAcc=81.98% | ValAcc=82.05% | TrainLoss=0.4793 | ValLoss=0.4721\n",
      "Epoch 27/200 | TrainAcc=82.25% | ValAcc=86.99% | TrainLoss=0.4778 | ValLoss=0.3734\n",
      "Epoch 28/200 | TrainAcc=82.24% | ValAcc=84.94% | TrainLoss=0.4708 | ValLoss=0.4169\n",
      "Epoch 29/200 | TrainAcc=82.30% | ValAcc=86.01% | TrainLoss=0.4709 | ValLoss=0.3909\n",
      "Epoch 30/200 | TrainAcc=82.38% | ValAcc=84.48% | TrainLoss=0.4695 | ValLoss=0.4123\n",
      "Epoch 31/200 | TrainAcc=82.98% | ValAcc=85.12% | TrainLoss=0.4546 | ValLoss=0.4032\n",
      "Epoch 32/200 | TrainAcc=83.17% | ValAcc=87.09% | TrainLoss=0.4479 | ValLoss=0.3542\n",
      "Epoch 33/200 | TrainAcc=83.13% | ValAcc=86.43% | TrainLoss=0.4521 | ValLoss=0.3751\n",
      "Epoch 34/200 | TrainAcc=83.16% | ValAcc=87.14% | TrainLoss=0.4493 | ValLoss=0.3544\n",
      "Epoch 35/200 | TrainAcc=83.37% | ValAcc=85.44% | TrainLoss=0.4464 | ValLoss=0.3917\n",
      "Epoch 36/200 | TrainAcc=83.31% | ValAcc=87.21% | TrainLoss=0.4448 | ValLoss=0.3561\n",
      "Epoch 37/200 | TrainAcc=83.51% | ValAcc=85.74% | TrainLoss=0.4451 | ValLoss=0.3950\n",
      "Epoch 38/200 | TrainAcc=83.57% | ValAcc=86.61% | TrainLoss=0.4393 | ValLoss=0.3661\n",
      "Epoch 39/200 | TrainAcc=83.41% | ValAcc=85.38% | TrainLoss=0.4434 | ValLoss=0.3962\n",
      "Epoch 40/200 | TrainAcc=83.54% | ValAcc=86.92% | TrainLoss=0.4386 | ValLoss=0.3662\n",
      "Epoch 41/200 | TrainAcc=83.56% | ValAcc=85.06% | TrainLoss=0.4424 | ValLoss=0.4164\n",
      "Epoch 42/200 | TrainAcc=83.67% | ValAcc=86.11% | TrainLoss=0.4404 | ValLoss=0.3792\n",
      "Epoch 43/200 | TrainAcc=83.61% | ValAcc=86.72% | TrainLoss=0.4374 | ValLoss=0.3648\n",
      "Epoch 44/200 | TrainAcc=83.67% | ValAcc=84.37% | TrainLoss=0.4397 | ValLoss=0.4285\n",
      "Early stopping.\n",
      "Trial 7 done. BestValAcc=87.14 | TestAcc=87.20\n",
      "\n",
      "=== Trial 8/8 | cfg: {'lr': 0.0003, 'weight_decay': 1e-05, 'batch_size': 64, 'channels': 32, 'dropout': 0.0, 'epochs': 200, 'patience': 10} ===\n",
      "Epoch 1/200 | TrainAcc=64.76% | ValAcc=39.11% | TrainLoss=1.1558 | ValLoss=2.1795\n",
      "Epoch 2/200 | TrainAcc=85.30% | ValAcc=68.43% | TrainLoss=0.4732 | ValLoss=0.9020\n",
      "Epoch 3/200 | TrainAcc=88.21% | ValAcc=84.49% | TrainLoss=0.3532 | ValLoss=0.4076\n",
      "Epoch 4/200 | TrainAcc=89.99% | ValAcc=47.96% | TrainLoss=0.2948 | ValLoss=1.9802\n",
      "Epoch 5/200 | TrainAcc=90.82% | ValAcc=80.69% | TrainLoss=0.2672 | ValLoss=0.5348\n",
      "Epoch 6/200 | TrainAcc=91.80% | ValAcc=7.19% | TrainLoss=0.2429 | ValLoss=26.6033\n",
      "Epoch 7/200 | TrainAcc=91.26% | ValAcc=71.26% | TrainLoss=0.2558 | ValLoss=1.0058\n",
      "Epoch 8/200 | TrainAcc=92.84% | ValAcc=52.17% | TrainLoss=0.2069 | ValLoss=1.9696\n",
      "Epoch 9/200 | TrainAcc=93.31% | ValAcc=14.27% | TrainLoss=0.1973 | ValLoss=23.4657\n",
      "Epoch 10/200 | TrainAcc=92.29% | ValAcc=87.39% | TrainLoss=0.2274 | ValLoss=0.3752\n",
      "Epoch 11/200 | TrainAcc=93.60% | ValAcc=84.81% | TrainLoss=0.1854 | ValLoss=0.4170\n",
      "Epoch 12/200 | TrainAcc=94.04% | ValAcc=82.13% | TrainLoss=0.1699 | ValLoss=0.4996\n",
      "Epoch 13/200 | TrainAcc=94.39% | ValAcc=80.46% | TrainLoss=0.1620 | ValLoss=0.5704\n",
      "Epoch 14/200 | TrainAcc=94.53% | ValAcc=62.90% | TrainLoss=0.1567 | ValLoss=1.3432\n",
      "Epoch 15/200 | TrainAcc=94.65% | ValAcc=73.75% | TrainLoss=0.1528 | ValLoss=0.8494\n",
      "Epoch 16/200 | TrainAcc=94.93% | ValAcc=60.43% | TrainLoss=0.1441 | ValLoss=2.5476\n",
      "Epoch 17/200 | TrainAcc=94.83% | ValAcc=16.31% | TrainLoss=0.1488 | ValLoss=14.2916\n",
      "Epoch 18/200 | TrainAcc=95.21% | ValAcc=88.19% | TrainLoss=0.1379 | ValLoss=0.3404\n",
      "Epoch 19/200 | TrainAcc=95.31% | ValAcc=71.13% | TrainLoss=0.1348 | ValLoss=1.3169\n",
      "Epoch 20/200 | TrainAcc=95.50% | ValAcc=67.51% | TrainLoss=0.1310 | ValLoss=1.3555\n",
      "Epoch 21/200 | TrainAcc=95.44% | ValAcc=51.41% | TrainLoss=0.1311 | ValLoss=3.3795\n",
      "Epoch 22/200 | TrainAcc=95.67% | ValAcc=66.28% | TrainLoss=0.1317 | ValLoss=1.5766\n",
      "Epoch 23/200 | TrainAcc=95.82% | ValAcc=10.03% | TrainLoss=0.1235 | ValLoss=27.0143\n",
      "Epoch 24/200 | TrainAcc=95.46% | ValAcc=61.41% | TrainLoss=0.1317 | ValLoss=2.1479\n",
      "Epoch 25/200 | TrainAcc=96.13% | ValAcc=87.04% | TrainLoss=0.1149 | ValLoss=0.4085\n",
      "Epoch 26/200 | TrainAcc=95.94% | ValAcc=91.32% | TrainLoss=0.1146 | ValLoss=0.2448\n",
      "Epoch 27/200 | TrainAcc=96.22% | ValAcc=67.01% | TrainLoss=0.1063 | ValLoss=1.7646\n",
      "Epoch 28/200 | TrainAcc=96.42% | ValAcc=89.07% | TrainLoss=0.1082 | ValLoss=0.3158\n",
      "Epoch 29/200 | TrainAcc=96.38% | ValAcc=71.06% | TrainLoss=0.1070 | ValLoss=1.4044\n",
      "Epoch 30/200 | TrainAcc=96.41% | ValAcc=82.86% | TrainLoss=0.1026 | ValLoss=0.6260\n",
      "Epoch 31/200 | TrainAcc=97.21% | ValAcc=91.94% | TrainLoss=0.0806 | ValLoss=0.2417\n",
      "Epoch 32/200 | TrainAcc=97.22% | ValAcc=94.36% | TrainLoss=0.0781 | ValLoss=0.1527\n",
      "Epoch 33/200 | TrainAcc=97.50% | ValAcc=91.41% | TrainLoss=0.0738 | ValLoss=0.2531\n",
      "Epoch 34/200 | TrainAcc=97.55% | ValAcc=87.89% | TrainLoss=0.0734 | ValLoss=0.3891\n",
      "Epoch 35/200 | TrainAcc=97.61% | ValAcc=92.40% | TrainLoss=0.0740 | ValLoss=0.2316\n",
      "Epoch 36/200 | TrainAcc=97.53% | ValAcc=95.96% | TrainLoss=0.0715 | ValLoss=0.1159\n",
      "Epoch 37/200 | TrainAcc=97.70% | ValAcc=63.59% | TrainLoss=0.0679 | ValLoss=1.8627\n",
      "Epoch 38/200 | TrainAcc=97.76% | ValAcc=91.62% | TrainLoss=0.0668 | ValLoss=0.2415\n",
      "Epoch 39/200 | TrainAcc=97.73% | ValAcc=72.14% | TrainLoss=0.0657 | ValLoss=1.4201\n",
      "Epoch 40/200 | TrainAcc=97.79% | ValAcc=94.03% | TrainLoss=0.0645 | ValLoss=0.1702\n",
      "Epoch 41/200 | TrainAcc=97.83% | ValAcc=85.12% | TrainLoss=0.0647 | ValLoss=0.5419\n",
      "Epoch 42/200 | TrainAcc=97.70% | ValAcc=83.45% | TrainLoss=0.0695 | ValLoss=0.5727\n",
      "Epoch 43/200 | TrainAcc=97.81% | ValAcc=94.62% | TrainLoss=0.0661 | ValLoss=0.1511\n",
      "Epoch 44/200 | TrainAcc=97.90% | ValAcc=90.69% | TrainLoss=0.0649 | ValLoss=0.2821\n",
      "Epoch 45/200 | TrainAcc=97.87% | ValAcc=83.83% | TrainLoss=0.0623 | ValLoss=0.6384\n",
      "Epoch 46/200 | TrainAcc=97.95% | ValAcc=79.17% | TrainLoss=0.0626 | ValLoss=0.8182\n",
      "Early stopping.\n",
      "Trial 8 done. BestValAcc=95.96 | TestAcc=95.76\n",
      "\n",
      "=== Param search finished ===\n",
      "Best test acc: 95.76 | config: {'lr': 0.0003, 'weight_decay': 1e-05, 'batch_size': 64, 'channels': 32, 'dropout': 0.0, 'epochs': 200, 'patience': 10}\n",
      "Results saved in: ./search_results\\2025-11-24_15-16-22_param_search_SNR20dB_fd266_classes_20\n",
      "Done. Best result:\n",
      "{'acc': 95.75969187574242, 'config': {'lr': 0.0003, 'weight_decay': 1e-05, 'batch_size': 64, 'channels': 32, 'dropout': 0.0, 'epochs': 200, 'patience': 10}, 'model_path': './search_results\\\\2025-11-24_15-16-22_param_search_SNR20dB_fd266_classes_20\\\\trial_8\\\\best_model.pth'}\n",
      "Trial summary saved to ./search_results\\2025-11-24_15-16-22_param_search_SNR20dB_fd266_classes_20\\trial_summary.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from time import time as ttime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import pywt\n",
    "\n",
    "# ====================== 配置参数 ======================\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 数据参数（按需修改）\n",
    "SNR_dB = 20\n",
    "ADD_NOISE = True\n",
    "ADD_DOPPLER = True\n",
    "FS = 20e6\n",
    "FC = 2.4e9\n",
    "VELOCITY_KMH = 120\n",
    "\n",
    "# Wavelet 特征\n",
    "USE_LOG = True\n",
    "WAVELET = 'db6'\n",
    "WAVELET_LEVEL = 6\n",
    "\n",
    "# 训练默认参数（可被参数搜索覆盖）\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 10\n",
    "\n",
    "# 参数搜索默认\n",
    "N_TRIALS_DEFAULT = 12\n",
    "\n",
    "# 保存路径\n",
    "SAVE_ROOT = \"./search_results\"\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "# 数据文件夹（请修改为你的路径）\n",
    "DATA_FOLDER = r\"..\\los_data\"  # Windows 风格相对路径示例\n",
    "\n",
    "# ====================== 数据读取 ======================\n",
    "def load_iq_mat_dataset(data_folder):\n",
    "    file_list = sorted([f for f in os.listdir(data_folder) if f.endswith('.mat')])\n",
    "    if len(file_list) == 0:\n",
    "        raise FileNotFoundError(f\"No .mat files found in {data_folder}\")\n",
    "    X_list, y_list = [], []\n",
    "    for idx, file_name in enumerate(file_list):\n",
    "        mat = loadmat(os.path.join(data_folder, file_name))\n",
    "        if 'data_Ineed' not in mat:\n",
    "            print(f\"Warning: {file_name} 没有 'data_Ineed' 变量，跳过。\")\n",
    "            continue\n",
    "        data_arr = mat['data_Ineed'].T  # 转置为 [num_samples, length]\n",
    "        X_list.append(data_arr)\n",
    "        y_list.append(np.full(data_arr.shape[0], idx, dtype=np.int64))\n",
    "        print(f\"Loaded file idx={idx}: {file_name}, shape (after transpose): {data_arr.shape}\")\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    print(f\"Total data shape: {X.shape}, labels shape: {y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "# ====================== 数据处理函数 ======================\n",
    "def compute_doppler_shift(v_kmh, fc_hz):\n",
    "    if not v_kmh:\n",
    "        return 0.0\n",
    "    c = 3e8\n",
    "    v_mps = v_kmh / 3.6\n",
    "    return fc_hz * v_mps / c\n",
    "\n",
    "def add_complex_awgn(signal, snr_db):\n",
    "    if snr_db is None:\n",
    "        return signal\n",
    "    power = np.mean(np.abs(signal)**2)\n",
    "    noise_power = power / (10**(snr_db/10))\n",
    "    noise_std = np.sqrt(noise_power/2)\n",
    "    noise = noise_std * (np.random.randn(*signal.shape) + 1j*np.random.randn(*signal.shape))\n",
    "    return signal + noise\n",
    "\n",
    "def apply_doppler_shift(signal, fd_hz, fs_hz):\n",
    "    if fd_hz is None or fd_hz == 0:\n",
    "        return signal\n",
    "    t = np.arange(len(signal)) / fs_hz\n",
    "    return signal * np.exp(1j * 2 * np.pi * fd_hz * t)\n",
    "\n",
    "def process_signal_led_rff(sig_complex, use_log=False, wavelet='db6', level=6):\n",
    "    # 1. FFT 幅度谱（取对称谱前半段）\n",
    "    freq_sig = np.fft.fft(sig_complex)\n",
    "    amp = np.abs(freq_sig)\n",
    "    amp = amp[:len(amp)//2]\n",
    "\n",
    "    # 2. 可选 log\n",
    "    if use_log:\n",
    "        amp = np.log(amp + 1e-8)\n",
    "\n",
    "    # 3. 小波分解 + 低频置零 + 重构\n",
    "    coeffs = pywt.wavedec(amp, wavelet, level=level)\n",
    "    coeffs[0] = np.zeros_like(coeffs[0])\n",
    "    rec = pywt.waverec(coeffs, wavelet)\n",
    "    rec = rec[:len(amp)]\n",
    "\n",
    "    # 4. 归一化\n",
    "    mu, sigma = rec.mean(), rec.std()\n",
    "    if sigma < 1e-8:\n",
    "        feat = (rec - mu).astype(np.float32)\n",
    "    else:\n",
    "        feat = ((rec - mu) / (sigma + 1e-8)).astype(np.float32)\n",
    "    return feat\n",
    "\n",
    "def preprocess_iq_dataset_led_rff(data_real, snr_db=SNR_dB, velocity_kmh=VELOCITY_KMH,\n",
    "                                  fc_hz=FC, fs_hz=FS, use_log=USE_LOG,\n",
    "                                  wavelet=WAVELET, level=WAVELET_LEVEL,\n",
    "                                  add_noise=ADD_NOISE, add_doppler=ADD_DOPPLER):\n",
    "    \"\"\"\n",
    "    输入 data_real: numpy array [N, length] (real-valued samples but treated as complex)\n",
    "    返回: torch.Tensor [N, 1, feat_len]\n",
    "    \"\"\"\n",
    "    num_samples, sig_len = data_real.shape\n",
    "    processed_feats = []\n",
    "    data_complex = data_real.astype(np.complex64)\n",
    "    fd_hz = compute_doppler_shift(velocity_kmh, fc_hz) if add_doppler else None\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sig = data_complex[i]\n",
    "        if add_noise:\n",
    "            sig = add_complex_awgn(sig, snr_db)\n",
    "        if add_doppler:\n",
    "            sig = apply_doppler_shift(sig, fd_hz, fs_hz)\n",
    "        feat = process_signal_led_rff(sig, use_log=use_log, wavelet=wavelet, level=level)\n",
    "        processed_feats.append(feat)\n",
    "    processed_feats = np.stack(processed_feats, axis=0)\n",
    "    return torch.tensor(processed_feats, dtype=torch.float32)[:, None, :]  # [N, 1, length]\n",
    "\n",
    "# ====================== InceptionTime 模型 ======================\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = max(1, out_channels // 4)\n",
    "        self.bottleneck = nn.Conv1d(in_channels, bottleneck_channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(bottleneck_channels, out_channels, kernel_size=10, padding=5)\n",
    "        self.conv2 = nn.Conv1d(bottleneck_channels, out_channels, kernel_size=20, padding=10)\n",
    "        self.conv3 = nn.Conv1d(bottleneck_channels, out_channels, kernel_size=40, padding=20)\n",
    "        self.maxpool = nn.MaxPool1d(3, stride=1, padding=1)\n",
    "        self.convpool = nn.Conv1d(bottleneck_channels, out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(4*out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # ⭐ 加入 dropout（0 不启用）\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_b = self.bottleneck(x)\n",
    "        c1 = self.conv1(x_b)\n",
    "        c2 = self.conv2(x_b)\n",
    "        c3 = self.conv3(x_b)\n",
    "        c4 = self.convpool(self.maxpool(x_b))\n",
    "\n",
    "        min_len = min(c1.shape[-1], c2.shape[-1], c3.shape[-1], c4.shape[-1])\n",
    "        c1 = c1[..., :min_len]\n",
    "        c2 = c2[..., :min_len]\n",
    "        c3 = c3[..., :min_len]\n",
    "        c4 = c4[..., :min_len]\n",
    "\n",
    "        out = torch.cat([c1, c2, c3, c4], dim=1)\n",
    "        out = self.relu(self.bn(out))\n",
    "        return self.dropout(out)\n",
    "\n",
    "\n",
    "class InceptionTime(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1, channels=32, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.b1 = InceptionBlock(in_channels, channels, dropout=dropout)\n",
    "        self.b2 = InceptionBlock(4*channels, channels, dropout=dropout)\n",
    "        self.b3 = InceptionBlock(4*channels, channels, dropout=dropout)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(4*channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.shape[-1] % 2 == 1:\n",
    "            x = x[..., :-1]\n",
    "        x = self.b1(x); x = self.b2(x); x = self.b3(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ====================== 工具函数 ======================\n",
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            _, p = torch.max(out, 1)\n",
    "            correct += (p == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "            all_preds.extend(p.cpu().numpy())\n",
    "    acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, fold, save_folder, dataset_type='Test'):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{dataset_type} Confusion Matrix Trial{fold}')\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig(os.path.join(save_folder, f'{dataset_type.lower()}_cm_trial{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_curves(train_losses, val_losses, train_acc, val_acc, fold, save_folder):\n",
    "    plt.figure(); plt.plot(train_losses,label='Train Loss'); plt.plot(val_losses,label='Val Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Trial {fold} Loss'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder,f'loss_trial{fold}.png')); plt.close()\n",
    "    plt.figure(); plt.plot(train_acc,label='Train Acc'); plt.plot(val_acc,label='Val Acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.title(f'Trial {fold} Accuracy'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder,f'acc_trial{fold}.png')); plt.close()\n",
    "\n",
    "# ====================== 训练单次试验 ======================\n",
    "def train_one_run(model, tr_loader, va_loader, criterion, optimizer, scheduler,\n",
    "                  device, epochs, patience, results_file):\n",
    "    best_val = 0.0\n",
    "    best_wts = None\n",
    "    patience_cnt = 0\n",
    "    train_losses, val_losses, train_acc_list, val_acc_list = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for xb, yb in tr_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, p = torch.max(out, 1)\n",
    "            correct += (p == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "        train_loss = running_loss / len(tr_loader)\n",
    "        train_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "        train_losses.append(train_loss); train_acc_list.append(train_acc)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        vloss, vcorrect, vtotal = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in va_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                vloss += loss.item()\n",
    "                _, p = torch.max(out, 1)\n",
    "                vcorrect += (p == yb).sum().item()\n",
    "                vtotal += yb.size(0)\n",
    "        val_loss = vloss / len(va_loader) if len(va_loader) > 0 else 0.0\n",
    "        val_acc = 100.0 * vcorrect / vtotal if vtotal > 0 else 0.0\n",
    "        val_losses.append(val_loss); val_acc_list.append(val_acc)\n",
    "\n",
    "        # logging\n",
    "        line = f\"Epoch {epoch+1}/{epochs} | TrainAcc={train_acc:.2f}% | ValAcc={val_acc:.2f}% | TrainLoss={train_loss:.4f} | ValLoss={val_loss:.4f}\"\n",
    "        print(line)\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "        # check best\n",
    "        if val_acc > best_val + 0.1:\n",
    "            best_val = val_acc\n",
    "            best_wts = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "        if scheduler is not None:\n",
    "            try:\n",
    "                scheduler.step()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # restore best weights if available\n",
    "    if best_wts is not None:\n",
    "        model.load_state_dict(best_wts)\n",
    "    return model, best_val, (train_losses, val_losses, train_acc_list, val_acc_list)\n",
    "\n",
    "# ====================== 参数搜索主函数 ======================\n",
    "def param_search(X_train_val, y_train_val, X_test, y_test, num_classes,\n",
    "                 param_grid=None, mode='grid', n_trials=N_TRIALS_DEFAULT, val_size=0.2,\n",
    "                 device=DEVICE, save_root=SAVE_ROOT, random_seed=42):\n",
    "    \"\"\"\n",
    "    param_grid: dict of lists, e.g.\n",
    "      {\n",
    "        'lr': [1e-3, 3e-4],\n",
    "        'weight_decay': [1e-4, 1e-5],\n",
    "        'batch_size': [32,64],\n",
    "        'channels': [16,32],\n",
    "        'epochs': [100],\n",
    "      }\n",
    "    mode: 'grid' or 'random'\n",
    "    n_trials: limit number of trials (for random or to cap grid)\n",
    "    \"\"\"\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    save_dir = f\"{timestamp}_param_search_SNR{SNR_dB}dB_fd{int(compute_doppler_shift(VELOCITY_KMH, FC))}_classes_{num_classes}\"\n",
    "    base_folder = os.path.join(save_root, save_dir)\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "    results_file_all = os.path.join(base_folder, \"param_search_results.txt\")\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'lr': [1e-3, 3e-4, 1e-4],\n",
    "            'weight_decay': [1e-4, 1e-5],\n",
    "            'batch_size': [32, 64],\n",
    "            'channels': [16, 32],\n",
    "            'epochs': [80],\n",
    "            'patience': [10],\n",
    "        }\n",
    "\n",
    "    keys = list(param_grid.keys())\n",
    "    combos = []\n",
    "    if mode == 'grid':\n",
    "        for vals in itertools.product(*(param_grid[k] for k in keys)):\n",
    "            combos.append(dict(zip(keys, vals)))\n",
    "        # if too many grid combinations, limit\n",
    "        if len(combos) > n_trials:\n",
    "            random.shuffle(combos)\n",
    "            combos = combos[:n_trials]\n",
    "    else:  # random mode\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        for _ in range(n_trials):\n",
    "            choice = {k: random.choice(param_grid[k]) for k in keys}\n",
    "            combos.append(choice)\n",
    "\n",
    "    print(f\"Param search: mode={mode}, total_trials={len(combos)}. Results base: {base_folder}\")\n",
    "    with open(results_file_all, 'w') as f:\n",
    "        f.write(f\"Param search started at {timestamp}\\nMode: {mode}\\nTotal trials: {len(combos)}\\n\\n\")\n",
    "\n",
    "    # fixed test loader\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    trial_summaries = []\n",
    "    best_overall = {'acc': -1.0, 'config': None, 'model_path': None}\n",
    "\n",
    "    for tidx, cfg in enumerate(combos):\n",
    "        t_start = ttime()\n",
    "        print(f\"\\n=== Trial {tidx+1}/{len(combos)} | cfg: {cfg} ===\")\n",
    "        trial_folder = os.path.join(base_folder, f\"trial_{tidx+1}\")\n",
    "        os.makedirs(trial_folder, exist_ok=True)\n",
    "        results_file = os.path.join(trial_folder, \"log.txt\")\n",
    "        with open(results_file, 'w') as f:\n",
    "            f.write(\"Config:\\n\" + json.dumps(cfg, indent=2) + \"\\n\\n\")\n",
    "\n",
    "        # split train/val from X_train_val\n",
    "        X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=val_size, stratify=y_train_val, random_state=42 + tidx\n",
    "        )\n",
    "\n",
    "        batch_size = int(cfg.get('batch_size', BATCH_SIZE))\n",
    "        tr_loader = DataLoader(TensorDataset(X_tr, y_tr), batch_size=batch_size, shuffle=True)\n",
    "        va_loader = DataLoader(TensorDataset(X_va, y_va), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        channels = int(cfg.get('channels', 16))\n",
    "        dropout = float(cfg.get('dropout', 0.0))\n",
    "        model = InceptionTime(num_classes=num_classes, in_channels=1, channels=channels, dropout=dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        lr = float(cfg.get('lr', LR))\n",
    "        wd = float(cfg.get('weight_decay', WEIGHT_DECAY))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "        epochs = int(cfg.get('epochs', EPOCHS))\n",
    "        patience = int(cfg.get('patience', PATIENCE))\n",
    "\n",
    "        model, best_val_acc, hist = train_one_run(model, tr_loader, va_loader, criterion,\n",
    "                                                  optimizer, scheduler, device, epochs,\n",
    "                                                  patience, results_file)\n",
    "        test_acc, test_cm = evaluate_model(model, test_loader, device, num_classes)\n",
    "        print(f\"Trial {tidx+1} done. BestValAcc={best_val_acc:.2f} | TestAcc={test_acc:.2f}\")\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write(f\"\\nTrial Summary: BestValAcc={best_val_acc:.2f} | TestAcc={test_acc:.2f}\\n\")\n",
    "\n",
    "        model_path = os.path.join(trial_folder, \"best_model.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        plot_confusion_matrix(test_cm, classes=list(range(num_classes)), fold=tidx+1, save_folder=trial_folder, dataset_type='Test')\n",
    "        plot_curves(*hist, fold=tidx+1, save_folder=trial_folder)\n",
    "\n",
    "        elapsed = ttime() - t_start\n",
    "        rec = {**cfg}\n",
    "        rec.update({'trial': tidx+1, 'best_val_acc': float(best_val_acc), 'test_acc': float(test_acc),\n",
    "                    'model_path': model_path, 'trial_folder': trial_folder, 'elapsed_sec': elapsed})\n",
    "        trial_summaries.append(rec)\n",
    "\n",
    "        if test_acc > best_overall['acc']:\n",
    "            best_overall['acc'] = float(test_acc)\n",
    "            best_overall['config'] = cfg\n",
    "            best_overall['model_path'] = model_path\n",
    "\n",
    "        with open(results_file_all, 'a') as f:\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # save summary dataframe\n",
    "    try:\n",
    "        df = pd.DataFrame(trial_summaries)\n",
    "        df.to_csv(os.path.join(base_folder, \"trial_summary.csv\"), index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Warning: cannot save summary dataframe:\", e)\n",
    "        df = None\n",
    "\n",
    "    with open(os.path.join(base_folder, \"best_config.json\"), 'w') as f:\n",
    "        json.dump({'best_test_acc': best_overall['acc'], 'best_config': best_overall['config'], 'model_path': best_overall['model_path']}, f, indent=2)\n",
    "\n",
    "    print(\"\\n=== Param search finished ===\")\n",
    "    print(f\"Best test acc: {best_overall['acc']:.2f} | config: {best_overall['config']}\")\n",
    "    print(f\"Results saved in: {base_folder}\")\n",
    "    return best_overall, df, base_folder\n",
    "\n",
    "# ====================== 主流程 ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) 加载原始 IQ 数据 (numpy)\n",
    "    print(\"Loading data...\")\n",
    "    X_raw, y_raw = load_iq_mat_dataset(DATA_FOLDER)\n",
    "    num_classes = len(np.unique(y_raw))\n",
    "    print(f\"Num classes detected: {num_classes}\")\n",
    "\n",
    "    # 2) 预处理 -> 特征 (只做一次以加快参数搜索)\n",
    "    print(\"Preprocessing (this may take some time)...\")\n",
    "    X_proc = preprocess_iq_dataset_led_rff(X_raw,\n",
    "                                           snr_db=SNR_dB,\n",
    "                                           velocity_kmh=VELOCITY_KMH,\n",
    "                                           fc_hz=FC,\n",
    "                                           fs_hz=FS,\n",
    "                                           use_log=USE_LOG,\n",
    "                                           wavelet=WAVELET,\n",
    "                                           level=WAVELET_LEVEL,\n",
    "                                           add_noise=ADD_NOISE,\n",
    "                                           add_doppler=ADD_DOPPLER)\n",
    "    y_torch = torch.tensor(y_raw, dtype=torch.long)\n",
    "    print(f\"Preprocessed features shape: {X_proc.shape}\")\n",
    "\n",
    "    # 3) 划分 train_val / test（参数搜索会在 train_val 上再做 train/val 划分）\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X_proc, y_torch, test_size=0.2, stratify=y_torch, random_state=42\n",
    "    )\n",
    "    print(f\"Train_val size: {len(X_train_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    # 4) 设置参数搜索网格（示例，可按需修改）\n",
    "    param_grid = {\n",
    "    'lr': [1e-3, 3e-4],\n",
    "    'weight_decay': [1e-4, 1e-5],\n",
    "    'batch_size': [32, 64],\n",
    "    'channels': [16, 32],\n",
    "    'dropout': [0.0, 0.1, 0.3, 0.5], \n",
    "    'epochs': [200],\n",
    "    'patience': [10],\n",
    "}\n",
    "\n",
    "\n",
    "    # 5) 运行参数搜索（mode='grid' 或 'random'）\n",
    "    #    如果使用 grid 并且组合过多，会被截断到 n_trials。\n",
    "    best, df_summary, save_folder = param_search(\n",
    "        X_train_val, y_train_val, X_test, y_test, num_classes,\n",
    "        param_grid=param_grid, mode='grid', n_trials=8, val_size=0.2,\n",
    "        device=DEVICE, save_root=SAVE_ROOT, random_seed=42\n",
    "    )\n",
    "\n",
    "    print(\"Done. Best result:\")\n",
    "    print(best)\n",
    "    if df_summary is not None:\n",
    "        print(f\"Trial summary saved to {os.path.join(save_folder, 'trial_summary.csv')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
