{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38d64943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬0ä¸ªæ–‡ä»¶ï¼ˆdev0.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (7014, 320), å‰5ä¸ªå€¼: [-0.01318091-0.00598181j -0.00856645-0.0066582j  -0.01293569+0.00314399j\n",
      " -0.00608675-0.00281703j -0.00453262-0.00123845j]\n",
      "ç¬¬1ä¸ªæ–‡ä»¶ï¼ˆdev1.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (6632, 320), å‰5ä¸ªå€¼: [-0.05595885-0.01681558j -0.04190274-0.01379795j -0.02817297-0.00111078j\n",
      " -0.02078103-0.00585922j -0.00773754-0.00191155j]\n",
      "ç¬¬2ä¸ªæ–‡ä»¶ï¼ˆdev10.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (8935, 320), å‰5ä¸ªå€¼: [-0.07714929-0.02866302j -0.07859567-0.01964287j -0.07749676-0.0211156j\n",
      " -0.04533909-0.0204815j  -0.05166423-0.02073226j]\n",
      "ç¬¬3ä¸ªæ–‡ä»¶ï¼ˆdev11.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (7776, 320), å‰5ä¸ªå€¼: [ 1.71212724e-03+0.00604403j -9.08998346e-05+0.01620005j\n",
      " -2.51134976e-02-0.00123921j -5.13536853e-03-0.01767933j\n",
      "  7.84350184e-03+0.01182339j]\n",
      "ç¬¬4ä¸ªæ–‡ä»¶ï¼ˆdev13.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (7410, 320), å‰5ä¸ªå€¼: [-0.02351107-0.00558919j -0.0092649 -0.01073413j -0.01412528-0.00914526j\n",
      " -0.01682761-0.00316691j -0.01362142-0.00254273j]\n",
      "ç¬¬5ä¸ªæ–‡ä»¶ï¼ˆdev14.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (6274, 320), å‰5ä¸ªå€¼: [ 0.41253131+0.17627416j  0.2342232 +0.34427072j -0.36166071+0.15586186j\n",
      " -0.56342863+0.40145559j  0.37736334-0.41501732j]\n",
      "ç¬¬6ä¸ªæ–‡ä»¶ï¼ˆdev15.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (5706, 320), å‰5ä¸ªå€¼: [-0.75523841+0.17676383j -0.30789476+0.54702624j  0.32670117+0.07917728j\n",
      "  0.58185414+0.77621894j  0.54010091+0.72085082j]\n",
      "ç¬¬7ä¸ªæ–‡ä»¶ï¼ˆdev16.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (12968, 320), å‰5ä¸ªå€¼: [ 0.43206902+0.06840523j -0.34614252+0.2747257j  -0.25646164+0.36397322j\n",
      " -0.39065214-0.23106272j -0.11294723-0.39158577j]\n",
      "ç¬¬8ä¸ªæ–‡ä»¶ï¼ˆdev17.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (9508, 320), å‰5ä¸ªå€¼: [ 0.72436952-0.19821906j -0.00179727-0.82174j     0.6401512 -0.466624j\n",
      " -0.64709927-0.47376196j  0.56438878+0.49753179j]\n",
      "ç¬¬9ä¸ªæ–‡ä»¶ï¼ˆdev18.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (3343, 320), å‰5ä¸ªå€¼: [0.07326945+0.40289134j 0.18065997+0.1174917j  0.25627887-0.38004509j\n",
      " 0.16535565+0.10998554j 0.03783765-0.14559615j]\n",
      "ç¬¬10ä¸ªæ–‡ä»¶ï¼ˆdev19.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (4756, 320), å‰5ä¸ªå€¼: [ 0.        +0.j          0.        +0.j         -0.26164098-0.1168667j\n",
      " -0.19234628-0.08874352j -0.14618305-0.1105697j ]\n",
      "ç¬¬11ä¸ªæ–‡ä»¶ï¼ˆdev2.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (6316, 320), å‰5ä¸ªå€¼: [-0.00887014-0.00827849j -0.01267446-0.00072719j -0.01266217+0.00347028j\n",
      " -0.00816151-0.00575298j  0.00033981+0.00404782j]\n",
      "ç¬¬12ä¸ªæ–‡ä»¶ï¼ˆdev20.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (5592, 320), å‰5ä¸ªå€¼: [ 0.28002897-0.2938319j   0.21062443+0.31766863j -0.36139997+0.22062231j\n",
      "  0.07738923+0.99981022j -0.06493303-0.57282563j]\n",
      "ç¬¬13ä¸ªæ–‡ä»¶ï¼ˆdev3.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (5536, 320), å‰5ä¸ªå€¼: [-0.01873567-0.01689641j -0.02890113-0.00449824j -0.01535944-0.00360087j\n",
      " -0.01764242-0.00029898j -0.01194241+0.00965787j]\n",
      "ç¬¬14ä¸ªæ–‡ä»¶ï¼ˆdev4.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (6669, 320), å‰5ä¸ªå€¼: [-0.02889289-0.00517339j -0.01837757-0.00089796j -0.02868811-0.00201487j\n",
      " -0.00806683-0.0145996j  -0.00060478+0.01440117j]\n",
      "ç¬¬15ä¸ªæ–‡ä»¶ï¼ˆdev5.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (5237, 320), å‰5ä¸ªå€¼: [-0.00688618-0.04157866j -0.03823901-0.02562551j -0.02999431+0.02119722j\n",
      " -0.03932358-0.00208778j  0.01064791+0.02812483j]\n",
      "ç¬¬16ä¸ªæ–‡ä»¶ï¼ˆdev6.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (5460, 320), å‰5ä¸ªå€¼: [ 0.00139658-0.00781024j -0.02151178+0.00369563j -0.01038959+0.01678896j\n",
      "  0.01463856+0.0006863j   0.01634722-0.00344983j]\n",
      "ç¬¬17ä¸ªæ–‡ä»¶ï¼ˆdev7.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (8926, 320), å‰5ä¸ªå€¼: [-0.03614023-0.01603984j -0.03492438+0.00454156j -0.00247585+0.00838098j\n",
      " -0.00387644-0.01460931j -0.01029942+0.01103444j]\n",
      "ç¬¬18ä¸ªæ–‡ä»¶ï¼ˆdev8.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (7614, 320), å‰5ä¸ªå€¼: [-0.01331813-0.0143382j  -0.00739304-0.00106726j -0.01788934+0.00440387j\n",
      " -0.01351875-0.01404354j  0.00288583-0.0108815j ]\n",
      "ç¬¬19ä¸ªæ–‡ä»¶ï¼ˆdev9.matï¼‰çš„æ•°æ® shape (å¤„ç†å): (7232, 320), å‰5ä¸ªå€¼: [-0.05391459-0.00585862j -0.0417583 -0.01431051j -0.0387997 -0.01820837j\n",
      " -0.01969059-0.00362016j -0.02455715-0.0162344j ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "folder_path = r\"..\\los_data\"  # ä½ çš„æ–‡ä»¶å¤¹è·¯å¾„\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "file_list = sorted(file_list)\n",
    "\n",
    "# é€‰æ‹©å¤„ç†é€»è¾‘ï¼š\n",
    "# 1 -> å…ˆå·®åˆ†å†è½¬ç½®\n",
    "# 2 -> å…ˆè½¬ç½®å†å·®åˆ†\n",
    "process_mode = 1  # æ”¹æˆ 2 å¯å¯¹æ¯”å¦ä¸€ä¸ªé¡ºåº\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, file_name in enumerate(file_list):\n",
    "    full_path = os.path.join(folder_path, file_name)\n",
    "    mat_contents = loadmat(full_path)\n",
    "\n",
    "    if 'data_Ineed' in mat_contents:\n",
    "        raw_data = mat_contents['data_Ineed']\n",
    "\n",
    "        if process_mode == 1:\n",
    "            # å…ˆå·®åˆ†å†è½¬ç½®\n",
    "            diff_data = np.empty_like(raw_data)\n",
    "            diff_data[0] = raw_data[0]\n",
    "            diff_data[1:] = raw_data[1:] - raw_data[:-1]\n",
    "            processed_data = diff_data.T\n",
    "\n",
    "            # æŒ‰ 320 ä¸ªä¿¡å·é‡æ„\n",
    "            # num_signals, num_samples = processed_data.shape\n",
    "            # block_size = 320\n",
    "            # num_blocks = num_signals // block_size\n",
    "            # processed_data = processed_data[:num_blocks * block_size, :]\n",
    "            # processed_data = processed_data.reshape((block_size, num_blocks * num_samples)).T\n",
    "\n",
    "        elif process_mode == 2:\n",
    "            # å…ˆè½¬ç½®\n",
    "            transposed = raw_data.T\n",
    "\n",
    "            # æŒ‰ 320 ä¸ªä¿¡å·é‡æ„\n",
    "            num_signals, num_samples = transposed.shape\n",
    "            block_size = 320\n",
    "            num_blocks = num_signals // block_size\n",
    "            reshaped_data = transposed[:num_blocks * block_size, :]\n",
    "            reshaped_data = reshaped_data.reshape((block_size, num_blocks * num_samples)).T\n",
    "\n",
    "            # è½¬ç½®ï¼Œè®©æ—¶é—´è½´åœ¨ axis=0ï¼ˆå’Œ process_mode=1 å¯¹é½ï¼‰\n",
    "            reshaped_data_T = reshaped_data.T\n",
    "\n",
    "            # å·®åˆ†\n",
    "            diff_data = np.empty_like(reshaped_data_T)\n",
    "            diff_data[0] = reshaped_data_T[0]\n",
    "            diff_data[1:] = reshaped_data_T[1:] - reshaped_data_T[:-1]\n",
    "\n",
    "            # å†è½¬ç½®å›æ¥\n",
    "            processed_data = diff_data.T\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"process_mode å¿…é¡»æ˜¯ 1 æˆ– 2\")\n",
    "\n",
    "        data.append(processed_data)\n",
    "    else:\n",
    "        print(f\"Warning: {file_name} é‡Œæ²¡æœ‰ 'data_Ineed' å˜é‡ï¼\")\n",
    "\n",
    "# æ‰“å°æ£€æŸ¥\n",
    "for i, d in enumerate(data):\n",
    "    print(f\"ç¬¬{i}ä¸ªæ–‡ä»¶ï¼ˆ{file_list[i]}ï¼‰çš„æ•°æ® shape (å¤„ç†å): {d.shape}, å‰5ä¸ªå€¼: {d[:5,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73a917a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== å¼€å§‹æ·»åŠ å™ªå£° (SNR=-20dB) ===\n",
      "æ–‡ä»¶0: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(7014, 320)\n",
      "æ–‡ä»¶1: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(6632, 320)\n",
      "æ–‡ä»¶2: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(8935, 320)\n",
      "æ–‡ä»¶3: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(7776, 320)\n",
      "æ–‡ä»¶4: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(7410, 320)\n",
      "æ–‡ä»¶5: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(6274, 320)\n",
      "æ–‡ä»¶6: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(5706, 320)\n",
      "æ–‡ä»¶7: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(12968, 320)\n",
      "æ–‡ä»¶8: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(9508, 320)\n",
      "æ–‡ä»¶9: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(3343, 320)\n",
      "æ–‡ä»¶10: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(4756, 320)\n",
      "æ–‡ä»¶11: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(6316, 320)\n",
      "æ–‡ä»¶12: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(5592, 320)\n",
      "æ–‡ä»¶13: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(5536, 320)\n",
      "æ–‡ä»¶14: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(6669, 320)\n",
      "æ–‡ä»¶15: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(5237, 320)\n",
      "æ–‡ä»¶16: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(5460, 320)\n",
      "æ–‡ä»¶17: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(8926, 320)\n",
      "æ–‡ä»¶18: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(7614, 320)\n",
      "æ–‡ä»¶19: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape=(7232, 320)\n",
      "\n",
      "âœ… æ‰€æœ‰æ–‡ä»¶å™ªå£°æ·»åŠ å®Œæˆï¼\n",
      "\n",
      "==================================================\n",
      "å™ªå£°æ·»åŠ æ•ˆæœéªŒè¯\n",
      "==================================================\n",
      "\n",
      "æ–‡ä»¶0 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.054822\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 105.543235\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.265569\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.263242\n",
      "\n",
      "æ–‡ä»¶1 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.049678\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 104.904557\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.245255\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.239531\n",
      "\n",
      "æ–‡ä»¶2 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.947755\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 94.769639\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.882094\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.885231\n",
      "\n",
      "æ–‡ä»¶3 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.909322\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 90.992204\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.749451\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.740704\n",
      "\n",
      "æ–‡ä»¶4 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.025075\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 102.478776\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.160742\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.155587\n",
      "\n",
      "æ–‡ä»¶5 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.988749\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 98.947438\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.035096\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.032409\n",
      "\n",
      "æ–‡ä»¶6 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.835532\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 83.533549\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.457888\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.467550\n",
      "\n",
      "æ–‡ä»¶7 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.844712\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 84.407344\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.495964\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.496905\n",
      "\n",
      "æ–‡ä»¶8 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.966841\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 96.654372\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.953147\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.950403\n",
      "\n",
      "æ–‡ä»¶9 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.988929\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 98.844621\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.028036\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.032161\n",
      "\n",
      "æ–‡ä»¶10 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.284350\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 128.338491\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 8.007573\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 8.013562\n",
      "\n",
      "æ–‡ä»¶11 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.062786\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 106.306563\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.288610\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.292648\n",
      "\n",
      "æ–‡ä»¶12 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.968237\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 96.798738\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.955217\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.958700\n",
      "\n",
      "æ–‡ä»¶13 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.01dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.075324\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 107.669884\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.334312\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.340134\n",
      "\n",
      "æ–‡ä»¶14 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.058564\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 105.862171\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.278295\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.272453\n",
      "\n",
      "æ–‡ä»¶15 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.875431\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 87.516774\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.618016\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.612002\n",
      "\n",
      "æ–‡ä»¶16 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.898693\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 89.797509\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.701368\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.699937\n",
      "\n",
      "æ–‡ä»¶17 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.116664\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 111.591728\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.469520\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.469805\n",
      "\n",
      "æ–‡ä»¶18 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 1.073984\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 107.502568\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 7.333721\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 7.329331\n",
      "\n",
      "æ–‡ä»¶19 - å¤æ•°ä¿¡å·éªŒè¯:\n",
      "  ğŸ“Š ç›®æ ‡SNR: -20dB, å®é™…SNR: -20.00dB\n",
      "  âš¡ ä¿¡å·åŠŸç‡: 0.967824\n",
      "  ğŸ”Š å™ªå£°åŠŸç‡: 96.776742\n",
      "  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: 6.955743\n",
      "  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: 6.956607\n",
      "\n",
      "==================================================\n",
      "æ•°æ®æ ·æœ¬è¯¦ç»†å¯¹æ¯”\n",
      "==================================================\n",
      "\n",
      "ğŸ“ æ–‡ä»¶0 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0132-0.0060j |  7.5385+12.2160j | -1.8747+3.3335j\n",
      "   1   | -0.0086-0.0067j | 14.7613+2.1040j | -3.9742+9.0256j\n",
      "   2   | -0.0129+0.0031j | -2.0610+9.6833j | 18.1626+9.1805j\n",
      "   3   | -0.0061-0.0028j | -17.2658-1.4325j | 10.1970-2.8386j\n",
      "   4   | -0.0045-0.0012j |  5.0014-10.4994j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶1 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0560-0.0168j | 11.6128-2.5936j | -1.8747+3.3335j\n",
      "   1   | -0.0419-0.0138j |  3.5097+1.4371j | -3.9742+9.0256j\n",
      "   2   | -0.0282-0.0011j |  1.0480+6.1620j | 18.1626+9.1805j\n",
      "   3   | -0.0208-0.0059j |  1.8040-0.8636j | 10.1970-2.8386j\n",
      "   4   | -0.0077-0.0019j |  4.5876-0.6151j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶2 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0771-0.0287j |  4.3073-5.9755j | -1.8747+3.3335j\n",
      "   1   | -0.0786-0.0196j | -3.1593+14.5806j | -3.9742+9.0256j\n",
      "   2   | -0.0775-0.0211j |  1.3993-2.0608j | 18.1626+9.1805j\n",
      "   3   | -0.0453-0.0205j | -10.8378+2.4427j | 10.1970-2.8386j\n",
      "   4   | -0.0517-0.0207j | -2.0725-0.5630j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶3 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.0017+0.0060j | -16.8331+3.6404j | -1.8747+3.3335j\n",
      "   1   | -0.0001+0.0162j | -9.6961+3.5734j | -3.9742+9.0256j\n",
      "   2   | -0.0251-0.0012j | -6.3991+11.0640j | 18.1626+9.1805j\n",
      "   3   | -0.0051-0.0177j | -4.5455-6.4668j | 10.1970-2.8386j\n",
      "   4   |  0.0078+0.0118j |  5.0459+1.6308j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶4 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0235-0.0056j | -4.5811+6.2571j | -1.8747+3.3335j\n",
      "   1   | -0.0093-0.0107j |  4.5062-3.1917j | -3.9742+9.0256j\n",
      "   2   | -0.0141-0.0091j | -3.2455-1.0752j | 18.1626+9.1805j\n",
      "   3   | -0.0168-0.0032j | -4.9052+7.2210j | 10.1970-2.8386j\n",
      "   4   | -0.0136-0.0025j | -8.2686+4.4010j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶5 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.4125+0.1763j | -3.3589+11.9036j | -1.8747+3.3335j\n",
      "   1   |  0.2342+0.3443j | -2.8544+3.5368j | -3.9742+9.0256j\n",
      "   2   | -0.3617+0.1559j | -7.3014+8.5339j | 18.1626+9.1805j\n",
      "   3   | -0.5634+0.4015j | -11.4114-4.2175j | 10.1970-2.8386j\n",
      "   4   |  0.3774-0.4150j | -5.2320+3.9151j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶6 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.7552+0.1768j |  2.9682+4.9288j | -1.8747+3.3335j\n",
      "   1   | -0.3079+0.5470j | -13.6964-1.5375j | -3.9742+9.0256j\n",
      "   2   |  0.3267+0.0792j | -5.4279-17.8262j | 18.1626+9.1805j\n",
      "   3   |  0.5819+0.7762j | -0.6229+7.3531j | 10.1970-2.8386j\n",
      "   4   |  0.5401+0.7209j |  2.7724-7.7312j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶7 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.4321+0.0684j | -3.2127-10.6451j | -1.8747+3.3335j\n",
      "   1   | -0.3461+0.2747j |  7.8156-0.1570j | -3.9742+9.0256j\n",
      "   2   | -0.2565+0.3640j |  4.8823-3.0698j | 18.1626+9.1805j\n",
      "   3   | -0.3907-0.2311j | -14.5292-0.2570j | 10.1970-2.8386j\n",
      "   4   | -0.1129-0.3916j | -4.2419-0.1108j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶8 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.7244-0.1982j | -0.8339-11.6247j | -1.8747+3.3335j\n",
      "   1   | -0.0018-0.8217j |  2.8073+3.5388j | -3.9742+9.0256j\n",
      "   2   |  0.6402-0.4666j | -2.4435-2.1342j | 18.1626+9.1805j\n",
      "   3   | -0.6471-0.4738j |  2.5899-5.6759j | 10.1970-2.8386j\n",
      "   4   |  0.5644+0.4975j |  4.4556-5.1260j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶9 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.0733+0.4029j | -2.7149+4.6068j | -1.8747+3.3335j\n",
      "   1   |  0.1807+0.1175j |  8.1794+13.6736j | -3.9742+9.0256j\n",
      "   2   |  0.2563-0.3800j | -7.6357+0.5947j | 18.1626+9.1805j\n",
      "   3   |  0.1654+0.1100j |  2.4859+8.5660j | 10.1970-2.8386j\n",
      "   4   |  0.0378-0.1456j | 12.1822+3.8978j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶10 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.0000+0.0000j |  6.8631-6.4140j | -1.8747+3.3335j\n",
      "   1   |  0.0000+0.0000j | -2.2458-8.1544j | -3.9742+9.0256j\n",
      "   2   | -0.2616-0.1169j | -8.3541-5.3209j | 18.1626+9.1805j\n",
      "   3   | -0.1923-0.0887j | -2.4301-1.5727j | 10.1970-2.8386j\n",
      "   4   | -0.1462-0.1106j |  4.0802-5.0905j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶11 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0089-0.0083j | -0.4937-0.2193j | -1.8747+3.3335j\n",
      "   1   | -0.0127-0.0007j | -7.1495-2.9361j | -3.9742+9.0256j\n",
      "   2   | -0.0127+0.0035j |  0.1434-10.9150j | 18.1626+9.1805j\n",
      "   3   | -0.0082-0.0058j |  3.5640-2.7696j | 10.1970-2.8386j\n",
      "   4   |  0.0003+0.0040j | -16.9596+10.8801j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶12 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.2800-0.2938j | 14.2621-3.7378j | -1.8747+3.3335j\n",
      "   1   |  0.2106+0.3177j | 19.4904-8.1270j | -3.9742+9.0256j\n",
      "   2   | -0.3614+0.2206j | -3.9981+2.8259j | 18.1626+9.1805j\n",
      "   3   |  0.0774+0.9998j | -2.4491-0.8723j | 10.1970-2.8386j\n",
      "   4   | -0.0649-0.5728j |  0.1305-4.3524j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶13 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0187-0.0169j | -7.3689-2.9234j | -1.8747+3.3335j\n",
      "   1   | -0.0289-0.0045j | -11.4023+1.8752j | -3.9742+9.0256j\n",
      "   2   | -0.0154-0.0036j |  0.9315+11.4065j | 18.1626+9.1805j\n",
      "   3   | -0.0176-0.0003j |  2.5249-2.5381j | 10.1970-2.8386j\n",
      "   4   | -0.0119+0.0097j |  3.0171-1.3419j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶14 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0289-0.0052j | -3.5613-14.9276j | -1.8747+3.3335j\n",
      "   1   | -0.0184-0.0009j |  4.9911-9.1984j | -3.9742+9.0256j\n",
      "   2   | -0.0287-0.0020j |  2.7048-4.4975j | 18.1626+9.1805j\n",
      "   3   | -0.0081-0.0146j | -5.2899+6.9883j | 10.1970-2.8386j\n",
      "   4   | -0.0006+0.0144j |  7.9403-1.3567j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶15 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0069-0.0416j | -6.7494+1.3920j | -1.8747+3.3335j\n",
      "   1   | -0.0382-0.0256j | -0.0461-0.5584j | -3.9742+9.0256j\n",
      "   2   | -0.0300+0.0212j | -4.4712+1.8307j | 18.1626+9.1805j\n",
      "   3   | -0.0393-0.0021j |  4.6151-2.2586j | 10.1970-2.8386j\n",
      "   4   |  0.0106+0.0281j | 13.6290-3.9309j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶16 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   |  0.0014-0.0078j | -3.1037+0.5360j | -1.8747+3.3335j\n",
      "   1   | -0.0215+0.0037j | -12.0199+11.5328j | -3.9742+9.0256j\n",
      "   2   | -0.0104+0.0168j | -3.2344-5.5225j | 18.1626+9.1805j\n",
      "   3   |  0.0146+0.0007j |  6.6746-0.2510j | 10.1970-2.8386j\n",
      "   4   |  0.0163-0.0034j | -2.7114+6.2557j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶17 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0361-0.0160j | -8.3647+5.6805j | -1.8747+3.3335j\n",
      "   1   | -0.0349+0.0045j |  1.5495-0.6382j | -3.9742+9.0256j\n",
      "   2   | -0.0025+0.0084j |  9.9246-6.2322j | 18.1626+9.1805j\n",
      "   3   | -0.0039-0.0146j | -6.9155-8.2538j | 10.1970-2.8386j\n",
      "   4   | -0.0103+0.0110j |  4.6230+3.6364j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶18 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0133-0.0143j |  1.6755+18.1308j | -1.8747+3.3335j\n",
      "   1   | -0.0074-0.0011j |  5.9583-2.6529j | -3.9742+9.0256j\n",
      "   2   | -0.0179+0.0044j | -1.4075-4.3296j | 18.1626+9.1805j\n",
      "   3   | -0.0135-0.0140j | -0.0800+6.2127j | 10.1970-2.8386j\n",
      "   4   |  0.0029-0.0109j | -1.5067-6.1128j |  5.4647+0.3299j\n",
      "\n",
      "ğŸ“ æ–‡ä»¶19 - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\n",
      "  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\n",
      "  --------------------------------------------------------------------------------\n",
      "   0   | -0.0539-0.0059j | -1.9286+3.3276j | -1.8747+3.3335j\n",
      "   1   | -0.0418-0.0143j | -4.0159+9.0113j | -3.9742+9.0256j\n",
      "   2   | -0.0388-0.0182j | 18.1238+9.1623j | 18.1626+9.1805j\n",
      "   3   | -0.0197-0.0036j | 10.1773-2.8422j | 10.1970-2.8386j\n",
      "   4   | -0.0246-0.0162j |  5.4402+0.3137j |  5.4647+0.3299j\n",
      "\n",
      "==================================================\n",
      "æ·»åŠ å™ªå£°ç»Ÿè®¡æ€»ç»“\n",
      "==================================================\n",
      "ğŸ“‚ æ€»æ–‡ä»¶æ•°: 20\n",
      "ğŸ”· å¤æ•°ä¿¡å·æ–‡ä»¶: 20\n",
      "ğŸ”¶ å®æ•°ä¿¡å·æ–‡ä»¶: 0\n",
      "ğŸ¯ SNRæ§åˆ¶ç²¾åº¦:\n",
      "  å¹³å‡è¯¯å·®: 0.0022 dB\n",
      "  æœ€å¤§è¯¯å·®: 0.0056 dB\n",
      "  âœ… ä¼˜ç§€\n",
      "\n",
      "ğŸ‰ å™ªå£°æ·»åŠ å®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å¹¶éªŒè¯ã€‚\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# å‡è®¾dataæ˜¯ä»ä¹‹å‰çš„åŠ è½½ä»£ç ä¸­è·å–çš„\n",
    "# data = <ä»å‰ä¸€éƒ¨åˆ†ä»£ç ä¸­åŠ è½½çš„æ•°æ®>\n",
    "\n",
    "SNR_dB = -20  # è®¾å®šä¿¡å™ªæ¯”ï¼ˆdBï¼‰\n",
    "\n",
    "noisy_data = []  # ç”¨æ¥å­˜å‚¨åŠ å™ªå£°åçš„æ•°æ®\n",
    "\n",
    "print(f\"=== å¼€å§‹æ·»åŠ å™ªå£° (SNR={SNR_dB}dB) ===\")\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    # æ£€æŸ¥ä¿¡å·ç±»å‹ï¼ˆå®æ•°/å¤æ•°ï¼‰\n",
    "    is_complex = np.iscomplexobj(d)\n",
    "    \n",
    "    if is_complex:\n",
    "        print(f\"æ–‡ä»¶{i}: æ£€æµ‹åˆ°å¤æ•°ä¿¡å·ï¼Œshape={d.shape}\")\n",
    "        \n",
    "        # è®¡ç®—å¤æ•°ä¿¡å·åŠŸç‡\n",
    "        signal_power = np.mean(np.abs(d) ** 2)\n",
    "        \n",
    "        # è®¡ç®—å™ªå£°åŠŸç‡\n",
    "        noise_power = signal_power / (10 ** (SNR_dB / 10))\n",
    "        \n",
    "        # å¤æ•°å™ªå£°ï¼šå®éƒ¨å’Œè™šéƒ¨å„å ä¸€åŠåŠŸç‡\n",
    "        noise_std = np.sqrt(noise_power / 2)\n",
    "        \n",
    "        # ç”Ÿæˆç‹¬ç«‹çš„å®éƒ¨å’Œè™šéƒ¨å™ªå£°\n",
    "        real_noise = np.random.normal(0, noise_std, d.shape)\n",
    "        imag_noise = np.random.normal(0, noise_std, d.shape) * 1j\n",
    "        \n",
    "        # åˆæˆå¤æ•°å™ªå£°å¹¶æ·»åŠ åˆ°ä¿¡å·\n",
    "        complex_noise = real_noise + imag_noise\n",
    "        noisy_signal = d + complex_noise\n",
    "        \n",
    "    else:\n",
    "        print(f\"æ–‡ä»¶{i}: å®æ•°ä¿¡å·ï¼Œshape={d.shape}\")\n",
    "        \n",
    "        # è®¡ç®—ä¿¡å·çš„æ ‡å‡†å·®\n",
    "        signal_std = np.std(d)\n",
    "        \n",
    "        # è®¡ç®—å™ªå£°çš„æ ‡å‡†å·®ï¼Œæ ¹æ®ä¿¡å™ªæ¯”ï¼ˆSNRï¼‰\n",
    "        noise_std = signal_std / (10 ** (SNR_dB / 20))  # æ ¹æ® SNR(dB) è®¡ç®—å™ªå£°æ ‡å‡†å·®\n",
    "        \n",
    "        # ç”Ÿæˆé«˜æ–¯å™ªå£°å¹¶åŠ åˆ°åŸä¿¡å·ä¸Š\n",
    "        noise = np.random.normal(0, noise_std, d.shape)  # å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸ºå™ªå£°æ ‡å‡†å·®\n",
    "        noisy_signal = d + noise  # æ·»åŠ å™ªå£°\n",
    "    \n",
    "    noisy_data.append(noisy_signal)  # ä¿å­˜åŠ å™ªå£°åçš„ä¿¡å·\n",
    "\n",
    "print(\"\\nâœ… æ‰€æœ‰æ–‡ä»¶å™ªå£°æ·»åŠ å®Œæˆï¼\")\n",
    "\n",
    "# è¯¦ç»†çš„éªŒè¯å’Œå¯¹æ¯”\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"å™ªå£°æ·»åŠ æ•ˆæœéªŒè¯\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, (orig, noisy) in enumerate(zip(data, noisy_data)):\n",
    "    actual_noise = noisy - orig\n",
    "    \n",
    "    if np.iscomplexobj(orig):\n",
    "        # å¤æ•°ä¿¡å·éªŒè¯\n",
    "        signal_power = np.mean(np.abs(orig) ** 2)\n",
    "        noise_power = np.mean(np.abs(actual_noise) ** 2)\n",
    "        actual_snr_db = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')\n",
    "        \n",
    "        print(f\"\\næ–‡ä»¶{i} - å¤æ•°ä¿¡å·éªŒè¯:\")\n",
    "        print(f\"  ğŸ“Š ç›®æ ‡SNR: {SNR_dB}dB, å®é™…SNR: {actual_snr_db:.2f}dB\")\n",
    "        print(f\"  âš¡ ä¿¡å·åŠŸç‡: {signal_power:.6f}\")\n",
    "        print(f\"  ğŸ”Š å™ªå£°åŠŸç‡: {noise_power:.6f}\")\n",
    "        print(f\"  ğŸ“ å®éƒ¨å™ªå£°æ ‡å‡†å·®: {np.std(actual_noise.real):.6f}\")\n",
    "        print(f\"  ğŸ“ è™šéƒ¨å™ªå£°æ ‡å‡†å·®: {np.std(actual_noise.imag):.6f}\")\n",
    "        \n",
    "    else:\n",
    "        # å®æ•°ä¿¡å·éªŒè¯\n",
    "        signal_power = np.var(orig)\n",
    "        noise_power = np.var(actual_noise)\n",
    "        actual_snr_db = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')\n",
    "        \n",
    "        print(f\"\\næ–‡ä»¶{i} - å®æ•°ä¿¡å·éªŒè¯:\")\n",
    "        print(f\"  ğŸ“Š ç›®æ ‡SNR: {SNR_dB}dB, å®é™…SNR: {actual_snr_db:.2f}dB\")\n",
    "        print(f\"  âš¡ ä¿¡å·åŠŸç‡: {signal_power:.6f}\")\n",
    "        print(f\"  ğŸ”Š å™ªå£°åŠŸç‡: {noise_power:.6f}\")\n",
    "        print(f\"  ğŸ“ å™ªå£°æ ‡å‡†å·®: {np.std(actual_noise):.6f}\")\n",
    "\n",
    "# æ‰“å°æ£€æŸ¥åŠ å™ªå£°åçš„æ•°æ®æ ·æœ¬\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ•°æ®æ ·æœ¬è¯¦ç»†å¯¹æ¯”\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, (orig, noisy) in enumerate(zip(data, noisy_data)):\n",
    "    print(f\"\\nğŸ“ æ–‡ä»¶{i} - å‰5ä¸ªé‡‡æ ·ç‚¹å¯¹æ¯”:\")\n",
    "    \n",
    "    if np.iscomplexobj(orig):\n",
    "        # å¤æ•°ä¿¡å·æ ·æœ¬å¯¹æ¯”\n",
    "        print(\"  ç´¢å¼• | åŸå§‹ä¿¡å· (å®éƒ¨+è™šéƒ¨j) | åŠ å™ªä¿¡å· (å®éƒ¨+è™šéƒ¨j) | å™ªå£° (å®éƒ¨+è™šéƒ¨j)\")\n",
    "        print(\"  \" + \"-\" * 80)\n",
    "        for j in range(min(5, orig.shape[0])):\n",
    "            orig_val = orig[j, 0] if orig.ndim > 1 else orig[j]\n",
    "            noisy_val = noisy[j, 0] if noisy.ndim > 1 else noisy[j]\n",
    "            noise_val = actual_noise[j, 0] if actual_noise.ndim > 1 else actual_noise[j]\n",
    "            \n",
    "            print(f\"  {j:2d}   | {orig_val.real:7.4f}{orig_val.imag:+.4f}j | \"\n",
    "                  f\"{noisy_val.real:7.4f}{noisy_val.imag:+.4f}j | \"\n",
    "                  f\"{noise_val.real:7.4f}{noise_val.imag:+.4f}j\")\n",
    "    else:\n",
    "        # å®æ•°ä¿¡å·æ ·æœ¬å¯¹æ¯”\n",
    "        print(\"  ç´¢å¼• | åŸå§‹ä¿¡å· | åŠ å™ªä¿¡å· | å™ªå£°\")\n",
    "        print(\"  \" + \"-\" * 50)\n",
    "        for j in range(min(5, orig.shape[0])):\n",
    "            orig_val = orig[j, 0] if orig.ndim > 1 else orig[j]\n",
    "            noisy_val = noisy[j, 0] if noisy.ndim > 1 else noisy[j]\n",
    "            noise_val = actual_noise[j, 0] if actual_noise.ndim > 1 else actual_noise[j]\n",
    "            \n",
    "            print(f\"  {j:2d}   | {orig_val:8.4f} | {noisy_val:8.4f} | {noise_val:8.4f}\")\n",
    "\n",
    "# ç»Ÿè®¡ä¿¡æ¯æ€»ç»“\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"æ·»åŠ å™ªå£°ç»Ÿè®¡æ€»ç»“\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "total_files = len(data)\n",
    "complex_files = sum(1 for d in data if np.iscomplexobj(d))\n",
    "real_files = total_files - complex_files\n",
    "\n",
    "print(f\"ğŸ“‚ æ€»æ–‡ä»¶æ•°: {total_files}\")\n",
    "print(f\"ğŸ”· å¤æ•°ä¿¡å·æ–‡ä»¶: {complex_files}\")\n",
    "print(f\"ğŸ”¶ å®æ•°ä¿¡å·æ–‡ä»¶: {real_files}\")\n",
    "\n",
    "# æ£€æŸ¥SNRæ§åˆ¶ç²¾åº¦\n",
    "snr_errors = []\n",
    "for i, (orig, noisy) in enumerate(zip(data, noisy_data)):\n",
    "    actual_noise = noisy - orig\n",
    "    if np.iscomplexobj(orig):\n",
    "        signal_power = np.mean(np.abs(orig) ** 2)\n",
    "        noise_power = np.mean(np.abs(actual_noise) ** 2)\n",
    "    else:\n",
    "        signal_power = np.var(orig)\n",
    "        noise_power = np.var(actual_noise)\n",
    "    \n",
    "    actual_snr_db = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')\n",
    "    snr_error = abs(actual_snr_db - SNR_dB)\n",
    "    snr_errors.append(snr_error)\n",
    "\n",
    "avg_snr_error = np.mean(snr_errors)\n",
    "max_snr_error = np.max(snr_errors)\n",
    "\n",
    "print(f\"ğŸ¯ SNRæ§åˆ¶ç²¾åº¦:\")\n",
    "print(f\"  å¹³å‡è¯¯å·®: {avg_snr_error:.4f} dB\")\n",
    "print(f\"  æœ€å¤§è¯¯å·®: {max_snr_error:.4f} dB\")\n",
    "print(f\"  {'âœ… ä¼˜ç§€' if avg_snr_error < 0.1 else 'âš ï¸ è‰¯å¥½' if avg_snr_error < 0.5 else 'âŒ éœ€è¦æ£€æŸ¥'}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ å™ªå£°æ·»åŠ å®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å¹¶éªŒè¯ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b23f813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®¡ç®—å¾—åˆ°çš„å¤šæ™®å‹’é¢‘ç§» fd = 266.67 Hz\n",
      "æ·»åŠ å¤šæ™®å‹’é¢‘ç§»åçš„ä¿¡å·ï¼š\n",
      "[array([[  7.53852354+12.21596528j,   9.36289189+14.48596641j,\n",
      "         -4.01749505 -6.99853127j, ...,   0.19828091-11.12670367j,\n",
      "          3.48221492 -8.8144443j ,  -5.65560707+14.77067157j],\n",
      "       [ 14.76130414 +2.10403577j, -13.04936381 -8.53257378j,\n",
      "         12.28425974 -4.24925573j, ...,   0.93486698 -2.12232628j,\n",
      "         -3.88410216 +0.28264447j,  18.81607197 +2.05172531j],\n",
      "       [ -2.06101275 +9.68332712j,   6.53166314 -2.07564782j,\n",
      "         10.86841262 +5.03806088j, ...,   3.91315681 +5.67628209j,\n",
      "          9.20393318 +0.13391789j,   0.49575968 +0.40856746j],\n",
      "       ...,\n",
      "       [  8.9276438  +2.67814778j,  -5.04043967 -7.46207378j,\n",
      "        -12.29256853 +4.05388807j, ...,  -0.13262478+16.23824732j,\n",
      "         11.96014606 -1.00828098j,   1.49303397+10.39551169j],\n",
      "       [  1.42098583+12.63638251j,  -1.80672518 +0.38002514j,\n",
      "          6.08402714 +5.85355285j, ...,   2.34009186-14.01919119j,\n",
      "          4.04878574 +1.17378612j,   1.24538785 +8.11167566j],\n",
      "       [ -5.87124781 -5.51536171j,   2.88767364 +2.64680334j,\n",
      "         -3.89798193 -2.13202362j, ...,   4.2317061  +1.47622093j,\n",
      "          0.02071735 +4.0528868j ,   2.79590128 -3.36664119j]],\n",
      "      shape=(7014, 320)), array([[ 11.61279599 -2.59361901j,  -0.26305946 -0.31047401j,\n",
      "         -1.16079886+11.34797666j, ...,  -1.80405855 +7.0313277j ,\n",
      "         -3.91461668+10.07570347j,   1.9432123 -12.82363628j],\n",
      "       [  3.50969931 +1.43709211j,  -4.94904096 -4.89955423j,\n",
      "         -2.68363296 -6.48088283j, ...,  -6.69296728 +1.13097448j,\n",
      "         -1.32243929-10.02958707j,   3.99888822-11.97634287j],\n",
      "       [  1.04795603 +6.1620124j ,  -7.38851452 -6.14687841j,\n",
      "         -2.75022415 -4.92054659j, ...,  -8.60190715 -7.91152156j,\n",
      "          7.58631588 -9.09396764j,  11.66182913 -8.82582361j],\n",
      "       ...,\n",
      "       [-17.13219629 -1.10877973j,  11.99318382-11.26866915j,\n",
      "         -6.5192651  -8.39701633j, ...,   0.25751477-10.22678304j,\n",
      "         -5.98411155 -1.28720345j,  -9.48710107 +4.44346597j],\n",
      "       [  1.69120351 +1.20000961j,   1.89483212 +7.28546528j,\n",
      "          6.60181886 +0.44201614j, ...,  -0.05220147 -4.67353751j,\n",
      "         -0.13630664+10.90053213j,   0.52684502 -8.81178573j],\n",
      "       [ -2.28327742 -7.66827436j,  -8.36309862+11.90501425j,\n",
      "          6.58040162 +6.73589921j, ...,   9.96661789 +9.54840689j,\n",
      "          4.17836161 +5.89413964j,  -3.90924391 -7.09814096j]],\n",
      "      shape=(6632, 320)), array([[  4.30729615 -5.97551071j,   6.51271735+11.53206751j,\n",
      "        -10.18965862 +3.03520215j, ...,   4.85930154 -2.66537572j,\n",
      "         -3.15037968 +0.99555357j,   5.8856979  +1.84865376j],\n",
      "       [ -3.15934282+14.580624j  ,   1.91881594 -3.60204177j,\n",
      "         -5.83262035 -2.53077933j, ...,   0.32786298 -2.29619861j,\n",
      "         -0.94038118 -3.17539199j,   9.33788387 +6.52704304j],\n",
      "       [  1.39933557 -2.0608423j ,   1.29870055 +3.15537945j,\n",
      "          8.3456648 -14.52019155j, ...,  -5.51111607 -3.75780399j,\n",
      "          6.45012276 -9.68900793j, -11.14325215 -1.52425039j],\n",
      "       ...,\n",
      "       [ -7.77127432 +7.26982455j,   4.32951806 +1.9179208j ,\n",
      "         10.74088562 +6.76809098j, ...,  12.98044782-21.40417046j,\n",
      "         -2.84121198 +3.32276456j,  -0.07334429 +4.44955399j],\n",
      "       [ -3.94214101 +3.91291684j, -12.49781932 +7.54677584j,\n",
      "          8.74039968 +0.99465246j, ...,   6.38143689 -9.25703397j,\n",
      "         -7.6245299  -6.709825j  ,   0.05872129+16.50046277j],\n",
      "       [  9.74766682 -0.13259193j,  -1.9722245  +3.32590693j,\n",
      "         -6.95755606+12.62625496j, ...,   5.39743087 -7.2185042j ,\n",
      "        -11.78198878 +8.34997901j,  -2.43419665 -6.87432564j]],\n",
      "      shape=(8935, 320)), array([[-16.83306811 +3.64038567j,  -5.9866602 +13.07233375j,\n",
      "         -1.3937646  +2.33215256j, ...,  -9.9922311  +0.41551923j,\n",
      "         -4.9879576 -10.15846085j,  -5.61061626+11.76679016j],\n",
      "       [ -9.69614538 +3.57339472j,  -5.17608309 -4.42101251j,\n",
      "         -8.99861793 +4.91263639j, ...,  12.82635261 +4.30966028j,\n",
      "         -0.56130817 +5.60902447j,  -9.05490651 +7.40943322j],\n",
      "       [ -6.39914039+11.0639558j ,  -2.92510045 -9.94830928j,\n",
      "          7.70768358 -6.09698295j, ...,   8.48213592 -3.54962946j,\n",
      "         -2.87400959 +1.87822993j,  -1.68703617 -4.40830181j],\n",
      "       ...,\n",
      "       [ -3.49891085 +8.71706722j,  -3.11275827-12.38254187j,\n",
      "         -2.62713921 +4.32686312j, ...,   9.00977689 +7.49066256j,\n",
      "        -18.70806249-10.98651806j,  10.05320507 +1.63782961j],\n",
      "       [  3.22014206 +2.91269486j,  -3.39067212+12.74662965j,\n",
      "         -3.28282613 -2.79913721j, ...,   2.92018083 +2.68686092j,\n",
      "         -1.22427071+11.60156529j,  -5.19482565 +0.41207899j],\n",
      "       [ 11.45493671 -9.52095879j,   5.78623432 +0.12967109j,\n",
      "          4.93019383 -4.2429051j , ...,  -2.25314198 +3.20173856j,\n",
      "          4.61034012 +1.63228004j,  -9.86302175 -1.79224696j]],\n",
      "      shape=(7776, 320)), array([[ -4.5810946  +6.25705546j, -13.44908025 +4.4443258j ,\n",
      "          1.96013907 -0.04143809j, ...,  -8.75444237 -2.86786777j,\n",
      "          5.5931608 +14.00110376j,  -9.90568338 +2.59061235j],\n",
      "       [  4.50623578 -3.19174471j,   2.77042509 +6.72043385j,\n",
      "         -2.42906737 +5.6169797j , ...,   6.32896544 +0.8882143j ,\n",
      "          8.21384952 +2.91393824j,   1.210442   +1.31646438j],\n",
      "       [ -3.24545288 -1.07524289j,  -4.0252185  +0.18705844j,\n",
      "          4.64913003 -8.28166235j, ...,   0.69696776-11.73516511j,\n",
      "          4.91601413 +2.2621639j ,  -8.15595809 +8.71410691j],\n",
      "       ...,\n",
      "       [-14.76318366 -3.96845895j,  -5.77220374 -5.3039497j ,\n",
      "          6.3843685 -12.48388225j, ...,   2.44919254 +1.61156872j,\n",
      "          2.19537743 +3.03598335j,  10.19115558 -6.59450997j],\n",
      "       [ -1.42608642 -3.24591331j,  -2.77893246 +8.06656416j,\n",
      "         -6.66035082 -1.41942242j, ...,  -4.0795095  -2.1799295j ,\n",
      "         -8.25771755 -9.87229388j,  -2.01617693 -8.1558939j ],\n",
      "       [ 13.99930504 -1.78259398j,  10.399062   +7.45092299j,\n",
      "        -10.96425643 +0.15068781j, ...,  -9.83113489 +2.3833049j ,\n",
      "         15.28863885 +0.31605532j,  -9.83436214 +4.96298218j]],\n",
      "      shape=(7410, 320)), array([[ -3.35894292+11.90359564j,  11.94694021 -7.53638991j,\n",
      "        -17.72409599 -7.91128369j, ...,  -7.4252944  +2.53138393j,\n",
      "          2.10577494 -5.49019855j,   1.044907   -4.08694958j],\n",
      "       [ -2.85436556 +3.5367611j ,   3.74115067 +6.08812211j,\n",
      "         -4.85670454 +4.83064283j, ...,  -6.25373894 +2.82750653j,\n",
      "         -0.76170544 -5.64945327j,  18.21474342 +6.34647025j],\n",
      "       [ -7.30135414 +8.53393068j,   7.24706607 -8.26699693j,\n",
      "          0.97608237 -7.74088365j, ...,  -0.42696891 +2.76377592j,\n",
      "          5.7893347  -0.31852657j,  -6.28420933 +5.14892961j],\n",
      "       ...,\n",
      "       [  3.73615611 +3.62694188j,  -7.46954007 +1.42109126j,\n",
      "        -10.51221878 -0.92117369j, ...,  -4.59296505 -0.08144029j,\n",
      "        -10.84700906 -9.92326455j, -12.10086088-11.9046195j ],\n",
      "       [ -4.24628486 +0.49167532j,  -6.79697501 +0.80434468j,\n",
      "         -4.99005139+11.18954803j, ...,   1.34318806 +1.81835859j,\n",
      "          2.41772983 +3.23558411j,  -0.53393174 +6.67416928j],\n",
      "       [ -2.65511396 +0.81865698j, -13.07475001 +9.0996429j ,\n",
      "          1.68659699 -5.99329316j, ...,   1.06217155 +6.88645506j,\n",
      "         -0.94762947 +6.45876556j,  -5.40894642 +2.90661401j]],\n",
      "      shape=(6274, 320)), array([[  2.96816359 +4.92880521j,  -4.53127421 -1.16007978j,\n",
      "          2.6343969  +1.43213146j, ...,   5.04748326 +0.65872618j,\n",
      "         -1.96971921 -2.25227938j,   3.35957602 +1.0298153j ],\n",
      "       [-13.69640302 -1.53752326j,   0.6527572 -11.12028204j,\n",
      "          6.68013137 -4.09468175j, ...,   5.54282129 +4.34210607j,\n",
      "         -1.49550551 +6.76223797j,   3.01459724 +1.76342867j],\n",
      "       [ -5.42794266-17.82618436j,   0.88588621+10.11332452j,\n",
      "         -3.78974835 -1.58040783j, ..., -11.52215203 +3.867966j  ,\n",
      "         11.69883931 -7.49463233j,   0.48194423+21.57436468j],\n",
      "       ...,\n",
      "       [ -2.63022354 -1.92858756j,   1.14537435 +2.7342592j ,\n",
      "         -3.92780895 -1.7105107j , ...,   7.13790371 -6.95650337j,\n",
      "         -0.21140103 +4.88996534j, -10.23310695 +8.97321427j],\n",
      "       [  7.29850274 +2.99227053j,  -5.06353364 +1.89596713j,\n",
      "         -5.90741385 -5.94602681j, ...,   3.06623517 +3.01530359j,\n",
      "         -1.4274089  -3.55086489j, -10.37506226 -1.92626754j],\n",
      "       [ 12.91259769 -2.67317695j, -16.53688742 -2.99644247j,\n",
      "         -4.23928884 -7.00623148j, ...,   2.46412182 +3.90232447j,\n",
      "        -13.35629083 +1.89126321j,  -1.45129031 -0.96448724j]],\n",
      "      shape=(5706, 320)), array([[ -3.21266677-10.64508465j,  -4.62718271 +2.48976176j,\n",
      "         16.46404352 -7.43898192j, ...,  -0.86166001-13.27642618j,\n",
      "         -2.71256458 -9.51301764j,   1.6915215  -9.72964298j],\n",
      "       [  7.81555826 -0.15697653j, -13.04486127 +1.68549548j,\n",
      "          3.87713908 -9.24537698j, ...,   3.96776462 -6.85573538j,\n",
      "        -17.00512785-10.9003433j ,   9.04643655-10.59124099j],\n",
      "       [  4.88232318 -3.06980934j,  16.90687463 -2.85709055j,\n",
      "          1.99138537 +6.98266365j, ...,  -6.06968136 -6.86209999j,\n",
      "          1.59462122 +9.00461151j,  -6.736033   -3.6535181j ],\n",
      "       ...,\n",
      "       [ -5.96954224 -0.79301095j,  11.84463254 -6.83428189j,\n",
      "          2.7785226 -10.62340588j, ...,   1.24816502 +4.37445587j,\n",
      "         -4.6640598 -10.89800367j,  -0.35632639 -4.1500092j ],\n",
      "       [ -5.4638131  +5.06721375j,   1.76673628 -0.72263175j,\n",
      "          8.06356871 +7.18165764j, ...,  -5.37319405-13.74766591j,\n",
      "         16.18469568 -6.9164694j ,   2.66075267 +7.31958163j],\n",
      "       [  7.73799661 -5.13695084j,  -7.81103253 +7.83401581j,\n",
      "         -6.90640289+10.14717023j, ...,   6.24576881 +3.05762358j,\n",
      "          0.66930966 +3.64748031j,   3.98680393 +6.47600305j]],\n",
      "      shape=(12968, 320)), array([[ -0.8338821 -11.62468622j,  11.88465606 +7.9806735j ,\n",
      "          1.83760631 -0.56476528j, ...,  -0.03930729+10.67581433j,\n",
      "        -16.01521363 -7.97418038j,   4.34480607 +1.44252512j],\n",
      "       [  2.80730087 +3.53879461j,  -2.59056716-15.44205833j,\n",
      "          4.40555109 -2.40766455j, ...,   7.57750258 +8.31294348j,\n",
      "        -10.91402127 -5.54030048j,  -8.06840718 +1.20886767j],\n",
      "       [ -2.44350962 -2.13420673j,  13.34754042 -3.04801119j,\n",
      "          0.73116509 -0.41581716j, ...,  -1.08745013 +9.77346j   ,\n",
      "         -1.70151027 -4.58994366j,  -3.47240878 +0.57970671j],\n",
      "       ...,\n",
      "       [ -9.17025162 -8.79406408j,   2.72205708 +9.99897288j,\n",
      "         -3.40206612 -9.03349158j, ...,   8.82179374 -6.96680468j,\n",
      "         -3.13585924 +9.29667415j,   4.00479362 +4.09421974j],\n",
      "       [  5.99796464 +7.20877918j, -14.46506805 +1.16730778j,\n",
      "          3.63797398 +3.59207659j, ..., -13.31570257-17.1927176j ,\n",
      "         13.69331376 -7.5627395j ,  -3.00121741 -3.63699947j],\n",
      "       [  5.80882673+16.35232214j,  25.34445137 +0.79120201j,\n",
      "          0.62155508 -4.91473778j, ...,   4.63134633 +2.12496314j,\n",
      "          4.22278328 +1.86881534j,  -4.96921084 +0.48922543j]],\n",
      "      shape=(9508, 320)), array([[ -2.71493851 +4.60683258j,  -6.12751037 -1.1681939j ,\n",
      "          7.12689386-10.98912961j, ..., -18.1998239  -3.87785125j,\n",
      "         -5.89747636-12.34938693j,  12.0685704  +1.48280261j],\n",
      "       [  8.17939159+13.67361288j, -13.20853683+14.40961098j,\n",
      "          1.70683187-11.25111132j, ...,  -3.92600614 -4.30660527j,\n",
      "          1.10008765 -7.28621082j,   8.93619928 -2.67346384j],\n",
      "       [ -7.6356617  +0.59474128j,   7.16883316 -0.95643461j,\n",
      "         -2.28295021+18.98615515j, ...,   5.22403736 -1.96334173j,\n",
      "         -1.95538765 +6.55647246j,   0.12887898+10.55398548j],\n",
      "       ...,\n",
      "       [  3.70969619 +3.40411456j,  -3.81305014 -2.79257765j,\n",
      "          1.6630459  -0.2652827j , ...,   0.22984104 -7.30739806j,\n",
      "         -8.54310378 -8.21695212j,  -4.6065017 -19.0361149j ],\n",
      "       [  7.08651078 +6.60572403j,  -0.21590928 +2.59576085j,\n",
      "        -12.20626554 -8.10869249j, ...,   1.46179316 -8.14386267j,\n",
      "        -13.94497155 +0.54574162j,   3.86694935 +4.7554649j ],\n",
      "       [ -0.75044022 +4.67649907j,  -6.25252488 -4.25416478j,\n",
      "          9.18628513 +5.65834526j, ...,   3.53108694 -5.88535j   ,\n",
      "         -6.70532641 -3.02202332j,  -5.46664335 +1.54065138j]],\n",
      "      shape=(3343, 320)), array([[  6.86306769 -6.41397265j,  -0.56535481 -2.86371232j,\n",
      "         -2.01781284 -6.87311414j, ...,  -3.43665567 -1.65177324j,\n",
      "         -5.03376139 -4.49739606j, -12.64653377 -4.34113086j],\n",
      "       [ -2.24583488 -8.15438925j,  -8.74891398 +5.0417946j ,\n",
      "          5.22794623 -3.8399336j , ..., -17.56425174 -2.85605931j,\n",
      "          3.67326386 +5.75411381j,  -5.1099905  -5.75335537j],\n",
      "       [ -8.35414908 -5.32094722j,  -4.67801056 +3.11788156j,\n",
      "         -6.56305384 -4.47687271j, ...,  -3.68873096 +4.67426126j,\n",
      "         -0.95264802-15.93496272j,   1.58816831 +6.44501596j],\n",
      "       ...,\n",
      "       [ -0.20869589+13.42244247j,  -3.10010231 +0.40850808j,\n",
      "          4.09458378-21.42724621j, ..., -12.27632608 -0.37087329j,\n",
      "          1.78196876 +3.18837435j,   4.14932031-10.69701218j],\n",
      "       [-18.0001141  -8.35914037j,  -7.83459966+11.13916045j,\n",
      "         -4.73622333 -4.85379205j, ...,   5.14986753 -5.69945225j,\n",
      "         -9.82712568 -7.2381586j ,   1.28205308 -8.67037358j],\n",
      "       [-10.9770198  -8.56889152j,   4.85227999 +1.34254371j,\n",
      "         -3.14959087 -9.70411362j, ...,   9.67876389 -8.22281395j,\n",
      "          6.34607904 -3.52661166j,   5.89195373 +4.7671027j ]],\n",
      "      shape=(4756, 320)), array([[ -0.49365456 -0.21928939j,   3.7428074  +8.22919848j,\n",
      "         -3.65316856-11.47060305j, ...,  -1.9063863  +0.55117291j,\n",
      "          7.89051203 -4.75629046j,   7.54091308 -8.35784452j],\n",
      "       [ -7.14951752 -2.93608317j,  10.41586372 +5.10494202j,\n",
      "         -9.86044286 +5.03256518j, ...,   0.07649161 -0.82103231j,\n",
      "          5.22778407 +0.67553876j,  -6.80834686 +1.91909242j],\n",
      "       [  0.14341189-10.91501563j,  -3.04291531-12.16129863j,\n",
      "          0.78238082 +1.70889558j, ...,   7.58405454 +7.87953812j,\n",
      "          5.4797246 +14.52178184j,   5.10431954 +5.96646428j],\n",
      "       ...,\n",
      "       [-14.43739155 +2.40426654j,  -5.18541506 -2.44120424j,\n",
      "         -0.28343021 +7.19821743j, ...,  13.33050362 -4.49636595j,\n",
      "         -3.52367437 +3.49126469j,   6.87023429 -3.23138551j],\n",
      "       [ 20.80924635+14.8440149j ,  -5.06487786 +1.61571043j,\n",
      "          3.22935544 -1.71585944j, ...,  -4.81868195 -3.40208621j,\n",
      "          6.30915301 -6.74248589j,  -8.85909946 +5.89796561j],\n",
      "       [ -2.64670735 -7.48363531j,  -5.81970541 -6.03392257j,\n",
      "         -6.85118371+11.57137642j, ...,   2.01195752 -4.86195014j,\n",
      "        -10.22601663-12.16452503j,   1.43043388+12.9350057j ]],\n",
      "      shape=(6316, 320)), array([[ 14.26210988 -3.73780573j,   2.46889192 -0.61836976j,\n",
      "         -1.25124245+10.13641665j, ...,   1.66633285 -1.92615164j,\n",
      "          4.61445174 +2.46004023j, -16.27467013 -6.29060536j],\n",
      "       [ 19.49036396 -8.12702617j,  -1.35360461 +8.95263751j,\n",
      "         -7.52440596 +4.13734445j, ...,   1.98081082 -5.0087942j ,\n",
      "         13.92909192 -0.33995971j,  14.189427   +7.09715398j],\n",
      "       [ -3.99812043 +2.82591909j,  -2.15974472 +0.98749117j,\n",
      "          2.38515237 -1.239594j  , ...,  -7.90734125+18.88677705j,\n",
      "          1.99635546 +5.93997902j,  -4.11043761 +1.44771664j],\n",
      "       ...,\n",
      "       [  1.65262395 +2.79879121j,  -1.66416607 -1.62237852j,\n",
      "          7.30381191-14.78574405j, ...,   5.0170565  -2.2586403j ,\n",
      "        -12.85002062 -0.98080095j,   8.04343317 -2.47339568j],\n",
      "       [  7.27066854-10.08182628j,   5.66130552 +0.32092368j,\n",
      "          6.29345034 +2.6381467j , ...,   5.2178804  +5.2044027j ,\n",
      "         -0.66899013 -8.23816371j,   1.79666482 +3.22116219j],\n",
      "       [  0.66650458 +8.16077314j,   1.21548291 +2.81193639j,\n",
      "          6.48718092 -5.74548172j, ...,   6.16403678 -9.2140167j ,\n",
      "         -7.69762309 -4.3149612j , -13.55444134 +1.3550684j ]],\n",
      "      shape=(5592, 320)), array([[ -7.36891565 -2.92344396j,  -2.34909167-15.04088381j,\n",
      "          6.85171547 -3.60185396j, ...,  -4.47481049 +4.44314708j,\n",
      "         -4.21423667 -2.80433927j,   0.78518247 +4.13432887j],\n",
      "       [-11.40230824 +1.87520366j,   6.82462507 -1.86910386j,\n",
      "          2.64921417 +1.84008628j, ...,  -4.43563392 +4.86477863j,\n",
      "          4.47755218 +5.60738161j,  -6.74971968-10.28350891j],\n",
      "       [  0.93151058+11.40654461j,  -7.44518745 -4.46100266j,\n",
      "          2.14625277 +8.22910527j, ...,  12.03918108 +6.61366053j,\n",
      "         18.56260498-15.3226515j ,  -8.66877084 -2.75245397j],\n",
      "       ...,\n",
      "       [ 17.8841481  +4.34154501j,  16.35222121+16.22957309j,\n",
      "          2.0796584  -5.49313182j, ...,   2.93390487 +8.95477974j,\n",
      "          7.70003909 -6.17197387j, -14.33515907 -4.76796817j],\n",
      "       [  4.61063503+10.78776773j,   9.10510774 -4.83531275j,\n",
      "        -12.30694955 -1.63553116j, ...,  -0.10834528 -3.74808665j,\n",
      "          4.34062884 +0.84448802j,   0.40143004 -6.11541182j],\n",
      "       [  7.28349546 +7.88563821j,  -0.02925258 -7.06515831j,\n",
      "         -5.12270979 +4.69652965j, ...,  -1.1778218  +6.2683237j ,\n",
      "         -6.06773572 +2.08115872j,   1.90120654+12.5395811j ]],\n",
      "      shape=(5536, 320)), array([[-3.56128198e+00-14.92762328j, -9.21663677e+00 -0.69181725j,\n",
      "        -3.53289581e+00 -1.76049349j, ..., -4.06458410e+00 +3.65250419j,\n",
      "         5.99046726e+00 -5.47143011j,  8.66042465e+00+10.33995389j],\n",
      "       [ 4.99106855e+00 -9.19839201j,  1.03895857e+01 +3.08446542j,\n",
      "         5.38401669e+00+12.53077799j, ..., -2.04696010e-03-14.61768614j,\n",
      "         2.63443032e-01 -0.39560899j,  5.35440493e+00 +4.70829651j],\n",
      "       [ 2.70475897e+00 -4.49748099j, -3.21684928e+00 +1.42235574j,\n",
      "        -1.05577963e+01 -5.64190787j, ..., -7.82191536e-01 -8.41659876j,\n",
      "        -1.14196332e+01 -7.35303476j, -6.61813979e+00 +4.51654592j],\n",
      "       ...,\n",
      "       [ 4.40048061e+00-11.98293454j,  1.18878916e+01 -3.45419622j,\n",
      "        -1.38113273e+01+15.65030991j, ...,  1.63279000e+01 +2.29092398j,\n",
      "         3.56830711e+00 -5.28041183j, -5.57516969e+00+10.12455746j],\n",
      "       [ 1.02023601e+00 -1.24965527j,  6.14358011e+00+10.06049709j,\n",
      "         1.18154269e+01 +2.28043128j, ..., -9.25600920e+00 -2.13312049j,\n",
      "        -1.63110483e+00 +4.32895989j, -6.66421879e+00 +3.87851809j],\n",
      "       [ 8.94057001e+00+12.80654074j, -7.87370196e+00-14.63973512j,\n",
      "         4.25306322e-01 -4.5708826j , ..., -9.62747898e+00 -1.89939944j,\n",
      "        -9.81503446e-01 +4.64085417j, -5.04953622e+00-10.31370193j]],\n",
      "      shape=(6669, 320)), array([[ -6.74935974 +1.3919747j ,   0.12005813 -8.28989269j,\n",
      "          9.37289411 +1.821208j  , ...,   1.95285406 +7.2958166j ,\n",
      "          1.13908832-11.42434387j,  -2.93566648 +4.47149035j],\n",
      "       [ -0.04610347 -0.5584185j ,   9.64480503 +3.63258976j,\n",
      "          7.86559682 -3.04036363j, ...,   5.42840032 -1.08906531j,\n",
      "          4.51856022 +1.36224589j,  -2.50816462 +3.00049444j],\n",
      "       [ -4.4712161  +1.83065622j,   2.26760596 +0.57836098j,\n",
      "         -2.55617075 +0.70297586j, ...,  -5.33586192-10.4239104j ,\n",
      "        -11.31956451+13.89190828j,   2.52750544 -2.79619024j],\n",
      "       ...,\n",
      "       [  0.0545523  +4.55701702j,  -9.5915544  -4.41151777j,\n",
      "         -1.69888863 -9.14342847j, ..., -11.75704422 +1.06542333j,\n",
      "         -0.13326147 +0.34625377j,   5.56052271 -5.45390514j],\n",
      "       [ -0.53414765 +3.43747676j,  -1.7521756 -10.26278646j,\n",
      "         -0.13161069 -2.8128795j , ...,  -0.58161374 -4.85963538j,\n",
      "         -8.96389168-10.91643544j,   0.05429704-14.61692341j],\n",
      "       [ -2.80734386 -2.44044167j, -17.34268885 -7.15728923j,\n",
      "         -5.13274415+10.29000554j, ...,   2.50016081+11.32201128j,\n",
      "         -7.54763866 +7.19245822j,  -2.77688053 -2.92156299j]],\n",
      "      shape=(5237, 320)), array([[ -3.10366721 +0.53604669j,  -4.08557439 +3.20142619j,\n",
      "         -6.43549516 -3.66300225j, ...,   8.62621109 -6.75662327j,\n",
      "         11.74385742 +1.03246962j,   0.23284501 -4.39140549j],\n",
      "       [-12.01989437+11.53278617j,  -2.95846234 -5.12658922j,\n",
      "         -0.44276906 +8.32850277j, ...,  -6.22883721 +0.35523511j,\n",
      "          1.79135359 +8.97961417j,   7.40173349 +8.96236811j],\n",
      "       [ -3.23443479 -5.52250592j,   2.08321587-15.56353987j,\n",
      "         -6.35001741 +1.94375306j, ...,   0.59718432 +0.24102771j,\n",
      "         -2.27429297 +9.6463365j ,  -0.96643369 +1.92484102j],\n",
      "       ...,\n",
      "       [  4.46766185 -0.05914394j,   4.94876198 -6.7340144j ,\n",
      "          0.61083326 -1.81754086j, ...,  -1.96830873 +1.66714272j,\n",
      "          1.73961414 +0.94485842j, -12.93877731 -7.44164943j],\n",
      "       [  4.07057877 +4.04542499j,  -4.7440979  -4.31952237j,\n",
      "        -10.60341589 +3.11295144j, ...,  -3.94352577 +1.18058989j,\n",
      "         -1.07593922 +5.74054614j,  -1.46747978 +6.29317144j],\n",
      "       [ 12.17898094 -5.72243679j,   1.59318251 -4.20575246j,\n",
      "          1.04246585 +5.1210451j , ...,  -0.1896783  +3.47909078j,\n",
      "         -0.6162319  +1.28745291j,  -1.198833   +3.44285649j]],\n",
      "      shape=(5460, 320)), array([[ -8.36471677 +5.68048305j,  11.67809618 -0.80305946j,\n",
      "          7.50642947 -5.09952586j, ..., -11.01240421 +8.76239156j,\n",
      "          7.04944855-11.96704401j,   3.7396369 +10.09776412j],\n",
      "       [  1.5494529  -0.63821969j,   1.46489439 -2.10273607j,\n",
      "         -5.52826798 +7.37417591j, ...,  -0.37883416 -2.74544125j,\n",
      "          3.10818336 +8.38263831j,  -9.33771193 +9.53704286j],\n",
      "       [  9.92455114 -6.23215387j,   2.59379893+15.66076937j,\n",
      "         -3.94074954 -1.9415119j , ...,  -4.76367575 -2.18153108j,\n",
      "          8.32141767 +5.42621759j, -10.83365527 -2.17728091j],\n",
      "       ...,\n",
      "       [ -6.11075212 -0.56598332j,   3.86082966 -4.18144898j,\n",
      "          0.94711568 -1.00492465j, ...,   3.64915818-19.90632829j,\n",
      "          0.67162017 -2.22472335j,   3.73677459-14.39030675j],\n",
      "       [ -0.68257965 +9.68781825j, -10.02363058 -7.2465149j ,\n",
      "          8.86037726 -1.88832435j, ...,  -5.51618734 -4.54482299j,\n",
      "         -2.81110927 -6.66851061j,  -1.8239294  +1.98945722j],\n",
      "       [ -1.68068467+13.72556987j,  -1.55484665 +7.56089314j,\n",
      "         -2.51047643 -1.42882209j, ...,  -2.92551998 -4.26306124j,\n",
      "         -2.9745065  -2.69141228j,   8.67051757 +0.18957605j]],\n",
      "      shape=(8926, 320)), array([[  1.67547214+1.81307505e+01j,   3.79999089-5.12448343e+00j,\n",
      "         -9.94246233+4.98584663e+00j, ...,   2.6140214 +1.05902733e+01j,\n",
      "          2.76597641-4.03685694e+00j,   7.4018063 +3.00192180e+00j],\n",
      "       [  5.95830006-2.65285797e+00j,  -4.13502797+5.34390134e+00j,\n",
      "         -3.1708634 +1.25262452e-02j, ..., -10.52520216+2.89434494e-01j,\n",
      "         -6.40892801+4.89836506e+00j,   9.4911948 -7.54536394e+00j],\n",
      "       [ -1.4075095 -4.32956354e+00j,   1.06273906-2.60019862e+00j,\n",
      "        -13.88294796+9.79280516e+00j, ...,  -3.34207775+9.02778572e+00j,\n",
      "          0.86367926-8.13444341e+00j,   6.91511369+6.12742379e+00j],\n",
      "       ...,\n",
      "       [  0.72069285-1.00100091e+01j,   3.53599774+1.30058257e+00j,\n",
      "         -6.01913392-2.73925966e+00j, ...,  -3.9805777 -8.82343944e-01j,\n",
      "         10.64908363+2.06738845e+00j,  -4.06854528-8.08459906e+00j],\n",
      "       [ -4.76428244+2.84712474e+00j,   0.07240256-9.53947403e+00j,\n",
      "          9.36749084+1.15830391e+00j, ...,  -1.99343556+1.73305302e+00j,\n",
      "        -10.11009236-1.13529688e+01j,  -5.60771352+8.61888078e-01j],\n",
      "       [ -3.72418579+8.47961685e+00j,   6.10056079+6.20820219e+00j,\n",
      "         -5.36122991-5.51920523e+00j, ...,   5.62513119-3.68482748e+00j,\n",
      "        -15.1905104 +3.33497982e+00j,   6.14407532+1.87158004e+01j]],\n",
      "      shape=(7614, 320)), array([[ -1.92864628 +3.32761995j,  -4.65087878 +6.25010678j,\n",
      "        -10.7150968  +0.65255706j, ...,  -8.49953631 -2.96227315j,\n",
      "         -6.06340722 -6.19886947j,  -4.06326987 -4.59798112j],\n",
      "       [ -4.01594304 +9.01129167j,   0.23317753 +2.40212325j,\n",
      "        -13.90506789 -3.41839954j, ...,   1.29695163 +7.15809747j,\n",
      "          1.64547424 -6.86618808j,  -7.0408236  +6.09928431j],\n",
      "       [ 18.12375974 +9.16227496j,  -0.95598258 -5.45951112j,\n",
      "          1.29221703 -6.90120351j, ...,  -2.5086671  -0.27809386j,\n",
      "          6.96947871-10.2823695j ,  -6.44467832 +1.81794869j],\n",
      "       ...,\n",
      "       [ 11.71773657 +2.53064881j,  -2.80640051 +4.55867425j,\n",
      "          4.66547242 +6.76095699j, ...,  11.89948649 -7.77799394j,\n",
      "          9.87486788 -0.59835551j,   0.86221696 -0.40065599j],\n",
      "       [ 18.19973322 -0.31640474j,  -1.60799952 -8.04635979j,\n",
      "        -12.47376972 -1.76583056j, ...,  -0.63424826 -3.83044981j,\n",
      "         13.2698061 +15.69830165j,   5.19420684 -5.66282654j],\n",
      "       [ -5.62623684 -3.11362469j, -11.72694277 -2.53678134j,\n",
      "         -1.92013121 +7.05563125j, ...,  -6.91693214 +3.58377275j,\n",
      "         -3.41952778 -1.14525768j,   4.66574157 -6.2001315j ]],\n",
      "      shape=(7232, 320))]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_doppler_shift(v, fc):\n",
    "    \"\"\"\n",
    "    æ ¹æ®ç§»åŠ¨é€Ÿåº¦ v (m/s) å’Œè½½æ³¢é¢‘ç‡ fc (Hz) è®¡ç®—å¤šæ™®å‹’é¢‘ç§»\n",
    "    \"\"\"\n",
    "    c = 3e8  # å…‰é€Ÿ m/s\n",
    "    v = v/3.6 # æ¢ç®—æˆm/s\n",
    "    return (v / c) * fc\n",
    "\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    \"\"\"\n",
    "    ç»™IQä¿¡å·åŠ å¤šæ™®å‹’é¢‘ç§»\n",
    "    signal: shape (num_channels, num_samples)ï¼Œå¤æ•°IQä¿¡å·\n",
    "    fd: å¤šæ™®å‹’é¢‘ç§» (Hz)\n",
    "    fs: é‡‡æ ·ç‡ (Hz)\n",
    "    \"\"\"\n",
    "    num_channels, num_samples = signal.shape\n",
    "    t = np.arange(num_samples) / fs  # æ—¶é—´è½´\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)  # å¤æŒ‡æ•°\n",
    "    return signal * doppler_phase\n",
    "\n",
    "# ä¾‹å­\n",
    "fs = 20e6  # é‡‡æ ·ç‡ï¼Œæ¯”å¦‚1 MHz\n",
    "fc = 2.4e9  # è½½æ³¢é¢‘ç‡ï¼Œæ¯”å¦‚2.4 GHz Wi-Fi\n",
    "v = 120  # ç§»åŠ¨é€Ÿåº¦ï¼Œ(km/h)\n",
    "\n",
    "fd = compute_doppler_shift(v, fc)  # å…ˆè®¡ç®—å¤šæ™®å‹’é¢‘ç§»\n",
    "print(f\"è®¡ç®—å¾—åˆ°çš„å¤šæ™®å‹’é¢‘ç§» fd = {fd:.2f} Hz\")\n",
    "\n",
    "# å‡è®¾ data æ˜¯ä½ ä¹‹å‰è¯»å‡ºæ¥çš„listï¼Œæ¯ä¸ªæ˜¯ shape (ä¿¡å·æ•°é‡, é‡‡æ ·ç‚¹æ•°)\n",
    "data_with_doppler = []\n",
    "for sig in noisy_data:\n",
    "    shifted_sig = add_doppler_shift(sig, fd, fs)\n",
    "    data_with_doppler.append(shifted_sig)\n",
    "\n",
    "print(\"æ·»åŠ å¤šæ™®å‹’é¢‘ç§»åçš„ä¿¡å·ï¼š\")\n",
    "print(data_with_doppler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01de1c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœ€ç»ˆæ•°æ® shape: torch.Size([138904, 320])\n",
      "æœ€ç»ˆæ ‡ç­¾ shape: torch.Size([138904])\n",
      "è®­ç»ƒé›†å¤§å°: 111123\n",
      "æµ‹è¯•é›†å¤§å°: 27781\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# === æ‹¼æ¥æ•°æ® ===\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for device_idx, device_signals in enumerate(data_with_doppler):\n",
    "    device_labels = np.full((device_signals.shape[0],), device_idx)\n",
    "    all_data.append(torch.tensor(device_signals, dtype=torch.float32))\n",
    "    all_labels.append(torch.tensor(device_labels, dtype=torch.long))\n",
    "\n",
    "all_data = torch.cat(all_data, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "print(f\"æœ€ç»ˆæ•°æ® shape: {all_data.shape}\")\n",
    "print(f\"æœ€ç»ˆæ ‡ç­¾ shape: {all_labels.shape}\")\n",
    "\n",
    "dataset = TensorDataset(all_data, all_labels)\n",
    "\n",
    "# === å›ºå®šåˆ’åˆ†è®­ç»ƒé›† + æµ‹è¯•é›† ===\n",
    "train_size = int(0.8 * len(dataset))  # 80% è®­ç»ƒ\n",
    "test_size = len(dataset) - train_size # 20% æµ‹è¯•\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\n",
    "print(f\"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5ffb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== æ•°æ®å¢å¼ºï¼šå¯¹è®­ç»ƒé›†æ·»åŠ é«˜æ–¯å™ªå£° ====\n",
    "\n",
    "def add_noise_to_dataset(dataset, noise_std=0.01):\n",
    "    noisy_data = []\n",
    "    noisy_labels = []\n",
    "    for x, y in dataset:\n",
    "        noise = torch.randn_like(x) * noise_std\n",
    "        noisy_x = x + noise\n",
    "        noisy_data.append(noisy_x)\n",
    "        noisy_labels.append(y)\n",
    "    noisy_data = torch.stack(noisy_data)\n",
    "    noisy_labels = torch.tensor(noisy_labels)\n",
    "    return TensorDataset(noisy_data, noisy_labels)\n",
    "\n",
    "train_dataset = add_noise_to_dataset(train_dataset, noise_std=0.01)  # å¯è°ƒèŠ‚ std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e0edaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "====== Fold 1/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.59batch/s, train_accuracy=7.21, train_loss=3.02]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 141.09batch/s, val_accuracy=9.61, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 3.0225, Train Acc: 7.21%, Val Loss: 2.9604, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.04batch/s, train_accuracy=7.84, train_loss=3]  \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 128.91batch/s, val_accuracy=9.61, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: Train Loss: 2.9965, Train Acc: 7.84%, Val Loss: 2.9604, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.64batch/s, train_accuracy=7.96, train_loss=2.99]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 127.39batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: Train Loss: 2.9901, Train Acc: 7.96%, Val Loss: 2.9571, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.40batch/s, train_accuracy=8.27, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 137.86batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: Train Loss: 2.9825, Train Acc: 8.27%, Val Loss: 2.9569, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.05batch/s, train_accuracy=8.63, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 126.12batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: Train Loss: 2.9764, Train Acc: 8.63%, Val Loss: 2.9596, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.93batch/s, train_accuracy=8.75, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 136.28batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: Train Loss: 2.9727, Train Acc: 8.75%, Val Loss: 2.9570, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.01batch/s, train_accuracy=8.87, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 96.07batch/s, val_accuracy=9.61, val_loss=0.733]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: Train Loss: 2.9697, Train Acc: 8.87%, Val Loss: 2.9569, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.35batch/s, train_accuracy=9.11, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 135.45batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: Train Loss: 2.9662, Train Acc: 9.11%, Val Loss: 2.9561, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.88batch/s, train_accuracy=9.17, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 138.84batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: Train Loss: 2.9646, Train Acc: 9.17%, Val Loss: 2.9558, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.75batch/s, train_accuracy=9.14, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 145.30batch/s, val_accuracy=9.61, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: Train Loss: 2.9627, Train Acc: 9.14%, Val Loss: 2.9567, Val Acc: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.65batch/s, train_accuracy=9.21, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 135.78batch/s, val_accuracy=9.6, val_loss=0.733] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: Train Loss: 2.9577, Train Acc: 9.21%, Val Loss: 2.9584, Val Acc: 9.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.25batch/s, train_accuracy=9.17, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 125.24batch/s, val_accuracy=9.4, val_loss=0.735] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: Train Loss: 2.9489, Train Acc: 9.17%, Val Loss: 2.9663, Val Acc: 9.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.87batch/s, train_accuracy=9.39, train_loss=2.94]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 116.87batch/s, val_accuracy=9.19, val_loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: Train Loss: 2.9392, Train Acc: 9.39%, Val Loss: 2.9718, Val Acc: 9.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.14batch/s, train_accuracy=9.74, train_loss=2.93]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.62batch/s, val_accuracy=8.64, val_loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: Train Loss: 2.9286, Train Acc: 9.74%, Val Loss: 2.9864, Val Acc: 8.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.49batch/s, train_accuracy=10, train_loss=2.92]  \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 139.52batch/s, val_accuracy=7.56, val_loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: Train Loss: 2.9157, Train Acc: 10.01%, Val Loss: 3.0018, Val Acc: 7.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.07batch/s, train_accuracy=10.5, train_loss=2.9]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 138.51batch/s, val_accuracy=8.2, val_loss=0.745] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: Train Loss: 2.9016, Train Acc: 10.53%, Val Loss: 3.0079, Val Acc: 8.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.78batch/s, train_accuracy=11.2, train_loss=2.88]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 134.37batch/s, val_accuracy=7.39, val_loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: Train Loss: 2.8824, Train Acc: 11.20%, Val Loss: 3.0208, Val Acc: 7.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.41batch/s, train_accuracy=12.4, train_loss=2.86]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.02batch/s, val_accuracy=7.28, val_loss=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: Train Loss: 2.8564, Train Acc: 12.35%, Val Loss: 3.0307, Val Acc: 7.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.44batch/s, train_accuracy=13.7, train_loss=2.82]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 140.21batch/s, val_accuracy=7.59, val_loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: Train Loss: 2.8207, Train Acc: 13.68%, Val Loss: 3.0353, Val Acc: 7.59%\n",
      "Early stopping at epoch 19\n",
      "Fold 1: Best Val Acc=7.59%, Test Acc=7.54%\n",
      "\n",
      "====== Fold 2/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.01batch/s, train_accuracy=7.31, train_loss=3.02]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 129.11batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 3.0183, Train Acc: 7.31%, Val Loss: 2.9630, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.46batch/s, train_accuracy=7.8, train_loss=2.99] \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 140.86batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: Train Loss: 2.9943, Train Acc: 7.80%, Val Loss: 2.9630, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.11batch/s, train_accuracy=8.34, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 146.28batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: Train Loss: 2.9821, Train Acc: 8.34%, Val Loss: 2.9599, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 33.79batch/s, train_accuracy=8.68, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 145.57batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: Train Loss: 2.9728, Train Acc: 8.68%, Val Loss: 2.9627, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.60batch/s, train_accuracy=8.91, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 141.68batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: Train Loss: 2.9692, Train Acc: 8.91%, Val Loss: 2.9622, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.25batch/s, train_accuracy=9.04, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 90.67batch/s, val_accuracy=9.47, val_loss=0.734] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: Train Loss: 2.9659, Train Acc: 9.04%, Val Loss: 2.9605, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.41batch/s, train_accuracy=9.16, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 137.30batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: Train Loss: 2.9643, Train Acc: 9.16%, Val Loss: 2.9606, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.00batch/s, train_accuracy=9.21, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.36batch/s, val_accuracy=9.47, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: Train Loss: 2.9618, Train Acc: 9.21%, Val Loss: 2.9594, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.83batch/s, train_accuracy=9.22, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 143.78batch/s, val_accuracy=9.47, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: Train Loss: 2.9610, Train Acc: 9.22%, Val Loss: 2.9577, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.73batch/s, train_accuracy=9.25, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 120.69batch/s, val_accuracy=9.47, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: Train Loss: 2.9602, Train Acc: 9.25%, Val Loss: 2.9595, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.16batch/s, train_accuracy=9.2, train_loss=2.95] \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 123.66batch/s, val_accuracy=9.47, val_loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: Train Loss: 2.9546, Train Acc: 9.20%, Val Loss: 2.9641, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.35batch/s, train_accuracy=9.31, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 97.07batch/s, val_accuracy=9.36, val_loss=0.737] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: Train Loss: 2.9457, Train Acc: 9.31%, Val Loss: 2.9750, Val Acc: 9.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.94batch/s, train_accuracy=9.54, train_loss=2.94]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 136.68batch/s, val_accuracy=8.94, val_loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: Train Loss: 2.9360, Train Acc: 9.54%, Val Loss: 2.9873, Val Acc: 8.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.31batch/s, train_accuracy=9.8, train_loss=2.93] \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 144.06batch/s, val_accuracy=8.91, val_loss=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: Train Loss: 2.9262, Train Acc: 9.80%, Val Loss: 2.9923, Val Acc: 8.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.50batch/s, train_accuracy=10.3, train_loss=2.91]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.82batch/s, val_accuracy=8.09, val_loss=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: Train Loss: 2.9143, Train Acc: 10.33%, Val Loss: 3.0083, Val Acc: 8.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.39batch/s, train_accuracy=10.8, train_loss=2.9] \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 126.93batch/s, val_accuracy=7.65, val_loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: Train Loss: 2.9010, Train Acc: 10.85%, Val Loss: 3.0169, Val Acc: 7.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.85batch/s, train_accuracy=11.4, train_loss=2.88]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 113.49batch/s, val_accuracy=7.26, val_loss=0.752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: Train Loss: 2.8833, Train Acc: 11.39%, Val Loss: 3.0353, Val Acc: 7.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.87batch/s, train_accuracy=12.5, train_loss=2.86]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 118.45batch/s, val_accuracy=7.5, val_loss=0.754]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: Train Loss: 2.8577, Train Acc: 12.51%, Val Loss: 3.0434, Val Acc: 7.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.27batch/s, train_accuracy=14.1, train_loss=2.82]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 145.71batch/s, val_accuracy=7.49, val_loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: Train Loss: 2.8204, Train Acc: 14.12%, Val Loss: 3.0550, Val Acc: 7.49%\n",
      "Early stopping at epoch 19\n",
      "Fold 2: Best Val Acc=7.49%, Test Acc=7.49%\n",
      "\n",
      "====== Fold 3/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.84batch/s, train_accuracy=7.36, train_loss=3.02]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.77batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 3.0206, Train Acc: 7.36%, Val Loss: 2.9635, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.37batch/s, train_accuracy=7.73, train_loss=3]  \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 149.58batch/s, val_accuracy=9.44, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: Train Loss: 2.9963, Train Acc: 7.73%, Val Loss: 2.9708, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.81batch/s, train_accuracy=8.29, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.80batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: Train Loss: 2.9844, Train Acc: 8.29%, Val Loss: 2.9597, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.21batch/s, train_accuracy=8.58, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 149.03batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: Train Loss: 2.9760, Train Acc: 8.58%, Val Loss: 2.9624, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.41batch/s, train_accuracy=8.83, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 112.52batch/s, val_accuracy=9.44, val_loss=0.734] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: Train Loss: 2.9716, Train Acc: 8.83%, Val Loss: 2.9597, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.81batch/s, train_accuracy=9.02, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 100.69batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: Train Loss: 2.9679, Train Acc: 9.02%, Val Loss: 2.9635, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.41batch/s, train_accuracy=9.16, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 143.36batch/s, val_accuracy=9.44, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: Train Loss: 2.9651, Train Acc: 9.16%, Val Loss: 2.9589, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.25batch/s, train_accuracy=9.19, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 149.77batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: Train Loss: 2.9637, Train Acc: 9.19%, Val Loss: 2.9601, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.53batch/s, train_accuracy=9.22, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 146.07batch/s, val_accuracy=9.44, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: Train Loss: 2.9618, Train Acc: 9.22%, Val Loss: 2.9592, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.95batch/s, train_accuracy=9.24, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 133.91batch/s, val_accuracy=9.44, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: Train Loss: 2.9601, Train Acc: 9.24%, Val Loss: 2.9597, Val Acc: 9.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.41batch/s, train_accuracy=9.24, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 101.39batch/s, val_accuracy=9.47, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: Train Loss: 2.9550, Train Acc: 9.24%, Val Loss: 2.9627, Val Acc: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.75batch/s, train_accuracy=9.28, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 111.53batch/s, val_accuracy=9.26, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: Train Loss: 2.9482, Train Acc: 9.28%, Val Loss: 2.9708, Val Acc: 9.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.19batch/s, train_accuracy=9.5, train_loss=2.94] \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 140.27batch/s, val_accuracy=9.19, val_loss=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: Train Loss: 2.9388, Train Acc: 9.50%, Val Loss: 2.9788, Val Acc: 9.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.35batch/s, train_accuracy=9.87, train_loss=2.93]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 142.48batch/s, val_accuracy=8.4, val_loss=0.742] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: Train Loss: 2.9279, Train Acc: 9.87%, Val Loss: 2.9923, Val Acc: 8.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.60batch/s, train_accuracy=10.1, train_loss=2.92]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 143.24batch/s, val_accuracy=8.28, val_loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: Train Loss: 2.9173, Train Acc: 10.08%, Val Loss: 3.0000, Val Acc: 8.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.79batch/s, train_accuracy=10.5, train_loss=2.9]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 130.72batch/s, val_accuracy=7.94, val_loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: Train Loss: 2.9033, Train Acc: 10.48%, Val Loss: 3.0213, Val Acc: 7.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 31.27batch/s, train_accuracy=11.3, train_loss=2.89]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 95.72batch/s, val_accuracy=7.67, val_loss=0.751] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: Train Loss: 2.8858, Train Acc: 11.27%, Val Loss: 3.0312, Val Acc: 7.67%\n",
      "Early stopping at epoch 17\n",
      "Fold 3: Best Val Acc=7.67%, Test Acc=7.27%\n",
      "\n",
      "====== Fold 4/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.03batch/s, train_accuracy=7.37, train_loss=3.02]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 117.79batch/s, val_accuracy=9.18, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 3.0208, Train Acc: 7.37%, Val Loss: 2.9607, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.46batch/s, train_accuracy=7.89, train_loss=3]  \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 141.62batch/s, val_accuracy=9.18, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: Train Loss: 2.9961, Train Acc: 7.89%, Val Loss: 2.9625, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.22batch/s, train_accuracy=8.13, train_loss=2.99]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 121.45batch/s, val_accuracy=9.18, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: Train Loss: 2.9863, Train Acc: 8.13%, Val Loss: 2.9610, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.70batch/s, train_accuracy=8.54, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 140.25batch/s, val_accuracy=9.18, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: Train Loss: 2.9773, Train Acc: 8.54%, Val Loss: 2.9618, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 32.90batch/s, train_accuracy=8.93, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 138.77batch/s, val_accuracy=9.18, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: Train Loss: 2.9720, Train Acc: 8.93%, Val Loss: 2.9593, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.83batch/s, train_accuracy=9.09, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 134.60batch/s, val_accuracy=9.18, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: Train Loss: 2.9676, Train Acc: 9.09%, Val Loss: 2.9588, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.45batch/s, train_accuracy=9.12, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 123.83batch/s, val_accuracy=9.18, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: Train Loss: 2.9659, Train Acc: 9.12%, Val Loss: 2.9592, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.46batch/s, train_accuracy=9.26, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 112.09batch/s, val_accuracy=9.18, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: Train Loss: 2.9637, Train Acc: 9.26%, Val Loss: 2.9590, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.61batch/s, train_accuracy=9.25, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 116.18batch/s, val_accuracy=9.18, val_loss=0.734] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: Train Loss: 2.9620, Train Acc: 9.25%, Val Loss: 2.9597, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.22batch/s, train_accuracy=9.32, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 133.26batch/s, val_accuracy=9.18, val_loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: Train Loss: 2.9605, Train Acc: 9.32%, Val Loss: 2.9592, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:12<00:00, 28.87batch/s, train_accuracy=9.25, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 107.88batch/s, val_accuracy=9.18, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: Train Loss: 2.9553, Train Acc: 9.25%, Val Loss: 2.9615, Val Acc: 9.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:12<00:00, 28.74batch/s, train_accuracy=9.34, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 127.42batch/s, val_accuracy=8.73, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: Train Loss: 2.9475, Train Acc: 9.34%, Val Loss: 2.9707, Val Acc: 8.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.45batch/s, train_accuracy=9.51, train_loss=2.94]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 118.06batch/s, val_accuracy=8.63, val_loss=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: Train Loss: 2.9383, Train Acc: 9.51%, Val Loss: 2.9793, Val Acc: 8.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.10batch/s, train_accuracy=9.84, train_loss=2.93]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 109.82batch/s, val_accuracy=8.3, val_loss=0.742] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: Train Loss: 2.9283, Train Acc: 9.84%, Val Loss: 2.9951, Val Acc: 8.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.69batch/s, train_accuracy=10.1, train_loss=2.92]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 127.86batch/s, val_accuracy=7.8, val_loss=0.745] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: Train Loss: 2.9170, Train Acc: 10.14%, Val Loss: 3.0060, Val Acc: 7.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.44batch/s, train_accuracy=10.7, train_loss=2.9]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 108.27batch/s, val_accuracy=7.53, val_loss=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: Train Loss: 2.9022, Train Acc: 10.67%, Val Loss: 3.0279, Val Acc: 7.53%\n",
      "Early stopping at epoch 16\n",
      "Fold 4: Best Val Acc=7.53%, Test Acc=7.34%\n",
      "\n",
      "====== Fold 5/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:12<00:00, 28.06batch/s, train_accuracy=7.35, train_loss=3.02]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 120.25batch/s, val_accuracy=8.97, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: Train Loss: 3.0208, Train Acc: 7.35%, Val Loss: 2.9708, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.27batch/s, train_accuracy=7.88, train_loss=3]   \n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 133.83batch/s, val_accuracy=8.97, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: Train Loss: 2.9997, Train Acc: 7.88%, Val Loss: 2.9685, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.81batch/s, train_accuracy=8.22, train_loss=2.99]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 132.28batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: Train Loss: 2.9856, Train Acc: 8.22%, Val Loss: 2.9634, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.06batch/s, train_accuracy=8.55, train_loss=2.98]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 126.98batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: Train Loss: 2.9793, Train Acc: 8.55%, Val Loss: 2.9605, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:12<00:00, 28.85batch/s, train_accuracy=8.92, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 128.45batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: Train Loss: 2.9727, Train Acc: 8.92%, Val Loss: 2.9616, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:12<00:00, 27.66batch/s, train_accuracy=9.02, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 129.73batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: Train Loss: 2.9683, Train Acc: 9.02%, Val Loss: 2.9605, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.29batch/s, train_accuracy=9.15, train_loss=2.97]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 137.12batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: Train Loss: 2.9659, Train Acc: 9.15%, Val Loss: 2.9604, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.10batch/s, train_accuracy=9.24, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 137.83batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: Train Loss: 2.9648, Train Acc: 9.24%, Val Loss: 2.9619, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.92batch/s, train_accuracy=9.34, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 131.34batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: Train Loss: 2.9626, Train Acc: 9.34%, Val Loss: 2.9614, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.23batch/s, train_accuracy=9.37, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 116.79batch/s, val_accuracy=8.97, val_loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: Train Loss: 2.9615, Train Acc: 9.37%, Val Loss: 2.9611, Val Acc: 8.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.10batch/s, train_accuracy=9.36, train_loss=2.96]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 129.44batch/s, val_accuracy=8.91, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: Train Loss: 2.9561, Train Acc: 9.36%, Val Loss: 2.9689, Val Acc: 8.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.84batch/s, train_accuracy=9.36, train_loss=2.95]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 117.30batch/s, val_accuracy=8.83, val_loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: Train Loss: 2.9489, Train Acc: 9.36%, Val Loss: 2.9681, Val Acc: 8.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:10<00:00, 31.93batch/s, train_accuracy=9.49, train_loss=2.94]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 112.03batch/s, val_accuracy=8.41, val_loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: Train Loss: 2.9398, Train Acc: 9.49%, Val Loss: 2.9799, Val Acc: 8.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.96batch/s, train_accuracy=9.78, train_loss=2.93]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 108.32batch/s, val_accuracy=8.1, val_loss=0.741] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: Train Loss: 2.9303, Train Acc: 9.78%, Val Loss: 2.9900, Val Acc: 8.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.64batch/s, train_accuracy=10.1, train_loss=2.92]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 132.95batch/s, val_accuracy=7.86, val_loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: Train Loss: 2.9191, Train Acc: 10.13%, Val Loss: 2.9993, Val Acc: 7.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 30.16batch/s, train_accuracy=10.6, train_loss=2.9]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 130.34batch/s, val_accuracy=7.47, val_loss=0.747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: Train Loss: 2.9039, Train Acc: 10.62%, Val Loss: 3.0146, Val Acc: 7.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347/347 [00:11<00:00, 29.39batch/s, train_accuracy=11.2, train_loss=2.89]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86/86 [00:00<00:00, 130.58batch/s, val_accuracy=7.22, val_loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: Train Loss: 2.8852, Train Acc: 11.18%, Val Loss: 3.0233, Val Acc: 7.22%\n",
      "Early stopping at epoch 17\n",
      "Fold 5: Best Val Acc=7.22%, Test Acc=7.69%\n",
      "\n",
      "Average Val Acc=7.50%, Average Test Acc=7.46%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# æ£€æŸ¥ GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# å‡è®¾ SNR_dB å’Œ fd å·²ç»åœ¨ä¹‹å‰å®šä¹‰\n",
    "SNR_dB = globals().get('SNR_dB', 'no')\n",
    "fd = globals().get('fd', 'no')\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹å‚æ•°\n",
    "input_dim = 320\n",
    "num_heads = 2\n",
    "num_layers = 3\n",
    "num_classes = 20\n",
    "dropout = 0.5\n",
    "\n",
    "# è®­ç»ƒå‚æ•°\n",
    "batch_size = 256\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "patience = 10\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "script_name = \"los_DCTF\"\n",
    "\n",
    "folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{fd}_classes_{num_classes}_Transformer\"\n",
    "save_folder = os.path.join(os.getcwd(), \"training_results\", folder_name)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "results_file = os.path.join(save_folder, \"results.txt\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    f.write(f\"=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Feature Folder: trajectory_plots\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "\n",
    "# å®šä¹‰SignalTransformeræ¨¡å‹\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, input_dim)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x, x)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# KæŠ˜äº¤å‰éªŒè¯\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "test_results = []\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"\\n====== Fold {fold+1}/{n_splits} ======\")\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = SignalTransformer(input_dim=input_dim, num_heads=num_heads,\n",
    "                              num_layers=num_layers, num_classes=num_classes,\n",
    "                              dropout=dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    best_model_wts = None\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train, total_train = 0, 0\n",
    "        \n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (inputs, labels) in enumerate(tepoch):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "                train_accuracy = 100 * correct_train / total_train\n",
    "                tepoch.set_postfix(train_loss=running_train_loss / (batch_idx + 1), train_accuracy=train_accuracy)\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        epoch_train_acc = 100 * correct_train / total_train\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "        # éªŒè¯\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val, total_val = 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(val_loader, desc=\"Validation\", unit=\"batch\") as vepoch:\n",
    "                for val_inputs, val_labels in vepoch:\n",
    "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_labels)\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    _, val_predicted = torch.max(val_outputs, 1)\n",
    "                    total_val += val_labels.size(0)\n",
    "                    correct_val += (val_predicted == val_labels).sum().item()\n",
    "                    val_accuracy = 100 * correct_val / total_val\n",
    "                    vepoch.set_postfix(val_loss=running_val_loss / (batch_idx + 1), val_accuracy=val_accuracy)\n",
    "\n",
    "\n",
    "                    # ä¿å­˜æ··æ·†çŸ©é˜µæ•°æ®\n",
    "                    all_preds.extend(val_predicted.cpu().numpy())\n",
    "                    all_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        epoch_val_acc = 100 * correct_val / total_val\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch+1} | Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}% | Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.2f}%\\n\")\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_acc = epoch_val_acc   # æ›´æ–°æœ€ä½³éªŒè¯ç²¾åº¦\n",
    "            best_model_wts = model.state_dict()  # ä¿å­˜æœ€ä½³å‚æ•°\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # ========= æ¢å¤æœ€ä¼˜æ¨¡å‹å¹¶æµ‹è¯• =========\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    model.eval()\n",
    "\n",
    "    # --- åœ¨æœ€ä¼˜æ¨¡å‹ä¸Šé‡æ–°è·‘éªŒè¯é›†ï¼Œå¾—åˆ°æ··æ·†çŸ©é˜µ ---\n",
    "    all_preds, all_labels = [], []\n",
    "    correct_val, total_val = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            total_val += val_labels.size(0)\n",
    "            correct_val += (val_predicted == val_labels).sum().item()\n",
    "            all_preds.extend(val_predicted.cpu().numpy())\n",
    "            all_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "    best_val_acc = 100 * correct_val / total_val\n",
    "\n",
    "    # --- åœ¨æœ€ä¼˜æ¨¡å‹ä¸Šé‡æ–°è·‘æµ‹è¯•é›† ---\n",
    "    correct_test, total_test = 0, 0\n",
    "    test_preds, test_labels_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "            outputs = model(test_inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += test_labels.size(0)\n",
    "            correct_test += (predicted == test_labels).sum().item()\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            test_labels_all.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_acc = 100 * correct_test / total_test\n",
    "\n",
    "    print(f\"Fold {fold+1}: Best Val Acc={best_val_acc:.2f}%, Test Acc={test_acc:.2f}%\")\n",
    "\n",
    "    fold_results.append(best_val_acc)\n",
    "    test_results.append(test_acc)\n",
    "\n",
    "    # --- ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼ˆåŸºäºæœ€ä¼˜æ¨¡å‹çš„éªŒè¯é›†ï¼‰---\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title(f'Fold {fold+1} Validation Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_val_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "    np.savetxt(os.path.join(save_folder, f\"fold_{fold+1}_val_confusion_matrix.txt\"), cm, fmt='%d')\n",
    "\n",
    "    # --- æµ‹è¯•é›†æ··æ·†çŸ©é˜µ ---\n",
    "    cm_test = confusion_matrix(test_labels_all, test_preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title(f'Fold {fold+1} Test Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_test_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "    np.savetxt(os.path.join(save_folder, f\"fold_{fold+1}_test_confusion_matrix.txt\"), cm_test, fmt='%d')\n",
    "\n",
    "    # ç»˜å›¾\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses)+1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()\n",
    "    plt.title(f'Fold {fold+1} Loss Curve')\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(train_accuracies)+1), train_accuracies, label='Train Acc')\n",
    "    plt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='Val Acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()\n",
    "    plt.title(f'Fold {fold+1} Accuracy Curve')\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_accuracy_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# æ±‡æ€»ç»“æœ\n",
    "avg_acc = np.mean(fold_results)\n",
    "avg_test_acc = np.mean(test_results)\n",
    "with open(results_file, \"a\") as f:\n",
    "    for i in range(n_splits):\n",
    "        f.write(f\"Fold {i+1}: Val Acc={fold_results[i]:.2f}%, Test Acc={test_results[i]:.2f}%\\n\")\n",
    "    f.write(f\"\\nAverage Val Accuracy: {avg_acc:.2f}%\\n\")\n",
    "    f.write(f\"Average Test Accuracy: {avg_test_acc:.2f}%\\n\")\n",
    "\n",
    "print(f\"\\nAverage Val Acc={avg_acc:.2f}%, Average Test Acc={avg_test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
