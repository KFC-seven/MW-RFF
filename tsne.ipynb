{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ltev_feature_tsne_sample_level_export_mat_and_figs.py\n",
    "# 样本级（非block聚合）特征 t-SNE：RAW vs XFR，joint-fit 2D/3D\n",
    "# 输出：4张独立图（PDF+PNG, 无title, 学术风格） + 4份.mat + 1份总.mat\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "\n",
    "# ===================== 你需要确认/修改的参数 =====================\n",
    "DATA_PATH = r\"E:/rf_datasets/\"  # LTE-V .mat 文件夹\n",
    "\n",
    "EXP_XFR_DIR = r\"./training_results/2026-01-07_19-01-27_LTE-V_XFR_SNR20dB_fd655_classes_9_ResNet\"\n",
    "EXP_RAW_DIR = r\"./training_results/2025-11-27_11-25-06_LTE_time_SNR20dB_fd960_classes_9\"\n",
    "\n",
    "OUT_DIR = r\"./TSNE\"\n",
    "\n",
    "GROUP_SIZE = 864\n",
    "TEST_SIZE = 0.25\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "# 为了公平对比，建议 True：两边用同一个 SNR/fd 注入生成同源 blocks\n",
    "USE_COMMON_CHANNEL = True\n",
    "FS = 5e6\n",
    "APPLY_DOPPLER = True\n",
    "APPLY_AWGN = True\n",
    "\n",
    "# 抽样（样本级每类最多点数，避免t-SNE过慢）\n",
    "MAX_SAMPLES_PER_CLASS_RAW = 1500\n",
    "MAX_SAMPLES_PER_CLASS_XFR = 1500\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# t-SNE\n",
    "SEED = 42\n",
    "PCA_DIM = 50\n",
    "TSNE_PERPLEXITY = 30\n",
    "TSNE_ITERS = 1500\n",
    "TSNE_METRIC = \"cosine\"\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "# ===================== 论文风格绘图配置 =====================\n",
    "def set_paper_style():\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.size\": 9,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"legend.frameon\": False,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"axes.facecolor\": \"white\",\n",
    "    })\n",
    "\n",
    "\n",
    "def save_tsne_2d_single(emb2, y, out_base, xlim=None, ylim=None, point_size=3, alpha=0.85):\n",
    "    \"\"\"\n",
    "    输出单独的 2D 图：out_base.pdf + out_base.png\n",
    "    \"\"\"\n",
    "    set_paper_style()\n",
    "    num_classes = int(y.max()) + 1\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", num_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(3.4, 3.0), dpi=400)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(emb2[:, 0], emb2[:, 1], c=y, cmap=cmap, s=point_size, alpha=alpha, linewidths=0)\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE 1\")\n",
    "    ax.set_ylabel(\"t-SNE 2\")\n",
    "\n",
    "    # 论文常见：去掉上右边框\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "    plt.savefig(out_base + \".pdf\", bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.savefig(out_base + \".png\", bbox_inches=\"tight\", pad_inches=0.02, dpi=400)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def save_tsne_3d_single(emb3, y, out_base, xlim=None, ylim=None, zlim=None,\n",
    "                       view=(18, -60), point_size=3, alpha=0.85, grid_alpha=0.25):\n",
    "    \"\"\"\n",
    "    输出单独的 3D 图：out_base.pdf + out_base.png\n",
    "    \"\"\"\n",
    "    set_paper_style()\n",
    "    num_classes = int(y.max()) + 1\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", num_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(3.4, 3.0), dpi=400)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "    ax.scatter(emb3[:, 0], emb3[:, 1], emb3[:, 2], c=y, cmap=cmap, s=point_size, alpha=alpha, linewidths=0)\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE 1\", labelpad=2)\n",
    "    ax.set_ylabel(\"t-SNE 2\", labelpad=2)\n",
    "    ax.set_zlabel(\"t-SNE 3\", labelpad=2)\n",
    "\n",
    "    ax.view_init(elev=view[0], azim=view[1])\n",
    "    ax.grid(True, alpha=grid_alpha)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if zlim is not None:\n",
    "        ax.set_zlim(zlim)\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "    plt.savefig(out_base + \".pdf\", bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.savefig(out_base + \".png\", bbox_inches=\"tight\", pad_inches=0.02, dpi=400)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ===================== .mat 导出 =====================\n",
    "def save_embedding_mat_2d(emb2, y, out_path, meta=None):\n",
    "    \"\"\"\n",
    "    保存 2D t-SNE 到 .mat：\n",
    "      - emb: [N,2]\n",
    "      - label: [N,1]\n",
    "      - meta: dict（可选）\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    mdict = {\n",
    "        \"emb\": emb2.astype(np.float64),\n",
    "        \"label\": y.astype(np.int64).reshape(-1, 1),\n",
    "    }\n",
    "    if meta is not None:\n",
    "        mdict[\"meta\"] = meta\n",
    "    savemat(out_path, mdict)\n",
    "    print(f\"[OK] Saved mat: {out_path}\")\n",
    "\n",
    "\n",
    "def save_embedding_mat_3d(emb3, y, out_path, meta=None):\n",
    "    \"\"\"\n",
    "    保存 3D t-SNE 到 .mat：\n",
    "      - emb: [N,3]\n",
    "      - label: [N,1]\n",
    "      - meta: dict（可选）\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    mdict = {\n",
    "        \"emb\": emb3.astype(np.float64),\n",
    "        \"label\": y.astype(np.int64).reshape(-1, 1),\n",
    "    }\n",
    "    if meta is not None:\n",
    "        mdict[\"meta\"] = meta\n",
    "    savemat(out_path, mdict)\n",
    "    print(f\"[OK] Saved mat: {out_path}\")\n",
    "\n",
    "\n",
    "# ===================== 信号处理 =====================\n",
    "def apply_doppler_shift(signal_c, fd_hz, fs_hz):\n",
    "    t = np.arange(signal_c.shape[-1]) / fs_hz\n",
    "    return signal_c * np.exp(1j * 2 * np.pi * fd_hz * t)\n",
    "\n",
    "\n",
    "def add_awgn(signal_c, snr_db):\n",
    "    power = np.mean(np.abs(signal_c) ** 2) + 1e-12\n",
    "    noise_power = power / (10 ** (snr_db / 10))\n",
    "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal_c.shape) + 1j * np.random.randn(*signal_c.shape))\n",
    "    return signal_c + noise\n",
    "\n",
    "\n",
    "def parse_snr_fd_classes(folder_name: str):\n",
    "    snr = None\n",
    "    fd = None\n",
    "    ncls = None\n",
    "    m = re.search(r\"SNR(-?\\d+)dB\", folder_name)\n",
    "    if m:\n",
    "        snr = int(m.group(1))\n",
    "    m = re.search(r\"fd(\\d+)\", folder_name)\n",
    "    if m:\n",
    "        fd = int(m.group(1))\n",
    "    m = re.search(r\"classes[_-](\\d+)\", folder_name)\n",
    "    if m:\n",
    "        ncls = int(m.group(1))\n",
    "    return snr, fd, ncls\n",
    "\n",
    "\n",
    "# ===================== LTE-V blocks =====================\n",
    "def load_blocks_ltev(mat_folder,\n",
    "                     group_size=864,\n",
    "                     apply_doppler=True,\n",
    "                     fd_hz=655,\n",
    "                     apply_awgn=True,\n",
    "                     snr_db=20,\n",
    "                     fs=5e6):\n",
    "    mat_files = glob.glob(os.path.join(mat_folder, \"*.mat\"))\n",
    "    if len(mat_files) == 0:\n",
    "        raise RuntimeError(f\"在 {mat_folder} 未找到 .mat 文件\")\n",
    "\n",
    "    X_files, y_files, label_set = [], [], set()\n",
    "\n",
    "    print(f\"[INFO] Found {len(mat_files)} .mat files\")\n",
    "    for file in tqdm(mat_files, desc=\"Reading LTE-V .mat\"):\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            rfDataset = f[\"rfDataset\"]\n",
    "            dmrs = rfDataset[\"dmrs\"][:]\n",
    "            dmrs_complex = dmrs[\"real\"] + 1j * dmrs[\"imag\"]\n",
    "            txID_uint16 = rfDataset[\"txID\"][:].flatten()\n",
    "            tx_id = \"\".join(chr(c) for c in txID_uint16 if c != 0)\n",
    "\n",
    "            processed = []\n",
    "            for i in range(dmrs_complex.shape[0]):\n",
    "                sig = dmrs_complex[i, :].astype(np.complex64)\n",
    "                sig = sig / (np.sqrt(np.mean(np.abs(sig) ** 2)) + 1e-12)\n",
    "\n",
    "                if apply_doppler:\n",
    "                    sig = apply_doppler_shift(sig, fd_hz, fs)\n",
    "\n",
    "                if apply_awgn:\n",
    "                    sig = add_awgn(sig, snr_db)\n",
    "\n",
    "                iq = np.stack([sig.real, sig.imag], axis=-1).astype(np.float32)\n",
    "                processed.append(iq)\n",
    "\n",
    "            processed = np.array(processed, dtype=np.float32)\n",
    "            X_files.append(processed)\n",
    "            y_files.append(tx_id)\n",
    "            label_set.add(tx_id)\n",
    "\n",
    "    label_list = sorted(list(label_set))\n",
    "    label_to_idx = {lb: i for i, lb in enumerate(label_list)}\n",
    "\n",
    "    raw_blocks_list = []\n",
    "    xfr_blocks_list = []\n",
    "    y_blocks_list = []\n",
    "\n",
    "    for label in label_list:\n",
    "        files_idx = [i for i, y in enumerate(y_files) if y == label]\n",
    "        num_files = len(files_idx)\n",
    "        if num_files == 0:\n",
    "            continue\n",
    "\n",
    "        samples_per_file = group_size // num_files\n",
    "        if samples_per_file == 0:\n",
    "            continue\n",
    "\n",
    "        min_samples = min([X_files[i].shape[0] for i in files_idx])\n",
    "        max_groups = min_samples // samples_per_file\n",
    "        if max_groups == 0:\n",
    "            continue\n",
    "\n",
    "        for gi in range(max_groups):\n",
    "            pieces = []\n",
    "            for fi in files_idx:\n",
    "                s = gi * samples_per_file\n",
    "                e = s + samples_per_file\n",
    "                pieces.append(X_files[fi][s:e])\n",
    "            big_block = np.concatenate(pieces, axis=0)  # (G,L,2)\n",
    "\n",
    "            raw_blocks_list.append(big_block)  # (G,L,2)\n",
    "            xfr_blocks_list.append(np.transpose(big_block, (1, 0, 2)))  # (L,G,2)\n",
    "            y_blocks_list.append(label_to_idx[label])\n",
    "\n",
    "    if len(raw_blocks_list) == 0:\n",
    "        raise RuntimeError(\"未生成任何 block，请检查 group_size 或数据组织。\")\n",
    "\n",
    "    raw_blocks = np.stack(raw_blocks_list, axis=0)  # (B,G,L,2)\n",
    "    xfr_blocks = np.stack(xfr_blocks_list, axis=0)  # (B,L,G,2)\n",
    "    y_blocks = np.array(y_blocks_list, dtype=np.int64)\n",
    "\n",
    "    print(f\"[INFO] blocks={raw_blocks.shape[0]}, group_size={raw_blocks.shape[1]}, sample_len={raw_blocks.shape[2]}, classes={len(label_list)}\")\n",
    "    return raw_blocks, xfr_blocks, y_blocks\n",
    "\n",
    "\n",
    "# ===================== ResNet18_1D extract_features =====================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = out + identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.extract_features(x)\n",
    "        return self.fc(feat)\n",
    "\n",
    "\n",
    "def strip_module_prefix(state_dict):\n",
    "    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        return {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def find_fold_models(exp_dir):\n",
    "    paths = glob.glob(os.path.join(exp_dir, \"best_model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        paths = glob.glob(os.path.join(exp_dir, \"model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        raise RuntimeError(f\"在 {exp_dir} 未找到 best_model_fold*.pth 或 model_fold*.pth\")\n",
    "\n",
    "    def fold_key(p):\n",
    "        m = re.search(r\"fold(\\d+)\", os.path.basename(p))\n",
    "        return int(m.group(1)) if m else 999\n",
    "\n",
    "    return sorted(paths, key=fold_key)\n",
    "\n",
    "\n",
    "# ===================== 样本级 dataset =====================\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "def stratified_sample_indices(y, max_per_class, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    keep = []\n",
    "    for c in np.unique(y):\n",
    "        idx = np.where(y == c)[0]\n",
    "        if len(idx) > max_per_class:\n",
    "            idx = rng.choice(idx, size=max_per_class, replace=False)\n",
    "        keep.append(idx)\n",
    "    keep = np.concatenate(keep)\n",
    "    rng.shuffle(keep)\n",
    "    return keep\n",
    "\n",
    "\n",
    "def extract_features_foldmean(model_paths, X, y, device):\n",
    "    \"\"\"\n",
    "    对同一批样本，逐fold提特征后做 fold-mean，返回 (N,512)\n",
    "    \"\"\"\n",
    "    ds = SimpleDataset(X, y)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    feats_folds = []\n",
    "    for mp in model_paths:\n",
    "        state = strip_module_prefix(torch.load(mp, map_location=device))\n",
    "        in_planes = state[\"conv1.weight\"].shape[0]\n",
    "        num_classes = state[\"fc.weight\"].shape[0]\n",
    "\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=0.0).to(device)\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        model.eval()\n",
    "\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in tqdm(loader, desc=f\"Extract {os.path.basename(mp)}\", leave=False):\n",
    "                xb = xb.to(device)\n",
    "                f = model.extract_features(xb).cpu().numpy()\n",
    "                feats.append(f)\n",
    "        feats = np.concatenate(feats, axis=0)  # (N,512)\n",
    "        feats_folds.append(feats)\n",
    "\n",
    "    feats_folds = np.stack(feats_folds, axis=0)  # (F,N,512)\n",
    "    return feats_folds.mean(axis=0)              # (N,512)\n",
    "\n",
    "\n",
    "def tsne_joint(feat_a, feat_b, n_components, seed=42):\n",
    "    \"\"\"\n",
    "    joint-fit：拼接后一次拟合，保证同一坐标系\n",
    "    \"\"\"\n",
    "    X = np.concatenate([feat_a, feat_b], axis=0).astype(np.float32)\n",
    "\n",
    "    pca_dim_eff = min(PCA_DIM, X.shape[1])\n",
    "    X_pca = PCA(n_components=pca_dim_eff, random_state=seed).fit_transform(X)\n",
    "\n",
    "    # 兼容不同 sklearn 版本：n_iter vs max_iter\n",
    "    tsne_kwargs = dict(\n",
    "        n_components=n_components,\n",
    "        perplexity=TSNE_PERPLEXITY,\n",
    "        init=\"pca\",\n",
    "        learning_rate=\"auto\",\n",
    "        metric=TSNE_METRIC,\n",
    "        random_state=seed,\n",
    "        verbose=1\n",
    "    )\n",
    "    try:\n",
    "        tsne = TSNE(**tsne_kwargs, n_iter=TSNE_ITERS)\n",
    "    except TypeError:\n",
    "        tsne = TSNE(**tsne_kwargs, max_iter=TSNE_ITERS)\n",
    "\n",
    "    emb = tsne.fit_transform(X_pca)\n",
    "    return emb[:feat_a.shape[0]], emb[feat_a.shape[0]:]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 固定随机性（尽量可复现）\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    xfr_name = os.path.basename(EXP_XFR_DIR)\n",
    "    raw_name = os.path.basename(EXP_RAW_DIR)\n",
    "\n",
    "    snr_xfr, fd_xfr, _ = parse_snr_fd_classes(xfr_name)\n",
    "    snr_raw, fd_raw, _ = parse_snr_fd_classes(raw_name)\n",
    "\n",
    "    if USE_COMMON_CHANNEL:\n",
    "        snr_use = snr_xfr if snr_xfr is not None else 20\n",
    "        fd_use = fd_xfr if fd_xfr is not None else 655\n",
    "        print(f\"[INFO] Common channel: SNR={snr_use} dB, fd={fd_use} Hz\")\n",
    "    else:\n",
    "        snr_use = snr_xfr or 20\n",
    "        fd_use = fd_xfr or 655\n",
    "\n",
    "    # 构造 blocks（同源）\n",
    "    raw_blocks, xfr_blocks, y_blocks = load_blocks_ltev(\n",
    "        DATA_PATH,\n",
    "        group_size=GROUP_SIZE,\n",
    "        apply_doppler=APPLY_DOPPLER,\n",
    "        fd_hz=fd_use,\n",
    "        apply_awgn=APPLY_AWGN,\n",
    "        snr_db=snr_use,\n",
    "        fs=FS\n",
    "    )\n",
    "\n",
    "    num_blocks = raw_blocks.shape[0]\n",
    "    sample_len = raw_blocks.shape[2]\n",
    "\n",
    "    # block split（与你训练一致）\n",
    "    block_idx = np.arange(num_blocks)\n",
    "    _, test_idx, _, _ = train_test_split(\n",
    "        block_idx, y_blocks, test_size=TEST_SIZE, stratify=y_blocks, random_state=SPLIT_SEED\n",
    "    )\n",
    "    sel_blocks = test_idx\n",
    "    y_sel_blocks = y_blocks[sel_blocks]\n",
    "\n",
    "    # ====== 组装样本级数据 ======\n",
    "    # RAW samples: (nb*G, L,2)\n",
    "    raw_sel = raw_blocks[sel_blocks]  # (nb,G,L,2)\n",
    "    X_raw = raw_sel.reshape(-1, sample_len, 2)\n",
    "    y_raw = np.repeat(y_sel_blocks, raw_sel.shape[1])\n",
    "\n",
    "    # XFR samples: (nb*L, G,2)\n",
    "    xfr_sel = xfr_blocks[sel_blocks]  # (nb,L,G,2)\n",
    "    X_xfr = xfr_sel.reshape(-1, raw_sel.shape[1], 2)\n",
    "    y_xfr = np.repeat(y_sel_blocks, xfr_sel.shape[1])\n",
    "\n",
    "    # ====== 样本级分层抽样（否则太大） ======\n",
    "    idx_raw = stratified_sample_indices(y_raw, MAX_SAMPLES_PER_CLASS_RAW, seed=SEED)\n",
    "    idx_xfr = stratified_sample_indices(y_xfr, MAX_SAMPLES_PER_CLASS_XFR, seed=SEED)\n",
    "\n",
    "    X_raw = X_raw[idx_raw]\n",
    "    y_raw = y_raw[idx_raw]\n",
    "    X_xfr = X_xfr[idx_xfr]\n",
    "    y_xfr = y_xfr[idx_xfr]\n",
    "\n",
    "    print(f\"[INFO] sample-level selected: RAW={len(y_raw)}, XFR={len(y_xfr)}\")\n",
    "\n",
    "    # ====== fold models ======\n",
    "    raw_models = find_fold_models(EXP_RAW_DIR)\n",
    "    xfr_models = find_fold_models(EXP_XFR_DIR)\n",
    "\n",
    "    print(f\"[INFO] RAW folds: {len(raw_models)}, XFR folds: {len(xfr_models)}\")\n",
    "\n",
    "    # ====== fold-mean features ======\n",
    "    feat_raw = extract_features_foldmean(raw_models, X_raw, y_raw, device)\n",
    "    feat_xfr = extract_features_foldmean(xfr_models, X_xfr, y_xfr, device)\n",
    "\n",
    "    # ====== joint t-SNE ======\n",
    "    emb2_raw, emb2_xfr = tsne_joint(feat_raw, feat_xfr, n_components=2, seed=SEED)\n",
    "    emb3_raw, emb3_xfr = tsne_joint(feat_raw, feat_xfr, n_components=3, seed=SEED)\n",
    "\n",
    "    # ====== 统一坐标范围（论文对比更规范） ======\n",
    "    x2_all = np.concatenate([emb2_raw[:, 0], emb2_xfr[:, 0]])\n",
    "    y2_all = np.concatenate([emb2_raw[:, 1], emb2_xfr[:, 1]])\n",
    "    xlim2 = (float(x2_all.min()), float(x2_all.max()))\n",
    "    ylim2 = (float(y2_all.min()), float(y2_all.max()))\n",
    "\n",
    "    x3_all = np.concatenate([emb3_raw[:, 0], emb3_xfr[:, 0]])\n",
    "    y3_all = np.concatenate([emb3_raw[:, 1], emb3_xfr[:, 1]])\n",
    "    z3_all = np.concatenate([emb3_raw[:, 2], emb3_xfr[:, 2]])\n",
    "    xlim3 = (float(x3_all.min()), float(x3_all.max()))\n",
    "    ylim3 = (float(y3_all.min()), float(y3_all.max()))\n",
    "    zlim3 = (float(z3_all.min()), float(z3_all.max()))\n",
    "\n",
    "    # ====== 输出 4 张独立图（PDF + PNG，无title） ======\n",
    "    save_tsne_2d_single(emb2_raw, y_raw, os.path.join(OUT_DIR, \"RAW_2D\"), xlim=xlim2, ylim=ylim2)\n",
    "    save_tsne_2d_single(emb2_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_2D\"), xlim=xlim2, ylim=ylim2)\n",
    "\n",
    "    # 3D 两张保持同 view 与坐标范围\n",
    "    view = (18, -60)\n",
    "    save_tsne_3d_single(emb3_raw, y_raw, os.path.join(OUT_DIR, \"RAW_3D\"), xlim=xlim3, ylim=ylim3, zlim=zlim3, view=view)\n",
    "    save_tsne_3d_single(emb3_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_3D\"), xlim=xlim3, ylim=ylim3, zlim=zlim3, view=view)\n",
    "\n",
    "    print(\"[OK] Saved 4 individual figures (PDF+PNG).\")\n",
    "\n",
    "    # ====== 输出 4 份 .mat（分别对应4张图） ======\n",
    "    meta = {\n",
    "        \"DATA_PATH\": DATA_PATH,\n",
    "        \"EXP_RAW_DIR\": EXP_RAW_DIR,\n",
    "        \"EXP_XFR_DIR\": EXP_XFR_DIR,\n",
    "        \"SNR_use_dB\": snr_use,\n",
    "        \"fd_use_Hz\": fd_use,\n",
    "        \"USE_COMMON_CHANNEL\": int(USE_COMMON_CHANNEL),\n",
    "        \"GROUP_SIZE\": GROUP_SIZE,\n",
    "        \"TEST_SIZE\": TEST_SIZE,\n",
    "        \"SPLIT_SEED\": SPLIT_SEED,\n",
    "        \"MAX_SAMPLES_PER_CLASS_RAW\": MAX_SAMPLES_PER_CLASS_RAW,\n",
    "        \"MAX_SAMPLES_PER_CLASS_XFR\": MAX_SAMPLES_PER_CLASS_XFR,\n",
    "        \"PCA_DIM\": PCA_DIM,\n",
    "        \"TSNE_PERPLEXITY\": TSNE_PERPLEXITY,\n",
    "        \"TSNE_ITERS\": TSNE_ITERS,\n",
    "        \"TSNE_METRIC\": TSNE_METRIC,\n",
    "        \"SEED\": SEED,\n",
    "    }\n",
    "\n",
    "    save_embedding_mat_2d(emb2_raw, y_raw, os.path.join(OUT_DIR, \"RAW_2D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_2d(emb2_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_2D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_3d(emb3_raw, y_raw, os.path.join(OUT_DIR, \"RAW_3D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_3d(emb3_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_3D_tsne.mat\"), meta=meta)\n",
    "\n",
    "    # ====== 额外：输出一个总 .mat（包含四个嵌入和标签） ======\n",
    "    all_mat_path = os.path.join(OUT_DIR, \"LTEV_tsne_all.mat\")\n",
    "    savemat(all_mat_path, {\n",
    "        \"emb2_raw\": emb2_raw.astype(np.float64),\n",
    "        \"emb2_xfr\": emb2_xfr.astype(np.float64),\n",
    "        \"emb3_raw\": emb3_raw.astype(np.float64),\n",
    "        \"emb3_xfr\": emb3_xfr.astype(np.float64),\n",
    "        \"y_raw\": y_raw.astype(np.int64).reshape(-1, 1),\n",
    "        \"y_xfr\": y_xfr.astype(np.int64).reshape(-1, 1),\n",
    "        \"meta\": meta\n",
    "    })\n",
    "    print(f\"[OK] Saved mat: {all_mat_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03726e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_wisig_time_SNR20_savepth.py\n",
    "# ManySig (WiSig) 单个SNR训练：保存 best_model_fold*.pth 供后续 t-SNE 特征提取使用\n",
    "\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import os\n",
    "from data_utilities import *\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ================== 数据加载与划分 ==================\n",
    "dataset_name = \"ManySig\"\n",
    "dataset_path = \"../ManySig.pkl/\"\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path, dataset_name)\n",
    "\n",
    "print(\"数据集发射机数量：\", len(compact_dataset[\"tx_list\"]), \"具体为：\", compact_dataset[\"tx_list\"])\n",
    "print(\"数据集接收机数量：\", len(compact_dataset[\"rx_list\"]), \"具体为：\", compact_dataset[\"rx_list\"])\n",
    "print(\"数据集采集天数：\", len(compact_dataset[\"capture_date_list\"]), \"具体为：\", compact_dataset[\"capture_date_list\"])\n",
    "\n",
    "tx_list = compact_dataset[\"tx_list\"]\n",
    "rx_list = compact_dataset[\"rx_list\"]\n",
    "\n",
    "train_dates = [\"2021_03_15\"]\n",
    "test_dates  = [\"2021_03_01\"]\n",
    "equalized = 0\n",
    "\n",
    "X_train, y_train, X_test, y_test = preprocess_dataset_for_classification_cross_date(\n",
    "    compact_dataset, tx_list, rx_list, train_dates, test_dates, max_sig=None, equalized=equalized\n",
    ")\n",
    "\n",
    "print(\"训练集所选日期：\", train_dates, \"测试集所选日期：\", test_dates)\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape,  \"y_test :\", y_test.shape)\n",
    "\n",
    "\n",
    "# ================== 信号处理参数 ==================\n",
    "fs = 20e6\n",
    "fc = 2.4e9\n",
    "v_kmh = 120\n",
    "ADD_NOISE = True\n",
    "ADD_DOPPLER = True\n",
    "\n",
    "def compute_doppler_shift(v, fc):\n",
    "    c = 3e8\n",
    "    v = v / 3.6\n",
    "    return (v / c) * fc\n",
    "\n",
    "fd = compute_doppler_shift(v_kmh, fc)\n",
    "print(f\"[INFO] Doppler fd={fd:.2f} Hz\")\n",
    "\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    num_samples = signal.shape[-1]\n",
    "    t = np.arange(num_samples) / fs\n",
    "    return signal * np.exp(1j * 2 * np.pi * fd * t)\n",
    "\n",
    "def add_complex_awgn(signal, snr_db):\n",
    "    signal_power = np.mean(np.abs(signal) ** 2) + 1e-12\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = signal_power / snr_linear\n",
    "    noise_std = np.sqrt(noise_power / 2)\n",
    "    noise = np.random.normal(0, noise_std, signal.shape) + 1j * np.random.normal(0, noise_std, signal.shape)\n",
    "    return signal + noise\n",
    "\n",
    "def preprocess_iq_data(data_real_imag, snr_db=None, fd=None, fs=None, add_noise=True, add_doppler=True):\n",
    "    \"\"\"\n",
    "    输入: [N, L, 2] float\n",
    "    输出: [N, L, 2] float\n",
    "    流程: 功率归一化 -> Doppler -> AWGN\n",
    "    \"\"\"\n",
    "    if add_noise and snr_db is None:\n",
    "        raise ValueError(\"add_noise=True 时必须提供 snr_db\")\n",
    "    if add_doppler and (fd is None or fs is None):\n",
    "        raise ValueError(\"add_doppler=True 时必须提供 fd/fs\")\n",
    "\n",
    "    data_complex = data_real_imag[..., 0] + 1j * data_real_imag[..., 1]\n",
    "    processed = []\n",
    "\n",
    "    for sig in data_complex:\n",
    "        sig = sig / (np.sqrt(np.mean(np.abs(sig) ** 2)) + 1e-12)\n",
    "        cur = sig\n",
    "\n",
    "        if add_doppler:\n",
    "            cur = add_doppler_shift(cur, fd, fs)\n",
    "        if add_noise:\n",
    "            cur = add_complex_awgn(cur, snr_db)\n",
    "\n",
    "        processed.append(cur)\n",
    "\n",
    "    processed = np.array(processed)\n",
    "    return np.stack([processed.real, processed.imag], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "# ================== ResNet18_1D 模型 ==================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = out + identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [B,L,2] -> [B,2,L]\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ================== 训练配置 ==================\n",
    "SNR_dB = 0                       # 你要补训练的 RAW IQ 就固定 20 dB\n",
    "batch_size = 64\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "in_planes = 64\n",
    "dropout = 0.5\n",
    "patience = 5\n",
    "n_splits = 5\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] device={device}, num_classes={num_classes}\")\n",
    "\n",
    "SAVE_ROOT = \"./training_results\"\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "script_name = \"wisig_time\"\n",
    "folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{int(fd)}_classes_{num_classes}_ResNet18\"\n",
    "save_folder = os.path.join(SAVE_ROOT, folder_name)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "results_file = os.path.join(save_folder, \"results.txt\")\n",
    "with open(results_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd: {fd:.4f} Hz\\n\")\n",
    "    f.write(f\"equalized: {equalized}\\n\")\n",
    "    f.write(f\"train_dates: {train_dates}\\n\")\n",
    "    f.write(f\"test_dates : {test_dates}\\n\")\n",
    "    f.write(f\"num_classes: {num_classes}\\n\\n\")\n",
    "\n",
    "print(f\"[INFO] save_folder={save_folder}\")\n",
    "\n",
    "\n",
    "# ================== 数据处理（固定20dB） ==================\n",
    "X_train_processed = preprocess_iq_data(\n",
    "    X_train, snr_db=SNR_dB, fd=fd, fs=fs, add_noise=ADD_NOISE, add_doppler=ADD_DOPPLER\n",
    ")\n",
    "X_test_processed = preprocess_iq_data(\n",
    "    X_test, snr_db=SNR_dB, fd=fd, fs=fs, add_noise=ADD_NOISE, add_doppler=ADD_DOPPLER\n",
    ")\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_processed, dtype=torch.float32),\n",
    "                              torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset  = TensorDataset(torch.tensor(X_test_processed, dtype=torch.float32),\n",
    "                              torch.tensor(y_test, dtype=torch.long))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    if len(x) < w:\n",
    "        w = max(1, len(x))\n",
    "    return np.convolve(x, np.ones(w), \"valid\") / w\n",
    "\n",
    "\n",
    "# ================== KFold 训练并保存 best_model_fold*.pth ==================\n",
    "fold_val_accs = []\n",
    "fold_test_accs = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset), start=1):\n",
    "    print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset   = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader   = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "    patience_cnt = 0\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for xb, yb in tqdm(train_loader, desc=f\"Fold{fold} Epoch{epoch}/{num_epochs}\", leave=False):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, pred = torch.max(out, 1)\n",
    "            total += yb.size(0)\n",
    "            correct += (pred == yb).sum().item()\n",
    "\n",
    "        tr_loss = running_loss / max(1, len(train_loader))\n",
    "        tr_acc = 100.0 * correct / max(1, total)\n",
    "        train_losses.append(tr_loss)\n",
    "        train_accs.append(tr_acc)\n",
    "\n",
    "        # ---- val ----\n",
    "        model.eval()\n",
    "        vloss, vcorrect, vtotal = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                vloss += loss.item()\n",
    "                _, pred = torch.max(out, 1)\n",
    "                vtotal += yb.size(0)\n",
    "                vcorrect += (pred == yb).sum().item()\n",
    "\n",
    "        va_loss = vloss / max(1, len(val_loader))\n",
    "        va_acc = 100.0 * vcorrect / max(1, vtotal)\n",
    "        val_losses.append(va_loss)\n",
    "        val_accs.append(va_acc)\n",
    "\n",
    "        log = (f\"Fold{fold} Epoch{epoch} | \"\n",
    "               f\"TrainAcc={tr_acc:.2f}% ValAcc={va_acc:.2f}% | \"\n",
    "               f\"TrainLoss={tr_loss:.4f} ValLoss={va_loss:.4f}\")\n",
    "        print(log)\n",
    "        with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(log + \"\\n\")\n",
    "\n",
    "        # ---- early stop on ValAcc (更符合你后续挑 best_model) ----\n",
    "        if va_acc > best_val_acc + 0.01:\n",
    "            best_val_acc = va_acc\n",
    "            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"[INFO] Early stopping triggered.\")\n",
    "                with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(\"[INFO] Early stopping triggered.\\n\")\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # 保存 best_model_fold*.pth（你后续 t-SNE 需要）\n",
    "    if best_state is None:\n",
    "        best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n",
    "\n",
    "    best_path = os.path.join(save_folder, f\"best_model_fold{fold}.pth\")\n",
    "    torch.save(best_state, best_path)\n",
    "    print(f\"[OK] Saved: {best_path}\")\n",
    "\n",
    "    # 也保存最终模型（可选）\n",
    "    last_path = os.path.join(save_folder, f\"model_fold{fold}.pth\")\n",
    "    torch.save({k: v.detach().cpu() for k, v in model.state_dict().items()}, last_path)\n",
    "\n",
    "    # 画训练曲线（无须改你原先风格）\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\")\n",
    "    plt.plot(moving_average(train_losses), \"--\", label=\"Train Loss Smooth\")\n",
    "    plt.plot(moving_average(val_losses), \"--\", label=\"Val Loss Smooth\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold}_loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_accs, label=\"Train Acc\")\n",
    "    plt.plot(val_accs, label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold}_acc_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # 测试集评估：用 best_state\n",
    "    model.load_state_dict(best_state, strict=True)\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            _, pred = torch.max(out, 1)\n",
    "            test_preds.append(pred.cpu().numpy())\n",
    "            test_true.append(yb.cpu().numpy())\n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    test_true = np.concatenate(test_true)\n",
    "    test_acc = 100.0 * np.mean(test_preds == test_true)\n",
    "\n",
    "    fold_val_accs.append(best_val_acc)\n",
    "    fold_test_accs.append(test_acc)\n",
    "\n",
    "    print(f\"[RESULT] Fold{fold}: BestValAcc={best_val_acc:.2f}% TestAcc={test_acc:.2f}%\")\n",
    "    with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[RESULT] Fold{fold}: BestValAcc={best_val_acc:.2f}% TestAcc={test_acc:.2f}%\\n\")\n",
    "\n",
    "    cm = confusion_matrix(test_true, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold}_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# 汇总\n",
    "with open(results_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n=== Overall Summary ===\\n\")\n",
    "    f.write(f\"Avg Best Val Acc: {np.mean(fold_val_accs):.2f} ± {np.std(fold_val_accs):.2f}\\n\")\n",
    "    f.write(f\"Avg Test Acc    : {np.mean(fold_test_accs):.2f} ± {np.std(fold_test_accs):.2f}\\n\")\n",
    "\n",
    "print(\"\\n[OK] Training done.\")\n",
    "print(f\"[OK] Models saved in: {save_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_wisig_tsne_train_test_overlay2d_export_mat.py\n",
    "# WiSig (ManySig.pkl) 训练集 vs 测试集：2D t-SNE（RAW 与 XFR 各一张 overlay）\n",
    "# 输出：\n",
    "#   1) RAW_train_test_2D.pdf/.png\n",
    "#   2) XFR_train_test_2D.pdf/.png\n",
    "#   3) WISIG_train_test_tsne_2D_all.mat  (包含RAW/XFR train/test嵌入与标签/元信息)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from matplotlib.patches import Ellipse\n",
    "import numpy.linalg as LA\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "# 你项目里已有\n",
    "from data_utilities import load_compact_pkl_dataset\n",
    "\n",
    "\n",
    "# ===================== 参数区（按你实际情况改） =====================\n",
    "DATASET_NAME = \"ManySig\"\n",
    "DATASET_PATH = r\"../ManySig.pkl/\"\n",
    "\n",
    "EXP_XFR_DIR = r\"./training_results/2025-11-28_19-42-37_wisig_XFR_SNR20dB_fd266_classes_6_ResNet\"\n",
    "EXP_RAW_DIR = r\"./training_results/2026-01-23_16-40-16_wisig_time_SNR20dB_fd266_classes_6_ResNet18\"\n",
    "\n",
    "OUT_DIR = r\"./TSNE_WISIG_20dB_TRAIN_TEST\"\n",
    "\n",
    "# 数据构造参数（必须与训练一致）\n",
    "EQUALIZED = 0\n",
    "MAX_SIG = None\n",
    "BLOCK_SIZE = 240     # 关键：XFR模型训练用的 input_length（你已确认=240）\n",
    "Y_PER_RX = 10\n",
    "\n",
    "TRAIN_DATES = [\"2021_03_15\"]\n",
    "TEST_DATES  = [\"2021_03_01\"]\n",
    "\n",
    "# 信道注入（与你训练一致；若训练时没开，请置 False）\n",
    "USE_COMMON_CHANNEL = True\n",
    "FS = 20e6\n",
    "FC = 2.4e9\n",
    "VELOCITY_KMH = 120\n",
    "APPLY_DOPPLER = True\n",
    "APPLY_AWGN = True\n",
    "\n",
    "# 抽样：每个 split 每类最多点数（t-SNE太大很慢）\n",
    "MAX_SAMPLES_PER_CLASS_RAW_TRAIN = 1200\n",
    "MAX_SAMPLES_PER_CLASS_RAW_TEST  = 1200\n",
    "MAX_SAMPLES_PER_CLASS_XFR_TRAIN = 1200\n",
    "MAX_SAMPLES_PER_CLASS_XFR_TEST  = 1200\n",
    "\n",
    "# 特征提取 batch\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# t-SNE\n",
    "SEED = 42\n",
    "PCA_DIM = 50\n",
    "TSNE_PERPLEXITY = 30\n",
    "TSNE_ITERS = 1500\n",
    "TSNE_METRIC = \"cosine\"\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "# ===================== 绘图风格（学术风） =====================\n",
    "def set_paper_style():\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.size\": 9,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"legend.frameon\": False,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"axes.facecolor\": \"white\",\n",
    "    })\n",
    "\n",
    "\n",
    "def _subsample(idx, max_n, rng):\n",
    "    if (max_n is None) or (len(idx) <= max_n):\n",
    "        return idx\n",
    "    return rng.choice(idx, size=max_n, replace=False)\n",
    "\n",
    "def _add_cov_ellipse(ax, pts2d, edgecolor, linestyle=\"-\", n_std=2.0, lw=0.9, alpha=0.9, zorder=2):\n",
    "    \"\"\"\n",
    "    画2D协方差椭圆：n_std=2 相当于“约95%”范围（对高斯近似）。\n",
    "    pts2d: (N,2)\n",
    "    \"\"\"\n",
    "    if pts2d is None or len(pts2d) < 10:\n",
    "        return\n",
    "    mu = np.mean(pts2d, axis=0)\n",
    "    cov = np.cov(pts2d.T)\n",
    "    if not np.all(np.isfinite(cov)):\n",
    "        return\n",
    "    vals, vecs = LA.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals = vals[order]\n",
    "    vecs = vecs[:, order]\n",
    "    if np.any(vals <= 1e-12):\n",
    "        return\n",
    "\n",
    "    # 椭圆主轴长度\n",
    "    width, height = 2 * n_std * np.sqrt(vals[0]), 2 * n_std * np.sqrt(vals[1])\n",
    "    angle = np.degrees(np.arctan2(vecs[1, 0], vecs[0, 0]))\n",
    "\n",
    "    e = Ellipse(xy=mu, width=width, height=height, angle=angle,\n",
    "                facecolor=\"none\", edgecolor=edgecolor, linestyle=linestyle,\n",
    "                linewidth=lw, alpha=alpha)\n",
    "    e.set_zorder(zorder)\n",
    "    ax.add_patch(e)\n",
    "\n",
    "def save_tsne_2d_train_test_overlay(\n",
    "    emb_train, y_train, emb_test, y_test,\n",
    "    class_names, out_base,\n",
    "    xlim=None, ylim=None,\n",
    "    # ====== 关键可调参数（建议保留默认） ======\n",
    "    plot_max_per_class_train=400,\n",
    "    plot_max_per_class_test=400,\n",
    "    train_marker=\".\",\n",
    "    train_size=14,\n",
    "    train_alpha=0.9,\n",
    "    test_marker=\"^\",\n",
    "    test_size=14,\n",
    "    test_alpha=0.90,\n",
    "    test_edgecolor=\"k\",\n",
    "    test_lw=0.25,\n",
    "    draw_ellipses=True,\n",
    "    ellipse_nstd=2.0\n",
    "):\n",
    "    \"\"\"\n",
    "    同一张图：Train vs Test overlay（更抗过绘制版本）\n",
    "      - Train: 极淡小点（背景密度云）\n",
    "      - Test : 大三角 + 黑描边（前景）\n",
    "      - 类别用 TXk 文本标注（默认不再重复画类别legend）\n",
    "      - 可选协方差椭圆：Train 实线，Test 虚线\n",
    "    \"\"\"\n",
    "    set_paper_style()\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    num_classes = int(max(y_train.max(), y_test.max())) + 1\n",
    "    cmap = plt.cm.get_cmap(\"tab10\", num_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(3.6, 3.1), dpi=450)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        col = cmap(c)\n",
    "\n",
    "        idx_tr_all = np.where(y_train == c)[0]\n",
    "        idx_te_all = np.where(y_test == c)[0]\n",
    "\n",
    "        # 仅用于“画图显示”的二次下采样（t-SNE拟合已完成，不受影响）\n",
    "        idx_tr = _subsample(idx_tr_all, plot_max_per_class_train, rng)\n",
    "        idx_te = _subsample(idx_te_all, plot_max_per_class_test, rng)\n",
    "\n",
    "        # Train：背景云（极淡）\n",
    "        if len(idx_tr) > 0:\n",
    "            ax.scatter(\n",
    "                emb_train[idx_tr, 0], emb_train[idx_tr, 1],\n",
    "                s=train_size, c=[col], alpha=train_alpha,\n",
    "                marker=train_marker, linewidths=0,\n",
    "                zorder=1, rasterized=True\n",
    "            )\n",
    "\n",
    "        # Test：前景（三角+描边）\n",
    "        if len(idx_te) > 0:\n",
    "            ax.scatter(\n",
    "                emb_test[idx_te, 0], emb_test[idx_te, 1],\n",
    "                s=test_size, c=[col], alpha=test_alpha,\n",
    "                marker=test_marker, linewidths=test_lw,\n",
    "                edgecolors=test_edgecolor,\n",
    "                zorder=3, rasterized=True\n",
    "            )\n",
    "\n",
    "        # 协方差椭圆（用全量点算，更稳定；显示更清晰）\n",
    "        if draw_ellipses:\n",
    "            if len(idx_tr_all) > 15:\n",
    "                _add_cov_ellipse(ax, emb_train[idx_tr_all], edgecolor=col, linestyle=\"-\",\n",
    "                                 n_std=ellipse_nstd, lw=0.9, alpha=0.85, zorder=2)\n",
    "            if len(idx_te_all) > 15:\n",
    "                _add_cov_ellipse(ax, emb_test[idx_te_all], edgecolor=col, linestyle=\"--\",\n",
    "                                 n_std=ellipse_nstd, lw=0.9, alpha=0.85, zorder=2)\n",
    "\n",
    "        # 类标注：用 train+test 的“中位数”更鲁棒（比均值不容易被散点拖偏）\n",
    "        pts = []\n",
    "        if len(idx_tr_all) > 0:\n",
    "            pts.append(emb_train[idx_tr_all])\n",
    "        if len(idx_te_all) > 0:\n",
    "            pts.append(emb_test[idx_te_all])\n",
    "        if len(pts) > 0:\n",
    "            pts = np.vstack(pts)\n",
    "            cx, cy = np.median(pts, axis=0)\n",
    "\n",
    "            txt = ax.text(\n",
    "                cx, cy, class_names[c],\n",
    "                fontsize=9, color=\"black\",\n",
    "                ha=\"center\", va=\"center\", zorder=4\n",
    "            )\n",
    "            txt.set_path_effects([pe.withStroke(linewidth=2.2, foreground=\"white\")])\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE 1\")\n",
    "    ax.set_ylabel(\"t-SNE 2\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    # 只保留 Train/Test legend（类别已在图中标注TX1~TX6）\n",
    "    from matplotlib.lines import Line2D\n",
    "    split_handles = [\n",
    "        Line2D([0], [0], marker=train_marker, color=\"none\", markerfacecolor=\"gray\",\n",
    "               markersize=5, label=\"date 03_15\"),\n",
    "        Line2D([0], [0], marker=test_marker, color=\"none\", markerfacecolor=\"gray\",\n",
    "               markeredgecolor=\"k\", markersize=6, label=\"date 03_01\"),\n",
    "    ]\n",
    "    ax.legend(handles=split_handles, loc=\"upper right\", fontsize=8, handletextpad=0.4, borderpad=0.2)\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "    os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "    plt.savefig(out_base + \".pdf\", bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.savefig(out_base + \".png\", bbox_inches=\"tight\", pad_inches=0.02, dpi=450)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "# ===================== .mat 导出 =====================\n",
    "def save_mat_train_test(out_path, payload: dict):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    savemat(out_path, payload)\n",
    "    print(f\"[OK] Saved mat: {out_path}\")\n",
    "\n",
    "\n",
    "# ===================== 信道/预处理（与你训练一致） =====================\n",
    "def compute_doppler_shift(v_kmh, fc_hz):\n",
    "    c = 3e8\n",
    "    v = v_kmh / 3.6\n",
    "    return fc_hz * v / c\n",
    "\n",
    "\n",
    "def apply_doppler_shift(signal_c, fd_hz, fs_hz):\n",
    "    t = np.arange(signal_c.shape[-1]) / fs_hz\n",
    "    return signal_c * np.exp(1j * 2 * np.pi * fd_hz * t)\n",
    "\n",
    "\n",
    "def add_awgn(signal_c, snr_db):\n",
    "    power = np.mean(np.abs(signal_c) ** 2) + 1e-12\n",
    "    noise_power = power / (10 ** (snr_db / 10))\n",
    "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal_c.shape) + 1j * np.random.randn(*signal_c.shape))\n",
    "    return signal_c + noise\n",
    "\n",
    "\n",
    "def preprocess_for_pointcloud_cnn(data_real_imag, add_noise=False, snr_db=None,\n",
    "                                  add_doppler=False, fd_hz=None, fs_hz=FS):\n",
    "    \"\"\"\n",
    "    功率归一化 -> Doppler -> AWGN -> per-sample z-score\n",
    "    \"\"\"\n",
    "    data = data_real_imag.astype(np.float32, copy=True)\n",
    "    N, L, _ = data.shape\n",
    "    out = np.empty_like(data, dtype=np.float32)\n",
    "\n",
    "    for i in range(N):\n",
    "        iq = data[i]\n",
    "        sigc = iq[..., 0] + 1j * iq[..., 1]\n",
    "\n",
    "        sigc = sigc / (np.sqrt(np.mean(np.abs(sigc) ** 2)) + 1e-12)\n",
    "\n",
    "        if add_doppler and fd_hz is not None:\n",
    "            sigc = apply_doppler_shift(sigc, fd_hz, fs_hz)\n",
    "\n",
    "        if add_noise and snr_db is not None:\n",
    "            sigc = add_awgn(sigc, snr_db)\n",
    "\n",
    "        iq2 = np.stack([np.real(sigc), np.imag(sigc)], axis=-1).astype(np.float32)\n",
    "\n",
    "        mu = iq2.mean(axis=0)\n",
    "        sigma = iq2.std(axis=0)\n",
    "        sigma[sigma < 1e-8] = 1.0\n",
    "        out[i] = (iq2 - mu) / sigma\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def parse_snr_fd_classes(folder_name: str):\n",
    "    snr = None\n",
    "    fd = None\n",
    "    ncls = None\n",
    "    m = re.search(r\"SNR(-?\\d+)dB\", folder_name)\n",
    "    if m:\n",
    "        snr = int(m.group(1))\n",
    "    m = re.search(r\"fd(\\d+)\", folder_name)\n",
    "    if m:\n",
    "        fd = int(m.group(1))\n",
    "    m = re.search(r\"classes[_-](\\d+)\", folder_name)\n",
    "    if m:\n",
    "        ncls = int(m.group(1))\n",
    "    return snr, fd, ncls\n",
    "\n",
    "\n",
    "# ===================== WiSig blocks（与你 cyclic 逻辑一致） =====================\n",
    "def load_blocks_wisig_cyclic(compact_dataset, tx_list, dates,\n",
    "                             max_sig=None, equalized=0, block_size=240, y=10):\n",
    "    \"\"\"\n",
    "    返回：\n",
    "      raw_blocks: (B, G, 256, 2) 其中 G=block_size\n",
    "      xfr_blocks: (B, 256, G, 2)\n",
    "      y_blocks:   (B,)\n",
    "    \"\"\"\n",
    "    raw_blocks, xfr_blocks, y_blocks = [], [], []\n",
    "\n",
    "    try:\n",
    "        eq_i = compact_dataset[\"equalized_list\"].index(equalized)\n",
    "    except ValueError:\n",
    "        raise RuntimeError(f\"equalized={equalized} 不在 equalized_list 中\")\n",
    "\n",
    "    for tx_idx, tx in enumerate(tx_list):\n",
    "        try:\n",
    "            tx_i = compact_dataset[\"tx_list\"].index(tx)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        for date in dates:\n",
    "            if date not in compact_dataset[\"capture_date_list\"]:\n",
    "                continue\n",
    "            date_i = compact_dataset[\"capture_date_list\"].index(date)\n",
    "\n",
    "            rx_signals = []\n",
    "            for rx_i in range(len(compact_dataset[\"rx_list\"])):\n",
    "                sig_data = compact_dataset[\"data\"][tx_i][rx_i][date_i][eq_i]\n",
    "                if max_sig is not None:\n",
    "                    sig_data = sig_data[:max_sig]\n",
    "                rx_signals.append(list(sig_data))\n",
    "\n",
    "            num_rx = len(rx_signals)\n",
    "            rx_pointer = 0\n",
    "            accum_block = []\n",
    "\n",
    "            while any(len(sig_list) > 0 for sig_list in rx_signals):\n",
    "                rx_idx = rx_pointer % num_rx\n",
    "                sig_list = rx_signals[rx_idx]\n",
    "\n",
    "                if len(sig_list) > 0:\n",
    "                    take_n = min(y, len(sig_list))\n",
    "                    sampled = [sig_list.pop(0) for _ in range(take_n)]\n",
    "                    accum_block.extend(sampled)\n",
    "\n",
    "                rx_pointer += 1\n",
    "\n",
    "                while len(accum_block) >= block_size:\n",
    "                    block_chunk = accum_block[:block_size]\n",
    "                    accum_block = accum_block[block_size:]\n",
    "\n",
    "                    block_array = np.array(block_chunk)  # (G,256,2)\n",
    "                    if block_array.ndim != 3 or block_array.shape[-1] != 2:\n",
    "                        raise RuntimeError(f\"Unexpected signal shape: {block_array.shape}\")\n",
    "\n",
    "                    raw_blocks.append(block_array.astype(np.float32))\n",
    "                    xfr_blocks.append(block_array.transpose(1, 0, 2).astype(np.float32))  # (256,G,2)\n",
    "                    y_blocks.append(tx_idx)\n",
    "\n",
    "            accum_block = []\n",
    "\n",
    "    if len(raw_blocks) == 0:\n",
    "        raise RuntimeError(\"未生成任何 block：检查 dates / block_size / y / max_sig 等参数\")\n",
    "\n",
    "    raw_blocks = np.stack(raw_blocks, axis=0)\n",
    "    xfr_blocks = np.stack(xfr_blocks, axis=0)\n",
    "    y_blocks = np.array(y_blocks, dtype=np.int64)\n",
    "\n",
    "    return raw_blocks, xfr_blocks, y_blocks\n",
    "\n",
    "\n",
    "# ===================== 模型（自动识别 ResNet18_1D / RF1DCNN） =====================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = out + identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        feat = self.extract_features(x)\n",
    "        return self.fc(feat)\n",
    "\n",
    "\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=1):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        out = out + identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class RF1DCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.3, input_length=256):\n",
    "        super().__init__()\n",
    "        self.layer1 = ResidualBlock1D(2, 32, kernel_size=7); self.pool1 = nn.MaxPool1d(2)\n",
    "        self.layer2 = ResidualBlock1D(32, 64, kernel_size=5); self.pool2 = nn.MaxPool1d(2)\n",
    "        self.layer3 = ResidualBlock1D(64, 128, kernel_size=5); self.pool3 = nn.MaxPool1d(2)\n",
    "        self.layer4 = ResidualBlock1D(128, 256, kernel_size=3); self.pool4 = nn.MaxPool1d(2)\n",
    "\n",
    "        L = input_length\n",
    "        for _ in range(4):\n",
    "            L = L // 2\n",
    "        self.flattened_length = 256 * L\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flattened_length, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.layer1(x); x = self.pool1(x)\n",
    "        x = self.layer2(x); x = self.pool2(x)\n",
    "        x = self.layer3(x); x = self.pool3(x)\n",
    "        x = self.layer4(x); x = self.pool4(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc[1](x)\n",
    "        x = self.fc[2](x)\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        feat = self.extract_features(x)\n",
    "        x = self.fc[3](feat)\n",
    "        x = self.fc[4](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def strip_module_prefix(state_dict):\n",
    "    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        return {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def find_fold_models(exp_dir):\n",
    "    import glob\n",
    "    paths = glob.glob(os.path.join(exp_dir, \"best_model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        paths = glob.glob(os.path.join(exp_dir, \"model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        raise RuntimeError(f\"在 {exp_dir} 未找到 best_model_fold*.pth 或 model_fold*.pth\")\n",
    "\n",
    "    def fold_key(p):\n",
    "        m = re.search(r\"fold(\\d+)\", os.path.basename(p))\n",
    "        return int(m.group(1)) if m else 999\n",
    "    return sorted(paths, key=fold_key)\n",
    "\n",
    "\n",
    "def build_model_from_state(state, input_length_hint, device):\n",
    "    keys = list(state.keys())\n",
    "\n",
    "    is_resnet18 = any(k.startswith(\"layer1.0.\") for k in keys) and (\"fc.weight\" in keys)\n",
    "    is_rf1dcnn = any(k.startswith(\"layer1.conv1.\") for k in keys) and any(k.startswith(\"fc.1.\") for k in keys)\n",
    "\n",
    "    if is_resnet18:\n",
    "        in_planes = state[\"conv1.weight\"].shape[0]\n",
    "        num_classes = state[\"fc.weight\"].shape[0]\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=0.0).to(device)\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    if is_rf1dcnn:\n",
    "        # 关键：RF1DCNN 的 flatten 维度依赖 input_length_hint（=你的BLOCK_SIZE）\n",
    "        num_classes = state[\"fc.4.weight\"].shape[0]\n",
    "        model = RF1DCNN(num_classes=num_classes, dropout=0.3, input_length=input_length_hint).to(device)\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    raise RuntimeError(\"无法识别模型结构：state_dict keys不匹配 ResNet18_1D / RF1DCNN。\")\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "def stratified_sample_indices(y, max_per_class, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    keep = []\n",
    "    for c in np.unique(y):\n",
    "        idx = np.where(y == c)[0]\n",
    "        if len(idx) > max_per_class:\n",
    "            idx = rng.choice(idx, size=max_per_class, replace=False)\n",
    "        keep.append(idx)\n",
    "    keep = np.concatenate(keep)\n",
    "    rng.shuffle(keep)\n",
    "    return keep\n",
    "\n",
    "\n",
    "def extract_features_foldmean(model_paths, X, y, device):\n",
    "    ds = SimpleDataset(X, y)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    feats_folds = []\n",
    "    input_length_hint = X.shape[1]\n",
    "\n",
    "    for mp in model_paths:\n",
    "        state = strip_module_prefix(torch.load(mp, map_location=device))\n",
    "        model = build_model_from_state(state, input_length_hint=input_length_hint, device=device)\n",
    "\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in tqdm(loader, desc=f\"Extract {os.path.basename(mp)}\", leave=False):\n",
    "                xb = xb.to(device)\n",
    "                f = model.extract_features(xb).cpu().numpy()\n",
    "                feats.append(f)\n",
    "        feats = np.concatenate(feats, axis=0)\n",
    "        feats_folds.append(feats)\n",
    "\n",
    "    feats_folds = np.stack(feats_folds, axis=0)\n",
    "    return feats_folds.mean(axis=0)\n",
    "\n",
    "\n",
    "def tsne_joint_two_splits(feat_train, feat_test, n_components=2, seed=42):\n",
    "    \"\"\"\n",
    "    对 train+test 拼接 joint-fit，确保同一坐标系\n",
    "    \"\"\"\n",
    "    X = np.concatenate([feat_train, feat_test], axis=0).astype(np.float32)\n",
    "\n",
    "    pca_dim_eff = min(PCA_DIM, X.shape[1])\n",
    "    X_pca = PCA(n_components=pca_dim_eff, random_state=seed).fit_transform(X)\n",
    "\n",
    "    tsne_kwargs = dict(\n",
    "        n_components=n_components,\n",
    "        perplexity=TSNE_PERPLEXITY,\n",
    "        init=\"pca\",\n",
    "        learning_rate=\"auto\",\n",
    "        metric=TSNE_METRIC,\n",
    "        random_state=seed,\n",
    "        verbose=1\n",
    "    )\n",
    "    try:\n",
    "        tsne = TSNE(**tsne_kwargs, n_iter=TSNE_ITERS)\n",
    "    except TypeError:\n",
    "        tsne = TSNE(**tsne_kwargs, max_iter=TSNE_ITERS)\n",
    "\n",
    "    emb = tsne.fit_transform(X_pca)\n",
    "    return emb[:feat_train.shape[0]], emb[feat_train.shape[0]:]\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    # common channel parameters\n",
    "    snr_xfr, fd_xfr, _ = parse_snr_fd_classes(os.path.basename(EXP_XFR_DIR))\n",
    "    if USE_COMMON_CHANNEL:\n",
    "        snr_use = snr_xfr if snr_xfr is not None else 20\n",
    "        fd_use = fd_xfr if fd_xfr is not None else int(compute_doppler_shift(VELOCITY_KMH, FC))\n",
    "    else:\n",
    "        snr_use = snr_xfr or 20\n",
    "        fd_use = fd_xfr or int(compute_doppler_shift(VELOCITY_KMH, FC))\n",
    "\n",
    "    print(f\"[INFO] SNR_use={snr_use} dB, fd_use={fd_use} Hz\")\n",
    "\n",
    "    # load dataset\n",
    "    compact_dataset = load_compact_pkl_dataset(DATASET_PATH, DATASET_NAME)\n",
    "    tx_list = compact_dataset[\"tx_list\"]\n",
    "    n_tx = len(tx_list)\n",
    "    if n_tx != 6:\n",
    "        print(f\"[WARN] 当前tx数量={n_tx}，但你希望标注TX1~TX6。将按实际n_tx生成class_names。\")\n",
    "\n",
    "    class_names = [f\"TX{i+1}\" for i in range(n_tx)]\n",
    "\n",
    "    # 1) 构造 train blocks 与 test blocks（按日期划分）\n",
    "    raw_tr_blk, xfr_tr_blk, y_tr_blk = load_blocks_wisig_cyclic(\n",
    "        compact_dataset, tx_list, TRAIN_DATES,\n",
    "        max_sig=MAX_SIG, equalized=EQUALIZED, block_size=BLOCK_SIZE, y=Y_PER_RX\n",
    "    )\n",
    "    raw_te_blk, xfr_te_blk, y_te_blk = load_blocks_wisig_cyclic(\n",
    "        compact_dataset, tx_list, TEST_DATES,\n",
    "        max_sig=MAX_SIG, equalized=EQUALIZED, block_size=BLOCK_SIZE, y=Y_PER_RX\n",
    "    )\n",
    "\n",
    "    # shapes\n",
    "    Btr, G, L, _ = raw_tr_blk.shape   # RAW: (B,G,256,2)\n",
    "    Bte, _, _, _ = raw_te_blk.shape\n",
    "    assert xfr_tr_blk.shape == (Btr, L, G, 2)\n",
    "    assert xfr_te_blk.shape == (Bte, L, G, 2)\n",
    "\n",
    "    # 2) 组装样本级：RAW(time-IQ) 与 XFR(cross-IQ)\n",
    "    # RAW samples: (B*G, 256,2)\n",
    "    X_raw_tr = raw_tr_blk.reshape(-1, L, 2)\n",
    "    y_raw_tr = np.repeat(y_tr_blk, G)\n",
    "    X_raw_te = raw_te_blk.reshape(-1, L, 2)\n",
    "    y_raw_te = np.repeat(y_te_blk, G)\n",
    "\n",
    "    # XFR samples: (B*L, G,2) 其中 G=BLOCK_SIZE(240)\n",
    "    X_xfr_tr = xfr_tr_blk.reshape(-1, G, 2)\n",
    "    y_xfr_tr = np.repeat(y_tr_blk, L)\n",
    "    X_xfr_te = xfr_te_blk.reshape(-1, G, 2)\n",
    "    y_xfr_te = np.repeat(y_te_blk, L)\n",
    "\n",
    "    # 3) 分层抽样控制规模（分别对 train/test）\n",
    "    idx = stratified_sample_indices(y_raw_tr, MAX_SAMPLES_PER_CLASS_RAW_TRAIN, seed=SEED)\n",
    "    X_raw_tr, y_raw_tr = X_raw_tr[idx], y_raw_tr[idx]\n",
    "    idx = stratified_sample_indices(y_raw_te, MAX_SAMPLES_PER_CLASS_RAW_TEST, seed=SEED)\n",
    "    X_raw_te, y_raw_te = X_raw_te[idx], y_raw_te[idx]\n",
    "\n",
    "    idx = stratified_sample_indices(y_xfr_tr, MAX_SAMPLES_PER_CLASS_XFR_TRAIN, seed=SEED)\n",
    "    X_xfr_tr, y_xfr_tr = X_xfr_tr[idx], y_xfr_tr[idx]\n",
    "    idx = stratified_sample_indices(y_xfr_te, MAX_SAMPLES_PER_CLASS_XFR_TEST, seed=SEED)\n",
    "    X_xfr_te, y_xfr_te = X_xfr_te[idx], y_xfr_te[idx]\n",
    "\n",
    "    print(f\"[INFO] RAW train/test samples: {len(y_raw_tr)}/{len(y_raw_te)}\")\n",
    "    print(f\"[INFO] XFR train/test samples: {len(y_xfr_tr)}/{len(y_xfr_te)}\")\n",
    "\n",
    "    # 4) 注入信道 + per-sample 标准化（保持与训练一致）\n",
    "    if APPLY_DOPPLER or APPLY_AWGN:\n",
    "        # 为可复现：固定随机种子后再处理（AWGN用到了np.random）\n",
    "        np.random.seed(SEED)\n",
    "        X_raw_tr = preprocess_for_pointcloud_cnn(X_raw_tr, add_noise=APPLY_AWGN, snr_db=snr_use,\n",
    "                                                 add_doppler=APPLY_DOPPLER, fd_hz=fd_use, fs_hz=FS)\n",
    "        X_raw_te = preprocess_for_pointcloud_cnn(X_raw_te, add_noise=APPLY_AWGN, snr_db=snr_use,\n",
    "                                                 add_doppler=APPLY_DOPPLER, fd_hz=fd_use, fs_hz=FS)\n",
    "\n",
    "        np.random.seed(SEED + 1)\n",
    "        X_xfr_tr = preprocess_for_pointcloud_cnn(X_xfr_tr, add_noise=APPLY_AWGN, snr_db=snr_use,\n",
    "                                                 add_doppler=APPLY_DOPPLER, fd_hz=fd_use, fs_hz=FS)\n",
    "        X_xfr_te = preprocess_for_pointcloud_cnn(X_xfr_te, add_noise=APPLY_AWGN, snr_db=snr_use,\n",
    "                                                 add_doppler=APPLY_DOPPLER, fd_hz=fd_use, fs_hz=FS)\n",
    "\n",
    "    # 5) 加载模型fold\n",
    "    raw_models = find_fold_models(EXP_RAW_DIR)\n",
    "    xfr_models = find_fold_models(EXP_XFR_DIR)\n",
    "    print(f\"[INFO] folds: RAW={len(raw_models)} XFR={len(xfr_models)}\")\n",
    "\n",
    "    # 6) 提取特征（fold-mean）\n",
    "    feat_raw_tr = extract_features_foldmean(raw_models, X_raw_tr, y_raw_tr, device)\n",
    "    feat_raw_te = extract_features_foldmean(raw_models, X_raw_te, y_raw_te, device)\n",
    "\n",
    "    feat_xfr_tr = extract_features_foldmean(xfr_models, X_xfr_tr, y_xfr_tr, device)\n",
    "    feat_xfr_te = extract_features_foldmean(xfr_models, X_xfr_te, y_xfr_te, device)\n",
    "\n",
    "    # 7) 2D t-SNE：分别对 RAW 与 XFR 做 train+test joint-fit\n",
    "    emb2_raw_tr, emb2_raw_te = tsne_joint_two_splits(feat_raw_tr, feat_raw_te, n_components=2, seed=SEED)\n",
    "    emb2_xfr_tr, emb2_xfr_te = tsne_joint_two_splits(feat_xfr_tr, feat_xfr_te, n_components=2, seed=SEED)\n",
    "\n",
    "    # 统一坐标范围（同一方法内 train/test 共享范围；RAW与XFR不强行共范围）\n",
    "    def lim2(emb_a, emb_b):\n",
    "        x_all = np.concatenate([emb_a[:, 0], emb_b[:, 0]])\n",
    "        y_all = np.concatenate([emb_a[:, 1], emb_b[:, 1]])\n",
    "        return (float(x_all.min()), float(x_all.max())), (float(y_all.min()), float(y_all.max()))\n",
    "\n",
    "    xlim_raw, ylim_raw = lim2(emb2_raw_tr, emb2_raw_te)\n",
    "    xlim_xfr, ylim_xfr = lim2(emb2_xfr_tr, emb2_xfr_te)\n",
    "\n",
    "    # 8) 输出两张 overlay 图（每张图里 train/test 在一起）\n",
    "    save_tsne_2d_train_test_overlay(\n",
    "        emb2_raw_tr, y_raw_tr, emb2_raw_te, y_raw_te,\n",
    "        class_names=class_names,\n",
    "        out_base=os.path.join(OUT_DIR, \"RAW_train_test_2D\"),\n",
    "        xlim=xlim_raw, ylim=ylim_raw\n",
    "    )\n",
    "\n",
    "    save_tsne_2d_train_test_overlay(\n",
    "        emb2_xfr_tr, y_xfr_tr, emb2_xfr_te, y_xfr_te,\n",
    "        class_names=class_names,\n",
    "        out_base=os.path.join(OUT_DIR, \"XFR_train_test_2D\"),\n",
    "        xlim=xlim_xfr, ylim=ylim_xfr\n",
    "    )\n",
    "\n",
    "    print(\"[OK] Saved 2 overlay figures (RAW/XFR).\")\n",
    "\n",
    "    # 9) 导出 .mat（MATLAB可直接画/分析）\n",
    "    meta = {\n",
    "        \"DATASET_NAME\": DATASET_NAME,\n",
    "        \"DATASET_PATH\": DATASET_PATH,\n",
    "        \"EXP_RAW_DIR\": EXP_RAW_DIR,\n",
    "        \"EXP_XFR_DIR\": EXP_XFR_DIR,\n",
    "        \"TRAIN_DATES\": TRAIN_DATES,\n",
    "        \"TEST_DATES\": TEST_DATES,\n",
    "        \"EQUALIZED\": int(EQUALIZED),\n",
    "        \"MAX_SIG\": -1 if MAX_SIG is None else int(MAX_SIG),\n",
    "        \"BLOCK_SIZE\": int(BLOCK_SIZE),\n",
    "        \"Y_PER_RX\": int(Y_PER_RX),\n",
    "        \"SNR_use_dB\": int(snr_use),\n",
    "        \"fd_use_Hz\": int(fd_use),\n",
    "        \"FS\": float(FS),\n",
    "        \"FC\": float(FC),\n",
    "        \"VELOCITY_KMH\": float(VELOCITY_KMH),\n",
    "        \"APPLY_DOPPLER\": int(APPLY_DOPPLER),\n",
    "        \"APPLY_AWGN\": int(APPLY_AWGN),\n",
    "        \"MAX_SAMPLES_PER_CLASS_RAW_TRAIN\": int(MAX_SAMPLES_PER_CLASS_RAW_TRAIN),\n",
    "        \"MAX_SAMPLES_PER_CLASS_RAW_TEST\": int(MAX_SAMPLES_PER_CLASS_RAW_TEST),\n",
    "        \"MAX_SAMPLES_PER_CLASS_XFR_TRAIN\": int(MAX_SAMPLES_PER_CLASS_XFR_TRAIN),\n",
    "        \"MAX_SAMPLES_PER_CLASS_XFR_TEST\": int(MAX_SAMPLES_PER_CLASS_XFR_TEST),\n",
    "        \"PCA_DIM\": int(PCA_DIM),\n",
    "        \"TSNE_PERPLEXITY\": int(TSNE_PERPLEXITY),\n",
    "        \"TSNE_ITERS\": int(TSNE_ITERS),\n",
    "        \"TSNE_METRIC\": TSNE_METRIC,\n",
    "        \"SEED\": int(SEED),\n",
    "    }\n",
    "\n",
    "    out_mat = os.path.join(OUT_DIR, \"WISIG_train_test_tsne_2D_all.mat\")\n",
    "    payload = {\n",
    "        # RAW\n",
    "        \"emb2_raw_train\": emb2_raw_tr.astype(np.float64),\n",
    "        \"emb2_raw_test\":  emb2_raw_te.astype(np.float64),\n",
    "        \"y_raw_train\": y_raw_tr.astype(np.int64).reshape(-1, 1),\n",
    "        \"y_raw_test\":  y_raw_te.astype(np.int64).reshape(-1, 1),\n",
    "\n",
    "        # XFR\n",
    "        \"emb2_xfr_train\": emb2_xfr_tr.astype(np.float64),\n",
    "        \"emb2_xfr_test\":  emb2_xfr_te.astype(np.float64),\n",
    "        \"y_xfr_train\": y_xfr_tr.astype(np.int64).reshape(-1, 1),\n",
    "        \"y_xfr_test\":  y_xfr_te.astype(np.int64).reshape(-1, 1),\n",
    "\n",
    "        # names / meta\n",
    "        \"class_names\": np.array(class_names, dtype=object),\n",
    "        \"meta\": meta,\n",
    "    }\n",
    "    save_mat_train_test(out_mat, payload)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee2f340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Common channel: SNR=20 dB, fd=655 Hz\n",
      "[INFO] Found 72 .mat files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading LTE-V .mat: 100%|██████████| 72/72 [00:10<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] blocks=243, group_size=864, sample_len=288, classes=9\n",
      "[INFO] sample-level selected: RAW=13500, XFR=13500\n",
      "[INFO] RAW folds: 5, XFR folds: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZY\\.conda\\envs\\MW-RFF\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 27000 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 27000 samples in 4.288s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 27000\n",
      "[t-SNE] Mean sigma: 0.008513\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 85.293739\n",
      "[t-SNE] KL divergence after 1500 iterations: 1.961186\n",
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 27000 samples in 0.001s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZY\\.conda\\envs\\MW-RFF\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 27000 samples in 4.190s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 27000\n",
      "[t-SNE] Computed conditional probabilities for sample 27000 / 27000\n",
      "[t-SNE] Mean sigma: 0.008513\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 84.641853\n",
      "[t-SNE] KL divergence after 1500 iterations: 1.729060\n",
      "[INFO] Class mapping (TXk -> tx_id):\n",
      "  TX1 -> 001\n",
      "  TX2 -> 002\n",
      "  TX3 -> 003\n",
      "  TX4 -> 004\n",
      "  TX5 -> 005\n",
      "  TX6 -> 006\n",
      "  TX7 -> 007\n",
      "  TX8 -> 008\n",
      "  TX9 -> 009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZY\\AppData\\Local\\Temp\\ipykernel_50440\\2434778422.py:140: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap(\"tab10\", 10)\n",
      "C:\\Users\\ZY\\AppData\\Local\\Temp\\ipykernel_50440\\2434778422.py:228: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = plt.cm.get_cmap(\"tab10\", 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved 4 figures (RAW=legend lower-left, XFR=text on-plot).\n",
      "[OK] Saved mat: ./TSNE\\RAW_2D_tsne.mat\n",
      "[OK] Saved mat: ./TSNE\\XFR_2D_tsne.mat\n",
      "[OK] Saved mat: ./TSNE\\RAW_3D_tsne.mat\n",
      "[OK] Saved mat: ./TSNE\\XFR_3D_tsne.mat\n",
      "[OK] Saved mat: ./TSNE\\LTEV_tsne_all.mat\n"
     ]
    }
   ],
   "source": [
    "# plot_ltev_feature_tsne_sample_level_export_mat_and_figs.py\n",
    "# 样本级（非block聚合）特征 t-SNE：RAW vs XFR，joint-fit 2D/3D\n",
    "# 输出：4张独立图（PDF+PNG, 无title, WiSig同款学术风格） + 4份.mat + 1份总.mat\n",
    "#\n",
    "# 本版修改点（基于你给的脚本“直接改”）：\n",
    "#   - 不画椭圆\n",
    "#   - XFR：TXk 直接写在图上（白描边文字），不再单独放类别legend\n",
    "#   - RAW：不在图中写TXk，改为“左下角类别legend（TX1..TXn）”\n",
    "#   - 画图可二次下采样（只影响显示，不影响 t-SNE 拟合与 .mat 导出）\n",
    "#   - 总 .mat 增加 class_names / txid_list / mapping（便于追溯）\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.io import savemat\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "# ===================== 你需要确认/修改的参数 =====================\n",
    "DATA_PATH = r\"E:/rf_datasets/\"  # LTE-V .mat 文件夹\n",
    "\n",
    "EXP_XFR_DIR = r\"./training_results/2026-01-07_19-01-27_LTE-V_XFR_SNR20dB_fd655_classes_9_ResNet\"\n",
    "EXP_RAW_DIR = r\"./training_results/2025-11-27_11-25-06_LTE_time_SNR20dB_fd960_classes_9\"\n",
    "\n",
    "OUT_DIR = r\"./TSNE\"\n",
    "\n",
    "GROUP_SIZE = 864\n",
    "TEST_SIZE = 0.25\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "# 为了公平对比，建议 True：两边用同一个 SNR/fd 注入生成同源 blocks\n",
    "USE_COMMON_CHANNEL = True\n",
    "FS = 5e6\n",
    "APPLY_DOPPLER = True\n",
    "APPLY_AWGN = True\n",
    "\n",
    "# 抽样（样本级每类最多点数，避免t-SNE过慢）\n",
    "MAX_SAMPLES_PER_CLASS_RAW = 1500\n",
    "MAX_SAMPLES_PER_CLASS_XFR = 1500\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# t-SNE\n",
    "SEED = 42\n",
    "PCA_DIM = 50\n",
    "TSNE_PERPLEXITY = 30\n",
    "TSNE_ITERS = 1500\n",
    "TSNE_METRIC = \"cosine\"\n",
    "\n",
    "# ===== 绘图（WiSig同款）=====\n",
    "PLOT_MAX_PER_CLASS = 600    # 仅影响“画图显示”\n",
    "PLOT_MARKER = \"^\"\n",
    "PLOT_POINT_SIZE = 14\n",
    "PLOT_POINT_ALPHA = 0.90\n",
    "PLOT_EDGE_LW = 0.25\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "# ===================== 论文风格绘图配置（WiSig模板） =====================\n",
    "def set_paper_style():\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.size\": 9,\n",
    "        \"axes.labelsize\": 9,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"legend.frameon\": False,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"axes.facecolor\": \"white\",\n",
    "    })\n",
    "\n",
    "\n",
    "def _subsample(idx, max_n, rng):\n",
    "    if (max_n is None) or (len(idx) <= max_n):\n",
    "        return idx\n",
    "    return rng.choice(idx, size=max_n, replace=False)\n",
    "\n",
    "\n",
    "def _build_class_legend_handles(class_names, cmap, marker=\"^\", edge_color=\"k\", edge_lw=0.25, alpha=0.90):\n",
    "    handles = []\n",
    "    for i, name in enumerate(class_names):\n",
    "        col = cmap(i % 10)\n",
    "        h = Line2D(\n",
    "            [0], [0],\n",
    "            marker=marker,\n",
    "            linestyle=\"None\",\n",
    "            markerfacecolor=col,\n",
    "            markeredgecolor=edge_color,\n",
    "            markeredgewidth=edge_lw,\n",
    "            alpha=alpha,\n",
    "            markersize=6,\n",
    "            label=name\n",
    "        )\n",
    "        handles.append(h)\n",
    "    return handles\n",
    "\n",
    "\n",
    "def save_tsne_2d_single_wisig_style(\n",
    "    emb2, y, class_names, out_base,\n",
    "    xlim=None, ylim=None,\n",
    "    plot_max_per_class=600,\n",
    "    marker=\"^\", point_size=14, alpha=0.90,\n",
    "    edge_lw=0.25, edge_color=\"k\",\n",
    "    label_mode=\"text\",            # \"text\"=TXk写在图上；\"legend\"=不写TXk，改左下角legend\n",
    "    legend_loc=\"lower left\"\n",
    "):\n",
    "    \"\"\"\n",
    "    WiSig 风格单图（无椭圆）：\n",
    "      - tab10 配色（按类循环）\n",
    "      - 三角形点 + 黑描边\n",
    "      - label_mode=\"text\"：TXk 文字直接写在图上（白描边）\n",
    "      - label_mode=\"legend\"：不写文字，左下角放类别legend\n",
    "    \"\"\"\n",
    "    set_paper_style()\n",
    "    os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    num_classes = int(y.max()) + 1\n",
    "    cmap = plt.cm.get_cmap(\"tab10\", 10)\n",
    "\n",
    "    fig = plt.figure(figsize=(3.6, 3.1), dpi=450)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        idx_all = np.where(y == c)[0]\n",
    "        if idx_all.size == 0:\n",
    "            continue\n",
    "\n",
    "        col = cmap(c % 10)\n",
    "        idx_plot = _subsample(idx_all, plot_max_per_class, rng)\n",
    "\n",
    "        ax.scatter(\n",
    "            emb2[idx_plot, 0], emb2[idx_plot, 1],\n",
    "            s=point_size, c=[col], alpha=alpha,\n",
    "            marker=marker, linewidths=edge_lw, edgecolors=edge_color,\n",
    "            zorder=3, rasterized=True\n",
    "        )\n",
    "\n",
    "        if label_mode == \"text\":\n",
    "            cx, cy = np.median(emb2[idx_all], axis=0)\n",
    "            txt = ax.text(\n",
    "                cx, cy, class_names[c],\n",
    "                fontsize=9, color=\"black\",\n",
    "                ha=\"center\", va=\"center\", zorder=4\n",
    "            )\n",
    "            txt.set_path_effects([pe.withStroke(linewidth=2.2, foreground=\"white\")])\n",
    "\n",
    "    # RAW：左下角 legend\n",
    "    if label_mode == \"legend\":\n",
    "        handles = _build_class_legend_handles(\n",
    "            class_names=class_names,\n",
    "            cmap=cmap,\n",
    "            marker=marker,\n",
    "            edge_color=edge_color,\n",
    "            edge_lw=edge_lw,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        ax.legend(\n",
    "            handles=handles,\n",
    "            loc=legend_loc,\n",
    "            fontsize=7,\n",
    "            ncol=1,\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.2,\n",
    "            labelspacing=0.25\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE 1\")\n",
    "    ax.set_ylabel(\"t-SNE 2\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "    plt.savefig(out_base + \".pdf\", bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.savefig(out_base + \".png\", bbox_inches=\"tight\", pad_inches=0.02, dpi=450)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def save_tsne_3d_single_wisig_style(\n",
    "    emb3, y, class_names, out_base,\n",
    "    xlim=None, ylim=None, zlim=None,\n",
    "    view=(18, -60),\n",
    "    plot_max_per_class=600,\n",
    "    marker=\"^\", point_size=14, alpha=0.90,\n",
    "    edge_lw=0.25, edge_color=\"k\",\n",
    "    grid_alpha=0.25,\n",
    "    label_mode=\"text\",            # \"text\" or \"legend\"\n",
    "    legend_loc=\"lower left\"\n",
    "):\n",
    "    \"\"\"\n",
    "    WiSig 风格 3D 单图（无椭圆）：\n",
    "      - tab10 配色\n",
    "      - 三角形点 + 黑描边\n",
    "      - label_mode=\"text\"：TXk 写在图上（白描边）\n",
    "      - label_mode=\"legend\"：不写文字，左下角 legend\n",
    "    \"\"\"\n",
    "    set_paper_style()\n",
    "    os.makedirs(os.path.dirname(out_base), exist_ok=True)\n",
    "    rng = np.random.default_rng(SEED)\n",
    "\n",
    "    num_classes = int(y.max()) + 1\n",
    "    cmap = plt.cm.get_cmap(\"tab10\", 10)\n",
    "\n",
    "    fig = plt.figure(figsize=(3.6, 3.1), dpi=450)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        idx_all = np.where(y == c)[0]\n",
    "        if idx_all.size == 0:\n",
    "            continue\n",
    "        col = cmap(c % 10)\n",
    "        idx_plot = _subsample(idx_all, plot_max_per_class, rng)\n",
    "\n",
    "        ax.scatter(\n",
    "            emb3[idx_plot, 0], emb3[idx_plot, 1], emb3[idx_plot, 2],\n",
    "            s=point_size, c=[col], alpha=alpha,\n",
    "            marker=marker, linewidths=edge_lw, edgecolors=edge_color\n",
    "        )\n",
    "\n",
    "        if label_mode == \"text\":\n",
    "            cx, cy, cz = np.median(emb3[idx_all], axis=0)\n",
    "            txt = ax.text(\n",
    "                cx, cy, cz, class_names[c],\n",
    "                fontsize=9, color=\"black\",\n",
    "                ha=\"center\", va=\"center\"\n",
    "            )\n",
    "            txt.set_path_effects([pe.withStroke(linewidth=2.2, foreground=\"white\")])\n",
    "\n",
    "    if label_mode == \"legend\":\n",
    "        handles = _build_class_legend_handles(\n",
    "            class_names=class_names,\n",
    "            cmap=cmap,\n",
    "            marker=marker,\n",
    "            edge_color=edge_color,\n",
    "            edge_lw=edge_lw,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        ax.legend(\n",
    "            handles=handles,\n",
    "            loc=legend_loc,\n",
    "            fontsize=7,\n",
    "            ncol=1,\n",
    "            handletextpad=0.4,\n",
    "            borderpad=0.2,\n",
    "            labelspacing=0.25\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE 1\", labelpad=2)\n",
    "    ax.set_ylabel(\"t-SNE 2\", labelpad=2)\n",
    "    ax.set_zlabel(\"t-SNE 3\", labelpad=2)\n",
    "\n",
    "    ax.view_init(elev=view[0], azim=view[1])\n",
    "    ax.grid(True, alpha=grid_alpha)\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if zlim is not None:\n",
    "        ax.set_zlim(zlim)\n",
    "\n",
    "    plt.tight_layout(pad=0.2)\n",
    "    plt.savefig(out_base + \".pdf\", bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.savefig(out_base + \".png\", bbox_inches=\"tight\", pad_inches=0.02, dpi=450)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ===================== .mat 导出 =====================\n",
    "def save_embedding_mat_2d(emb2, y, out_path, meta=None):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    mdict = {\"emb\": emb2.astype(np.float64), \"label\": y.astype(np.int64).reshape(-1, 1)}\n",
    "    if meta is not None:\n",
    "        mdict[\"meta\"] = meta\n",
    "    savemat(out_path, mdict)\n",
    "    print(f\"[OK] Saved mat: {out_path}\")\n",
    "\n",
    "\n",
    "def save_embedding_mat_3d(emb3, y, out_path, meta=None):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    mdict = {\"emb\": emb3.astype(np.float64), \"label\": y.astype(np.int64).reshape(-1, 1)}\n",
    "    if meta is not None:\n",
    "        mdict[\"meta\"] = meta\n",
    "    savemat(out_path, mdict)\n",
    "    print(f\"[OK] Saved mat: {out_path}\")\n",
    "\n",
    "\n",
    "# ===================== 信号处理 =====================\n",
    "def apply_doppler_shift(signal_c, fd_hz, fs_hz):\n",
    "    t = np.arange(signal_c.shape[-1]) / fs_hz\n",
    "    return signal_c * np.exp(1j * 2 * np.pi * fd_hz * t)\n",
    "\n",
    "\n",
    "def add_awgn(signal_c, snr_db):\n",
    "    power = np.mean(np.abs(signal_c) ** 2) + 1e-12\n",
    "    noise_power = power / (10 ** (snr_db / 10))\n",
    "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal_c.shape) + 1j * np.random.randn(*signal_c.shape))\n",
    "    return signal_c + noise\n",
    "\n",
    "\n",
    "def parse_snr_fd_classes(folder_name: str):\n",
    "    snr = None\n",
    "    fd = None\n",
    "    ncls = None\n",
    "    m = re.search(r\"SNR(-?\\d+)dB\", folder_name)\n",
    "    if m:\n",
    "        snr = int(m.group(1))\n",
    "    m = re.search(r\"fd(\\d+)\", folder_name)\n",
    "    if m:\n",
    "        fd = int(m.group(1))\n",
    "    m = re.search(r\"classes[_-](\\d+)\", folder_name)\n",
    "    if m:\n",
    "        ncls = int(m.group(1))\n",
    "    return snr, fd, ncls\n",
    "\n",
    "\n",
    "# ===================== LTE-V blocks =====================\n",
    "def load_blocks_ltev(mat_folder,\n",
    "                     group_size=864,\n",
    "                     apply_doppler=True,\n",
    "                     fd_hz=655,\n",
    "                     apply_awgn=True,\n",
    "                     snr_db=20,\n",
    "                     fs=5e6):\n",
    "    mat_files = glob.glob(os.path.join(mat_folder, \"*.mat\"))\n",
    "    if len(mat_files) == 0:\n",
    "        raise RuntimeError(f\"在 {mat_folder} 未找到 .mat 文件\")\n",
    "\n",
    "    X_files, y_files, label_set = [], [], set()\n",
    "\n",
    "    print(f\"[INFO] Found {len(mat_files)} .mat files\")\n",
    "    for file in tqdm(mat_files, desc=\"Reading LTE-V .mat\"):\n",
    "        with h5py.File(file, \"r\") as f:\n",
    "            rfDataset = f[\"rfDataset\"]\n",
    "            dmrs = rfDataset[\"dmrs\"][:]\n",
    "            dmrs_complex = dmrs[\"real\"] + 1j * dmrs[\"imag\"]\n",
    "            txID_uint16 = rfDataset[\"txID\"][:].flatten()\n",
    "            tx_id = \"\".join(chr(c) for c in txID_uint16 if c != 0)\n",
    "\n",
    "            processed = []\n",
    "            for i in range(dmrs_complex.shape[0]):\n",
    "                sig = dmrs_complex[i, :].astype(np.complex64)\n",
    "                sig = sig / (np.sqrt(np.mean(np.abs(sig) ** 2)) + 1e-12)\n",
    "\n",
    "                if apply_doppler:\n",
    "                    sig = apply_doppler_shift(sig, fd_hz, fs)\n",
    "\n",
    "                if apply_awgn:\n",
    "                    sig = add_awgn(sig, snr_db)\n",
    "\n",
    "                iq = np.stack([sig.real, sig.imag], axis=-1).astype(np.float32)\n",
    "                processed.append(iq)\n",
    "\n",
    "            processed = np.array(processed, dtype=np.float32)\n",
    "            X_files.append(processed)\n",
    "            y_files.append(tx_id)\n",
    "            label_set.add(tx_id)\n",
    "\n",
    "    label_list = sorted(list(label_set))\n",
    "    label_to_idx = {lb: i for i, lb in enumerate(label_list)}\n",
    "\n",
    "    raw_blocks_list = []\n",
    "    xfr_blocks_list = []\n",
    "    y_blocks_list = []\n",
    "\n",
    "    for label in label_list:\n",
    "        files_idx = [i for i, y in enumerate(y_files) if y == label]\n",
    "        num_files = len(files_idx)\n",
    "        if num_files == 0:\n",
    "            continue\n",
    "\n",
    "        samples_per_file = group_size // num_files\n",
    "        if samples_per_file == 0:\n",
    "            continue\n",
    "\n",
    "        min_samples = min([X_files[i].shape[0] for i in files_idx])\n",
    "        max_groups = min_samples // samples_per_file\n",
    "        if max_groups == 0:\n",
    "            continue\n",
    "\n",
    "        for gi in range(max_groups):\n",
    "            pieces = []\n",
    "            for fi in files_idx:\n",
    "                s = gi * samples_per_file\n",
    "                e = s + samples_per_file\n",
    "                pieces.append(X_files[fi][s:e])\n",
    "            big_block = np.concatenate(pieces, axis=0)  # (G,L,2)\n",
    "\n",
    "            raw_blocks_list.append(big_block)  # (G,L,2)\n",
    "            xfr_blocks_list.append(np.transpose(big_block, (1, 0, 2)))  # (L,G,2)\n",
    "            y_blocks_list.append(label_to_idx[label])\n",
    "\n",
    "    if len(raw_blocks_list) == 0:\n",
    "        raise RuntimeError(\"未生成任何 block，请检查 group_size 或数据组织。\")\n",
    "\n",
    "    raw_blocks = np.stack(raw_blocks_list, axis=0)  # (B,G,L,2)\n",
    "    xfr_blocks = np.stack(xfr_blocks_list, axis=0)  # (B,L,G,2)\n",
    "    y_blocks = np.array(y_blocks_list, dtype=np.int64)\n",
    "\n",
    "    print(f\"[INFO] blocks={raw_blocks.shape[0]}, group_size={raw_blocks.shape[1]}, sample_len={raw_blocks.shape[2]}, classes={len(label_list)}\")\n",
    "    return raw_blocks, xfr_blocks, y_blocks, label_list\n",
    "\n",
    "\n",
    "# ===================== ResNet18_1D extract_features =====================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out = out + identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.extract_features(x)\n",
    "        return self.fc(feat)\n",
    "\n",
    "\n",
    "def strip_module_prefix(state_dict):\n",
    "    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        return {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def find_fold_models(exp_dir):\n",
    "    paths = glob.glob(os.path.join(exp_dir, \"best_model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        paths = glob.glob(os.path.join(exp_dir, \"model_fold*.pth\"))\n",
    "    if len(paths) == 0:\n",
    "        raise RuntimeError(f\"在 {exp_dir} 未找到 best_model_fold*.pth 或 model_fold*.pth\")\n",
    "\n",
    "    def fold_key(p):\n",
    "        m = re.search(r\"fold(\\d+)\", os.path.basename(p))\n",
    "        return int(m.group(1)) if m else 999\n",
    "\n",
    "    return sorted(paths, key=fold_key)\n",
    "\n",
    "\n",
    "# ===================== 样本级 dataset =====================\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "def stratified_sample_indices(y, max_per_class, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    keep = []\n",
    "    for c in np.unique(y):\n",
    "        idx = np.where(y == c)[0]\n",
    "        if len(idx) > max_per_class:\n",
    "            idx = rng.choice(idx, size=max_per_class, replace=False)\n",
    "        keep.append(idx)\n",
    "    keep = np.concatenate(keep)\n",
    "    rng.shuffle(keep)\n",
    "    return keep\n",
    "\n",
    "\n",
    "def extract_features_foldmean(model_paths, X, y, device):\n",
    "    ds = SimpleDataset(X, y)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    feats_folds = []\n",
    "    for mp in model_paths:\n",
    "        state = strip_module_prefix(torch.load(mp, map_location=device))\n",
    "        in_planes = state[\"conv1.weight\"].shape[0]\n",
    "        num_classes = state[\"fc.weight\"].shape[0]\n",
    "\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=0.0).to(device)\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        model.eval()\n",
    "\n",
    "        feats = []\n",
    "        with torch.no_grad():\n",
    "            for xb, _ in tqdm(loader, desc=f\"Extract {os.path.basename(mp)}\", leave=False):\n",
    "                xb = xb.to(device)\n",
    "                f = model.extract_features(xb).cpu().numpy()\n",
    "                feats.append(f)\n",
    "        feats = np.concatenate(feats, axis=0)\n",
    "        feats_folds.append(feats)\n",
    "\n",
    "    feats_folds = np.stack(feats_folds, axis=0)\n",
    "    return feats_folds.mean(axis=0)\n",
    "\n",
    "\n",
    "def tsne_joint(feat_a, feat_b, n_components, seed=42):\n",
    "    X = np.concatenate([feat_a, feat_b], axis=0).astype(np.float32)\n",
    "\n",
    "    pca_dim_eff = min(PCA_DIM, X.shape[1])\n",
    "    X_pca = PCA(n_components=pca_dim_eff, random_state=seed).fit_transform(X)\n",
    "\n",
    "    tsne_kwargs = dict(\n",
    "        n_components=n_components,\n",
    "        perplexity=TSNE_PERPLEXITY,\n",
    "        init=\"pca\",\n",
    "        learning_rate=\"auto\",\n",
    "        metric=TSNE_METRIC,\n",
    "        random_state=seed,\n",
    "        verbose=1\n",
    "    )\n",
    "    try:\n",
    "        tsne = TSNE(**tsne_kwargs, n_iter=TSNE_ITERS)\n",
    "    except TypeError:\n",
    "        tsne = TSNE(**tsne_kwargs, max_iter=TSNE_ITERS)\n",
    "\n",
    "    emb = tsne.fit_transform(X_pca)\n",
    "    return emb[:feat_a.shape[0]], emb[feat_a.shape[0]:]\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    xfr_name = os.path.basename(EXP_XFR_DIR)\n",
    "    raw_name = os.path.basename(EXP_RAW_DIR)\n",
    "\n",
    "    snr_xfr, fd_xfr, _ = parse_snr_fd_classes(xfr_name)\n",
    "    snr_raw, fd_raw, _ = parse_snr_fd_classes(raw_name)\n",
    "\n",
    "    if USE_COMMON_CHANNEL:\n",
    "        snr_use = snr_xfr if snr_xfr is not None else 20\n",
    "        fd_use = fd_xfr if fd_xfr is not None else 655\n",
    "        print(f\"[INFO] Common channel: SNR={snr_use} dB, fd={fd_use} Hz\")\n",
    "    else:\n",
    "        snr_use = snr_xfr or 20\n",
    "        fd_use = fd_xfr or 655\n",
    "\n",
    "    raw_blocks, xfr_blocks, y_blocks, txid_list = load_blocks_ltev(\n",
    "        DATA_PATH,\n",
    "        group_size=GROUP_SIZE,\n",
    "        apply_doppler=APPLY_DOPPLER,\n",
    "        fd_hz=fd_use,\n",
    "        apply_awgn=APPLY_AWGN,\n",
    "        snr_db=snr_use,\n",
    "        fs=FS\n",
    "    )\n",
    "\n",
    "    num_blocks = raw_blocks.shape[0]\n",
    "    sample_len = raw_blocks.shape[2]\n",
    "\n",
    "    block_idx = np.arange(num_blocks)\n",
    "    _, test_idx, _, _ = train_test_split(\n",
    "        block_idx, y_blocks, test_size=TEST_SIZE, stratify=y_blocks, random_state=SPLIT_SEED\n",
    "    )\n",
    "    sel_blocks = test_idx\n",
    "    y_sel_blocks = y_blocks[sel_blocks]\n",
    "\n",
    "    raw_sel = raw_blocks[sel_blocks]  # (nb,G,L,2)\n",
    "    X_raw = raw_sel.reshape(-1, sample_len, 2)\n",
    "    y_raw = np.repeat(y_sel_blocks, raw_sel.shape[1])\n",
    "\n",
    "    xfr_sel = xfr_blocks[sel_blocks]  # (nb,L,G,2)\n",
    "    X_xfr = xfr_sel.reshape(-1, raw_sel.shape[1], 2)\n",
    "    y_xfr = np.repeat(y_sel_blocks, xfr_sel.shape[1])\n",
    "\n",
    "    idx_raw = stratified_sample_indices(y_raw, MAX_SAMPLES_PER_CLASS_RAW, seed=SEED)\n",
    "    idx_xfr = stratified_sample_indices(y_xfr, MAX_SAMPLES_PER_CLASS_XFR, seed=SEED)\n",
    "    X_raw, y_raw = X_raw[idx_raw], y_raw[idx_raw]\n",
    "    X_xfr, y_xfr = X_xfr[idx_xfr], y_xfr[idx_xfr]\n",
    "    print(f\"[INFO] sample-level selected: RAW={len(y_raw)}, XFR={len(y_xfr)}\")\n",
    "\n",
    "    raw_models = find_fold_models(EXP_RAW_DIR)\n",
    "    xfr_models = find_fold_models(EXP_XFR_DIR)\n",
    "    print(f\"[INFO] RAW folds: {len(raw_models)}, XFR folds: {len(xfr_models)}\")\n",
    "\n",
    "    feat_raw = extract_features_foldmean(raw_models, X_raw, y_raw, device)\n",
    "    feat_xfr = extract_features_foldmean(xfr_models, X_xfr, y_xfr, device)\n",
    "\n",
    "    emb2_raw, emb2_xfr = tsne_joint(feat_raw, feat_xfr, n_components=2, seed=SEED)\n",
    "    emb3_raw, emb3_xfr = tsne_joint(feat_raw, feat_xfr, n_components=3, seed=SEED)\n",
    "\n",
    "    x2_all = np.concatenate([emb2_raw[:, 0], emb2_xfr[:, 0]])\n",
    "    y2_all = np.concatenate([emb2_raw[:, 1], emb2_xfr[:, 1]])\n",
    "    xlim2 = (float(x2_all.min()), float(x2_all.max()))\n",
    "    ylim2 = (float(y2_all.min()), float(y2_all.max()))\n",
    "\n",
    "    x3_all = np.concatenate([emb3_raw[:, 0], emb3_xfr[:, 0]])\n",
    "    y3_all = np.concatenate([emb3_raw[:, 1], emb3_xfr[:, 1]])\n",
    "    z3_all = np.concatenate([emb3_raw[:, 2], emb3_xfr[:, 2]])\n",
    "    xlim3 = (float(x3_all.min()), float(x3_all.max()))\n",
    "    ylim3 = (float(y3_all.min()), float(y3_all.max()))\n",
    "    zlim3 = (float(z3_all.min()), float(z3_all.max()))\n",
    "\n",
    "    n_cls = int(max(y_raw.max(), y_xfr.max())) + 1\n",
    "    class_names = [f\"TX{i+1}\" for i in range(n_cls)]\n",
    "    mapping = [(class_names[i], txid_list[i] if i < len(txid_list) else \"\") for i in range(n_cls)]\n",
    "    print(\"[INFO] Class mapping (TXk -> tx_id):\")\n",
    "    for a, b in mapping:\n",
    "        print(f\"  {a} -> {b}\")\n",
    "\n",
    "    # ====== 关键：RAW 用左下角 legend；XFR 用图上 TXk 文本 ======\n",
    "    save_tsne_2d_single_wisig_style(\n",
    "        emb2_raw, y_raw, class_names,\n",
    "        os.path.join(OUT_DIR, \"RAW_2D\"),\n",
    "        xlim=xlim2, ylim=ylim2,\n",
    "        plot_max_per_class=PLOT_MAX_PER_CLASS,\n",
    "        marker=PLOT_MARKER, point_size=PLOT_POINT_SIZE, alpha=PLOT_POINT_ALPHA,\n",
    "        edge_lw=PLOT_EDGE_LW, edge_color=\"k\",\n",
    "        label_mode=\"legend\",\n",
    "        legend_loc=\"lower right\"\n",
    "    )\n",
    "    save_tsne_2d_single_wisig_style(\n",
    "        emb2_xfr, y_xfr, class_names,\n",
    "        os.path.join(OUT_DIR, \"XFR_2D\"),\n",
    "        xlim=xlim2, ylim=ylim2,\n",
    "        plot_max_per_class=PLOT_MAX_PER_CLASS,\n",
    "        marker=PLOT_MARKER, point_size=PLOT_POINT_SIZE, alpha=PLOT_POINT_ALPHA,\n",
    "        edge_lw=PLOT_EDGE_LW, edge_color=\"k\",\n",
    "        label_mode=\"text\"\n",
    "    )\n",
    "\n",
    "    view = (18, -60)\n",
    "    save_tsne_3d_single_wisig_style(\n",
    "        emb3_raw, y_raw, class_names,\n",
    "        os.path.join(OUT_DIR, \"RAW_3D\"),\n",
    "        xlim=xlim3, ylim=ylim3, zlim=zlim3, view=view,\n",
    "        plot_max_per_class=PLOT_MAX_PER_CLASS,\n",
    "        marker=PLOT_MARKER, point_size=PLOT_POINT_SIZE, alpha=PLOT_POINT_ALPHA,\n",
    "        edge_lw=PLOT_EDGE_LW, edge_color=\"k\",\n",
    "        label_mode=\"legend\",\n",
    "        legend_loc=\"lower left\"\n",
    "    )\n",
    "    save_tsne_3d_single_wisig_style(\n",
    "        emb3_xfr, y_xfr, class_names,\n",
    "        os.path.join(OUT_DIR, \"XFR_3D\"),\n",
    "        xlim=xlim3, ylim=ylim3, zlim=zlim3, view=view,\n",
    "        plot_max_per_class=PLOT_MAX_PER_CLASS,\n",
    "        marker=PLOT_MARKER, point_size=PLOT_POINT_SIZE, alpha=PLOT_POINT_ALPHA,\n",
    "        edge_lw=PLOT_EDGE_LW, edge_color=\"k\",\n",
    "        label_mode=\"text\"\n",
    "    )\n",
    "\n",
    "    print(\"[OK] Saved 4 figures (RAW=legend lower-left, XFR=text on-plot).\")\n",
    "\n",
    "    meta = {\n",
    "        \"DATA_PATH\": DATA_PATH,\n",
    "        \"EXP_RAW_DIR\": EXP_RAW_DIR,\n",
    "        \"EXP_XFR_DIR\": EXP_XFR_DIR,\n",
    "        \"SNR_use_dB\": int(snr_use),\n",
    "        \"fd_use_Hz\": int(fd_use),\n",
    "        \"USE_COMMON_CHANNEL\": int(USE_COMMON_CHANNEL),\n",
    "        \"GROUP_SIZE\": int(GROUP_SIZE),\n",
    "        \"TEST_SIZE\": float(TEST_SIZE),\n",
    "        \"SPLIT_SEED\": int(SPLIT_SEED),\n",
    "        \"MAX_SAMPLES_PER_CLASS_RAW\": int(MAX_SAMPLES_PER_CLASS_RAW),\n",
    "        \"MAX_SAMPLES_PER_CLASS_XFR\": int(MAX_SAMPLES_PER_CLASS_XFR),\n",
    "        \"PCA_DIM\": int(PCA_DIM),\n",
    "        \"TSNE_PERPLEXITY\": int(TSNE_PERPLEXITY),\n",
    "        \"TSNE_ITERS\": int(TSNE_ITERS),\n",
    "        \"TSNE_METRIC\": TSNE_METRIC,\n",
    "        \"SEED\": int(SEED),\n",
    "        \"PLOT_MAX_PER_CLASS\": int(PLOT_MAX_PER_CLASS),\n",
    "        \"PLOT_MARKER\": PLOT_MARKER,\n",
    "        \"PLOT_POINT_SIZE\": float(PLOT_POINT_SIZE),\n",
    "        \"PLOT_POINT_ALPHA\": float(PLOT_POINT_ALPHA),\n",
    "        \"PLOT_EDGE_LW\": float(PLOT_EDGE_LW),\n",
    "        \"RAW_label_mode\": \"legend_lower_left\",\n",
    "        \"XFR_label_mode\": \"text_on_plot\",\n",
    "    }\n",
    "\n",
    "    save_embedding_mat_2d(emb2_raw, y_raw, os.path.join(OUT_DIR, \"RAW_2D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_2d(emb2_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_2D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_3d(emb3_raw, y_raw, os.path.join(OUT_DIR, \"RAW_3D_tsne.mat\"), meta=meta)\n",
    "    save_embedding_mat_3d(emb3_xfr, y_xfr, os.path.join(OUT_DIR, \"XFR_3D_tsne.mat\"), meta=meta)\n",
    "\n",
    "    all_mat_path = os.path.join(OUT_DIR, \"LTEV_tsne_all.mat\")\n",
    "    savemat(all_mat_path, {\n",
    "        \"emb2_raw\": emb2_raw.astype(np.float64),\n",
    "        \"emb2_xfr\": emb2_xfr.astype(np.float64),\n",
    "        \"emb3_raw\": emb3_raw.astype(np.float64),\n",
    "        \"emb3_xfr\": emb3_xfr.astype(np.float64),\n",
    "        \"y_raw\": y_raw.astype(np.int64).reshape(-1, 1),\n",
    "        \"y_xfr\": y_xfr.astype(np.int64).reshape(-1, 1),\n",
    "        \"class_names\": np.array(class_names, dtype=object),\n",
    "        \"txid_list\": np.array(txid_list, dtype=object),\n",
    "        \"class_mapping_TX_to_txid\": np.array([f\"{a} -> {b}\" for a, b in mapping], dtype=object),\n",
    "        \"meta\": meta\n",
    "    })\n",
    "    print(f\"[OK] Saved mat: {all_mat_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
