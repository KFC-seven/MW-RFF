{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "Loaded 150 classes from trajectory_pos\n",
      "Class 0 (1-1): 255 samples\n",
      "Class 1 (1-10): 255 samples\n",
      "Class 2 (1-11): 255 samples\n",
      "Class 3 (1-12): 255 samples\n",
      "Class 4 (1-14): 255 samples\n",
      "Class 5 (1-15): 255 samples\n",
      "Class 6 (1-16): 255 samples\n",
      "Class 7 (1-18): 255 samples\n",
      "Class 8 (1-19): 255 samples\n",
      "Class 9 (1-2): 255 samples\n",
      "Class 10 (1-8): 255 samples\n",
      "Class 11 (10-1): 255 samples\n",
      "Class 12 (10-10): 255 samples\n",
      "Class 13 (10-11): 255 samples\n",
      "Class 14 (10-17): 255 samples\n",
      "Class 15 (10-4): 255 samples\n",
      "Class 16 (10-7): 255 samples\n",
      "Class 17 (11-1): 255 samples\n",
      "Class 18 (11-10): 255 samples\n",
      "Class 19 (11-17): 255 samples\n",
      "Class 20 (11-19): 255 samples\n",
      "Class 21 (11-20): 255 samples\n",
      "Class 22 (11-4): 255 samples\n",
      "Class 23 (11-7): 255 samples\n",
      "Class 24 (12-1): 255 samples\n",
      "Class 25 (12-19): 255 samples\n",
      "Class 26 (12-20): 255 samples\n",
      "Class 27 (12-7): 255 samples\n",
      "Class 28 (13-14): 255 samples\n",
      "Class 29 (13-18): 255 samples\n",
      "Class 30 (13-19): 255 samples\n",
      "Class 31 (13-20): 255 samples\n",
      "Class 32 (13-3): 255 samples\n",
      "Class 33 (13-7): 255 samples\n",
      "Class 34 (14-10): 255 samples\n",
      "Class 35 (14-11): 255 samples\n",
      "Class 36 (14-12): 255 samples\n",
      "Class 37 (14-13): 255 samples\n",
      "Class 38 (14-14): 255 samples\n",
      "Class 39 (14-20): 255 samples\n",
      "Class 40 (14-7): 255 samples\n",
      "Class 41 (14-8): 255 samples\n",
      "Class 42 (14-9): 255 samples\n",
      "Class 43 (15-1): 255 samples\n",
      "Class 44 (15-19): 255 samples\n",
      "Class 45 (15-6): 255 samples\n",
      "Class 46 (16-1): 255 samples\n",
      "Class 47 (16-16): 255 samples\n",
      "Class 48 (16-19): 255 samples\n",
      "Class 49 (16-20): 255 samples\n",
      "Class 50 (16-5): 255 samples\n",
      "Class 51 (17-10): 255 samples\n",
      "Class 52 (17-11): 255 samples\n",
      "Class 53 (18-1): 255 samples\n",
      "Class 54 (18-10): 255 samples\n",
      "Class 55 (18-11): 255 samples\n",
      "Class 56 (18-12): 255 samples\n",
      "Class 57 (18-13): 255 samples\n",
      "Class 58 (18-14): 255 samples\n",
      "Class 59 (18-15): 255 samples\n",
      "Class 60 (18-16): 255 samples\n",
      "Class 61 (18-17): 255 samples\n",
      "Class 62 (18-2): 255 samples\n",
      "Class 63 (18-20): 255 samples\n",
      "Class 64 (18-4): 255 samples\n",
      "Class 65 (18-5): 255 samples\n",
      "Class 66 (18-7): 255 samples\n",
      "Class 67 (18-8): 255 samples\n",
      "Class 68 (18-9): 255 samples\n",
      "Class 69 (19-1): 255 samples\n",
      "Class 70 (19-10): 255 samples\n",
      "Class 71 (19-11): 255 samples\n",
      "Class 72 (19-12): 255 samples\n",
      "Class 73 (19-13): 255 samples\n",
      "Class 74 (19-14): 255 samples\n",
      "Class 75 (19-19): 255 samples\n",
      "Class 76 (19-2): 255 samples\n",
      "Class 77 (19-20): 255 samples\n",
      "Class 78 (19-3): 255 samples\n",
      "Class 79 (19-4): 255 samples\n",
      "Class 80 (19-6): 255 samples\n",
      "Class 81 (19-7): 255 samples\n",
      "Class 82 (19-8): 255 samples\n",
      "Class 83 (19-9): 255 samples\n",
      "Class 84 (2-1): 255 samples\n",
      "Class 85 (2-12): 255 samples\n",
      "Class 86 (2-13): 255 samples\n",
      "Class 87 (2-14): 255 samples\n",
      "Class 88 (2-15): 255 samples\n",
      "Class 89 (2-16): 255 samples\n",
      "Class 90 (2-17): 255 samples\n",
      "Class 91 (2-19): 255 samples\n",
      "Class 92 (2-20): 255 samples\n",
      "Class 93 (2-3): 255 samples\n",
      "Class 94 (2-4): 255 samples\n",
      "Class 95 (2-5): 255 samples\n",
      "Class 96 (2-6): 255 samples\n",
      "Class 97 (2-7): 255 samples\n",
      "Class 98 (2-8): 255 samples\n",
      "Class 99 (20-1): 255 samples\n",
      "Class 100 (20-12): 255 samples\n",
      "Class 101 (20-14): 255 samples\n",
      "Class 102 (20-15): 255 samples\n",
      "Class 103 (20-16): 255 samples\n",
      "Class 104 (20-18): 255 samples\n",
      "Class 105 (20-19): 255 samples\n",
      "Class 106 (20-20): 255 samples\n",
      "Class 107 (20-3): 255 samples\n",
      "Class 108 (20-4): 255 samples\n",
      "Class 109 (20-5): 255 samples\n",
      "Class 110 (20-7): 255 samples\n",
      "Class 111 (20-8): 255 samples\n",
      "Class 112 (3-1): 255 samples\n",
      "Class 113 (3-13): 255 samples\n",
      "Class 114 (3-18): 255 samples\n",
      "Class 115 (3-19): 255 samples\n",
      "Class 116 (3-2): 255 samples\n",
      "Class 117 (3-20): 255 samples\n",
      "Class 118 (3-8): 255 samples\n",
      "Class 119 (4-1): 255 samples\n",
      "Class 120 (4-10): 255 samples\n",
      "Class 121 (4-11): 255 samples\n",
      "Class 122 (5-1): 255 samples\n",
      "Class 123 (5-16): 255 samples\n",
      "Class 124 (5-20): 255 samples\n",
      "Class 125 (5-5): 255 samples\n",
      "Class 126 (6-1): 255 samples\n",
      "Class 127 (6-15): 255 samples\n",
      "Class 128 (6-6): 255 samples\n",
      "Class 129 (7-10): 255 samples\n",
      "Class 130 (7-11): 255 samples\n",
      "Class 131 (7-12): 255 samples\n",
      "Class 132 (7-13): 255 samples\n",
      "Class 133 (7-14): 255 samples\n",
      "Class 134 (7-20): 255 samples\n",
      "Class 135 (7-7): 255 samples\n",
      "Class 136 (7-8): 255 samples\n",
      "Class 137 (7-9): 255 samples\n",
      "Class 138 (8-1): 255 samples\n",
      "Class 139 (8-13): 255 samples\n",
      "Class 140 (8-14): 255 samples\n",
      "Class 141 (8-18): 255 samples\n",
      "Class 142 (8-20): 255 samples\n",
      "Class 143 (8-3): 255 samples\n",
      "Class 144 (8-7): 255 samples\n",
      "Class 145 (8-8): 255 samples\n",
      "Class 146 (9-1): 255 samples\n",
      "Class 147 (9-14): 255 samples\n",
      "Class 148 (9-20): 255 samples\n",
      "Class 149 (9-7): 255 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 90/90 [04:10<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 4.3316 | Val Loss: 3.9911 | Train Acc: 0.0651 | Val Acc: 0.0971 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 90/90 [04:52<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 3.5680 | Val Loss: 3.5473 | Train Acc: 0.1554 | Val Acc: 0.1561 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 90/90 [07:36<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 3.1402 | Val Loss: 3.3915 | Train Acc: 0.2265 | Val Acc: 0.1788 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 90/90 [05:35<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 2.7979 | Val Loss: 3.0769 | Train Acc: 0.2880 | Val Acc: 0.2361 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 90/90 [04:29<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 2.5251 | Val Loss: 3.3487 | Train Acc: 0.3458 | Val Acc: 0.2132 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 90/90 [04:26<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 2.2748 | Val Loss: 2.8921 | Train Acc: 0.4013 | Val Acc: 0.2753 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 90/90 [04:21<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 2.0389 | Val Loss: 2.9790 | Train Acc: 0.4585 | Val Acc: 0.2650 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 90/90 [04:49<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 1.7752 | Val Loss: 2.8482 | Train Acc: 0.5295 | Val Acc: 0.2941 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 90/90 [05:54<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 1.5035 | Val Loss: 2.9288 | Train Acc: 0.5993 | Val Acc: 0.2872 | LR: 5.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30:  40%|████      | 36/90 [02:44<04:06,  4.57s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\program\\\\IQ_signal_plots\\\\1-10\\\\trajectory_pos\\\\trajectory_pos_154.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 395\u001b[0m\n\u001b[0;32m    380\u001b[0m classifier \u001b[38;5;241m=\u001b[39m ImageClassifier()\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot_dir\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../IQ_signal_plots\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_folder\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrajectory_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# 可修改为任意文件夹名称\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m    393\u001b[0m }\n\u001b[1;32m--> 395\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 147\u001b[0m, in \u001b[0;36mImageClassifier.train\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    144\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# 训练循环\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# 最终评估\u001b[39;00m\n\u001b[0;32m    154\u001b[0m test_acc, cm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(model, test_loader)\n",
      "Cell \u001b[1;32mIn[1], line 211\u001b[0m, in \u001b[0;36mImageClassifier._train_loop\u001b[1;34m(self, model, optimizer, criterion, scheduler, scaler, train_loader, val_loader, epochs, patience)\u001b[0m\n\u001b[0;32m    208\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    209\u001b[0m train_loss, correct, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    212\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    214\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[1], line 37\u001b[0m, in \u001b[0;36mImageClassifier.ImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 37\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;28;01melse\u001b[39;00m image, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n",
      "File \u001b[1;32me:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\program\\\\IQ_signal_plots\\\\1-10\\\\trajectory_pos\\\\trajectory_pos_154.png'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "class ImageClassifier:\n",
    "    def __init__(self, device='cuda:0'):\n",
    "        self.device = torch.device(device)\n",
    "        self._setup_device()\n",
    "        \n",
    "    def _setup_device(self):\n",
    "        torch.cuda.set_device(self.device)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    class ImageDataset(Dataset):\n",
    "        def __init__(self, file_paths, labels, transform=None):\n",
    "            self.file_paths = file_paths\n",
    "            self.labels = labels\n",
    "            self.transform = transform\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.file_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(self.file_paths[idx]).convert(\"RGB\")\n",
    "            return self.transform(image) if self.transform else image, self.labels[idx]\n",
    "\n",
    "    def load_data(self, root_dir, target_folder, limit_per_class=None):\n",
    "        \"\"\"\n",
    "        加载指定文件夹结构的数据\n",
    "        :param root_dir: 根目录（包含各分类文件夹的父目录）\n",
    "        :param target_folder: 要训练的特征文件夹名称（如 'trajectory_pos'）\n",
    "        :param limit_per_class: 每个类别最大样本数（None表示不限制）\n",
    "        :return: (file_paths, labels, class_mapping)\n",
    "        \"\"\"\n",
    "        file_paths = []\n",
    "        labels = []\n",
    "        class_mapping = {}\n",
    "        \n",
    "        # 获取所有类别文件夹\n",
    "        class_folders = sorted([d.name for d in os.scandir(root_dir) if d.is_dir()])\n",
    "        class_mapping = {cls: idx for idx, cls in enumerate(class_folders)}\n",
    "        \n",
    "        for cls_name, cls_idx in class_mapping.items():\n",
    "            target_path = os.path.join(root_dir, cls_name, target_folder)\n",
    "            \n",
    "            if not os.path.exists(target_path):\n",
    "                print(f\"Warning: Missing {target_folder} in {cls_name}\")\n",
    "                continue\n",
    "                \n",
    "            images = [\n",
    "                os.path.join(target_path, f) \n",
    "                for f in os.listdir(target_path) \n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "            ]\n",
    "            \n",
    "            if limit_per_class:\n",
    "                images = images[:limit_per_class]\n",
    "                \n",
    "            file_paths.extend(images)\n",
    "            labels.extend([cls_idx] * len(images))\n",
    "        \n",
    "        print(f\"\\nLoaded {len(class_mapping)} classes from {target_folder}\")\n",
    "        self._print_class_stats(labels, class_mapping)\n",
    "        return file_paths, labels, class_mapping\n",
    "\n",
    "    def _print_class_stats(self, labels, class_mapping):\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        for cls_idx, count in zip(unique, counts):\n",
    "            cls_name = list(class_mapping.keys())[cls_idx]\n",
    "            print(f\"Class {cls_idx} ({cls_name}): {count} samples\")\n",
    "\n",
    "    def create_model(self, num_classes, model_name='resnet18'):\n",
    "        \"\"\"创建可配置的模型\"\"\"\n",
    "        model_map = {\n",
    "            'resnet18': models.resnet18,\n",
    "            'resnet50': models.resnet50,\n",
    "            'efficientnet_b0': models.efficientnet_b0\n",
    "        }\n",
    "        \n",
    "        model = model_map[model_name](weights='DEFAULT')\n",
    "        if 'resnet' in model_name:\n",
    "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        elif 'efficientnet' in model_name:\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "            \n",
    "        return model.to(self.device)\n",
    "\n",
    "    def train(self, config):\n",
    "        \"\"\"\n",
    "        完整的训练流程\n",
    "        :param config: 包含以下键的配置字典:\n",
    "            - root_dir: 数据根目录\n",
    "            - target_folder: 目标特征文件夹名称\n",
    "            - save_dir: 结果保存目录\n",
    "            - batch_size: 批大小\n",
    "            - epochs: 训练轮数\n",
    "            - lr: 学习率\n",
    "            - input_size: 输入尺寸\n",
    "            - limit_per_class: 每类最大样本数\n",
    "            - model_name: 模型名称\n",
    "            - patience: 早停耐心值\n",
    "        \"\"\"\n",
    "        # 初始化配置\n",
    "        config.setdefault('save_dir', 'model_results')\n",
    "        config.setdefault('model_name', 'resnet18')\n",
    "        config.setdefault('input_size', 224)\n",
    "        config.setdefault('patience', 5)\n",
    "        \n",
    "        # 数据加载\n",
    "        file_paths, labels, class_mapping = self.load_data(\n",
    "            config['root_dir'],\n",
    "            config['target_folder'],\n",
    "            config.get('limit_per_class')\n",
    "        )\n",
    "        \n",
    "        # 数据预处理\n",
    "        train_transform, test_transform = self._get_transforms(config['input_size'])\n",
    "        \n",
    "        # 数据集划分\n",
    "        train_loader, val_loader, test_loader = self._create_data_loaders(\n",
    "            file_paths, labels, \n",
    "            train_transform, test_transform,\n",
    "            config['batch_size']\n",
    "        )\n",
    "        \n",
    "        # 模型初始化\n",
    "        model = self.create_model(len(class_mapping), config['model_name'])\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-4)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        scaler = torch.amp.GradScaler()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "        \n",
    "        # 训练循环\n",
    "        history = self._train_loop(\n",
    "            model, optimizer, criterion, scheduler, scaler,\n",
    "            train_loader, val_loader,\n",
    "            config['epochs'], config['patience']\n",
    "        )\n",
    "        \n",
    "        # 最终评估\n",
    "        test_acc, cm = self.evaluate(model, test_loader)\n",
    "        \n",
    "        # 保存结果\n",
    "        self._save_results(\n",
    "            model, history, cm, class_mapping,\n",
    "            config, test_acc\n",
    "        )\n",
    "\n",
    "    def _get_transforms(self, input_size):\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        return train_transform, test_transform\n",
    "\n",
    "    def _create_data_loaders(self, file_paths, labels, train_trans, test_trans, batch_size):\n",
    "        # 数据集划分（60-20-20）\n",
    "        train_p, test_p, train_l, test_l = train_test_split(\n",
    "            file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "        )\n",
    "        train_p, val_p, train_l, val_l = train_test_split(\n",
    "            train_p, train_l, test_size=0.25, stratify=train_l, random_state=42\n",
    "        )\n",
    "        \n",
    "        return (\n",
    "            DataLoader(self.ImageDataset(train_p, train_l, train_trans), \n",
    "                      batch_size, shuffle=True, pin_memory=True),\n",
    "            DataLoader(self.ImageDataset(val_p, val_l, test_trans), \n",
    "                      batch_size, shuffle=False, pin_memory=True),\n",
    "            DataLoader(self.ImageDataset(test_p, test_l, test_trans), \n",
    "                      batch_size, shuffle=False, pin_memory=True)\n",
    "        )\n",
    "\n",
    "    def _train_loop(self, model, optimizer, criterion, scheduler, scaler, \n",
    "                   train_loader, val_loader, epochs, patience):\n",
    "        history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        best_acc = 0.0\n",
    "        early_stop_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # 训练阶段\n",
    "            model.train()\n",
    "            train_loss, correct, total = 0.0, 0, 0\n",
    "            \n",
    "            for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with torch.amp.autocast(device_type='cuda'):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # 验证阶段\n",
    "            val_acc, val_loss = self._validate(model, criterion, val_loader)\n",
    "            \n",
    "            # 记录指标\n",
    "            train_acc = correct / total\n",
    "            history['train_loss'].append(train_loss/len(train_loader))\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "            \n",
    "            # 学习率调整\n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # 早停机制\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                early_stop_counter = 0\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                if early_stop_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}: \"\n",
    "                  f\"Train Loss: {history['train_loss'][-1]:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Acc: {val_acc:.4f} | \"\n",
    "                  f\"LR: {history['lr'][-1]:.2e}\")\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "        return history\n",
    "\n",
    "    def _validate(self, model, criterion, val_loader):\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                val_loss += criterion(outputs, labels).item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "        return correct / total, val_loss / len(val_loader)\n",
    "\n",
    "    def evaluate(self, model, test_loader):\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        test_acc = correct / total\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        return test_acc, cm\n",
    "\n",
    "    def _save_results(self, model, history, cm, class_mapping, config, test_acc):\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path = os.path.join(\n",
    "            config['save_dir'],\n",
    "            f\"{config['target_folder']}_{timestamp}\"\n",
    "        )\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # 保存模型\n",
    "        torch.save({\n",
    "            'model_state': model.state_dict(),\n",
    "            'class_mapping': class_mapping,\n",
    "            'config': config,\n",
    "            'test_acc': test_acc\n",
    "        }, os.path.join(save_path, \"model.pth\"))\n",
    "        \n",
    "        # 可视化结果\n",
    "        self._plot_training_curves(history, save_path)\n",
    "        self._plot_confusion_matrix(cm, class_mapping, save_path)\n",
    "        \n",
    "        # 保存报告\n",
    "        self._save_report(config, history, test_acc, class_mapping, save_path)\n",
    "        \n",
    "        print(f\"\\nResults saved in: {save_path}\")\n",
    "\n",
    "    def _plot_training_curves(self, history, save_path):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history['train_loss'], label='Train')\n",
    "        plt.plot(history['val_loss'], label='Validation')\n",
    "        plt.title('Loss Curves')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history['train_acc'], label='Train')\n",
    "        plt.plot(history['val_acc'], label='Validation')\n",
    "        plt.title('Accuracy Curves')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_path, \"training_curves.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_confusion_matrix(self, cm, class_mapping, save_path):\n",
    "        plt.figure(figsize=(15, 12))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_mapping.keys(),\n",
    "                    yticklabels=class_mapping.keys())\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_path, \"confusion_matrix.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    def _save_report(self, config, history, test_acc, class_mapping, save_path):\n",
    "        with open(os.path.join(save_path, \"report.txt\"), \"w\") as f:\n",
    "            f.write(\"=== Training Configuration ===\\n\")\n",
    "            for k, v in config.items():\n",
    "                f.write(f\"{k}: {v}\\n\")\n",
    "            \n",
    "            f.write(\"\\n=== Performance Summary ===\\n\")\n",
    "            f.write(f\"Best Validation Accuracy: {max(history['val_acc']):.4f}\\n\")\n",
    "            f.write(f\"Final Test Accuracy: {test_acc:.4f}\\n\")\n",
    "            \n",
    "            f.write(\"\\n=== Class Distribution ===\\n\")\n",
    "            for cls_name, idx in class_mapping.items():\n",
    "                count = sum(1 for lbl in history['all_labels'] if lbl == idx)\n",
    "                f.write(f\"Class {idx} ({cls_name}): {count} samples\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用示例\n",
    "    classifier = ImageClassifier()\n",
    "    \n",
    "    config = {\n",
    "        'root_dir': \"../../IQ_signal_plots\",\n",
    "        'target_folder': \"trajectory_pos\",  # 可修改为任意文件夹名称\n",
    "        'save_dir': \"training_results\",\n",
    "        'batch_size': 256,\n",
    "        'epochs': 30,\n",
    "        'lr': 0.0005,\n",
    "        'limit_per_class': None,\n",
    "        'input_size': 224,\n",
    "        'model_name': \"resnet18\",\n",
    "        'patience': 5\n",
    "    }\n",
    "    \n",
    "    classifier.train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MW-RFF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
