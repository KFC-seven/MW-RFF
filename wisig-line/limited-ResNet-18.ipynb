{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading scatter plot images...\n",
      "Total classes: 150\n",
      "Class 0: 1000 images\n",
      "Class 1: 1000 images\n",
      "Class 2: 1000 images\n",
      "Class 3: 1000 images\n",
      "Class 4: 1000 images\n",
      "Class 5: 1000 images\n",
      "Class 6: 1000 images\n",
      "Class 7: 1000 images\n",
      "Class 8: 1000 images\n",
      "Class 9: 1000 images\n",
      "Class 10: 1000 images\n",
      "Class 11: 1000 images\n",
      "Class 12: 1000 images\n",
      "Class 13: 1000 images\n",
      "Class 14: 1000 images\n",
      "Class 15: 1000 images\n",
      "Class 16: 1000 images\n",
      "Class 17: 1000 images\n",
      "Class 18: 1000 images\n",
      "Class 19: 1000 images\n",
      "Class 20: 1000 images\n",
      "Class 21: 1000 images\n",
      "Class 22: 1000 images\n",
      "Class 23: 1000 images\n",
      "Class 24: 1000 images\n",
      "Class 25: 1000 images\n",
      "Class 26: 1000 images\n",
      "Class 27: 1000 images\n",
      "Class 28: 1000 images\n",
      "Class 29: 1000 images\n",
      "Class 30: 1000 images\n",
      "Class 31: 1000 images\n",
      "Class 32: 1000 images\n",
      "Class 33: 1000 images\n",
      "Class 34: 1000 images\n",
      "Class 35: 1000 images\n",
      "Class 36: 1000 images\n",
      "Class 37: 1000 images\n",
      "Class 38: 1000 images\n",
      "Class 39: 1000 images\n",
      "Class 40: 1000 images\n",
      "Class 41: 1000 images\n",
      "Class 42: 1000 images\n",
      "Class 43: 1000 images\n",
      "Class 44: 1000 images\n",
      "Class 45: 1000 images\n",
      "Class 46: 1000 images\n",
      "Class 47: 1000 images\n",
      "Class 48: 1000 images\n",
      "Class 49: 1000 images\n",
      "Class 50: 1000 images\n",
      "Class 51: 1000 images\n",
      "Class 52: 1000 images\n",
      "Class 53: 1000 images\n",
      "Class 54: 1000 images\n",
      "Class 55: 1000 images\n",
      "Class 56: 1000 images\n",
      "Class 57: 1000 images\n",
      "Class 58: 1000 images\n",
      "Class 59: 1000 images\n",
      "Class 60: 1000 images\n",
      "Class 61: 1000 images\n",
      "Class 62: 1000 images\n",
      "Class 63: 1000 images\n",
      "Class 64: 1000 images\n",
      "Class 65: 1000 images\n",
      "Class 66: 1000 images\n",
      "Class 67: 1000 images\n",
      "Class 68: 1000 images\n",
      "Class 69: 1000 images\n",
      "Class 70: 1000 images\n",
      "Class 71: 1000 images\n",
      "Class 72: 1000 images\n",
      "Class 73: 1000 images\n",
      "Class 74: 1000 images\n",
      "Class 75: 1000 images\n",
      "Class 76: 1000 images\n",
      "Class 77: 1000 images\n",
      "Class 78: 1000 images\n",
      "Class 79: 1000 images\n",
      "Class 80: 1000 images\n",
      "Class 81: 1000 images\n",
      "Class 82: 1000 images\n",
      "Class 83: 1000 images\n",
      "Class 84: 1000 images\n",
      "Class 85: 1000 images\n",
      "Class 86: 1000 images\n",
      "Class 87: 1000 images\n",
      "Class 88: 1000 images\n",
      "Class 89: 1000 images\n",
      "Class 90: 1000 images\n",
      "Class 91: 1000 images\n",
      "Class 92: 1000 images\n",
      "Class 93: 1000 images\n",
      "Class 94: 1000 images\n",
      "Class 95: 1000 images\n",
      "Class 96: 1000 images\n",
      "Class 97: 1000 images\n",
      "Class 98: 1000 images\n",
      "Class 99: 1000 images\n",
      "Class 100: 1000 images\n",
      "Class 101: 1000 images\n",
      "Class 102: 1000 images\n",
      "Class 103: 1000 images\n",
      "Class 104: 1000 images\n",
      "Class 105: 1000 images\n",
      "Class 106: 1000 images\n",
      "Class 107: 1000 images\n",
      "Class 108: 1000 images\n",
      "Class 109: 1000 images\n",
      "Class 110: 1000 images\n",
      "Class 111: 1000 images\n",
      "Class 112: 1000 images\n",
      "Class 113: 1000 images\n",
      "Class 114: 1000 images\n",
      "Class 115: 1000 images\n",
      "Class 116: 1000 images\n",
      "Class 117: 1000 images\n",
      "Class 118: 1000 images\n",
      "Class 119: 1000 images\n",
      "Class 120: 1000 images\n",
      "Class 121: 1000 images\n",
      "Class 122: 1000 images\n",
      "Class 123: 1000 images\n",
      "Class 124: 1000 images\n",
      "Class 125: 1000 images\n",
      "Class 126: 1000 images\n",
      "Class 127: 1000 images\n",
      "Class 128: 1000 images\n",
      "Class 129: 1000 images\n",
      "Class 130: 1000 images\n",
      "Class 131: 1000 images\n",
      "Class 132: 1000 images\n",
      "Class 133: 1000 images\n",
      "Class 134: 1000 images\n",
      "Class 135: 1000 images\n",
      "Class 136: 1000 images\n",
      "Class 137: 1000 images\n",
      "Class 138: 1000 images\n",
      "Class 139: 1000 images\n",
      "Class 140: 1000 images\n",
      "Class 141: 1000 images\n",
      "Class 142: 1000 images\n",
      "Class 143: 1000 images\n",
      "Class 144: 1000 images\n",
      "Class 145: 1000 images\n",
      "Class 146: 1000 images\n",
      "Class 147: 1000 images\n",
      "Class 148: 1000 images\n",
      "Class 149: 1000 images\n",
      "Loading trajectory plot images...\n",
      "Total classes: 150\n",
      "Class 0: 1000 images\n",
      "Class 1: 1000 images\n",
      "Class 2: 1000 images\n",
      "Class 3: 1000 images\n",
      "Class 4: 1000 images\n",
      "Class 5: 1000 images\n",
      "Class 6: 1000 images\n",
      "Class 7: 1000 images\n",
      "Class 8: 1000 images\n",
      "Class 9: 1000 images\n",
      "Class 10: 1000 images\n",
      "Class 11: 1000 images\n",
      "Class 12: 1000 images\n",
      "Class 13: 1000 images\n",
      "Class 14: 1000 images\n",
      "Class 15: 1000 images\n",
      "Class 16: 1000 images\n",
      "Class 17: 1000 images\n",
      "Class 18: 1000 images\n",
      "Class 19: 1000 images\n",
      "Class 20: 1000 images\n",
      "Class 21: 1000 images\n",
      "Class 22: 1000 images\n",
      "Class 23: 1000 images\n",
      "Class 24: 1000 images\n",
      "Class 25: 1000 images\n",
      "Class 26: 1000 images\n",
      "Class 27: 1000 images\n",
      "Class 28: 1000 images\n",
      "Class 29: 1000 images\n",
      "Class 30: 1000 images\n",
      "Class 31: 1000 images\n",
      "Class 32: 1000 images\n",
      "Class 33: 1000 images\n",
      "Class 34: 1000 images\n",
      "Class 35: 1000 images\n",
      "Class 36: 1000 images\n",
      "Class 37: 1000 images\n",
      "Class 38: 1000 images\n",
      "Class 39: 1000 images\n",
      "Class 40: 1000 images\n",
      "Class 41: 1000 images\n",
      "Class 42: 1000 images\n",
      "Class 43: 1000 images\n",
      "Class 44: 1000 images\n",
      "Class 45: 1000 images\n",
      "Class 46: 1000 images\n",
      "Class 47: 1000 images\n",
      "Class 48: 1000 images\n",
      "Class 49: 1000 images\n",
      "Class 50: 1000 images\n",
      "Class 51: 1000 images\n",
      "Class 52: 1000 images\n",
      "Class 53: 1000 images\n",
      "Class 54: 1000 images\n",
      "Class 55: 1000 images\n",
      "Class 56: 1000 images\n",
      "Class 57: 1000 images\n",
      "Class 58: 1000 images\n",
      "Class 59: 1000 images\n",
      "Class 60: 1000 images\n",
      "Class 61: 1000 images\n",
      "Class 62: 1000 images\n",
      "Class 63: 1000 images\n",
      "Class 64: 1000 images\n",
      "Class 65: 1000 images\n",
      "Class 66: 1000 images\n",
      "Class 67: 1000 images\n",
      "Class 68: 1000 images\n",
      "Class 69: 1000 images\n",
      "Class 70: 1000 images\n",
      "Class 71: 1000 images\n",
      "Class 72: 1000 images\n",
      "Class 73: 1000 images\n",
      "Class 74: 1000 images\n",
      "Class 75: 1000 images\n",
      "Class 76: 1000 images\n",
      "Class 77: 1000 images\n",
      "Class 78: 1000 images\n",
      "Class 79: 1000 images\n",
      "Class 80: 1000 images\n",
      "Class 81: 1000 images\n",
      "Class 82: 1000 images\n",
      "Class 83: 1000 images\n",
      "Class 84: 1000 images\n",
      "Class 85: 1000 images\n",
      "Class 86: 1000 images\n",
      "Class 87: 1000 images\n",
      "Class 88: 1000 images\n",
      "Class 89: 1000 images\n",
      "Class 90: 1000 images\n",
      "Class 91: 1000 images\n",
      "Class 92: 1000 images\n",
      "Class 93: 1000 images\n",
      "Class 94: 1000 images\n",
      "Class 95: 1000 images\n",
      "Class 96: 1000 images\n",
      "Class 97: 1000 images\n",
      "Class 98: 1000 images\n",
      "Class 99: 1000 images\n",
      "Class 100: 1000 images\n",
      "Class 101: 1000 images\n",
      "Class 102: 1000 images\n",
      "Class 103: 1000 images\n",
      "Class 104: 1000 images\n",
      "Class 105: 1000 images\n",
      "Class 106: 1000 images\n",
      "Class 107: 1000 images\n",
      "Class 108: 1000 images\n",
      "Class 109: 1000 images\n",
      "Class 110: 1000 images\n",
      "Class 111: 1000 images\n",
      "Class 112: 1000 images\n",
      "Class 113: 1000 images\n",
      "Class 114: 1000 images\n",
      "Class 115: 1000 images\n",
      "Class 116: 1000 images\n",
      "Class 117: 1000 images\n",
      "Class 118: 1000 images\n",
      "Class 119: 1000 images\n",
      "Class 120: 1000 images\n",
      "Class 121: 1000 images\n",
      "Class 122: 1000 images\n",
      "Class 123: 1000 images\n",
      "Class 124: 1000 images\n",
      "Class 125: 1000 images\n",
      "Class 126: 1000 images\n",
      "Class 127: 1000 images\n",
      "Class 128: 1000 images\n",
      "Class 129: 1000 images\n",
      "Class 130: 1000 images\n",
      "Class 131: 1000 images\n",
      "Class 132: 1000 images\n",
      "Class 133: 1000 images\n",
      "Class 134: 1000 images\n",
      "Class 135: 1000 images\n",
      "Class 136: 1000 images\n",
      "Class 137: 1000 images\n",
      "Class 138: 1000 images\n",
      "Class 139: 1000 images\n",
      "Class 140: 1000 images\n",
      "Class 141: 1000 images\n",
      "Class 142: 1000 images\n",
      "Class 143: 1000 images\n",
      "Class 144: 1000 images\n",
      "Class 145: 1000 images\n",
      "Class 146: 1000 images\n",
      "Class 147: 1000 images\n",
      "Class 148: 1000 images\n",
      "Class 149: 1000 images\n",
      "\n",
      "Training scatter plot model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\software\\anaconda\\envs\\MW-RFF\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/20 - Training:   3%|▎         | 94/3750 [00:34<22:27,  2.71it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# 指定 GPU 索引（假设选择 GPU 0）\n",
    "GPU_INDEX = 0\n",
    "\n",
    "# 检查 GPU 是否可用并设置设备\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please enable a GPU.\")\n",
    "\n",
    "device = torch.device(f\"cuda:{GPU_INDEX}\")\n",
    "torch.cuda.set_device(GPU_INDEX)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 数据加载\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_image_paths(folder, plot_type='scatter_plots', limit_per_class=1000):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    label = 0  # 为每个发射机分配标签\n",
    "    class_count = {}\n",
    "\n",
    "    for tx_id in os.listdir(folder):\n",
    "        tx_folder = os.path.join(folder, tx_id)\n",
    "        if os.path.isdir(tx_folder):\n",
    "            plot_folder = os.path.join(tx_folder, plot_type)\n",
    "            if os.path.exists(plot_folder):\n",
    "                tx_files = [f for f in os.listdir(plot_folder) if f.endswith('.png')]\n",
    "                \n",
    "                # 限制每个发射机类的图片数量\n",
    "                tx_files = tx_files[:limit_per_class]\n",
    "\n",
    "                for filename in tx_files:\n",
    "                    file_paths.append(os.path.join(plot_folder, filename))\n",
    "                    labels.append(label)\n",
    "\n",
    "                # 统计每个类的图片数量\n",
    "                class_count[label] = len(tx_files)\n",
    "\n",
    "            label += 1\n",
    "\n",
    "    # 打印每个类的图片数量\n",
    "    print(f\"Total classes: {len(class_count)}\")\n",
    "    for lbl, count in class_count.items():\n",
    "        print(f\"Class {lbl}: {count} images\")\n",
    "\n",
    "    return file_paths, labels\n",
    "\n",
    "# 模型构建\n",
    "def build_resnet_model(num_classes):\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    # 替换最后一层\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# 训练和评估\n",
    "def train_and_evaluate_model(model, train_loader, val_loader, test_loader, device, epochs=20, lr=0.001):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_val_acc = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Test loop\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = correct / total\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    return model, train_losses, val_losses, test_acc\n",
    "\n",
    "# 比较训练效果\n",
    "def compare_scatter_trajectory_training(folder, batch_size=32, epochs=20, lr=0.001):\n",
    "    print(\"Loading scatter plot images...\")\n",
    "    scatter_paths, scatter_labels = load_image_paths(folder, plot_type='scatter_plots', limit_per_class=1000)\n",
    "    print(\"Loading trajectory plot images...\")\n",
    "    trajectory_paths, trajectory_labels = load_image_paths(folder, plot_type='trajectory_plots', limit_per_class=1000)\n",
    "\n",
    "    # 数据集分割\n",
    "    scatter_train_paths, scatter_test_paths, scatter_train_labels, scatter_test_labels = train_test_split(\n",
    "        scatter_paths, scatter_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "    trajectory_train_paths, trajectory_test_paths, trajectory_train_labels, trajectory_test_labels = train_test_split(\n",
    "        trajectory_paths, trajectory_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 数据预处理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # 构造数据集和数据加载器\n",
    "    scatter_train_dataset = ImageDataset(scatter_train_paths, scatter_train_labels, transform)\n",
    "    scatter_test_dataset = ImageDataset(scatter_test_paths, scatter_test_labels, transform)\n",
    "    trajectory_train_dataset = ImageDataset(trajectory_train_paths, trajectory_train_labels, transform)\n",
    "    trajectory_test_dataset = ImageDataset(trajectory_test_paths, trajectory_test_labels, transform)\n",
    "\n",
    "    scatter_train_loader = DataLoader(scatter_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    scatter_test_loader = DataLoader(scatter_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    trajectory_train_loader = DataLoader(trajectory_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    trajectory_test_loader = DataLoader(trajectory_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 获取类别数量\n",
    "    num_classes = len(set(scatter_labels))\n",
    "\n",
    "    # 构建和训练散点图模型\n",
    "    print(\"\\nTraining scatter plot model...\")\n",
    "    scatter_model = build_resnet_model(num_classes)\n",
    "    scatter_model, scatter_train_losses, scatter_val_losses, scatter_test_acc = train_and_evaluate_model(\n",
    "        scatter_model, scatter_train_loader, scatter_test_loader, scatter_test_loader, device, epochs, lr\n",
    "    )\n",
    "\n",
    "    # 构建和训练轨迹图模型\n",
    "    print(\"\\nTraining trajectory plot model...\")\n",
    "    trajectory_model = build_resnet_model(num_classes)\n",
    "    trajectory_model, trajectory_train_losses, trajectory_val_losses, trajectory_test_acc = train_and_evaluate_model(\n",
    "        trajectory_model, trajectory_train_loader, trajectory_test_loader, trajectory_test_loader, device, epochs, lr\n",
    "    )\n",
    "\n",
    "    # 输出比较结果\n",
    "    print(\"\\nComparison of Test Accuracies:\")\n",
    "    print(f\"Scatter plot model test accuracy: {scatter_test_acc:.4f}\")\n",
    "    print(f\"Trajectory plot model test accuracy: {trajectory_test_acc:.4f}\")\n",
    "\n",
    "# 使用示例：比较散点图和轨迹图的训练效果\n",
    "folder = \"../../IQ_signal_plots\"  # 图像存储的文件夹\n",
    "compare_scatter_trajectory_training(folder, batch_size=32, epochs=20, lr=0.001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MW-RFF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
