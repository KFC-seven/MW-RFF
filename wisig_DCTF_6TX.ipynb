{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907bc930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZY\\.conda\\envs\\MW-RFF\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集发射机数量： 6 具体为： ['14-10', '14-7', '20-15', '20-19', '6-15', '8-20']\n",
      "数据集接收机数量： 12 具体为： ['1-1', '1-19', '14-7', '18-2', '19-2', '2-1', '2-19', '20-1', '3-19', '7-14', '7-7', '8-8']\n",
      "数据集采集天数： 4 具体为： ['2021_03_01', '2021_03_08', '2021_03_15', '2021_03_23']\n",
      "✅ 训练样本数: 72000, 测试样本数: 72000\n",
      "X_train shape: (72000, 256, 2)\n",
      "y_train shape: (72000,)\n",
      "X_test  shape: (72000, 256, 2)\n",
      "y_test  shape: (72000,)\n",
      "Using device: cuda\n",
      "\n",
      "===== 开始 SNR=20 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:09<00:00, 99.74batch/s, accuracy=62.7, grad_norm=5.42, loss=0.924] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 103.63batch/s, accuracy=92.6, grad_norm=2.69, loss=0.222] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 105.19batch/s, accuracy=96.5, grad_norm=2.63, loss=0.112]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 105.35batch/s, accuracy=97.8, grad_norm=3.74, loss=0.0763] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 104.91batch/s, accuracy=98.4, grad_norm=2.01, loss=0.0546]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 97.82batch/s, accuracy=98.6, grad_norm=3.16, loss=0.0478]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 102.47batch/s, accuracy=98.8, grad_norm=0.206, loss=0.0418]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 102.80batch/s, accuracy=99, grad_norm=2.72, loss=0.0351]     \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 101.02batch/s, accuracy=99.1, grad_norm=0.285, loss=0.0324]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 100.25batch/s, accuracy=99.2, grad_norm=2.02, loss=0.0291]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:09<00:00, 96.22batch/s, accuracy=99.5, grad_norm=0.856, loss=0.0199]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 102.30batch/s, accuracy=99.5, grad_norm=0.243, loss=0.0172]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 103.20batch/s, accuracy=99.5, grad_norm=1.13, loss=0.0182]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 103.04batch/s, accuracy=99.5, grad_norm=0.212, loss=0.0176]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:09<00:00, 97.01batch/s, accuracy=99.5, grad_norm=0.146, loss=0.0174]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:09<00:00, 99.29batch/s, accuracy=99.5, grad_norm=1.66, loss=0.0175]    \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:09<00:00, 95.07batch/s, accuracy=99.6, grad_norm=0.101, loss=0.0156]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:09<00:00, 98.31batch/s, accuracy=99.5, grad_norm=0.0596, loss=0.0162]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 102.32batch/s, accuracy=99.6, grad_norm=2.23, loss=0.0161]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 71.87%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:09<00:00, 96.10batch/s, accuracy=63.1, grad_norm=5.01, loss=0.908] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:09<00:00, 96.30batch/s, accuracy=92.8, grad_norm=6.91, loss=0.219] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 100.73batch/s, accuracy=96.6, grad_norm=1.44, loss=0.112]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:09<00:00, 97.49batch/s, accuracy=97.7, grad_norm=2.61, loss=0.076]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:09<00:00, 98.47batch/s, accuracy=98.3, grad_norm=3.04, loss=0.0596]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 103.67batch/s, accuracy=98.6, grad_norm=0.132, loss=0.05]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 104.65batch/s, accuracy=98.8, grad_norm=1.77, loss=0.0415]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 103.76batch/s, accuracy=98.9, grad_norm=1.02, loss=0.0403]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 103.30batch/s, accuracy=99, grad_norm=0.233, loss=0.035]     \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 100.33batch/s, accuracy=99.1, grad_norm=2.42, loss=0.0312]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 101.29batch/s, accuracy=99.4, grad_norm=1.16, loss=0.0204]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:09<00:00, 94.21batch/s, accuracy=99.4, grad_norm=2.97, loss=0.0203]    \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:09<00:00, 95.83batch/s, accuracy=99.5, grad_norm=0.393, loss=0.019]    \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:09<00:00, 98.83batch/s, accuracy=99.4, grad_norm=0.0547, loss=0.0201]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 103.97batch/s, accuracy=99.5, grad_norm=0.438, loss=0.0199]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 104.32batch/s, accuracy=99.5, grad_norm=0.912, loss=0.0186]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 102.17batch/s, accuracy=99.5, grad_norm=0.962, loss=0.0175]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:09<00:00, 98.13batch/s, accuracy=99.5, grad_norm=1.04, loss=0.0184]    \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 102.97batch/s, accuracy=99.5, grad_norm=0.127, loss=0.0173]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 102.51batch/s, accuracy=99.5, grad_norm=0.181, loss=0.017]   \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 102.00batch/s, accuracy=99.7, grad_norm=0.145, loss=0.0122]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:09<00:00, 96.95batch/s, accuracy=99.6, grad_norm=0.246, loss=0.0127]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:09<00:00, 93.02batch/s, accuracy=99.7, grad_norm=0.348, loss=0.0117]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 102.57batch/s, accuracy=99.7, grad_norm=0.185, loss=0.0119]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:08<00:00, 102.69batch/s, accuracy=99.7, grad_norm=0.0923, loss=0.0119] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:08<00:00, 101.99batch/s, accuracy=99.6, grad_norm=0.122, loss=0.0124]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:09<00:00, 95.94batch/s, accuracy=99.7, grad_norm=0.253, loss=0.0109]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:09<00:00, 99.56batch/s, accuracy=99.7, grad_norm=4.09, loss=0.012]     \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:08<00:00, 100.55batch/s, accuracy=99.7, grad_norm=0.0557, loss=0.0113] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:08<00:00, 102.31batch/s, accuracy=99.7, grad_norm=0.746, loss=0.0108]  \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:09<00:00, 97.87batch/s, accuracy=99.7, grad_norm=0.213, loss=0.00937]  \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:09<00:00, 97.74batch/s, accuracy=99.8, grad_norm=0.642, loss=0.0088]   \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:09<00:00, 94.04batch/s, accuracy=99.7, grad_norm=5.29, loss=0.00905]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:09<00:00, 99.12batch/s, accuracy=99.8, grad_norm=1.34, loss=0.00857]   \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:08<00:00, 102.27batch/s, accuracy=99.7, grad_norm=0.173, loss=0.00898] \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:08<00:00, 102.89batch/s, accuracy=99.8, grad_norm=0.0894, loss=0.00862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 74.53%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 102.82batch/s, accuracy=63.7, grad_norm=5.16, loss=0.887]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 103.24batch/s, accuracy=92.4, grad_norm=2.56, loss=0.226] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 103.70batch/s, accuracy=96.6, grad_norm=2.31, loss=0.11]   \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:09<00:00, 95.78batch/s, accuracy=97.6, grad_norm=2.66, loss=0.0791]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:09<00:00, 98.60batch/s, accuracy=98.3, grad_norm=4.19, loss=0.0586]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 96.03batch/s, accuracy=98.6, grad_norm=1.23, loss=0.0489]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 96.13batch/s, accuracy=98.8, grad_norm=0.592, loss=0.0411]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 100.41batch/s, accuracy=98.9, grad_norm=2.35, loss=0.037]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 105.09batch/s, accuracy=99, grad_norm=0.425, loss=0.0341]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 103.52batch/s, accuracy=99.1, grad_norm=0.0661, loss=0.0299] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 106.68batch/s, accuracy=99.4, grad_norm=0.827, loss=0.0195]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 107.31batch/s, accuracy=99.5, grad_norm=0.0329, loss=0.0177] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:09<00:00, 95.99batch/s, accuracy=99.5, grad_norm=1.1, loss=0.0189]    \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 104.10batch/s, accuracy=99.5, grad_norm=0.583, loss=0.0176]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 105.60batch/s, accuracy=99.5, grad_norm=0.135, loss=0.0182]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 107.40batch/s, accuracy=99.5, grad_norm=0.315, loss=0.0169]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 103.44batch/s, accuracy=99.6, grad_norm=0.374, loss=0.0169]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 101.57batch/s, accuracy=99.6, grad_norm=0.921, loss=0.0161]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 104.95batch/s, accuracy=99.5, grad_norm=2.03, loss=0.0168]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 104.29batch/s, accuracy=99.6, grad_norm=0.221, loss=0.0141]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 102.03batch/s, accuracy=99.6, grad_norm=0.0531, loss=0.013]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:09<00:00, 97.88batch/s, accuracy=99.7, grad_norm=0.0791, loss=0.0108]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 100.93batch/s, accuracy=99.7, grad_norm=0.107, loss=0.0107]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 103.23batch/s, accuracy=99.7, grad_norm=0.286, loss=0.0109]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 65.66batch/s, accuracy=99.7, grad_norm=0.208, loss=0.0107]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 64.44batch/s, accuracy=99.7, grad_norm=0.111, loss=0.0115]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 66.77batch/s, accuracy=99.7, grad_norm=0.0947, loss=0.0107] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 67.12batch/s, accuracy=99.7, grad_norm=1.31, loss=0.0109]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:13<00:00, 65.17batch/s, accuracy=99.7, grad_norm=0.327, loss=0.0112]  \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 73.35batch/s, accuracy=99.7, grad_norm=1.39, loss=0.0103]   \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:13<00:00, 67.82batch/s, accuracy=99.7, grad_norm=0.303, loss=0.00884] \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:13<00:00, 68.11batch/s, accuracy=99.7, grad_norm=0.0585, loss=0.00833] \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:12<00:00, 69.31batch/s, accuracy=99.8, grad_norm=0.355, loss=0.00852] \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:13<00:00, 68.08batch/s, accuracy=99.8, grad_norm=0.0948, loss=0.0087]  \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:13<00:00, 67.33batch/s, accuracy=99.8, grad_norm=0.307, loss=0.00792] \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:13<00:00, 68.27batch/s, accuracy=99.8, grad_norm=0.951, loss=0.0082]   \n",
      "Epoch 37/200: 100%|██████████| 900/900 [00:13<00:00, 67.67batch/s, accuracy=99.7, grad_norm=2.42, loss=0.00851]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 77.17%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 71.89batch/s, accuracy=64.4, grad_norm=3.99, loss=0.879]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.72batch/s, accuracy=92.2, grad_norm=1.77, loss=0.228] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 65.47batch/s, accuracy=96.6, grad_norm=1.96, loss=0.111]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 68.17batch/s, accuracy=97.9, grad_norm=1.73, loss=0.0722]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.86batch/s, accuracy=98.2, grad_norm=1.35, loss=0.0594]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.48batch/s, accuracy=98.6, grad_norm=1.09, loss=0.0476]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.95batch/s, accuracy=98.7, grad_norm=1.93, loss=0.0429]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:09<00:00, 99.53batch/s, accuracy=98.9, grad_norm=2.96, loss=0.0358]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:09<00:00, 98.08batch/s, accuracy=99, grad_norm=5.9, loss=0.0343]       \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:09<00:00, 99.49batch/s, accuracy=99.1, grad_norm=0.226, loss=0.032]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 102.68batch/s, accuracy=99.5, grad_norm=0.926, loss=0.0181]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.68batch/s, accuracy=99.5, grad_norm=0.617, loss=0.0173]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.53batch/s, accuracy=99.5, grad_norm=0.132, loss=0.0191]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 70.00batch/s, accuracy=99.5, grad_norm=0.332, loss=0.0184]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 68.04batch/s, accuracy=99.4, grad_norm=2.44, loss=0.0192]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 69.59batch/s, accuracy=99.6, grad_norm=0.728, loss=0.0165]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.15batch/s, accuracy=99.5, grad_norm=0.177, loss=0.0167]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.45batch/s, accuracy=99.5, grad_norm=2.24, loss=0.017]    \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 68.39batch/s, accuracy=99.6, grad_norm=0.861, loss=0.0155]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 67.32batch/s, accuracy=99.6, grad_norm=0.405, loss=0.0161]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 68.06batch/s, accuracy=99.7, grad_norm=0.894, loss=0.0116]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.34batch/s, accuracy=99.6, grad_norm=0.521, loss=0.0121]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 67.48batch/s, accuracy=99.6, grad_norm=0.129, loss=0.0118]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 67.84batch/s, accuracy=99.7, grad_norm=0.412, loss=0.0116]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 73.42batch/s, accuracy=99.7, grad_norm=0.354, loss=0.0113]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:14<00:00, 63.39batch/s, accuracy=99.7, grad_norm=0.158, loss=0.0105]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 70.03batch/s, accuracy=99.7, grad_norm=0.188, loss=0.011]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 66.92batch/s, accuracy=99.7, grad_norm=0.061, loss=0.011]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 70.94batch/s, accuracy=99.7, grad_norm=1.75, loss=0.0108]   \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 70.16batch/s, accuracy=99.7, grad_norm=5.72, loss=0.0111]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 76.12%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 107.57batch/s, accuracy=64.5, grad_norm=6.28, loss=0.876]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 104.51batch/s, accuracy=93.2, grad_norm=3.19, loss=0.209] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 102.87batch/s, accuracy=96.7, grad_norm=2.61, loss=0.106]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:10<00:00, 89.96batch/s, accuracy=97.7, grad_norm=2.57, loss=0.0759]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 69.90batch/s, accuracy=98.4, grad_norm=3.16, loss=0.0555]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.21batch/s, accuracy=98.6, grad_norm=3.03, loss=0.0485]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 72.77batch/s, accuracy=98.7, grad_norm=0.709, loss=0.0417] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 64.77batch/s, accuracy=98.9, grad_norm=1.55, loss=0.0383]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.00batch/s, accuracy=99, grad_norm=1.71, loss=0.034]      \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 73.31batch/s, accuracy=99.1, grad_norm=6.32, loss=0.0315]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.59batch/s, accuracy=99.4, grad_norm=1.53, loss=0.02]     \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.42batch/s, accuracy=99.4, grad_norm=1.84, loss=0.0193]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 66.44batch/s, accuracy=99.4, grad_norm=0.733, loss=0.0189]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:14<00:00, 64.05batch/s, accuracy=99.4, grad_norm=0.154, loss=0.019]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 69.17batch/s, accuracy=99.5, grad_norm=3.84, loss=0.0171]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.69batch/s, accuracy=99.5, grad_norm=3.48, loss=0.0189]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.03batch/s, accuracy=99.5, grad_norm=0.333, loss=0.0176]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.05batch/s, accuracy=99.6, grad_norm=0.32, loss=0.016]    \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 68.49batch/s, accuracy=99.6, grad_norm=0.105, loss=0.016]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 66.86batch/s, accuracy=99.5, grad_norm=0.188, loss=0.0163]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 70.41batch/s, accuracy=99.6, grad_norm=0.0706, loss=0.0122] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.00batch/s, accuracy=99.7, grad_norm=0.0416, loss=0.0108] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 68.19batch/s, accuracy=99.7, grad_norm=0.105, loss=0.0104]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 70.03batch/s, accuracy=99.7, grad_norm=0.612, loss=0.0116]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:09<00:00, 94.13batch/s, accuracy=99.7, grad_norm=0.243, loss=0.0112]   \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:08<00:00, 104.44batch/s, accuracy=99.7, grad_norm=1.57, loss=0.0116]   \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:08<00:00, 102.90batch/s, accuracy=99.7, grad_norm=0.103, loss=0.011]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:08<00:00, 107.20batch/s, accuracy=99.7, grad_norm=3.29, loss=0.0109]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 72.58%\n",
      "SNR=20 完成: Avg Val=99.71%, Avg Test=74.45%\n",
      "\n",
      "===== 开始 SNR=15 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 70.53batch/s, accuracy=60, grad_norm=4.62, loss=0.978]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 72.67batch/s, accuracy=91, grad_norm=4.34, loss=0.259]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 69.46batch/s, accuracy=96, grad_norm=3.08, loss=0.128]    \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 65.25batch/s, accuracy=97.4, grad_norm=3.17, loss=0.0864] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.49batch/s, accuracy=98.1, grad_norm=1.41, loss=0.0665]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.02batch/s, accuracy=98.3, grad_norm=2.94, loss=0.0555]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.15batch/s, accuracy=98.7, grad_norm=2.72, loss=0.0454]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.32batch/s, accuracy=98.7, grad_norm=1.32, loss=0.0423]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 65.54batch/s, accuracy=98.9, grad_norm=2.63, loss=0.0382]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 64.41batch/s, accuracy=99, grad_norm=1.74, loss=0.0357]     \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.49batch/s, accuracy=99.4, grad_norm=0.517, loss=0.0212]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.47batch/s, accuracy=99.5, grad_norm=0.139, loss=0.0203]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.76batch/s, accuracy=99.4, grad_norm=1.12, loss=0.0195]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.57batch/s, accuracy=99.4, grad_norm=1.06, loss=0.0197]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 66.05batch/s, accuracy=99.5, grad_norm=0.31, loss=0.0184]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.12batch/s, accuracy=99.5, grad_norm=3.37, loss=0.018]    \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.86batch/s, accuracy=99.5, grad_norm=0.199, loss=0.0181]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.88batch/s, accuracy=99.5, grad_norm=1.06, loss=0.0187]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 67.65batch/s, accuracy=99.5, grad_norm=0.146, loss=0.0172]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 64.68batch/s, accuracy=99.5, grad_norm=0.478, loss=0.0173]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 69.71batch/s, accuracy=99.7, grad_norm=0.232, loss=0.0109]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.69batch/s, accuracy=99.7, grad_norm=0.531, loss=0.0114]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 67.04batch/s, accuracy=99.7, grad_norm=0.0771, loss=0.0114] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 69.62batch/s, accuracy=99.7, grad_norm=1.72, loss=0.0114]   \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 67.88batch/s, accuracy=99.7, grad_norm=0.886, loss=0.0112]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 64.38batch/s, accuracy=99.7, grad_norm=0.485, loss=0.0105]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 69.92batch/s, accuracy=99.7, grad_norm=0.56, loss=0.0112]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 72.27%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.83batch/s, accuracy=62.6, grad_norm=5.54, loss=0.93] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.35batch/s, accuracy=91.2, grad_norm=3.12, loss=0.257] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.10batch/s, accuracy=95.8, grad_norm=1.97, loss=0.132]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 65.50batch/s, accuracy=97.1, grad_norm=2.89, loss=0.0916] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 65.92batch/s, accuracy=97.8, grad_norm=1.1, loss=0.0732]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=98.3, grad_norm=0.567, loss=0.0583] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.97batch/s, accuracy=98.5, grad_norm=1.45, loss=0.051]   \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 69.26batch/s, accuracy=98.7, grad_norm=0.529, loss=0.0451] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.62batch/s, accuracy=98.9, grad_norm=1.9, loss=0.0381]    \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 65.89batch/s, accuracy=98.9, grad_norm=0.205, loss=0.0367] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.77batch/s, accuracy=99.3, grad_norm=0.685, loss=0.0229]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 73.03batch/s, accuracy=99.4, grad_norm=0.986, loss=0.0218]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.23batch/s, accuracy=99.3, grad_norm=2.34, loss=0.0232]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.43batch/s, accuracy=99.4, grad_norm=0.524, loss=0.0206]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:14<00:00, 63.88batch/s, accuracy=99.3, grad_norm=1.12, loss=0.023]    \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=99.5, grad_norm=0.322, loss=0.0193]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.06batch/s, accuracy=99.4, grad_norm=0.901, loss=0.0201]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.99batch/s, accuracy=99.4, grad_norm=0.307, loss=0.0194]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 67.56batch/s, accuracy=99.5, grad_norm=0.158, loss=0.0186]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 66.65batch/s, accuracy=99.5, grad_norm=1.14, loss=0.0175]   \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:09<00:00, 97.13batch/s, accuracy=99.6, grad_norm=1.13, loss=0.0131]    \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 100.41batch/s, accuracy=99.6, grad_norm=0.312, loss=0.0125]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 104.99batch/s, accuracy=99.6, grad_norm=1.29, loss=0.0125]   \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 109.49batch/s, accuracy=99.6, grad_norm=0.104, loss=0.0135]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 65.69batch/s, accuracy=99.7, grad_norm=0.0518, loss=0.0118] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 69.19batch/s, accuracy=99.7, grad_norm=0.713, loss=0.0122]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 70.55batch/s, accuracy=99.6, grad_norm=0.613, loss=0.012]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 69.98%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 68.42batch/s, accuracy=58.6, grad_norm=4.09, loss=1.02] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.80batch/s, accuracy=89.4, grad_norm=5.92, loss=0.298] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.81batch/s, accuracy=95.2, grad_norm=2.16, loss=0.147]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 73.03batch/s, accuracy=97, grad_norm=1.99, loss=0.0956]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 73.80batch/s, accuracy=97.8, grad_norm=1.85, loss=0.0727] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.31batch/s, accuracy=98.3, grad_norm=1.61, loss=0.0571]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 64.68batch/s, accuracy=98.7, grad_norm=1.73, loss=0.0471]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.90batch/s, accuracy=98.8, grad_norm=0.713, loss=0.0414]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 68.86batch/s, accuracy=99, grad_norm=0.5, loss=0.0363]     \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.32batch/s, accuracy=99, grad_norm=0.596, loss=0.0336]    \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 66.33batch/s, accuracy=99.4, grad_norm=2.39, loss=0.022]    \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.15batch/s, accuracy=99.3, grad_norm=0.0841, loss=0.0223] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.91batch/s, accuracy=99.4, grad_norm=2.04, loss=0.0202]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.31batch/s, accuracy=99.4, grad_norm=0.289, loss=0.0217]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 72.38batch/s, accuracy=99.5, grad_norm=0.0688, loss=0.0186] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 68.39batch/s, accuracy=99.5, grad_norm=1.27, loss=0.0193]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 68.26batch/s, accuracy=99.4, grad_norm=2.17, loss=0.0195]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:10<00:00, 86.20batch/s, accuracy=99.5, grad_norm=0.277, loss=0.0179]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 104.39batch/s, accuracy=99.5, grad_norm=3.07, loss=0.0164]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 109.39batch/s, accuracy=99.5, grad_norm=0.156, loss=0.0173]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 68.60%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 108.67batch/s, accuracy=61.7, grad_norm=5.47, loss=0.934]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 107.96batch/s, accuracy=90.6, grad_norm=3.77, loss=0.273] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 107.25batch/s, accuracy=95.4, grad_norm=1.42, loss=0.141]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 106.42batch/s, accuracy=97.1, grad_norm=1.56, loss=0.0928] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 106.78batch/s, accuracy=97.9, grad_norm=2.61, loss=0.0679]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 109.24batch/s, accuracy=98.3, grad_norm=2.53, loss=0.0575]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 104.07batch/s, accuracy=98.6, grad_norm=1.26, loss=0.0468]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:09<00:00, 90.90batch/s, accuracy=98.7, grad_norm=1.85, loss=0.0449]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 72.09batch/s, accuracy=98.9, grad_norm=1.38, loss=0.0385]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 67.17batch/s, accuracy=98.9, grad_norm=3.36, loss=0.0367]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.28batch/s, accuracy=99.4, grad_norm=3.04, loss=0.0212]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.12batch/s, accuracy=99.4, grad_norm=0.191, loss=0.0212]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.33batch/s, accuracy=99.4, grad_norm=3.9, loss=0.0214]    \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 68.59batch/s, accuracy=99.4, grad_norm=1.77, loss=0.0202]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.95batch/s, accuracy=99.4, grad_norm=0.253, loss=0.02]     \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.85batch/s, accuracy=99.4, grad_norm=0.0645, loss=0.0189] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.75batch/s, accuracy=99.4, grad_norm=0.533, loss=0.0194]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 66.92batch/s, accuracy=99.5, grad_norm=3.09, loss=0.017]    \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 64.68batch/s, accuracy=99.5, grad_norm=0.135, loss=0.0184]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 69.01batch/s, accuracy=99.5, grad_norm=0.985, loss=0.0172]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 71.08batch/s, accuracy=99.7, grad_norm=0.638, loss=0.0124]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 73.50batch/s, accuracy=99.6, grad_norm=1.28, loss=0.0127]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 66.93batch/s, accuracy=99.7, grad_norm=0.195, loss=0.0118]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:14<00:00, 64.26batch/s, accuracy=99.7, grad_norm=0.201, loss=0.0122]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 71.17batch/s, accuracy=99.7, grad_norm=0.234, loss=0.0122]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:12<00:00, 72.72batch/s, accuracy=99.7, grad_norm=0.236, loss=0.0123]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 71.34batch/s, accuracy=99.7, grad_norm=2.92, loss=0.0111]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 67.15batch/s, accuracy=99.7, grad_norm=0.0413, loss=0.012]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 75.68%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:14<00:00, 63.91batch/s, accuracy=61.3, grad_norm=5.35, loss=0.959]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.39batch/s, accuracy=91, grad_norm=3.89, loss=0.257]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 72.41batch/s, accuracy=95.8, grad_norm=2.89, loss=0.131]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 71.17batch/s, accuracy=97.2, grad_norm=1.25, loss=0.0914] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 68.96batch/s, accuracy=97.9, grad_norm=2.24, loss=0.0681] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 66.73batch/s, accuracy=98.3, grad_norm=0.665, loss=0.0565] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.84batch/s, accuracy=98.5, grad_norm=2.49, loss=0.0491]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 73.78batch/s, accuracy=98.6, grad_norm=1.28, loss=0.0448]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=99, grad_norm=1.27, loss=0.0356]    \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.83batch/s, accuracy=99, grad_norm=1.11, loss=0.0345]     \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.27batch/s, accuracy=99.3, grad_norm=0.268, loss=0.0241]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 65.01batch/s, accuracy=99.4, grad_norm=0.0691, loss=0.0216] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.26batch/s, accuracy=99.3, grad_norm=1.07, loss=0.0228]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 69.21batch/s, accuracy=99.4, grad_norm=2.18, loss=0.0211]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.77batch/s, accuracy=99.5, grad_norm=0.557, loss=0.0198]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.25batch/s, accuracy=99.4, grad_norm=2.19, loss=0.0198]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 103.69batch/s, accuracy=99.4, grad_norm=0.103, loss=0.0209]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 102.83batch/s, accuracy=99.5, grad_norm=2.56, loss=0.0185]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 103.45batch/s, accuracy=99.4, grad_norm=0.332, loss=0.0193]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:09<00:00, 99.55batch/s, accuracy=99.5, grad_norm=0.595, loss=0.018]    \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 66.38batch/s, accuracy=99.6, grad_norm=0.718, loss=0.0133]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 66.71batch/s, accuracy=99.7, grad_norm=0.139, loss=0.012]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 69.89batch/s, accuracy=99.6, grad_norm=0.0507, loss=0.0129] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 70.13batch/s, accuracy=99.7, grad_norm=0.246, loss=0.0122]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 71.53batch/s, accuracy=99.6, grad_norm=0.446, loss=0.013]   \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 67.28batch/s, accuracy=99.6, grad_norm=0.829, loss=0.0125]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=99.6, grad_norm=0.165, loss=0.0121]  \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 71.59batch/s, accuracy=99.6, grad_norm=0.439, loss=0.0128]  \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 71.32batch/s, accuracy=99.7, grad_norm=0.163, loss=0.0116]  \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 68.17batch/s, accuracy=99.7, grad_norm=0.804, loss=0.0118]  \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:13<00:00, 67.47batch/s, accuracy=99.7, grad_norm=0.309, loss=0.0093]   \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:12<00:00, 71.64batch/s, accuracy=99.7, grad_norm=0.127, loss=0.00956]  \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:12<00:00, 72.97batch/s, accuracy=99.7, grad_norm=0.131, loss=0.00906]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:12<00:00, 70.58batch/s, accuracy=99.7, grad_norm=1.64, loss=0.00934]   \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:13<00:00, 68.17batch/s, accuracy=99.7, grad_norm=0.152, loss=0.00905]  \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:13<00:00, 66.12batch/s, accuracy=99.7, grad_norm=0.701, loss=0.00926] \n",
      "Epoch 37/200: 100%|██████████| 900/900 [00:12<00:00, 72.59batch/s, accuracy=99.7, grad_norm=0.449, loss=0.00932] \n",
      "Epoch 38/200: 100%|██████████| 900/900 [00:12<00:00, 70.49batch/s, accuracy=99.8, grad_norm=0.265, loss=0.0088]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 70.57%\n",
      "SNR=15 完成: Avg Val=99.70%, Avg Test=71.42%\n",
      "\n",
      "===== 开始 SNR=10 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.61batch/s, accuracy=58.4, grad_norm=4.97, loss=1.02] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 72.73batch/s, accuracy=86.8, grad_norm=4.49, loss=0.36]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 64.42batch/s, accuracy=93.5, grad_norm=4.6, loss=0.188]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.75batch/s, accuracy=96, grad_norm=2.1, loss=0.123]     \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.83batch/s, accuracy=96.8, grad_norm=2.5, loss=0.0957]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.34batch/s, accuracy=97.6, grad_norm=3.43, loss=0.0764] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.12batch/s, accuracy=97.9, grad_norm=3.28, loss=0.0659]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 67.47batch/s, accuracy=98.3, grad_norm=2.91, loss=0.0546]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 64.57batch/s, accuracy=98.4, grad_norm=0.569, loss=0.0547] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 68.29batch/s, accuracy=98.6, grad_norm=2.89, loss=0.0461]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.48batch/s, accuracy=99.1, grad_norm=3.13, loss=0.0311]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.40batch/s, accuracy=99.1, grad_norm=2.15, loss=0.0299]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.52batch/s, accuracy=99.2, grad_norm=0.539, loss=0.0295]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:14<00:00, 61.93batch/s, accuracy=99.2, grad_norm=2.17, loss=0.0283]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 69.42batch/s, accuracy=99.1, grad_norm=0.547, loss=0.0294]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.55batch/s, accuracy=99.3, grad_norm=0.11, loss=0.0239]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 69.77batch/s, accuracy=99.3, grad_norm=1.39, loss=0.0256]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.57batch/s, accuracy=99.3, grad_norm=0.937, loss=0.0253]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 64.50batch/s, accuracy=99.4, grad_norm=0.866, loss=0.0231]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:10<00:00, 85.33batch/s, accuracy=99.3, grad_norm=2.28, loss=0.0249]   \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 103.56batch/s, accuracy=99.5, grad_norm=1.4, loss=0.0172]    \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 105.55batch/s, accuracy=99.5, grad_norm=0.269, loss=0.0161]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 107.66batch/s, accuracy=99.6, grad_norm=0.0875, loss=0.0156] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 73.80batch/s, accuracy=99.5, grad_norm=2.65, loss=0.0167]    \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 72.51batch/s, accuracy=99.6, grad_norm=0.645, loss=0.0149]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 68.02batch/s, accuracy=99.6, grad_norm=0.223, loss=0.0153]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 66.69batch/s, accuracy=99.6, grad_norm=1.36, loss=0.0149]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 71.26batch/s, accuracy=99.6, grad_norm=0.384, loss=0.0156]  \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:13<00:00, 68.62batch/s, accuracy=99.6, grad_norm=2.26, loss=0.015]    \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 67.89batch/s, accuracy=99.6, grad_norm=0.235, loss=0.0151]  \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:12<00:00, 69.91batch/s, accuracy=99.7, grad_norm=1.12, loss=0.0113]   \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:13<00:00, 64.30batch/s, accuracy=99.7, grad_norm=0.858, loss=0.0108]  \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:12<00:00, 70.48batch/s, accuracy=99.7, grad_norm=1.49, loss=0.0112]    \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:13<00:00, 66.54batch/s, accuracy=99.7, grad_norm=0.276, loss=0.0109]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 72.25%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 71.24batch/s, accuracy=60.1, grad_norm=6.22, loss=0.981]\n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 72.68batch/s, accuracy=88.4, grad_norm=3.71, loss=0.323] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 65.99batch/s, accuracy=93.9, grad_norm=2.4, loss=0.182]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 65.16batch/s, accuracy=96.2, grad_norm=2.8, loss=0.121]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 68.52batch/s, accuracy=96.9, grad_norm=2.81, loss=0.0971] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 73.78batch/s, accuracy=97.5, grad_norm=1.71, loss=0.0791]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 67.75batch/s, accuracy=97.8, grad_norm=0.447, loss=0.0688] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 69.86batch/s, accuracy=98.2, grad_norm=0.222, loss=0.0593] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 65.23batch/s, accuracy=98.4, grad_norm=0.642, loss=0.0522] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 70.68batch/s, accuracy=98.4, grad_norm=3.19, loss=0.0508]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.76batch/s, accuracy=99.1, grad_norm=1.02, loss=0.0312]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.97batch/s, accuracy=99, grad_norm=0.721, loss=0.0312]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.46batch/s, accuracy=99.1, grad_norm=0.574, loss=0.0314]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.42batch/s, accuracy=99.2, grad_norm=4.56, loss=0.0285]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 65.93batch/s, accuracy=99.1, grad_norm=0.439, loss=0.0296] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.77batch/s, accuracy=99.1, grad_norm=0.903, loss=0.0283]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.38batch/s, accuracy=99.2, grad_norm=0.932, loss=0.0258]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.31batch/s, accuracy=99.2, grad_norm=2.96, loss=0.0263]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 68.33batch/s, accuracy=99.2, grad_norm=2.76, loss=0.0254]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 67.49batch/s, accuracy=99.3, grad_norm=1.82, loss=0.0239]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 71.33%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 71.85batch/s, accuracy=58.2, grad_norm=6.55, loss=1.02] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.41batch/s, accuracy=87.8, grad_norm=5.26, loss=0.337] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 67.69batch/s, accuracy=94.2, grad_norm=2.05, loss=0.171] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.28batch/s, accuracy=95.9, grad_norm=2.18, loss=0.124]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 70.92batch/s, accuracy=97.2, grad_norm=1.36, loss=0.0897] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 69.09batch/s, accuracy=97.5, grad_norm=2.33, loss=0.0788] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 67.12batch/s, accuracy=98.1, grad_norm=2.54, loss=0.0643]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 69.14batch/s, accuracy=98.3, grad_norm=3.36, loss=0.0556]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 69.75batch/s, accuracy=98.4, grad_norm=0.378, loss=0.0529] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.53batch/s, accuracy=98.5, grad_norm=1.75, loss=0.0486]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.45batch/s, accuracy=99.1, grad_norm=0.105, loss=0.0326]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 65.54batch/s, accuracy=99.1, grad_norm=1.52, loss=0.0301]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.02batch/s, accuracy=99.1, grad_norm=0.887, loss=0.0303]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 73.55batch/s, accuracy=99.1, grad_norm=0.562, loss=0.0303]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.84batch/s, accuracy=99.2, grad_norm=0.764, loss=0.0274]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 69.28batch/s, accuracy=99.1, grad_norm=0.136, loss=0.0293] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:14<00:00, 62.59batch/s, accuracy=99.2, grad_norm=0.396, loss=0.0262]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 71.40batch/s, accuracy=99.2, grad_norm=0.269, loss=0.0276]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 72.41batch/s, accuracy=99.3, grad_norm=4.07, loss=0.0245]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 74.15%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 72.05batch/s, accuracy=56.4, grad_norm=4.77, loss=1.06] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.01batch/s, accuracy=87, grad_norm=2.65, loss=0.353]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:14<00:00, 63.67batch/s, accuracy=93.4, grad_norm=1.93, loss=0.191] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 68.16batch/s, accuracy=95.6, grad_norm=2.34, loss=0.132]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.18batch/s, accuracy=96.9, grad_norm=2.4, loss=0.0981]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.86batch/s, accuracy=97.5, grad_norm=0.691, loss=0.0789]\n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 68.49batch/s, accuracy=97.8, grad_norm=3.04, loss=0.07]    \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 67.47batch/s, accuracy=98.2, grad_norm=0.919, loss=0.0592] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 67.52batch/s, accuracy=98.4, grad_norm=0.375, loss=0.054]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.66batch/s, accuracy=98.4, grad_norm=3.2, loss=0.0504]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.53batch/s, accuracy=99, grad_norm=3.88, loss=0.0316]     \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 69.17batch/s, accuracy=99.1, grad_norm=3.12, loss=0.029]    \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.07batch/s, accuracy=99.1, grad_norm=1.17, loss=0.0292]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 68.23batch/s, accuracy=99.1, grad_norm=0.216, loss=0.0282]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 69.35batch/s, accuracy=99.2, grad_norm=2.49, loss=0.0275]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.20batch/s, accuracy=99.3, grad_norm=1.56, loss=0.0252]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 104.17batch/s, accuracy=99.3, grad_norm=0.246, loss=0.025]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 107.38batch/s, accuracy=99.3, grad_norm=3.43, loss=0.0261]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 105.82batch/s, accuracy=99.2, grad_norm=0.605, loss=0.0256]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 109.35batch/s, accuracy=99.3, grad_norm=0.296, loss=0.0238]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 66.18batch/s, accuracy=99.6, grad_norm=1.23, loss=0.0158]    \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 66.34batch/s, accuracy=99.5, grad_norm=0.735, loss=0.0173]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 71.37batch/s, accuracy=99.6, grad_norm=1.04, loss=0.0156]   \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 74.11batch/s, accuracy=99.5, grad_norm=2.49, loss=0.0168]   \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 71.84batch/s, accuracy=99.5, grad_norm=0.465, loss=0.0166]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 68.88batch/s, accuracy=99.5, grad_norm=0.0521, loss=0.0161] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:14<00:00, 63.79batch/s, accuracy=99.6, grad_norm=0.249, loss=0.0154]  \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 69.59batch/s, accuracy=99.6, grad_norm=0.11, loss=0.0149]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 69.49batch/s, accuracy=99.6, grad_norm=1.09, loss=0.0159]   \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 71.51batch/s, accuracy=99.6, grad_norm=0.0401, loss=0.0153] \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:12<00:00, 69.78batch/s, accuracy=99.7, grad_norm=0.253, loss=0.0112]  \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:14<00:00, 63.27batch/s, accuracy=99.7, grad_norm=0.279, loss=0.0118]  \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:13<00:00, 66.10batch/s, accuracy=99.7, grad_norm=0.0422, loss=0.011]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:13<00:00, 68.80batch/s, accuracy=99.7, grad_norm=0.27, loss=0.0106]   \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:12<00:00, 73.08batch/s, accuracy=99.6, grad_norm=0.298, loss=0.0115]  \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:12<00:00, 69.24batch/s, accuracy=99.7, grad_norm=2.89, loss=0.0117]    \n",
      "Epoch 37/200: 100%|██████████| 900/900 [00:13<00:00, 68.25batch/s, accuracy=99.7, grad_norm=1.74, loss=0.0113]   \n",
      "Epoch 38/200: 100%|██████████| 900/900 [00:13<00:00, 65.42batch/s, accuracy=99.7, grad_norm=0.443, loss=0.0103]  \n",
      "Epoch 39/200: 100%|██████████| 900/900 [00:13<00:00, 68.19batch/s, accuracy=99.7, grad_norm=0.103, loss=0.0116]  \n",
      "Epoch 40/200: 100%|██████████| 900/900 [00:09<00:00, 94.62batch/s, accuracy=99.7, grad_norm=1.41, loss=0.0106]    \n",
      "Epoch 41/200: 100%|██████████| 900/900 [00:08<00:00, 103.03batch/s, accuracy=99.7, grad_norm=1.65, loss=0.0094]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 71.47%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 103.05batch/s, accuracy=57, grad_norm=5.07, loss=1.04]   \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 108.02batch/s, accuracy=86.5, grad_norm=2.53, loss=0.366] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 67.38batch/s, accuracy=93.5, grad_norm=3.93, loss=0.189] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.07batch/s, accuracy=95.8, grad_norm=1.39, loss=0.13]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 69.82batch/s, accuracy=96.4, grad_norm=4.79, loss=0.107]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.68batch/s, accuracy=97.3, grad_norm=3.09, loss=0.0831]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 73.47batch/s, accuracy=97.9, grad_norm=0.909, loss=0.0693] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 69.76batch/s, accuracy=98.1, grad_norm=0.758, loss=0.0608] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 69.81batch/s, accuracy=98.3, grad_norm=1.67, loss=0.055]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 67.51batch/s, accuracy=98.6, grad_norm=2.52, loss=0.0474]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.58batch/s, accuracy=98.9, grad_norm=1.7, loss=0.0351]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.92batch/s, accuracy=99.1, grad_norm=2.68, loss=0.0303]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.70batch/s, accuracy=99.1, grad_norm=1.98, loss=0.0311]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.39batch/s, accuracy=99.2, grad_norm=1.05, loss=0.0283]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 64.82batch/s, accuracy=99.2, grad_norm=2.71, loss=0.0272]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.70batch/s, accuracy=99.1, grad_norm=3.76, loss=0.0277]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.51batch/s, accuracy=99.3, grad_norm=0.733, loss=0.025]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 68.21batch/s, accuracy=99.2, grad_norm=1.78, loss=0.0256]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 67.72batch/s, accuracy=99.3, grad_norm=2.38, loss=0.0254]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 65.01batch/s, accuracy=99.2, grad_norm=2.31, loss=0.0255]   \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 65.89batch/s, accuracy=99.5, grad_norm=4.46, loss=0.0181]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.54batch/s, accuracy=99.5, grad_norm=1.17, loss=0.0164]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 73.45batch/s, accuracy=99.5, grad_norm=2.42, loss=0.017]    \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 69.16batch/s, accuracy=99.5, grad_norm=0.518, loss=0.0174]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 68.81batch/s, accuracy=99.5, grad_norm=0.784, loss=0.0168]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 65.93batch/s, accuracy=99.6, grad_norm=1.48, loss=0.0159]   \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 72.05batch/s, accuracy=99.6, grad_norm=0.596, loss=0.0157]  \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 70.03batch/s, accuracy=99.5, grad_norm=0.665, loss=0.016]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:13<00:00, 68.40batch/s, accuracy=99.6, grad_norm=0.0804, loss=0.0151] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 70.55batch/s, accuracy=99.5, grad_norm=1, loss=0.016]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 71.35%\n",
      "SNR=10 完成: Avg Val=99.63%, Avg Test=72.11%\n",
      "\n",
      "===== 开始 SNR=5 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 65.98batch/s, accuracy=49.4, grad_norm=6.27, loss=1.23] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 68.17batch/s, accuracy=78.5, grad_norm=4.16, loss=0.554] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.02batch/s, accuracy=86.8, grad_norm=4.02, loss=0.355] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.04batch/s, accuracy=91.3, grad_norm=2.84, loss=0.246] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 73.09batch/s, accuracy=93.4, grad_norm=4.52, loss=0.187] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 64.86batch/s, accuracy=94.7, grad_norm=2.53, loss=0.156] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 65.53batch/s, accuracy=95.5, grad_norm=2.77, loss=0.134]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:10<00:00, 89.88batch/s, accuracy=96.1, grad_norm=2.81, loss=0.117]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 105.80batch/s, accuracy=96.5, grad_norm=1.89, loss=0.103]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 107.42batch/s, accuracy=96.8, grad_norm=2.1, loss=0.0969]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 104.70batch/s, accuracy=97.7, grad_norm=2.71, loss=0.0715]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 107.58batch/s, accuracy=97.7, grad_norm=2.21, loss=0.0682]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 108.51batch/s, accuracy=97.9, grad_norm=1.08, loss=0.064]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 104.57batch/s, accuracy=98, grad_norm=1.63, loss=0.0619]    \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 106.63batch/s, accuracy=97.9, grad_norm=1.31, loss=0.063]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:09<00:00, 96.88batch/s, accuracy=98.1, grad_norm=2.68, loss=0.0584]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 106.66batch/s, accuracy=98.3, grad_norm=0.668, loss=0.0543] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:09<00:00, 97.35batch/s, accuracy=98.2, grad_norm=3.14, loss=0.0568]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 71.11batch/s, accuracy=98.3, grad_norm=2.59, loss=0.0513]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.03batch/s, accuracy=98.4, grad_norm=0.985, loss=0.0509] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 67.16batch/s, accuracy=98.7, grad_norm=0.344, loss=0.0405] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 66.10batch/s, accuracy=98.8, grad_norm=1.15, loss=0.0391]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 71.08batch/s, accuracy=98.8, grad_norm=0.808, loss=0.0379] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 73.21batch/s, accuracy=98.8, grad_norm=3.47, loss=0.0374]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 66.93batch/s, accuracy=98.9, grad_norm=2.3, loss=0.0359]   \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 68.30batch/s, accuracy=98.9, grad_norm=1.43, loss=0.036]   \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 66.20batch/s, accuracy=98.9, grad_norm=0.587, loss=0.0348] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 66.58batch/s, accuracy=98.9, grad_norm=1.21, loss=0.0345]  \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 72.19batch/s, accuracy=98.9, grad_norm=0.907, loss=0.0345] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 66.34batch/s, accuracy=98.9, grad_norm=4.14, loss=0.0331]   \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:12<00:00, 71.46batch/s, accuracy=99.2, grad_norm=0.771, loss=0.0283]  \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:13<00:00, 69.18batch/s, accuracy=99.2, grad_norm=1.73, loss=0.0274]  \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:13<00:00, 67.22batch/s, accuracy=99.2, grad_norm=0.254, loss=0.0273]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:13<00:00, 68.33batch/s, accuracy=99.2, grad_norm=3.03, loss=0.0262]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 71.00%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=49.2, grad_norm=6.55, loss=1.22] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.64batch/s, accuracy=78.3, grad_norm=4.87, loss=0.562] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 69.77batch/s, accuracy=87, grad_norm=3.1, loss=0.347]    \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.69batch/s, accuracy=91.2, grad_norm=3.38, loss=0.247] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.45batch/s, accuracy=93.3, grad_norm=2.92, loss=0.191] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.75batch/s, accuracy=94.4, grad_norm=2.92, loss=0.159] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.65batch/s, accuracy=95.3, grad_norm=2.24, loss=0.137]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.27batch/s, accuracy=95.9, grad_norm=1.89, loss=0.121]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=96.3, grad_norm=1.73, loss=0.109]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.64batch/s, accuracy=96.5, grad_norm=2.27, loss=0.102]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.76batch/s, accuracy=97.3, grad_norm=2.35, loss=0.0762] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.19batch/s, accuracy=97.7, grad_norm=1.97, loss=0.0705]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.89batch/s, accuracy=97.7, grad_norm=1.55, loss=0.0684]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 69.34batch/s, accuracy=97.7, grad_norm=1.07, loss=0.0664]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 64.76batch/s, accuracy=97.9, grad_norm=2.81, loss=0.0638]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 67.83batch/s, accuracy=98, grad_norm=4.57, loss=0.0598]    \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.19batch/s, accuracy=98.2, grad_norm=1.78, loss=0.0562]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 68.79batch/s, accuracy=98.1, grad_norm=1.84, loss=0.0578]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 72.41batch/s, accuracy=98.2, grad_norm=1.95, loss=0.0545]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 67.29batch/s, accuracy=98.2, grad_norm=2.27, loss=0.0532]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 67.50batch/s, accuracy=98.6, grad_norm=3.01, loss=0.0415]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 71.47%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 72.24batch/s, accuracy=49.6, grad_norm=5.26, loss=1.21] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 68.41batch/s, accuracy=76.8, grad_norm=5.51, loss=0.594] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.03batch/s, accuracy=86.5, grad_norm=3.61, loss=0.363] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.76batch/s, accuracy=91.1, grad_norm=3.96, loss=0.249] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 65.03batch/s, accuracy=93.2, grad_norm=3.01, loss=0.191] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 67.87batch/s, accuracy=94.5, grad_norm=0.964, loss=0.157]\n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 67.63batch/s, accuracy=95.2, grad_norm=1.65, loss=0.138]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.70batch/s, accuracy=96, grad_norm=2.62, loss=0.12]     \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 72.19batch/s, accuracy=96.1, grad_norm=2.57, loss=0.114]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.06batch/s, accuracy=96.6, grad_norm=2.62, loss=0.0995] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:10<00:00, 87.79batch/s, accuracy=97.5, grad_norm=1.21, loss=0.0752]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 101.86batch/s, accuracy=97.7, grad_norm=2.42, loss=0.0704]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 100.23batch/s, accuracy=97.8, grad_norm=1.27, loss=0.0668]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 106.86batch/s, accuracy=97.7, grad_norm=1.96, loss=0.0676]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 73.98batch/s, accuracy=97.8, grad_norm=3.14, loss=0.0652]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.48batch/s, accuracy=98.1, grad_norm=2.18, loss=0.0608]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 65.57batch/s, accuracy=98.1, grad_norm=1.61, loss=0.0581]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.66batch/s, accuracy=98.1, grad_norm=1.82, loss=0.0571]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 67.82%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 72.03batch/s, accuracy=47.1, grad_norm=5.08, loss=1.27] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.97batch/s, accuracy=77.2, grad_norm=5.39, loss=0.59]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.71batch/s, accuracy=86.5, grad_norm=4.09, loss=0.361] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 65.18batch/s, accuracy=90.8, grad_norm=3.07, loss=0.256] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 64.56batch/s, accuracy=93.4, grad_norm=3.84, loss=0.188] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.12batch/s, accuracy=94.7, grad_norm=3.9, loss=0.156]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.85batch/s, accuracy=95.6, grad_norm=1.43, loss=0.131]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.15batch/s, accuracy=95.9, grad_norm=1.85, loss=0.119] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.79batch/s, accuracy=96.4, grad_norm=1.84, loss=0.106]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.29batch/s, accuracy=96.7, grad_norm=2.95, loss=0.101]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.37batch/s, accuracy=97.6, grad_norm=0.753, loss=0.0738]\n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.60batch/s, accuracy=97.7, grad_norm=2.24, loss=0.0697]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.76batch/s, accuracy=97.7, grad_norm=1.03, loss=0.068]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 68.82batch/s, accuracy=98, grad_norm=1.68, loss=0.0628]    \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 72.23batch/s, accuracy=98, grad_norm=1.13, loss=0.0624]    \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 66.84batch/s, accuracy=98, grad_norm=2.15, loss=0.0594]    \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 69.57batch/s, accuracy=98.1, grad_norm=2.14, loss=0.0566]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.67batch/s, accuracy=98.1, grad_norm=3.61, loss=0.0563]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 71.20batch/s, accuracy=98.3, grad_norm=2.77, loss=0.0529]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.68batch/s, accuracy=98.4, grad_norm=3.77, loss=0.0498]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 69.67%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 106.40batch/s, accuracy=48.2, grad_norm=4.7, loss=1.25]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 107.04batch/s, accuracy=77.4, grad_norm=3.94, loss=0.578] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 100.65batch/s, accuracy=86.8, grad_norm=2.14, loss=0.354] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 105.38batch/s, accuracy=90.7, grad_norm=4.02, loss=0.257] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 69.02batch/s, accuracy=92.9, grad_norm=2.96, loss=0.198] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 72.68batch/s, accuracy=94.4, grad_norm=3.94, loss=0.164] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.87batch/s, accuracy=95.4, grad_norm=3.16, loss=0.138]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 68.24batch/s, accuracy=95.8, grad_norm=4.26, loss=0.123]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.88batch/s, accuracy=96.3, grad_norm=3.24, loss=0.11]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 73.82batch/s, accuracy=96.5, grad_norm=3.16, loss=0.103]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.65batch/s, accuracy=97.6, grad_norm=3.68, loss=0.0747] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.49batch/s, accuracy=97.5, grad_norm=1.69, loss=0.0741]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.18batch/s, accuracy=97.7, grad_norm=1.19, loss=0.0701]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.65batch/s, accuracy=97.9, grad_norm=2.14, loss=0.0635] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 71.36batch/s, accuracy=98, grad_norm=3.8, loss=0.0619]     \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 69.23batch/s, accuracy=98, grad_norm=1.87, loss=0.0608]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 69.13batch/s, accuracy=98.1, grad_norm=2.31, loss=0.059]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.80batch/s, accuracy=98.2, grad_norm=2.8, loss=0.0556]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 69.82%\n",
      "SNR=5 完成: Avg Val=98.65%, Avg Test=69.95%\n",
      "\n",
      "===== 开始 SNR=0 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 67.16batch/s, accuracy=37.8, grad_norm=5.59, loss=1.48] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.31batch/s, accuracy=62.9, grad_norm=5.2, loss=0.927] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.00batch/s, accuracy=73, grad_norm=3.79, loss=0.687]   \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 69.18batch/s, accuracy=78.3, grad_norm=4.44, loss=0.562] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 70.93batch/s, accuracy=81.8, grad_norm=4.17, loss=0.474] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 67.50batch/s, accuracy=84.4, grad_norm=3.8, loss=0.412]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.64batch/s, accuracy=85.8, grad_norm=2.08, loss=0.372] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.86batch/s, accuracy=87.4, grad_norm=4.64, loss=0.336] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 68.95batch/s, accuracy=88.2, grad_norm=4.22, loss=0.316] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 72.68batch/s, accuracy=89, grad_norm=4.27, loss=0.296]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.84batch/s, accuracy=90.8, grad_norm=2.8, loss=0.252]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:14<00:00, 62.65batch/s, accuracy=91.1, grad_norm=4.93, loss=0.243] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.62batch/s, accuracy=91.5, grad_norm=3.78, loss=0.231] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 70.80batch/s, accuracy=91.6, grad_norm=3.44, loss=0.228] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 72.23batch/s, accuracy=92.1, grad_norm=3.44, loss=0.216] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.59batch/s, accuracy=92.3, grad_norm=3.39, loss=0.21]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 65.04batch/s, accuracy=92.5, grad_norm=4.22, loss=0.203] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.65batch/s, accuracy=92.9, grad_norm=5.07, loss=0.196] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 70.14batch/s, accuracy=92.9, grad_norm=3.68, loss=0.195] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:09<00:00, 99.46batch/s, accuracy=93.2, grad_norm=3.43, loss=0.187]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 107.59batch/s, accuracy=93.8, grad_norm=2.79, loss=0.17]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 107.27batch/s, accuracy=94.1, grad_norm=3.04, loss=0.161] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 105.04batch/s, accuracy=94.1, grad_norm=3.08, loss=0.162] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 64.95%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:14<00:00, 61.43batch/s, accuracy=35.9, grad_norm=6.18, loss=1.52] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.54batch/s, accuracy=61.9, grad_norm=4.86, loss=0.948]\n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.29batch/s, accuracy=73.2, grad_norm=4, loss=0.686]    \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 73.23batch/s, accuracy=78, grad_norm=3.86, loss=0.564]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.96batch/s, accuracy=81.4, grad_norm=3.08, loss=0.48]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 65.62batch/s, accuracy=84.1, grad_norm=3.18, loss=0.417] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 65.19batch/s, accuracy=85.8, grad_norm=3.96, loss=0.378] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 68.70batch/s, accuracy=87.2, grad_norm=3.76, loss=0.343] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 71.23batch/s, accuracy=88, grad_norm=4.28, loss=0.321]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 70.83batch/s, accuracy=89, grad_norm=2.66, loss=0.297]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 73.55batch/s, accuracy=90.5, grad_norm=3.81, loss=0.256] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.06batch/s, accuracy=91.1, grad_norm=2.49, loss=0.242] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 105.43batch/s, accuracy=91.2, grad_norm=4.07, loss=0.236] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 103.35batch/s, accuracy=91.8, grad_norm=3.4, loss=0.225]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 104.09batch/s, accuracy=91.8, grad_norm=4.66, loss=0.222] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 107.07batch/s, accuracy=92.1, grad_norm=4.27, loss=0.212] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.75batch/s, accuracy=92.4, grad_norm=2.65, loss=0.208] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 71.24batch/s, accuracy=92.6, grad_norm=3.76, loss=0.2]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 69.02batch/s, accuracy=92.8, grad_norm=3.2, loss=0.196]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 66.38batch/s, accuracy=93, grad_norm=3.57, loss=0.19]    \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 69.87batch/s, accuracy=93.8, grad_norm=4.19, loss=0.17]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.44batch/s, accuracy=94.1, grad_norm=2.04, loss=0.164] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 72.48batch/s, accuracy=94.2, grad_norm=1.84, loss=0.16]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 73.47batch/s, accuracy=94.2, grad_norm=3.71, loss=0.158]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:14<00:00, 63.75batch/s, accuracy=94.4, grad_norm=3.71, loss=0.155]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 65.34batch/s, accuracy=94.6, grad_norm=2.12, loss=0.149] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 71.19batch/s, accuracy=94.6, grad_norm=3.92, loss=0.148] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 70.52batch/s, accuracy=94.8, grad_norm=4.39, loss=0.145] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 70.30batch/s, accuracy=94.9, grad_norm=2.86, loss=0.141] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 67.38batch/s, accuracy=94.9, grad_norm=3.65, loss=0.14]  \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:13<00:00, 64.67batch/s, accuracy=95.3, grad_norm=4.64, loss=0.131] \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:13<00:00, 67.80batch/s, accuracy=95.5, grad_norm=5.43, loss=0.127] \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:12<00:00, 72.94batch/s, accuracy=95.4, grad_norm=4.31, loss=0.129]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:12<00:00, 69.28batch/s, accuracy=95.5, grad_norm=3.68, loss=0.126]  \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:13<00:00, 68.43batch/s, accuracy=95.5, grad_norm=2.66, loss=0.125] \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:12<00:00, 69.53batch/s, accuracy=95.5, grad_norm=5.93, loss=0.123] \n",
      "Epoch 37/200: 100%|██████████| 900/900 [00:13<00:00, 69.04batch/s, accuracy=95.7, grad_norm=3.42, loss=0.119]  \n",
      "Epoch 38/200: 100%|██████████| 900/900 [00:12<00:00, 72.30batch/s, accuracy=95.7, grad_norm=3.67, loss=0.119]  \n",
      "Epoch 39/200: 100%|██████████| 900/900 [00:13<00:00, 68.34batch/s, accuracy=95.8, grad_norm=3.85, loss=0.115] \n",
      "Epoch 40/200: 100%|██████████| 900/900 [00:13<00:00, 68.78batch/s, accuracy=95.9, grad_norm=6.31, loss=0.115] \n",
      "Epoch 41/200: 100%|██████████| 900/900 [00:12<00:00, 72.07batch/s, accuracy=96, grad_norm=5.11, loss=0.111]   \n",
      "Epoch 42/200: 100%|██████████| 900/900 [00:13<00:00, 67.25batch/s, accuracy=96.1, grad_norm=1.73, loss=0.109]  \n",
      "Epoch 43/200: 100%|██████████| 900/900 [00:12<00:00, 71.13batch/s, accuracy=96.2, grad_norm=3.79, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 67.53%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.49batch/s, accuracy=35.4, grad_norm=6.35, loss=1.53] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.99batch/s, accuracy=60.5, grad_norm=4, loss=0.974]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.75batch/s, accuracy=71.5, grad_norm=3.79, loss=0.724] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 68.79batch/s, accuracy=77.5, grad_norm=3.26, loss=0.577] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.75batch/s, accuracy=81.7, grad_norm=3.84, loss=0.477] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.87batch/s, accuracy=84.2, grad_norm=3.35, loss=0.414] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.12batch/s, accuracy=85.8, grad_norm=2.85, loss=0.374] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 69.21batch/s, accuracy=87.3, grad_norm=4.06, loss=0.338] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 69.20batch/s, accuracy=88.3, grad_norm=3.09, loss=0.314] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:14<00:00, 62.92batch/s, accuracy=89, grad_norm=4.22, loss=0.295]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.67batch/s, accuracy=90.7, grad_norm=3.37, loss=0.251] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=91, grad_norm=2.67, loss=0.239]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.60batch/s, accuracy=91.3, grad_norm=2.6, loss=0.234]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 70.43batch/s, accuracy=91.8, grad_norm=3.45, loss=0.22]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:14<00:00, 63.56batch/s, accuracy=92.1, grad_norm=5.13, loss=0.215] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 68.87batch/s, accuracy=92.3, grad_norm=2.79, loss=0.209] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.85batch/s, accuracy=92.5, grad_norm=5.05, loss=0.205] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:11<00:00, 79.23batch/s, accuracy=92.8, grad_norm=5.23, loss=0.196] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 103.29batch/s, accuracy=93, grad_norm=3.18, loss=0.193]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 109.03batch/s, accuracy=93.2, grad_norm=4.53, loss=0.187] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 101.59batch/s, accuracy=94, grad_norm=5.11, loss=0.166]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 103.68batch/s, accuracy=94.3, grad_norm=2.91, loss=0.16]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 107.68batch/s, accuracy=94.3, grad_norm=6.72, loss=0.157] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 106.76batch/s, accuracy=94.3, grad_norm=4.38, loss=0.156]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:08<00:00, 107.60batch/s, accuracy=94.5, grad_norm=3.47, loss=0.153]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:08<00:00, 108.29batch/s, accuracy=94.7, grad_norm=2.15, loss=0.148] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:08<00:00, 105.36batch/s, accuracy=94.8, grad_norm=4.6, loss=0.145]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 68.26%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:10<00:00, 87.13batch/s, accuracy=36.6, grad_norm=6.19, loss=1.51]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 74.51batch/s, accuracy=62.4, grad_norm=4.84, loss=0.943] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 66.09batch/s, accuracy=72.6, grad_norm=4.5, loss=0.696]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 68.48batch/s, accuracy=78.3, grad_norm=4.09, loss=0.56]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 70.00batch/s, accuracy=81.9, grad_norm=3.53, loss=0.472] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.74batch/s, accuracy=84.3, grad_norm=3.3, loss=0.415]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.04batch/s, accuracy=86.3, grad_norm=3.33, loss=0.366] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.26batch/s, accuracy=87.3, grad_norm=3.45, loss=0.34]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 64.90batch/s, accuracy=88.3, grad_norm=3.2, loss=0.314]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:09<00:00, 90.85batch/s, accuracy=89.2, grad_norm=4.26, loss=0.291] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 101.11batch/s, accuracy=90.6, grad_norm=2.78, loss=0.254] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 103.29batch/s, accuracy=91.1, grad_norm=3.16, loss=0.239] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 106.27batch/s, accuracy=91.4, grad_norm=3.77, loss=0.232] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:11<00:00, 77.83batch/s, accuracy=91.8, grad_norm=3.65, loss=0.222]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 71.10batch/s, accuracy=92.3, grad_norm=2.88, loss=0.211] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 67.28batch/s, accuracy=92.4, grad_norm=3.23, loss=0.206] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.59batch/s, accuracy=92.6, grad_norm=2.88, loss=0.202] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 73.12batch/s, accuracy=92.9, grad_norm=3.83, loss=0.195] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 70.11batch/s, accuracy=93, grad_norm=2.37, loss=0.19]    \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 69.53batch/s, accuracy=93.2, grad_norm=4.06, loss=0.185] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 67.04batch/s, accuracy=94.2, grad_norm=2.84, loss=0.162] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 67.71batch/s, accuracy=94.3, grad_norm=3.72, loss=0.156] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 70.39batch/s, accuracy=94.2, grad_norm=3.4, loss=0.157]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 70.81batch/s, accuracy=94.4, grad_norm=3.36, loss=0.153] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 69.61batch/s, accuracy=94.6, grad_norm=3.81, loss=0.148] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 69.16batch/s, accuracy=94.7, grad_norm=4.2, loss=0.148]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 67.91batch/s, accuracy=94.7, grad_norm=3.74, loss=0.145]  \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 66.84batch/s, accuracy=95, grad_norm=4.82, loss=0.138]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 69.62batch/s, accuracy=95, grad_norm=3.25, loss=0.137]   \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 65.40batch/s, accuracy=95, grad_norm=3.34, loss=0.135]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 67.87%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 68.24batch/s, accuracy=35.4, grad_norm=5.08, loss=1.53] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.58batch/s, accuracy=60.4, grad_norm=5.34, loss=0.988]\n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.04batch/s, accuracy=71.2, grad_norm=5.06, loss=0.73]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.75batch/s, accuracy=77.3, grad_norm=3.83, loss=0.582] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 70.84batch/s, accuracy=81.3, grad_norm=3.26, loss=0.488] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 105.16batch/s, accuracy=83.9, grad_norm=3.22, loss=0.423] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 107.56batch/s, accuracy=85.8, grad_norm=3.7, loss=0.377]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 104.32batch/s, accuracy=86.8, grad_norm=3.36, loss=0.349] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 109.83batch/s, accuracy=88, grad_norm=3.49, loss=0.322]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 65.12batch/s, accuracy=88.8, grad_norm=3.33, loss=0.298]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.75batch/s, accuracy=90.4, grad_norm=4.72, loss=0.256]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.56batch/s, accuracy=90.7, grad_norm=4.04, loss=0.248] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 72.69batch/s, accuracy=91.1, grad_norm=4.78, loss=0.238] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 72.67batch/s, accuracy=91.6, grad_norm=2.88, loss=0.226] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:14<00:00, 63.10batch/s, accuracy=91.8, grad_norm=3.8, loss=0.221]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 67.82batch/s, accuracy=92.3, grad_norm=4.01, loss=0.211] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 74.02batch/s, accuracy=92.6, grad_norm=3.94, loss=0.203]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 72.30batch/s, accuracy=92.7, grad_norm=3.44, loss=0.198] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 69.46batch/s, accuracy=92.9, grad_norm=4.08, loss=0.193] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 65.13batch/s, accuracy=93.1, grad_norm=1.88, loss=0.187] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:14<00:00, 62.72batch/s, accuracy=93.9, grad_norm=3.27, loss=0.167] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 69.96batch/s, accuracy=94.2, grad_norm=3.11, loss=0.161] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 72.59batch/s, accuracy=94.3, grad_norm=3.08, loss=0.156] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 68.65batch/s, accuracy=94.4, grad_norm=3.39, loss=0.153] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 66.83batch/s, accuracy=94.5, grad_norm=2.39, loss=0.151]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 65.71batch/s, accuracy=94.6, grad_norm=2.69, loss=0.149]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 66.90batch/s, accuracy=94.6, grad_norm=2.61, loss=0.147] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 70.49batch/s, accuracy=94.9, grad_norm=3.68, loss=0.143] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:10<00:00, 88.27batch/s, accuracy=95, grad_norm=3.68, loss=0.138]   \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:08<00:00, 103.77batch/s, accuracy=95.1, grad_norm=2.1, loss=0.135]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 66.35%\n",
      "SNR=0 完成: Avg Val=93.94%, Avg Test=66.99%\n",
      "\n",
      "===== 开始 SNR=-5 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 106.32batch/s, accuracy=25.8, grad_norm=5.29, loss=1.71] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:11<00:00, 76.71batch/s, accuracy=35.2, grad_norm=5.13, loss=1.56]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.13batch/s, accuracy=48.5, grad_norm=4.13, loss=1.27] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 72.29batch/s, accuracy=54.4, grad_norm=3.6, loss=1.13]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 69.19batch/s, accuracy=57.2, grad_norm=3.57, loss=1.06] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.08batch/s, accuracy=59.5, grad_norm=3.94, loss=1]    \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.50batch/s, accuracy=61.6, grad_norm=3.68, loss=0.957]\n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.76batch/s, accuracy=63.3, grad_norm=3.72, loss=0.918]\n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 67.61batch/s, accuracy=65.1, grad_norm=3.77, loss=0.885] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=66.4, grad_norm=3.94, loss=0.852]\n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.39batch/s, accuracy=68.9, grad_norm=3.8, loss=0.795]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 73.12batch/s, accuracy=69.7, grad_norm=4.78, loss=0.772] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.22batch/s, accuracy=70.6, grad_norm=4.08, loss=0.752] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:14<00:00, 63.28batch/s, accuracy=71, grad_norm=4.37, loss=0.737]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 72.00batch/s, accuracy=71.9, grad_norm=3.75, loss=0.718] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.24batch/s, accuracy=72.4, grad_norm=3.67, loss=0.708] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.07batch/s, accuracy=73, grad_norm=4.67, loss=0.691]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.04batch/s, accuracy=73.7, grad_norm=5.39, loss=0.679] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 64.45batch/s, accuracy=74, grad_norm=5.02, loss=0.668]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.28batch/s, accuracy=74.5, grad_norm=4.38, loss=0.653] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 70.30batch/s, accuracy=75.8, grad_norm=4.23, loss=0.627] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 71.46batch/s, accuracy=76.5, grad_norm=5.24, loss=0.612] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 64.69batch/s, accuracy=76.8, grad_norm=5.54, loss=0.602] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 68.43batch/s, accuracy=77.1, grad_norm=5.33, loss=0.595] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 67.79batch/s, accuracy=77.4, grad_norm=4.43, loss=0.585] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:12<00:00, 70.69batch/s, accuracy=77.7, grad_norm=4.04, loss=0.58]  \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 69.78batch/s, accuracy=77.9, grad_norm=4.92, loss=0.572] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 69.10batch/s, accuracy=78.2, grad_norm=5.84, loss=0.566] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 69.54batch/s, accuracy=78.7, grad_norm=5.62, loss=0.557] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 70.55batch/s, accuracy=79, grad_norm=6.49, loss=0.55]    \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:12<00:00, 72.44batch/s, accuracy=79.8, grad_norm=5.67, loss=0.532] \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:13<00:00, 67.04batch/s, accuracy=80, grad_norm=6.32, loss=0.524]   \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:12<00:00, 70.32batch/s, accuracy=80.3, grad_norm=5.3, loss=0.518]  \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:12<00:00, 70.01batch/s, accuracy=80.6, grad_norm=6.24, loss=0.512] \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:12<00:00, 72.49batch/s, accuracy=80.5, grad_norm=6.7, loss=0.511]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 54.68%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:09<00:00, 96.38batch/s, accuracy=25.7, grad_norm=5.09, loss=1.71]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 102.64batch/s, accuracy=35.2, grad_norm=4.99, loss=1.56] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 104.08batch/s, accuracy=49.2, grad_norm=3.94, loss=1.26] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 107.19batch/s, accuracy=54.9, grad_norm=3.56, loss=1.12] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 74.16batch/s, accuracy=57.4, grad_norm=3.19, loss=1.05]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.86batch/s, accuracy=59.6, grad_norm=4.16, loss=1]    \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.42batch/s, accuracy=61.7, grad_norm=3.76, loss=0.955]\n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:14<00:00, 64.16batch/s, accuracy=63.3, grad_norm=3.95, loss=0.919]\n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 70.27batch/s, accuracy=64.7, grad_norm=3.71, loss=0.891] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 68.46batch/s, accuracy=66.2, grad_norm=3.2, loss=0.856] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 73.90batch/s, accuracy=68.7, grad_norm=3.63, loss=0.803] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.79batch/s, accuracy=69.5, grad_norm=3.65, loss=0.776] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 65.12batch/s, accuracy=70, grad_norm=3.83, loss=0.762]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.23batch/s, accuracy=70.9, grad_norm=5.17, loss=0.745] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 66.83batch/s, accuracy=71.6, grad_norm=4.1, loss=0.728]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.98batch/s, accuracy=72.3, grad_norm=4.08, loss=0.712] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.48batch/s, accuracy=72.7, grad_norm=4.97, loss=0.702] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 68.16batch/s, accuracy=73.4, grad_norm=4.89, loss=0.684] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 64.46batch/s, accuracy=73.6, grad_norm=3.52, loss=0.678] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.90batch/s, accuracy=74.3, grad_norm=4.44, loss=0.663] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 68.30batch/s, accuracy=75.9, grad_norm=5.12, loss=0.626] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 68.74batch/s, accuracy=76.1, grad_norm=5.01, loss=0.618] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 73.01batch/s, accuracy=76.4, grad_norm=4.9, loss=0.609]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 65.72batch/s, accuracy=77, grad_norm=6.74, loss=0.598]   \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 67.57batch/s, accuracy=77, grad_norm=6.38, loss=0.593]   \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:12<00:00, 73.54batch/s, accuracy=77.7, grad_norm=6.75, loss=0.584] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:08<00:00, 105.64batch/s, accuracy=77.5, grad_norm=6.04, loss=0.581] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:08<00:00, 106.08batch/s, accuracy=78.2, grad_norm=5.96, loss=0.569] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:08<00:00, 106.02batch/s, accuracy=78.3, grad_norm=5.25, loss=0.565] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:08<00:00, 109.23batch/s, accuracy=78.5, grad_norm=5.34, loss=0.557] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 55.07%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 107.95batch/s, accuracy=26.3, grad_norm=4.92, loss=1.71] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 107.42batch/s, accuracy=35.2, grad_norm=5.79, loss=1.56] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 104.56batch/s, accuracy=48, grad_norm=3.79, loss=1.28]   \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 105.17batch/s, accuracy=53.5, grad_norm=3.8, loss=1.15]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 105.50batch/s, accuracy=56.6, grad_norm=3.19, loss=1.08] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 91.13batch/s, accuracy=58.8, grad_norm=4.19, loss=1.02]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 72.30batch/s, accuracy=60.9, grad_norm=3.72, loss=0.974]\n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.67batch/s, accuracy=62.9, grad_norm=3.11, loss=0.929]\n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 65.27batch/s, accuracy=64.6, grad_norm=3.35, loss=0.887]\n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 68.39batch/s, accuracy=66.2, grad_norm=3.73, loss=0.856] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 73.21batch/s, accuracy=68.5, grad_norm=3.7, loss=0.801]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 73.80batch/s, accuracy=69.5, grad_norm=4.16, loss=0.778] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.37batch/s, accuracy=70.3, grad_norm=4.72, loss=0.759] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.46batch/s, accuracy=71, grad_norm=4.99, loss=0.739]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 65.49batch/s, accuracy=71.8, grad_norm=3.71, loss=0.721] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.04batch/s, accuracy=72.4, grad_norm=4.1, loss=0.707]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.79batch/s, accuracy=73.1, grad_norm=4.17, loss=0.695] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 70.46batch/s, accuracy=73.8, grad_norm=4.34, loss=0.677] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 67.67batch/s, accuracy=74.2, grad_norm=4.79, loss=0.669] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.07batch/s, accuracy=74.5, grad_norm=5.62, loss=0.654] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 68.53batch/s, accuracy=75.8, grad_norm=4.59, loss=0.622] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 72.12batch/s, accuracy=76.2, grad_norm=4.36, loss=0.612] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 70.21batch/s, accuracy=77, grad_norm=5.59, loss=0.597]   \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 69.12batch/s, accuracy=77.3, grad_norm=5.58, loss=0.591] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 69.74batch/s, accuracy=77.4, grad_norm=5.07, loss=0.588] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 66.48batch/s, accuracy=77.8, grad_norm=6.11, loss=0.578] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 72.42batch/s, accuracy=78, grad_norm=8.26, loss=0.569]   \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 68.40batch/s, accuracy=78, grad_norm=5.45, loss=0.567]   \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 69.30batch/s, accuracy=78.9, grad_norm=6.53, loss=0.553] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 69.91batch/s, accuracy=78.8, grad_norm=4.76, loss=0.551] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 54.98%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 107.10batch/s, accuracy=26.3, grad_norm=4.39, loss=1.71] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 101.97batch/s, accuracy=35.3, grad_norm=4.72, loss=1.55] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 100.77batch/s, accuracy=49.2, grad_norm=4.14, loss=1.24] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 106.63batch/s, accuracy=54.5, grad_norm=4.21, loss=1.12] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 72.89batch/s, accuracy=57.2, grad_norm=4.32, loss=1.06]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:11<00:00, 75.13batch/s, accuracy=59.5, grad_norm=3.35, loss=1.01]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.59batch/s, accuracy=61.4, grad_norm=3.22, loss=0.961]\n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 70.74batch/s, accuracy=63, grad_norm=3.76, loss=0.927]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:14<00:00, 63.42batch/s, accuracy=64.8, grad_norm=3.76, loss=0.886] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.39batch/s, accuracy=66.2, grad_norm=4.36, loss=0.852]\n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.20batch/s, accuracy=69, grad_norm=4.01, loss=0.793]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 73.30batch/s, accuracy=69.7, grad_norm=4.13, loss=0.771] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.64batch/s, accuracy=70.6, grad_norm=4.17, loss=0.754] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:14<00:00, 62.45batch/s, accuracy=71.2, grad_norm=4.17, loss=0.734] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 67.73batch/s, accuracy=71.5, grad_norm=4.12, loss=0.727] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:09<00:00, 99.91batch/s, accuracy=72.5, grad_norm=4.97, loss=0.705] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 106.22batch/s, accuracy=73.3, grad_norm=4.3, loss=0.689]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 104.81batch/s, accuracy=73.6, grad_norm=4.28, loss=0.679] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 102.80batch/s, accuracy=74.4, grad_norm=5, loss=0.664]    \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 71.22batch/s, accuracy=74.8, grad_norm=4.79, loss=0.652]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 67.16batch/s, accuracy=76, grad_norm=4.8, loss=0.619]    \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 67.39batch/s, accuracy=76.5, grad_norm=5.43, loss=0.61]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 71.60batch/s, accuracy=76.9, grad_norm=4.5, loss=0.598]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 67.15batch/s, accuracy=77.1, grad_norm=6.18, loss=0.591] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 68.48batch/s, accuracy=77.5, grad_norm=4.92, loss=0.583] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:12<00:00, 73.06batch/s, accuracy=77.5, grad_norm=6.06, loss=0.579] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 65.96batch/s, accuracy=78.3, grad_norm=6.04, loss=0.565] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 69.68batch/s, accuracy=78.3, grad_norm=4.72, loss=0.562] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 69.75batch/s, accuracy=78.6, grad_norm=6.85, loss=0.553] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:12<00:00, 71.28batch/s, accuracy=79, grad_norm=6.53, loss=0.545]   \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:08<00:00, 100.89batch/s, accuracy=80, grad_norm=6.06, loss=0.526]  \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:08<00:00, 101.27batch/s, accuracy=80.2, grad_norm=7.8, loss=0.521]  \n",
      "Epoch 33/200: 100%|██████████| 900/900 [00:08<00:00, 103.51batch/s, accuracy=80.2, grad_norm=6.91, loss=0.516] \n",
      "Epoch 34/200: 100%|██████████| 900/900 [00:08<00:00, 105.44batch/s, accuracy=80.4, grad_norm=6.55, loss=0.51]  \n",
      "Epoch 35/200: 100%|██████████| 900/900 [00:13<00:00, 65.08batch/s, accuracy=80.5, grad_norm=6.98, loss=0.507] \n",
      "Epoch 36/200: 100%|██████████| 900/900 [00:12<00:00, 69.77batch/s, accuracy=80.8, grad_norm=7.25, loss=0.502] \n",
      "Epoch 37/200: 100%|██████████| 900/900 [00:12<00:00, 71.77batch/s, accuracy=81, grad_norm=6.51, loss=0.495]   \n",
      "Epoch 38/200: 100%|██████████| 900/900 [00:12<00:00, 72.62batch/s, accuracy=81.2, grad_norm=7.79, loss=0.494] \n",
      "Epoch 39/200: 100%|██████████| 900/900 [00:13<00:00, 68.40batch/s, accuracy=81.6, grad_norm=6.19, loss=0.488] \n",
      "Epoch 40/200: 100%|██████████| 900/900 [00:13<00:00, 66.06batch/s, accuracy=81.4, grad_norm=6.9, loss=0.485]  \n",
      "Epoch 41/200: 100%|██████████| 900/900 [00:12<00:00, 70.23batch/s, accuracy=82.1, grad_norm=6.61, loss=0.471] \n",
      "Epoch 42/200: 100%|██████████| 900/900 [00:12<00:00, 69.54batch/s, accuracy=82.2, grad_norm=6.91, loss=0.472] \n",
      "Epoch 43/200: 100%|██████████| 900/900 [00:13<00:00, 67.19batch/s, accuracy=82.1, grad_norm=4.85, loss=0.471] \n",
      "Epoch 44/200: 100%|██████████| 900/900 [00:13<00:00, 68.50batch/s, accuracy=82.5, grad_norm=7.45, loss=0.463] \n",
      "Epoch 45/200: 100%|██████████| 900/900 [00:13<00:00, 68.81batch/s, accuracy=82.5, grad_norm=7.34, loss=0.461] \n",
      "Epoch 46/200: 100%|██████████| 900/900 [00:12<00:00, 69.98batch/s, accuracy=82.4, grad_norm=9.41, loss=0.464] \n",
      "Epoch 47/200: 100%|██████████| 900/900 [00:12<00:00, 69.61batch/s, accuracy=82.4, grad_norm=6.67, loss=0.458] \n",
      "Epoch 48/200: 100%|██████████| 900/900 [00:13<00:00, 69.23batch/s, accuracy=82.5, grad_norm=8.98, loss=0.458] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 55.70%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 67.97batch/s, accuracy=25.6, grad_norm=5.12, loss=1.72] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.60batch/s, accuracy=33.9, grad_norm=4.83, loss=1.58] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 69.44batch/s, accuracy=47.4, grad_norm=4.09, loss=1.29] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 71.43batch/s, accuracy=53.8, grad_norm=4.32, loss=1.14] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.83batch/s, accuracy=56.2, grad_norm=3.73, loss=1.08] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 95.99batch/s, accuracy=58.3, grad_norm=3.25, loss=1.03]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 106.05batch/s, accuracy=59.9, grad_norm=3.04, loss=0.993]\n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 103.13batch/s, accuracy=61.6, grad_norm=3.22, loss=0.954]\n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 106.64batch/s, accuracy=63.2, grad_norm=3.64, loss=0.921]\n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 69.66batch/s, accuracy=64.9, grad_norm=3.84, loss=0.884] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 66.98batch/s, accuracy=67.2, grad_norm=3.42, loss=0.832]\n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.52batch/s, accuracy=68.5, grad_norm=3.55, loss=0.801] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:11<00:00, 76.43batch/s, accuracy=69.2, grad_norm=4.13, loss=0.786] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.87batch/s, accuracy=70, grad_norm=5.25, loss=0.767]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 65.15batch/s, accuracy=70.9, grad_norm=4.82, loss=0.746] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 65.17batch/s, accuracy=71.2, grad_norm=4.47, loss=0.738] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 68.95batch/s, accuracy=71.8, grad_norm=4.08, loss=0.725] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 72.01batch/s, accuracy=72.8, grad_norm=5.01, loss=0.704] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 72.46batch/s, accuracy=73, grad_norm=5.35, loss=0.694]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 67.67batch/s, accuracy=73.5, grad_norm=5.44, loss=0.679] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:14<00:00, 63.03batch/s, accuracy=75, grad_norm=4.79, loss=0.648]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:09<00:00, 96.26batch/s, accuracy=75.6, grad_norm=4.89, loss=0.63]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 108.25batch/s, accuracy=75.7, grad_norm=4.83, loss=0.63]  \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 105.75batch/s, accuracy=76.1, grad_norm=4.62, loss=0.617] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:08<00:00, 104.41batch/s, accuracy=76.6, grad_norm=7.24, loss=0.607] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:08<00:00, 107.36batch/s, accuracy=76.8, grad_norm=5.15, loss=0.602] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:08<00:00, 106.93batch/s, accuracy=77.1, grad_norm=4.71, loss=0.594] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:08<00:00, 108.58batch/s, accuracy=77.5, grad_norm=5.21, loss=0.587] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 54.27%\n",
      "SNR=-5 完成: Avg Val=75.02%, Avg Test=54.94%\n",
      "\n",
      "===== 开始 SNR=-10 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 103.17batch/s, accuracy=23.8, grad_norm=5.79, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 107.40batch/s, accuracy=26.2, grad_norm=3.49, loss=1.71] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:09<00:00, 90.41batch/s, accuracy=27.6, grad_norm=2.72, loss=1.68]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 73.88batch/s, accuracy=28.8, grad_norm=3.16, loss=1.66] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.91batch/s, accuracy=30.3, grad_norm=2.35, loss=1.64] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.33batch/s, accuracy=32.8, grad_norm=3.28, loss=1.61] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 65.54batch/s, accuracy=36.6, grad_norm=3.15, loss=1.53] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 70.62batch/s, accuracy=39.4, grad_norm=2.88, loss=1.47] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 71.64batch/s, accuracy=40.7, grad_norm=3.24, loss=1.45] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 67.36batch/s, accuracy=41.5, grad_norm=2.74, loss=1.43] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 69.64batch/s, accuracy=42.8, grad_norm=3.65, loss=1.4]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.54batch/s, accuracy=43.1, grad_norm=2.81, loss=1.39] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 66.23batch/s, accuracy=43.9, grad_norm=2.68, loss=1.37] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 68.55batch/s, accuracy=44.4, grad_norm=2.75, loss=1.37] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 69.68batch/s, accuracy=44.6, grad_norm=3.49, loss=1.36] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.13batch/s, accuracy=44.8, grad_norm=3.47, loss=1.35] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 68.60batch/s, accuracy=45.5, grad_norm=3.92, loss=1.34] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.89batch/s, accuracy=45.4, grad_norm=3.79, loss=1.34] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 67.24batch/s, accuracy=46.1, grad_norm=3.59, loss=1.33] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.73batch/s, accuracy=46.6, grad_norm=3.72, loss=1.32] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 70.01batch/s, accuracy=47.7, grad_norm=3.84, loss=1.29] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.75batch/s, accuracy=48, grad_norm=4.18, loss=1.29]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 66.89batch/s, accuracy=48.4, grad_norm=4.18, loss=1.28] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 68.75batch/s, accuracy=48.7, grad_norm=4.16, loss=1.27] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 37.21%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 71.76batch/s, accuracy=23.6, grad_norm=5.05, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 68.73batch/s, accuracy=26.3, grad_norm=4.26, loss=1.71] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 67.91batch/s, accuracy=27.6, grad_norm=3.18, loss=1.69] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.73batch/s, accuracy=28.7, grad_norm=3.1, loss=1.66]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 65.05batch/s, accuracy=30.4, grad_norm=3.04, loss=1.64] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 69.03batch/s, accuracy=32.8, grad_norm=3.33, loss=1.6]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.60batch/s, accuracy=37.4, grad_norm=2.85, loss=1.51] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 69.45batch/s, accuracy=39.5, grad_norm=2.75, loss=1.47] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 69.68batch/s, accuracy=40.4, grad_norm=2.68, loss=1.44] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 72.65batch/s, accuracy=41.3, grad_norm=2.66, loss=1.43] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 107.35batch/s, accuracy=42.7, grad_norm=2.82, loss=1.4]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 101.57batch/s, accuracy=43, grad_norm=3.65, loss=1.39]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 104.91batch/s, accuracy=43.6, grad_norm=3.1, loss=1.38]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 100.32batch/s, accuracy=44, grad_norm=3.1, loss=1.37]    \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 66.56batch/s, accuracy=44.5, grad_norm=3.39, loss=1.36] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.82batch/s, accuracy=45, grad_norm=3.29, loss=1.35]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 69.29batch/s, accuracy=45.4, grad_norm=3.77, loss=1.34] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.86batch/s, accuracy=46, grad_norm=3.72, loss=1.33]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 69.32batch/s, accuracy=46.1, grad_norm=3.18, loss=1.33] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.78batch/s, accuracy=46.5, grad_norm=3.86, loss=1.32] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 71.66batch/s, accuracy=47.8, grad_norm=3.85, loss=1.29] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 72.26batch/s, accuracy=48.1, grad_norm=4.34, loss=1.28] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 64.83batch/s, accuracy=48.4, grad_norm=4.08, loss=1.27] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 64.51batch/s, accuracy=49, grad_norm=4.99, loss=1.26]   \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 69.76batch/s, accuracy=49, grad_norm=5.65, loss=1.26]   \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:12<00:00, 71.44batch/s, accuracy=49.4, grad_norm=5.04, loss=1.25] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 70.57batch/s, accuracy=50.1, grad_norm=5.26, loss=1.24] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=50, grad_norm=5.34, loss=1.24]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 37.30%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 65.92batch/s, accuracy=23.7, grad_norm=4.41, loss=1.74] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.58batch/s, accuracy=26.3, grad_norm=3.48, loss=1.71] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 70.64batch/s, accuracy=27.6, grad_norm=2.79, loss=1.69] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 68.46batch/s, accuracy=28.8, grad_norm=2.99, loss=1.67] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 64.86batch/s, accuracy=29.8, grad_norm=2.73, loss=1.65] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:14<00:00, 61.84batch/s, accuracy=31.6, grad_norm=3.19, loss=1.63] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.28batch/s, accuracy=34.4, grad_norm=3.45, loss=1.58] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.20batch/s, accuracy=37.9, grad_norm=3.23, loss=1.5]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 69.03batch/s, accuracy=39.6, grad_norm=3.32, loss=1.46] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 65.13batch/s, accuracy=40.7, grad_norm=3, loss=1.44]    \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 66.92batch/s, accuracy=42.2, grad_norm=3.13, loss=1.41] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.31batch/s, accuracy=42.9, grad_norm=3.38, loss=1.4]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.63batch/s, accuracy=43.6, grad_norm=3.05, loss=1.38] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.15batch/s, accuracy=43.7, grad_norm=3.36, loss=1.38] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 69.11batch/s, accuracy=44.3, grad_norm=2.98, loss=1.37] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 71.76batch/s, accuracy=44.4, grad_norm=3.2, loss=1.36]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:14<00:00, 63.17batch/s, accuracy=44.8, grad_norm=3.8, loss=1.35]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:11<00:00, 75.48batch/s, accuracy=45.4, grad_norm=3.83, loss=1.34] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 106.99batch/s, accuracy=46, grad_norm=3.45, loss=1.33]   \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 104.72batch/s, accuracy=46.2, grad_norm=3.44, loss=1.32] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 104.80batch/s, accuracy=47.6, grad_norm=3.47, loss=1.3]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:09<00:00, 91.27batch/s, accuracy=47.8, grad_norm=4.04, loss=1.29]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 69.79batch/s, accuracy=48.2, grad_norm=4.29, loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 38.09%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 66.42batch/s, accuracy=23.6, grad_norm=5.03, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 66.69batch/s, accuracy=26.6, grad_norm=3.7, loss=1.71]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.00batch/s, accuracy=27.6, grad_norm=2.74, loss=1.69] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 72.41batch/s, accuracy=28.8, grad_norm=3.4, loss=1.67]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.86batch/s, accuracy=30.4, grad_norm=2.81, loss=1.65] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 66.29batch/s, accuracy=32.2, grad_norm=2.43, loss=1.61] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.67batch/s, accuracy=34.4, grad_norm=3.01, loss=1.57] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.09batch/s, accuracy=38.2, grad_norm=3.21, loss=1.49] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 72.01batch/s, accuracy=39.8, grad_norm=3.01, loss=1.46] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 69.96batch/s, accuracy=40.8, grad_norm=2.49, loss=1.44] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 67.24batch/s, accuracy=42.5, grad_norm=2.75, loss=1.41] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 65.33batch/s, accuracy=43, grad_norm=3.46, loss=1.39]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 72.42batch/s, accuracy=43.3, grad_norm=2.91, loss=1.38] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.21batch/s, accuracy=43.7, grad_norm=3.28, loss=1.37] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.30batch/s, accuracy=44.3, grad_norm=3.34, loss=1.36] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 66.56batch/s, accuracy=44.7, grad_norm=3.55, loss=1.35] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 69.45batch/s, accuracy=45.3, grad_norm=3.33, loss=1.35] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 70.54batch/s, accuracy=45.7, grad_norm=3.32, loss=1.34] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 103.91batch/s, accuracy=45.7, grad_norm=3.97, loss=1.33] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 107.94batch/s, accuracy=46.4, grad_norm=3.79, loss=1.32] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 105.32batch/s, accuracy=47.6, grad_norm=4.89, loss=1.3]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 103.65batch/s, accuracy=47.8, grad_norm=4.9, loss=1.28]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 69.22batch/s, accuracy=48.6, grad_norm=4.73, loss=1.28] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 73.74batch/s, accuracy=48.7, grad_norm=4.36, loss=1.27]  \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 66.48batch/s, accuracy=49.1, grad_norm=4.29, loss=1.26] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 67.68batch/s, accuracy=49.6, grad_norm=5, loss=1.25]    \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:13<00:00, 66.38batch/s, accuracy=49.9, grad_norm=4.52, loss=1.25] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=50.4, grad_norm=5.5, loss=1.24]  \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:12<00:00, 72.09batch/s, accuracy=50.8, grad_norm=5.64, loss=1.23] \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:13<00:00, 66.11batch/s, accuracy=51, grad_norm=6.04, loss=1.22]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 38.34%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 65.02batch/s, accuracy=24, grad_norm=5.49, loss=1.74]   \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.64batch/s, accuracy=26.5, grad_norm=3.41, loss=1.7]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.70batch/s, accuracy=27.6, grad_norm=3.86, loss=1.68] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 72.66batch/s, accuracy=28.8, grad_norm=2.78, loss=1.66] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 69.47batch/s, accuracy=30.7, grad_norm=3.01, loss=1.63] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 64.35batch/s, accuracy=33.1, grad_norm=3.28, loss=1.59] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.50batch/s, accuracy=37.3, grad_norm=2.95, loss=1.52] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.91batch/s, accuracy=39.4, grad_norm=2.72, loss=1.47] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 73.55batch/s, accuracy=40.6, grad_norm=3.05, loss=1.44] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 65.78batch/s, accuracy=41.2, grad_norm=3.13, loss=1.43] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:14<00:00, 63.05batch/s, accuracy=42.7, grad_norm=2.97, loss=1.4]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.50batch/s, accuracy=43, grad_norm=3.01, loss=1.39]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 72.27batch/s, accuracy=43.7, grad_norm=3.64, loss=1.38] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 72.87batch/s, accuracy=44.3, grad_norm=3.15, loss=1.37] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.42batch/s, accuracy=44.3, grad_norm=3.67, loss=1.36] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 100.89batch/s, accuracy=45, grad_norm=3.75, loss=1.35]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 105.09batch/s, accuracy=45, grad_norm=3.27, loss=1.34]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 105.14batch/s, accuracy=45.4, grad_norm=3.61, loss=1.33] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:10<00:00, 86.02batch/s, accuracy=46.2, grad_norm=3.52, loss=1.33]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 37.22%\n",
      "SNR=-10 完成: Avg Val=42.35%, Avg Test=37.63%\n",
      "\n",
      "===== 开始 SNR=-15 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 68.43batch/s, accuracy=23.4, grad_norm=5, loss=1.75]    \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.36batch/s, accuracy=25.6, grad_norm=3.24, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 73.36batch/s, accuracy=26.8, grad_norm=2.75, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 67.40batch/s, accuracy=27.1, grad_norm=1.99, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 68.43batch/s, accuracy=27.4, grad_norm=1.94, loss=1.69] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.74batch/s, accuracy=27.5, grad_norm=2.13, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 72.51batch/s, accuracy=28, grad_norm=1.98, loss=1.68]   \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.03batch/s, accuracy=27.6, grad_norm=3, loss=1.68]    \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 72.52batch/s, accuracy=27.9, grad_norm=1.63, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 64.94batch/s, accuracy=28.2, grad_norm=1.85, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 66.82batch/s, accuracy=28.8, grad_norm=2.04, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.37batch/s, accuracy=29.1, grad_norm=1.88, loss=1.66] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 72.51batch/s, accuracy=29.7, grad_norm=2.18, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 72.71batch/s, accuracy=29.6, grad_norm=2.12, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 66.56batch/s, accuracy=29.8, grad_norm=1.95, loss=1.65] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 66.84batch/s, accuracy=29.8, grad_norm=1.69, loss=1.65] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.83batch/s, accuracy=30.2, grad_norm=2.36, loss=1.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 23.02%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 72.80batch/s, accuracy=23.2, grad_norm=4.55, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 72.10batch/s, accuracy=25.7, grad_norm=3.46, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 66.40batch/s, accuracy=26.6, grad_norm=3.24, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 64.75batch/s, accuracy=26.9, grad_norm=2.4, loss=1.7]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.97batch/s, accuracy=27.1, grad_norm=1.83, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=27.4, grad_norm=2.25, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 69.07batch/s, accuracy=27.5, grad_norm=2.01, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.45batch/s, accuracy=27.6, grad_norm=1.8, loss=1.69]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.73batch/s, accuracy=27.9, grad_norm=2.35, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 69.34batch/s, accuracy=28.2, grad_norm=2.9, loss=1.68]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.40batch/s, accuracy=28.7, grad_norm=2.54, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.52batch/s, accuracy=28.7, grad_norm=2.19, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.44batch/s, accuracy=29.1, grad_norm=2.39, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.78batch/s, accuracy=29.1, grad_norm=1.81, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 69.07batch/s, accuracy=29.2, grad_norm=1.72, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.33batch/s, accuracy=29.6, grad_norm=2.01, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 73.62batch/s, accuracy=29.6, grad_norm=2.26, loss=1.65] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 105.62batch/s, accuracy=29.6, grad_norm=2.28, loss=1.65] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 105.90batch/s, accuracy=30.1, grad_norm=3.53, loss=1.65] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 105.25batch/s, accuracy=30.2, grad_norm=2.89, loss=1.64] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 107.86batch/s, accuracy=30.6, grad_norm=2.42, loss=1.64] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 105.57batch/s, accuracy=30.7, grad_norm=2.52, loss=1.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 24.08%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 105.53batch/s, accuracy=22.9, grad_norm=5.45, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 102.36batch/s, accuracy=25.2, grad_norm=3.49, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 101.66batch/s, accuracy=26.8, grad_norm=2.74, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 108.05batch/s, accuracy=27, grad_norm=2.13, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:10<00:00, 84.06batch/s, accuracy=27.1, grad_norm=2.05, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.41batch/s, accuracy=27.5, grad_norm=2.02, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 68.52batch/s, accuracy=27.5, grad_norm=2.35, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:14<00:00, 64.27batch/s, accuracy=27.9, grad_norm=1.61, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 70.45batch/s, accuracy=27.9, grad_norm=1.51, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 74.17batch/s, accuracy=28.3, grad_norm=1.94, loss=1.68]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 69.70batch/s, accuracy=28.8, grad_norm=1.73, loss=1.66] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 67.41batch/s, accuracy=29.1, grad_norm=1.8, loss=1.66]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:14<00:00, 63.78batch/s, accuracy=29.1, grad_norm=1.74, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 68.55batch/s, accuracy=29.4, grad_norm=2.12, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 70.01batch/s, accuracy=29.6, grad_norm=2.81, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.09batch/s, accuracy=29.8, grad_norm=2.09, loss=1.65] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 67.62batch/s, accuracy=30.1, grad_norm=2.4, loss=1.65]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.41batch/s, accuracy=30, grad_norm=1.94, loss=1.65]   \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 65.70batch/s, accuracy=30.3, grad_norm=2.28, loss=1.64] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.18batch/s, accuracy=30.5, grad_norm=2.15, loss=1.64] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 69.57batch/s, accuracy=30.9, grad_norm=2.78, loss=1.63] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 70.85batch/s, accuracy=31, grad_norm=2.67, loss=1.63]   \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 72.30batch/s, accuracy=31.6, grad_norm=2.76, loss=1.62] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:13<00:00, 66.24batch/s, accuracy=31.5, grad_norm=2.87, loss=1.62] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:13<00:00, 68.16batch/s, accuracy=31.5, grad_norm=2.8, loss=1.62]  \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 69.12batch/s, accuracy=31.9, grad_norm=3.02, loss=1.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 24.13%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 71.33batch/s, accuracy=23.8, grad_norm=5.07, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.42batch/s, accuracy=25.9, grad_norm=3.52, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.15batch/s, accuracy=26.6, grad_norm=2.7, loss=1.71]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 67.20batch/s, accuracy=27, grad_norm=2.32, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.29batch/s, accuracy=27.2, grad_norm=2.21, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=27.4, grad_norm=2.2, loss=1.69]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 72.02batch/s, accuracy=27.5, grad_norm=2.18, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.07batch/s, accuracy=27.6, grad_norm=2.19, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:14<00:00, 62.13batch/s, accuracy=28, grad_norm=2.02, loss=1.68]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.82batch/s, accuracy=28.3, grad_norm=2.18, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.89batch/s, accuracy=28.8, grad_norm=2.96, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 72.83batch/s, accuracy=29, grad_norm=2.27, loss=1.66]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 70.98batch/s, accuracy=29.4, grad_norm=2.22, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:09<00:00, 98.55batch/s, accuracy=29.2, grad_norm=1.89, loss=1.66]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 100.71batch/s, accuracy=29.6, grad_norm=1.75, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 23.68%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 101.95batch/s, accuracy=23.4, grad_norm=4.48, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:10<00:00, 85.83batch/s, accuracy=25.7, grad_norm=3.17, loss=1.72]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.90batch/s, accuracy=26.5, grad_norm=2.28, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.52batch/s, accuracy=26.9, grad_norm=2.24, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.27batch/s, accuracy=27, grad_norm=2.31, loss=1.69]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 73.44batch/s, accuracy=27.2, grad_norm=2.41, loss=1.69]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.21batch/s, accuracy=27.6, grad_norm=2.08, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 72.03batch/s, accuracy=27.7, grad_norm=1.58, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 68.81batch/s, accuracy=27.9, grad_norm=1.54, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 68.65batch/s, accuracy=28.2, grad_norm=1.59, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.04batch/s, accuracy=28.6, grad_norm=2.28, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 67.79batch/s, accuracy=29, grad_norm=1.95, loss=1.66]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.86batch/s, accuracy=29.1, grad_norm=2.28, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.41batch/s, accuracy=29.3, grad_norm=1.82, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 21.62%\n",
      "SNR=-15 完成: Avg Val=22.51%, Avg Test=23.31%\n",
      "\n",
      "===== 开始 SNR=-20 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.61batch/s, accuracy=23.2, grad_norm=5.25, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.11batch/s, accuracy=26, grad_norm=3.79, loss=1.72]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 65.70batch/s, accuracy=26.4, grad_norm=2.96, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.59batch/s, accuracy=27.2, grad_norm=3.06, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 70.60batch/s, accuracy=27.7, grad_norm=2.46, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.55batch/s, accuracy=27.8, grad_norm=2.26, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.30batch/s, accuracy=27.7, grad_norm=2.05, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.55batch/s, accuracy=27.8, grad_norm=2.02, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 74.84batch/s, accuracy=28.3, grad_norm=1.81, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 104.91batch/s, accuracy=28.2, grad_norm=1.79, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 107.14batch/s, accuracy=28.9, grad_norm=2.07, loss=1.67] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 20.52%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 105.46batch/s, accuracy=23.1, grad_norm=5.06, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 101.39batch/s, accuracy=25.7, grad_norm=2.92, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 70.71batch/s, accuracy=26.6, grad_norm=2.6, loss=1.71]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 64.92batch/s, accuracy=27, grad_norm=2.35, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.53batch/s, accuracy=27.3, grad_norm=2.63, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.36batch/s, accuracy=27.4, grad_norm=2.38, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.37batch/s, accuracy=27.7, grad_norm=2.61, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.55batch/s, accuracy=27.8, grad_norm=2.33, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.57batch/s, accuracy=28.3, grad_norm=1.76, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 66.62batch/s, accuracy=28.4, grad_norm=1.72, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 67.45batch/s, accuracy=28.5, grad_norm=1.79, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.04batch/s, accuracy=28.8, grad_norm=2.25, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.55batch/s, accuracy=29.1, grad_norm=1.67, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 70.21batch/s, accuracy=29.1, grad_norm=1.8, loss=1.66]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 20.05%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 67.69batch/s, accuracy=23.2, grad_norm=5.54, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 66.62batch/s, accuracy=25.8, grad_norm=3.56, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.85batch/s, accuracy=26.6, grad_norm=2.56, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.38batch/s, accuracy=27.4, grad_norm=2.82, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.25batch/s, accuracy=27.5, grad_norm=1.99, loss=1.69] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.58batch/s, accuracy=27.7, grad_norm=2.21, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 66.97batch/s, accuracy=27.9, grad_norm=1.82, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.87batch/s, accuracy=28.3, grad_norm=2.72, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 68.96batch/s, accuracy=28.2, grad_norm=2.17, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 72.23batch/s, accuracy=28.5, grad_norm=1.98, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.40batch/s, accuracy=29, grad_norm=2.14, loss=1.67]   \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:11<00:00, 75.31batch/s, accuracy=29.1, grad_norm=1.91, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 101.91batch/s, accuracy=29.1, grad_norm=2.17, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:09<00:00, 94.79batch/s, accuracy=29.5, grad_norm=1.95, loss=1.66]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 105.12batch/s, accuracy=29.3, grad_norm=1.89, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:10<00:00, 87.89batch/s, accuracy=29.7, grad_norm=3.52, loss=1.66]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 73.43batch/s, accuracy=29.7, grad_norm=2.33, loss=1.65] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.64batch/s, accuracy=29.9, grad_norm=1.67, loss=1.65] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:14<00:00, 64.22batch/s, accuracy=29.9, grad_norm=1.88, loss=1.65] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:14<00:00, 64.00batch/s, accuracy=30.1, grad_norm=1.98, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 65.65batch/s, accuracy=30.4, grad_norm=2.54, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 21.70%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 67.49batch/s, accuracy=23, grad_norm=4.93, loss=1.75]   \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.85batch/s, accuracy=25.7, grad_norm=3.96, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.17batch/s, accuracy=26.6, grad_norm=2.87, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.71batch/s, accuracy=27.4, grad_norm=2.86, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.90batch/s, accuracy=27.5, grad_norm=2.45, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.43batch/s, accuracy=27.7, grad_norm=2.01, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 99.90batch/s, accuracy=28, grad_norm=2.03, loss=1.68]    \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 102.13batch/s, accuracy=28.2, grad_norm=2.18, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 103.21batch/s, accuracy=28.2, grad_norm=1.55, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 107.91batch/s, accuracy=28.2, grad_norm=1.92, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 65.47batch/s, accuracy=28.8, grad_norm=1.79, loss=1.67]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 72.77batch/s, accuracy=29.1, grad_norm=1.89, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.92batch/s, accuracy=29.2, grad_norm=1.75, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 69.36batch/s, accuracy=29.3, grad_norm=2.76, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 73.56batch/s, accuracy=29.3, grad_norm=2.15, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 68.67batch/s, accuracy=29.5, grad_norm=1.77, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 21.43%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 65.87batch/s, accuracy=23.2, grad_norm=5.39, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.61batch/s, accuracy=25.6, grad_norm=3.34, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 73.09batch/s, accuracy=26.8, grad_norm=2.76, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 71.80batch/s, accuracy=27, grad_norm=2.6, loss=1.7]     \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 72.94batch/s, accuracy=27.4, grad_norm=2.52, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:14<00:00, 63.67batch/s, accuracy=27.4, grad_norm=2.12, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.41batch/s, accuracy=27.7, grad_norm=2.35, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.33batch/s, accuracy=28.1, grad_norm=1.86, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 70.73batch/s, accuracy=28.2, grad_norm=1.69, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.71batch/s, accuracy=28.3, grad_norm=1.66, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 65.94batch/s, accuracy=28.9, grad_norm=1.89, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 66.06batch/s, accuracy=29.1, grad_norm=2.55, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.33batch/s, accuracy=29, grad_norm=1.87, loss=1.66]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 70.22batch/s, accuracy=29.1, grad_norm=1.88, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 69.73batch/s, accuracy=29.2, grad_norm=1.57, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:11<00:00, 75.88batch/s, accuracy=29.3, grad_norm=2.2, loss=1.66]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 105.28batch/s, accuracy=29.5, grad_norm=1.78, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 103.63batch/s, accuracy=29.5, grad_norm=2.18, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:09<00:00, 98.83batch/s, accuracy=29.8, grad_norm=1.99, loss=1.65]  \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 103.99batch/s, accuracy=29.9, grad_norm=1.92, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 108.65batch/s, accuracy=30.2, grad_norm=2.42, loss=1.65] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 106.03batch/s, accuracy=30.1, grad_norm=2.32, loss=1.64] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 105.44batch/s, accuracy=30.4, grad_norm=2.56, loss=1.64] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 107.43batch/s, accuracy=30.5, grad_norm=2.79, loss=1.64] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:08<00:00, 107.32batch/s, accuracy=30.7, grad_norm=2.72, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 21.43%\n",
      "SNR=-20 完成: Avg Val=20.66%, Avg Test=21.03%\n",
      "\n",
      "===== 开始 SNR=-25 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 65.42batch/s, accuracy=23.3, grad_norm=4.9, loss=1.75]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.01batch/s, accuracy=25.5, grad_norm=3.18, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 70.86batch/s, accuracy=26.7, grad_norm=2.86, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 72.02batch/s, accuracy=27, grad_norm=2.46, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 72.39batch/s, accuracy=27.4, grad_norm=2.2, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 69.17batch/s, accuracy=27.5, grad_norm=1.92, loss=1.7]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 65.22batch/s, accuracy=27.5, grad_norm=2.01, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:10<00:00, 84.68batch/s, accuracy=27.5, grad_norm=2, loss=1.69]    \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 104.34batch/s, accuracy=28.1, grad_norm=2.67, loss=1.69] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 104.79batch/s, accuracy=28.1, grad_norm=3.18, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 107.47batch/s, accuracy=28.7, grad_norm=1.75, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:11<00:00, 81.76batch/s, accuracy=28.8, grad_norm=2.21, loss=1.67]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.55batch/s, accuracy=29, grad_norm=2.07, loss=1.67]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 69.93batch/s, accuracy=29.1, grad_norm=2.01, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 71.73batch/s, accuracy=29.2, grad_norm=1.83, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 72.09batch/s, accuracy=29.2, grad_norm=2.32, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 70.70batch/s, accuracy=29.3, grad_norm=2.14, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 68.87batch/s, accuracy=29.7, grad_norm=2, loss=1.66]    \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:14<00:00, 64.11batch/s, accuracy=29.6, grad_norm=1.79, loss=1.65] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.36batch/s, accuracy=29.8, grad_norm=2.12, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 70.18batch/s, accuracy=30.2, grad_norm=2.32, loss=1.64] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 71.96batch/s, accuracy=30.3, grad_norm=2.68, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 21.47%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.80batch/s, accuracy=23.3, grad_norm=4.93, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.78batch/s, accuracy=25.4, grad_norm=3.61, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 69.23batch/s, accuracy=26.4, grad_norm=2.83, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 73.42batch/s, accuracy=27.2, grad_norm=2.31, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 68.13batch/s, accuracy=27.3, grad_norm=2.62, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.79batch/s, accuracy=27.2, grad_norm=3.18, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.57batch/s, accuracy=27.9, grad_norm=2.43, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 66.59batch/s, accuracy=27.8, grad_norm=1.84, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 69.01batch/s, accuracy=28, grad_norm=1.71, loss=1.68]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 69.62batch/s, accuracy=28.3, grad_norm=2.35, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 104.34batch/s, accuracy=28.5, grad_norm=2.14, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 105.51batch/s, accuracy=28.7, grad_norm=1.95, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 106.00batch/s, accuracy=29, grad_norm=1.86, loss=1.67]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 106.68batch/s, accuracy=29.1, grad_norm=1.9, loss=1.66]  \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:14<00:00, 63.00batch/s, accuracy=29.1, grad_norm=2.21, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 66.28batch/s, accuracy=29.2, grad_norm=2.14, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 21.50%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 69.05batch/s, accuracy=23.5, grad_norm=4.82, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 73.71batch/s, accuracy=26.1, grad_norm=3.99, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 73.67batch/s, accuracy=27.3, grad_norm=2.32, loss=1.7]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.21batch/s, accuracy=27.1, grad_norm=2.95, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 68.89batch/s, accuracy=27.5, grad_norm=2.32, loss=1.69] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.71batch/s, accuracy=28, grad_norm=2.08, loss=1.69]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 98.94batch/s, accuracy=27.8, grad_norm=1.58, loss=1.69]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 106.90batch/s, accuracy=28, grad_norm=1.65, loss=1.68]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 104.87batch/s, accuracy=28.1, grad_norm=2.21, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 103.09batch/s, accuracy=28.2, grad_norm=1.82, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 66.07batch/s, accuracy=29.1, grad_norm=1.63, loss=1.67]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.55batch/s, accuracy=28.9, grad_norm=1.54, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 73.47batch/s, accuracy=28.9, grad_norm=2.77, loss=1.66] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 73.31batch/s, accuracy=29.4, grad_norm=2.32, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 67.95batch/s, accuracy=29.5, grad_norm=2.31, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 69.23batch/s, accuracy=29.7, grad_norm=1.91, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:13<00:00, 68.06batch/s, accuracy=29.7, grad_norm=1.89, loss=1.66]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.44batch/s, accuracy=29.9, grad_norm=1.87, loss=1.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 23.09%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:10<00:00, 84.99batch/s, accuracy=23.8, grad_norm=4.6, loss=1.75]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 105.52batch/s, accuracy=26.3, grad_norm=3.23, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 108.05batch/s, accuracy=26.9, grad_norm=2.27, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 104.50batch/s, accuracy=27.3, grad_norm=2.51, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:10<00:00, 88.95batch/s, accuracy=27.5, grad_norm=1.83, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 65.80batch/s, accuracy=27.6, grad_norm=2.33, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 68.67batch/s, accuracy=27.8, grad_norm=1.43, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 68.55batch/s, accuracy=27.8, grad_norm=1.93, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 69.91batch/s, accuracy=28.2, grad_norm=2.24, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.50batch/s, accuracy=28.3, grad_norm=1.78, loss=1.68]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.51batch/s, accuracy=28.8, grad_norm=1.56, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.70batch/s, accuracy=28.9, grad_norm=1.8, loss=1.67]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 101.92batch/s, accuracy=29.3, grad_norm=2.17, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 103.56batch/s, accuracy=29.3, grad_norm=2.11, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 104.17batch/s, accuracy=29.1, grad_norm=1.91, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 108.56batch/s, accuracy=29.3, grad_norm=2.34, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 109.33batch/s, accuracy=29.5, grad_norm=1.8, loss=1.66]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 108.92batch/s, accuracy=29.7, grad_norm=1.69, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 110.54batch/s, accuracy=29.9, grad_norm=2.07, loss=1.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 20.97%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 106.00batch/s, accuracy=23.2, grad_norm=5.15, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 102.55batch/s, accuracy=25.4, grad_norm=3.08, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 109.58batch/s, accuracy=26.6, grad_norm=2.28, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:11<00:00, 76.59batch/s, accuracy=27.1, grad_norm=2.47, loss=1.7]   \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:11<00:00, 75.04batch/s, accuracy=27.1, grad_norm=2.34, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 72.80batch/s, accuracy=27.3, grad_norm=2.48, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 67.07batch/s, accuracy=27.9, grad_norm=2.71, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 65.11batch/s, accuracy=27.7, grad_norm=1.88, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 69.94batch/s, accuracy=27.9, grad_norm=1.67, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 72.66batch/s, accuracy=28.1, grad_norm=2.15, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.51batch/s, accuracy=28.6, grad_norm=2.37, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 68.62batch/s, accuracy=28.8, grad_norm=1.76, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 67.15batch/s, accuracy=29, grad_norm=1.7, loss=1.67]    \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 100.71batch/s, accuracy=29.2, grad_norm=1.63, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 104.03batch/s, accuracy=29.3, grad_norm=1.66, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 106.55batch/s, accuracy=29.3, grad_norm=1.86, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 108.52batch/s, accuracy=29.4, grad_norm=1.97, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.68batch/s, accuracy=29.4, grad_norm=1.66, loss=1.66]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 69.76batch/s, accuracy=29.5, grad_norm=2.78, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 68.97batch/s, accuracy=29.9, grad_norm=1.9, loss=1.65]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 67.74batch/s, accuracy=30, grad_norm=2.85, loss=1.65]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:12<00:00, 71.46batch/s, accuracy=30.2, grad_norm=2.1, loss=1.64]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 68.80batch/s, accuracy=30.3, grad_norm=2.37, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 21.73%\n",
      "SNR=-25 完成: Avg Val=21.25%, Avg Test=21.75%\n",
      "\n",
      "===== 开始 SNR=-30 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 73.93batch/s, accuracy=23.5, grad_norm=5.17, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 68.33batch/s, accuracy=25.7, grad_norm=3.42, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 65.34batch/s, accuracy=26.6, grad_norm=3.79, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 67.96batch/s, accuracy=27, grad_norm=3.7, loss=1.7]     \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 101.27batch/s, accuracy=27.5, grad_norm=2.54, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 106.72batch/s, accuracy=27.5, grad_norm=2.52, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 105.98batch/s, accuracy=27.7, grad_norm=1.79, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 107.85batch/s, accuracy=27.9, grad_norm=1.8, loss=1.69]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 74.38batch/s, accuracy=27.9, grad_norm=1.61, loss=1.69]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:14<00:00, 63.86batch/s, accuracy=28, grad_norm=1.94, loss=1.68]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 70.26batch/s, accuracy=28.8, grad_norm=2.03, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 69.80batch/s, accuracy=28.9, grad_norm=2.52, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 69.89batch/s, accuracy=28.8, grad_norm=2.37, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.22batch/s, accuracy=29.1, grad_norm=1.93, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 64.70batch/s, accuracy=29.1, grad_norm=1.74, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 67.87batch/s, accuracy=29.2, grad_norm=1.8, loss=1.66]  \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:10<00:00, 82.02batch/s, accuracy=29.4, grad_norm=2.08, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 107.09batch/s, accuracy=29.5, grad_norm=1.9, loss=1.66]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 105.80batch/s, accuracy=29.4, grad_norm=1.83, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:08<00:00, 104.29batch/s, accuracy=29.7, grad_norm=2.61, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:09<00:00, 90.56batch/s, accuracy=30, grad_norm=2.41, loss=1.65]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 22.15%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 68.07batch/s, accuracy=23.3, grad_norm=5.33, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.56batch/s, accuracy=25.3, grad_norm=3.53, loss=1.73] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.95batch/s, accuracy=26.4, grad_norm=2.62, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 66.11batch/s, accuracy=26.8, grad_norm=2.87, loss=1.71] \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 73.53batch/s, accuracy=27.3, grad_norm=2.88, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.81batch/s, accuracy=27.3, grad_norm=2.3, loss=1.7]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 69.37batch/s, accuracy=27.3, grad_norm=2.44, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 107.32batch/s, accuracy=27.9, grad_norm=2.34, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 104.84batch/s, accuracy=27.9, grad_norm=2.31, loss=1.69] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 104.26batch/s, accuracy=27.9, grad_norm=2.81, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 102.82batch/s, accuracy=28.5, grad_norm=1.77, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.28batch/s, accuracy=28.7, grad_norm=2.1, loss=1.67]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 74.84batch/s, accuracy=28.9, grad_norm=1.64, loss=1.67]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 65.21batch/s, accuracy=28.9, grad_norm=1.7, loss=1.67]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 19.64%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 69.13batch/s, accuracy=23.6, grad_norm=4.78, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.45batch/s, accuracy=25.9, grad_norm=3.83, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 69.21batch/s, accuracy=26.9, grad_norm=3.41, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 67.86batch/s, accuracy=27.3, grad_norm=2.08, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:15<00:00, 59.85batch/s, accuracy=27.3, grad_norm=2.23, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 69.27batch/s, accuracy=27.7, grad_norm=2.57, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 96.38batch/s, accuracy=27.7, grad_norm=2.13, loss=1.69]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 105.11batch/s, accuracy=27.9, grad_norm=1.77, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 108.40batch/s, accuracy=27.8, grad_norm=2.09, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 105.31batch/s, accuracy=28.1, grad_norm=2.07, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 105.40batch/s, accuracy=28.5, grad_norm=1.76, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 107.05batch/s, accuracy=28.9, grad_norm=1.52, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 100.45batch/s, accuracy=28.8, grad_norm=1.97, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 104.10batch/s, accuracy=28.8, grad_norm=2.71, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 104.68batch/s, accuracy=29.2, grad_norm=1.83, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 108.04batch/s, accuracy=29.3, grad_norm=1.87, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:11<00:00, 79.16batch/s, accuracy=29.1, grad_norm=2.94, loss=1.66]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 67.81batch/s, accuracy=29.4, grad_norm=2.27, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 69.37batch/s, accuracy=29.5, grad_norm=1.83, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:13<00:00, 66.27batch/s, accuracy=29.7, grad_norm=1.99, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:13<00:00, 66.88batch/s, accuracy=30.1, grad_norm=2.06, loss=1.65] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:11<00:00, 75.09batch/s, accuracy=30.2, grad_norm=3.13, loss=1.64]  \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:13<00:00, 67.98batch/s, accuracy=30.3, grad_norm=2.12, loss=1.64] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 70.98batch/s, accuracy=30.6, grad_norm=2.23, loss=1.64] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:12<00:00, 70.34batch/s, accuracy=30.6, grad_norm=2.92, loss=1.64] \n",
      "Epoch 26/200: 100%|██████████| 900/900 [00:13<00:00, 68.22batch/s, accuracy=30.5, grad_norm=2.45, loss=1.64] \n",
      "Epoch 27/200: 100%|██████████| 900/900 [00:12<00:00, 73.54batch/s, accuracy=30.8, grad_norm=2.66, loss=1.63] \n",
      "Epoch 28/200: 100%|██████████| 900/900 [00:13<00:00, 66.99batch/s, accuracy=30.9, grad_norm=4.36, loss=1.63] \n",
      "Epoch 29/200: 100%|██████████| 900/900 [00:10<00:00, 82.93batch/s, accuracy=31, grad_norm=3.46, loss=1.63]   \n",
      "Epoch 30/200: 100%|██████████| 900/900 [00:08<00:00, 108.38batch/s, accuracy=31.1, grad_norm=2.87, loss=1.63] \n",
      "Epoch 31/200: 100%|██████████| 900/900 [00:08<00:00, 106.99batch/s, accuracy=31.4, grad_norm=3.4, loss=1.62]  \n",
      "Epoch 32/200: 100%|██████████| 900/900 [00:08<00:00, 105.91batch/s, accuracy=31.3, grad_norm=3.55, loss=1.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 21.66%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 73.54batch/s, accuracy=23.6, grad_norm=5.14, loss=1.75]  \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 66.64batch/s, accuracy=25.7, grad_norm=3.92, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.66batch/s, accuracy=26.7, grad_norm=2.6, loss=1.71]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 73.90batch/s, accuracy=27.3, grad_norm=2.93, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=27.4, grad_norm=2.28, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:14<00:00, 63.20batch/s, accuracy=27.4, grad_norm=2.42, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 66.06batch/s, accuracy=27.8, grad_norm=1.89, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.49batch/s, accuracy=27.9, grad_norm=2.23, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 73.46batch/s, accuracy=28.2, grad_norm=1.76, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.95batch/s, accuracy=28.3, grad_norm=2.27, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:13<00:00, 68.82batch/s, accuracy=28.7, grad_norm=2.07, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:14<00:00, 63.85batch/s, accuracy=28.9, grad_norm=1.73, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:10<00:00, 87.61batch/s, accuracy=29.1, grad_norm=1.79, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 106.02batch/s, accuracy=29.2, grad_norm=2.02, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 109.28batch/s, accuracy=29.4, grad_norm=1.92, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 106.11batch/s, accuracy=29.5, grad_norm=2.22, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:11<00:00, 77.31batch/s, accuracy=29.6, grad_norm=1.37, loss=1.66]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 69.86batch/s, accuracy=29.7, grad_norm=1.8, loss=1.66]  \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:14<00:00, 64.17batch/s, accuracy=29.6, grad_norm=1.86, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 69.57batch/s, accuracy=30.3, grad_norm=2.23, loss=1.66] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:12<00:00, 69.79batch/s, accuracy=30, grad_norm=1.78, loss=1.65]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:13<00:00, 67.67batch/s, accuracy=30.6, grad_norm=2.73, loss=1.64] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:12<00:00, 71.86batch/s, accuracy=30.3, grad_norm=2.47, loss=1.64] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:12<00:00, 70.45batch/s, accuracy=30.5, grad_norm=2.27, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 21.42%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 70.36batch/s, accuracy=23.3, grad_norm=5.35, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 70.35batch/s, accuracy=25.5, grad_norm=3.66, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 68.76batch/s, accuracy=26.6, grad_norm=2.32, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.90batch/s, accuracy=27, grad_norm=2.59, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.99batch/s, accuracy=27.2, grad_norm=1.85, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:11<00:00, 78.75batch/s, accuracy=27.5, grad_norm=2.23, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 100.43batch/s, accuracy=27.8, grad_norm=1.93, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 104.99batch/s, accuracy=27.9, grad_norm=1.6, loss=1.69]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 102.67batch/s, accuracy=28.4, grad_norm=2, loss=1.68]    \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:11<00:00, 80.65batch/s, accuracy=28.3, grad_norm=1.71, loss=1.68]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 73.06batch/s, accuracy=28.7, grad_norm=2.31, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 73.85batch/s, accuracy=28.8, grad_norm=2.06, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 64.34batch/s, accuracy=28.8, grad_norm=1.62, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.51batch/s, accuracy=29.2, grad_norm=2.61, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 73.87batch/s, accuracy=29.2, grad_norm=2.01, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 73.09batch/s, accuracy=29.2, grad_norm=1.96, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.07batch/s, accuracy=29.4, grad_norm=2.31, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 66.28batch/s, accuracy=29.6, grad_norm=2.18, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 66.80batch/s, accuracy=29.5, grad_norm=1.86, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.17batch/s, accuracy=29.8, grad_norm=2.03, loss=1.65] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:10<00:00, 81.83batch/s, accuracy=30.1, grad_norm=2.15, loss=1.65] \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 107.49batch/s, accuracy=30.1, grad_norm=2.44, loss=1.64] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 106.49batch/s, accuracy=30.3, grad_norm=2.33, loss=1.64] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 104.83batch/s, accuracy=30.4, grad_norm=5.22, loss=1.64] \n",
      "Epoch 25/200: 100%|██████████| 900/900 [00:10<00:00, 87.21batch/s, accuracy=30.5, grad_norm=2.98, loss=1.64]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 22.35%\n",
      "SNR=-30 完成: Avg Val=21.89%, Avg Test=21.44%\n",
      "\n",
      "===== 开始 SNR=-35 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 70.69batch/s, accuracy=23.4, grad_norm=4.45, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.84batch/s, accuracy=25.9, grad_norm=3.34, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 70.01batch/s, accuracy=26.6, grad_norm=2.09, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:13<00:00, 69.08batch/s, accuracy=27.2, grad_norm=2.55, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=27.6, grad_norm=2.62, loss=1.69] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 66.06batch/s, accuracy=27.5, grad_norm=1.53, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.30batch/s, accuracy=27.8, grad_norm=1.85, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 67.19batch/s, accuracy=27.8, grad_norm=2.04, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:09<00:00, 94.01batch/s, accuracy=28.1, grad_norm=2.48, loss=1.68]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 106.69batch/s, accuracy=28.2, grad_norm=1.75, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 105.20batch/s, accuracy=28.4, grad_norm=1.62, loss=1.68] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 19.45%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 106.95batch/s, accuracy=23.1, grad_norm=5.68, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:08<00:00, 104.29batch/s, accuracy=25.4, grad_norm=2.99, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 102.48batch/s, accuracy=26.5, grad_norm=2.28, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 105.02batch/s, accuracy=26.9, grad_norm=2.82, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 106.33batch/s, accuracy=27.2, grad_norm=2.16, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 107.42batch/s, accuracy=27.4, grad_norm=2.13, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 97.06batch/s, accuracy=27.6, grad_norm=2.7, loss=1.69]   \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 70.89batch/s, accuracy=27.7, grad_norm=1.46, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 67.01batch/s, accuracy=28.3, grad_norm=2.34, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:13<00:00, 64.85batch/s, accuracy=28.4, grad_norm=2.48, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 72.30batch/s, accuracy=28.7, grad_norm=1.77, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 71.47batch/s, accuracy=28.8, grad_norm=1.97, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 72.55batch/s, accuracy=29, grad_norm=2.36, loss=1.67]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 67.86batch/s, accuracy=29.2, grad_norm=2.39, loss=1.66] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:14<00:00, 63.39batch/s, accuracy=29.4, grad_norm=2.31, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 66.71batch/s, accuracy=29.3, grad_norm=1.87, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.04batch/s, accuracy=29.3, grad_norm=1.85, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 72.98batch/s, accuracy=29.5, grad_norm=1.62, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 66.88batch/s, accuracy=29.5, grad_norm=2.08, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 69.33batch/s, accuracy=29.4, grad_norm=1.7, loss=1.66]  \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:08<00:00, 100.05batch/s, accuracy=30, grad_norm=2.28, loss=1.65]   \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 104.90batch/s, accuracy=30.1, grad_norm=2.08, loss=1.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 22.05%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 105.28batch/s, accuracy=23.6, grad_norm=5.29, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:09<00:00, 93.23batch/s, accuracy=25.8, grad_norm=3.12, loss=1.72]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 66.91batch/s, accuracy=26.8, grad_norm=2.54, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.63batch/s, accuracy=27, grad_norm=1.96, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 69.01batch/s, accuracy=27.4, grad_norm=2.01, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:13<00:00, 68.55batch/s, accuracy=27.7, grad_norm=2.03, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 71.18batch/s, accuracy=27.8, grad_norm=2.68, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 69.96batch/s, accuracy=28, grad_norm=2.77, loss=1.68]   \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 69.08batch/s, accuracy=27.9, grad_norm=1.7, loss=1.68]  \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 69.36batch/s, accuracy=28.3, grad_norm=1.78, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:09<00:00, 92.33batch/s, accuracy=28.8, grad_norm=2.24, loss=1.67]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 105.89batch/s, accuracy=28.9, grad_norm=1.91, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 102.06batch/s, accuracy=29.2, grad_norm=1.5, loss=1.67]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 103.46batch/s, accuracy=29, grad_norm=1.84, loss=1.67]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 20.97%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 70.02batch/s, accuracy=23.7, grad_norm=4.94, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.49batch/s, accuracy=26, grad_norm=4.08, loss=1.72]   \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 73.61batch/s, accuracy=26.6, grad_norm=2.7, loss=1.71]  \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:14<00:00, 63.07batch/s, accuracy=27.5, grad_norm=2.85, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.97batch/s, accuracy=27.4, grad_norm=2.1, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.61batch/s, accuracy=27.7, grad_norm=2.37, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 69.05batch/s, accuracy=28, grad_norm=2.32, loss=1.69]   \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 68.66batch/s, accuracy=27.9, grad_norm=1.9, loss=1.69]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:14<00:00, 60.99batch/s, accuracy=28.2, grad_norm=2.18, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:15<00:00, 59.97batch/s, accuracy=28.2, grad_norm=1.37, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:11<00:00, 75.53batch/s, accuracy=28.9, grad_norm=1.69, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 107.59batch/s, accuracy=29, grad_norm=2.09, loss=1.67]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 107.24batch/s, accuracy=28.8, grad_norm=2.6, loss=1.67]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 102.86batch/s, accuracy=29.1, grad_norm=2.37, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:08<00:00, 101.70batch/s, accuracy=29.3, grad_norm=1.89, loss=1.67] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 22.02%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 66.35batch/s, accuracy=23.2, grad_norm=4.75, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 69.80batch/s, accuracy=25.4, grad_norm=3.03, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 71.18batch/s, accuracy=26.7, grad_norm=2.41, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.73batch/s, accuracy=27, grad_norm=2.13, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=27.1, grad_norm=1.98, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.54batch/s, accuracy=27.4, grad_norm=2.3, loss=1.69]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 65.69batch/s, accuracy=27.5, grad_norm=3.5, loss=1.69]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 68.54batch/s, accuracy=27.7, grad_norm=2.12, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 68.48batch/s, accuracy=27.9, grad_norm=1.97, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 70.05batch/s, accuracy=28, grad_norm=1.57, loss=1.68]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:11<00:00, 78.91batch/s, accuracy=28.7, grad_norm=2.04, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 108.29batch/s, accuracy=28.7, grad_norm=2.3, loss=1.67]  \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 103.15batch/s, accuracy=28.7, grad_norm=1.71, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:08<00:00, 104.13batch/s, accuracy=28.8, grad_norm=2.09, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:10<00:00, 83.87batch/s, accuracy=29.1, grad_norm=2.16, loss=1.67]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.88batch/s, accuracy=29, grad_norm=1.85, loss=1.66]   \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 72.58batch/s, accuracy=29, grad_norm=2.43, loss=1.66]   \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:12<00:00, 73.29batch/s, accuracy=29.1, grad_norm=3.65, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 21.08%\n",
      "SNR=-35 完成: Avg Val=20.09%, Avg Test=21.12%\n",
      "\n",
      "===== 开始 SNR=-40 dB 实验 =====\n",
      "数据集已应用IQ差分处理\n",
      "数据集已应用IQ差分处理\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:13<00:00, 64.85batch/s, accuracy=23.1, grad_norm=4.65, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.99batch/s, accuracy=25.7, grad_norm=3.45, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 70.63batch/s, accuracy=26.5, grad_norm=2.43, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 100.92batch/s, accuracy=27, grad_norm=2.57, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 106.60batch/s, accuracy=27.3, grad_norm=2.1, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:08<00:00, 104.05batch/s, accuracy=27.4, grad_norm=2.05, loss=1.7]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:08<00:00, 108.08batch/s, accuracy=27.4, grad_norm=2.32, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 100.62batch/s, accuracy=27.8, grad_norm=2.24, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 106.16batch/s, accuracy=27.8, grad_norm=1.76, loss=1.69] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 107.36batch/s, accuracy=28.1, grad_norm=2.66, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 107.35batch/s, accuracy=28.7, grad_norm=1.95, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 109.50batch/s, accuracy=28.8, grad_norm=2.22, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:08<00:00, 110.04batch/s, accuracy=29, grad_norm=2.25, loss=1.67]   \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:11<00:00, 78.28batch/s, accuracy=29, grad_norm=1.57, loss=1.67]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 1 Test Accuracy: 20.07%\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.72batch/s, accuracy=23.4, grad_norm=5.28, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:13<00:00, 67.01batch/s, accuracy=25.7, grad_norm=3.56, loss=1.72] \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:12<00:00, 69.69batch/s, accuracy=26.3, grad_norm=2.99, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 70.35batch/s, accuracy=26.7, grad_norm=2.86, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 66.57batch/s, accuracy=27.4, grad_norm=1.97, loss=1.7]  \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 71.00batch/s, accuracy=27.2, grad_norm=2.01, loss=1.69] \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:10<00:00, 84.67batch/s, accuracy=27.6, grad_norm=1.83, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:08<00:00, 102.85batch/s, accuracy=27.5, grad_norm=2.1, loss=1.69]  \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:08<00:00, 104.79batch/s, accuracy=28.1, grad_norm=2.74, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 105.21batch/s, accuracy=28, grad_norm=2.54, loss=1.68]   \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:10<00:00, 85.32batch/s, accuracy=28.4, grad_norm=1.76, loss=1.67]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:12<00:00, 70.41batch/s, accuracy=28.8, grad_norm=1.75, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:12<00:00, 71.47batch/s, accuracy=28.6, grad_norm=1.97, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.46batch/s, accuracy=28.9, grad_norm=2.01, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:13<00:00, 68.26batch/s, accuracy=29, grad_norm=1.62, loss=1.66]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 2 Test Accuracy: 19.95%\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:12<00:00, 69.51batch/s, accuracy=23.3, grad_norm=4.77, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:12<00:00, 71.06batch/s, accuracy=25.8, grad_norm=2.9, loss=1.72]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:11<00:00, 75.71batch/s, accuracy=26.6, grad_norm=2.51, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 109.39batch/s, accuracy=27, grad_norm=2.36, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 108.76batch/s, accuracy=27.2, grad_norm=2.5, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 97.65batch/s, accuracy=27.4, grad_norm=1.98, loss=1.69]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:09<00:00, 98.24batch/s, accuracy=27.7, grad_norm=2.53, loss=1.69]  \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:12<00:00, 71.60batch/s, accuracy=27.4, grad_norm=1.86, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:12<00:00, 74.09batch/s, accuracy=27.9, grad_norm=1.78, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 71.99batch/s, accuracy=28.1, grad_norm=1.88, loss=1.68]  \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 69.43batch/s, accuracy=28.8, grad_norm=1.96, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 66.40batch/s, accuracy=29, grad_norm=1.48, loss=1.67]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.99batch/s, accuracy=28.8, grad_norm=1.54, loss=1.67] \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 71.25batch/s, accuracy=28.9, grad_norm=2.18, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 72.53batch/s, accuracy=29, grad_norm=1.87, loss=1.66]   \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:13<00:00, 68.96batch/s, accuracy=29.4, grad_norm=2.11, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 73.28batch/s, accuracy=29.3, grad_norm=2.16, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 104.42batch/s, accuracy=29.3, grad_norm=2.15, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:08<00:00, 102.84batch/s, accuracy=29.5, grad_norm=2.42, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 3 Test Accuracy: 22.00%\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 102.47batch/s, accuracy=23.3, grad_norm=5.35, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:10<00:00, 82.59batch/s, accuracy=25.9, grad_norm=3.53, loss=1.72]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:13<00:00, 66.62batch/s, accuracy=26.6, grad_norm=2.98, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:12<00:00, 69.45batch/s, accuracy=27, grad_norm=2.15, loss=1.7]    \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:13<00:00, 67.54batch/s, accuracy=27.1, grad_norm=2.9, loss=1.7]   \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:12<00:00, 70.14batch/s, accuracy=27.4, grad_norm=1.94, loss=1.7]   \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:12<00:00, 70.53batch/s, accuracy=27.8, grad_norm=2.63, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 67.67batch/s, accuracy=27.8, grad_norm=1.42, loss=1.69] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:11<00:00, 75.45batch/s, accuracy=28, grad_norm=1.91, loss=1.68]   \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:08<00:00, 108.26batch/s, accuracy=28.1, grad_norm=1.45, loss=1.68] \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:08<00:00, 108.82batch/s, accuracy=28.8, grad_norm=1.6, loss=1.67]  \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:08<00:00, 103.20batch/s, accuracy=29, grad_norm=1.99, loss=1.67]   \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:09<00:00, 97.99batch/s, accuracy=28.9, grad_norm=1.63, loss=1.67]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:13<00:00, 66.41batch/s, accuracy=29, grad_norm=2.35, loss=1.67]   \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:12<00:00, 71.05batch/s, accuracy=29.2, grad_norm=1.92, loss=1.66] \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:12<00:00, 70.69batch/s, accuracy=29.3, grad_norm=2.53, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:12<00:00, 71.77batch/s, accuracy=29.4, grad_norm=2.72, loss=1.66]  \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:13<00:00, 68.53batch/s, accuracy=29.5, grad_norm=2.69, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:13<00:00, 65.39batch/s, accuracy=29.7, grad_norm=2.11, loss=1.66] \n",
      "Epoch 20/200: 100%|██████████| 900/900 [00:12<00:00, 70.30batch/s, accuracy=29.6, grad_norm=1.69, loss=1.66] \n",
      "Epoch 21/200: 100%|██████████| 900/900 [00:09<00:00, 97.26batch/s, accuracy=30.3, grad_norm=1.95, loss=1.65]  \n",
      "Epoch 22/200: 100%|██████████| 900/900 [00:08<00:00, 103.16batch/s, accuracy=30.3, grad_norm=2.27, loss=1.65] \n",
      "Epoch 23/200: 100%|██████████| 900/900 [00:08<00:00, 104.34batch/s, accuracy=30.4, grad_norm=2.25, loss=1.64] \n",
      "Epoch 24/200: 100%|██████████| 900/900 [00:08<00:00, 107.95batch/s, accuracy=30.4, grad_norm=2.13, loss=1.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 4 Test Accuracy: 22.01%\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 900/900 [00:08<00:00, 108.52batch/s, accuracy=23.2, grad_norm=4.95, loss=1.75] \n",
      "Epoch 2/200: 100%|██████████| 900/900 [00:09<00:00, 99.36batch/s, accuracy=25.5, grad_norm=3.41, loss=1.72]  \n",
      "Epoch 3/200: 100%|██████████| 900/900 [00:08<00:00, 103.60batch/s, accuracy=26.7, grad_norm=2.64, loss=1.71] \n",
      "Epoch 4/200: 100%|██████████| 900/900 [00:08<00:00, 104.34batch/s, accuracy=26.9, grad_norm=2.83, loss=1.7]  \n",
      "Epoch 5/200: 100%|██████████| 900/900 [00:08<00:00, 107.70batch/s, accuracy=27.4, grad_norm=1.96, loss=1.69] \n",
      "Epoch 6/200: 100%|██████████| 900/900 [00:09<00:00, 97.69batch/s, accuracy=27.3, grad_norm=2.27, loss=1.69]  \n",
      "Epoch 7/200: 100%|██████████| 900/900 [00:13<00:00, 66.98batch/s, accuracy=27.6, grad_norm=2.33, loss=1.69] \n",
      "Epoch 8/200: 100%|██████████| 900/900 [00:13<00:00, 65.81batch/s, accuracy=27.8, grad_norm=2.48, loss=1.68] \n",
      "Epoch 9/200: 100%|██████████| 900/900 [00:13<00:00, 66.46batch/s, accuracy=27.7, grad_norm=2.21, loss=1.68] \n",
      "Epoch 10/200: 100%|██████████| 900/900 [00:12<00:00, 73.42batch/s, accuracy=28, grad_norm=1.81, loss=1.68]    \n",
      "Epoch 11/200: 100%|██████████| 900/900 [00:12<00:00, 71.09batch/s, accuracy=28.8, grad_norm=2.42, loss=1.67] \n",
      "Epoch 12/200: 100%|██████████| 900/900 [00:13<00:00, 66.02batch/s, accuracy=28.8, grad_norm=2.87, loss=1.67] \n",
      "Epoch 13/200: 100%|██████████| 900/900 [00:13<00:00, 68.01batch/s, accuracy=28.8, grad_norm=1.9, loss=1.67]  \n",
      "Epoch 14/200: 100%|██████████| 900/900 [00:12<00:00, 72.07batch/s, accuracy=28.9, grad_norm=1.86, loss=1.67] \n",
      "Epoch 15/200: 100%|██████████| 900/900 [00:09<00:00, 95.77batch/s, accuracy=29.3, grad_norm=1.89, loss=1.66]  \n",
      "Epoch 16/200: 100%|██████████| 900/900 [00:08<00:00, 103.68batch/s, accuracy=29.1, grad_norm=2.11, loss=1.66] \n",
      "Epoch 17/200: 100%|██████████| 900/900 [00:08<00:00, 104.04batch/s, accuracy=29.2, grad_norm=1.73, loss=1.66] \n",
      "Epoch 18/200: 100%|██████████| 900/900 [00:08<00:00, 106.25batch/s, accuracy=29.2, grad_norm=2.61, loss=1.66] \n",
      "Epoch 19/200: 100%|██████████| 900/900 [00:12<00:00, 69.41batch/s, accuracy=29.4, grad_norm=1.71, loss=1.66] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Fold 5 Test Accuracy: 21.27%\n",
      "SNR=-40 完成: Avg Val=20.70%, Avg Test=21.06%\n",
      "\n",
      "===== 所有 SNR 实验完成 =====\n",
      "SNR=20 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-28_22-28-17_wisig_DCTF_SNR20dB_fd266_classes_6_ResNet18\n",
      "SNR=15 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-28_22-56-23_wisig_DCTF_SNR15dB_fd266_classes_6_ResNet18\n",
      "SNR=10 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-28_23-27-11_wisig_DCTF_SNR10dB_fd266_classes_6_ResNet18\n",
      "SNR=5 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-28_23-59-30_wisig_DCTF_SNR5dB_fd266_classes_6_ResNet18\n",
      "SNR=0 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_00-23-45_wisig_DCTF_SNR0dB_fd266_classes_6_ResNet18\n",
      "SNR=-5 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_00-56-46_wisig_DCTF_SNR-5dB_fd266_classes_6_ResNet18\n",
      "SNR=-10 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_01-33-03_wisig_DCTF_SNR-10dB_fd266_classes_6_ResNet18\n",
      "SNR=-15 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_02-00-16_wisig_DCTF_SNR-15dB_fd266_classes_6_ResNet18\n",
      "SNR=-20 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_02-20-57_wisig_DCTF_SNR-20dB_fd266_classes_6_ResNet18\n",
      "SNR=-25 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_02-39-30_wisig_DCTF_SNR-25dB_fd266_classes_6_ResNet18\n",
      "SNR=-30 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_02-59-42_wisig_DCTF_SNR-30dB_fd266_classes_6_ResNet18\n",
      "SNR=-35 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_03-23-29_wisig_DCTF_SNR-35dB_fd266_classes_6_ResNet18\n",
      "SNR=-40 结果保存在: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2025-11-29_03-40-07_wisig_DCTF_SNR-40dB_fd266_classes_6_ResNet18\n"
     ]
    }
   ],
   "source": [
    "# Manysig SNR循环实验 ResNet 6TX 跨日期\n",
    "# === 导入必要库 ===\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from data_utilities import *\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# === 数据加载和预处理 ===\n",
    "dataset_name = 'ManySig'\n",
    "dataset_path='../ManySig.pkl/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "print(\"数据集发射机数量：\",len(compact_dataset['tx_list']),\"具体为：\",compact_dataset['tx_list'])\n",
    "print(\"数据集接收机数量：\",len(compact_dataset['rx_list']),\"具体为：\",compact_dataset['rx_list'])\n",
    "print(\"数据集采集天数：\",len(compact_dataset['capture_date_list']),\"具体为：\",compact_dataset['capture_date_list'])\n",
    "\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "\n",
    "train_dates = ['2021_03_15']\n",
    "test_dates  = ['2021_03_01']\n",
    "equalized = 0\n",
    "\n",
    "X_train, y_train, X_test, y_test = preprocess_dataset_for_classification_cross_date(\n",
    "    compact_dataset, tx_list, rx_list, train_dates, test_dates, max_sig=None, equalized=equalized)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape)\n",
    "print(\"y_test  shape:\", y_test.shape)\n",
    "\n",
    "# === 信号处理参数 ===\n",
    "fs = 20e6\n",
    "fc = 2.4e9\n",
    "v = 120\n",
    "Add_noise = True\n",
    "Add_doppler = True\n",
    "Add_diff = True\n",
    "\n",
    "def compute_doppler_shift(v, fc):\n",
    "    c = 3e8\n",
    "    v = v / 3.6\n",
    "    return (v / c) * fc\n",
    "\n",
    "fd = compute_doppler_shift(v, fc)\n",
    "\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    num_samples = signal.shape[-1]\n",
    "    t = np.arange(num_samples) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "def add_iq_differential(signal):\n",
    "    \"\"\"\n",
    "    对IQ信号进行差分处理\n",
    "    输入: 复数信号数组\n",
    "    输出: 差分后的复数信号数组（长度减1）\n",
    "    \"\"\"\n",
    "    # 对复数信号进行一阶差分\n",
    "    diff_signal = np.diff(signal)\n",
    "    return diff_signal\n",
    "def measure_snr(clean_signal, noisy_signal):\n",
    "    signal_power = np.mean(np.abs(clean_signal) ** 2)\n",
    "    noise = noisy_signal - clean_signal\n",
    "    noise_power = np.mean(np.abs(noise) ** 2)\n",
    "    if noise_power == 0:\n",
    "        return float('inf')\n",
    "    return 10 * np.log10(signal_power / noise_power)\n",
    "\n",
    "def add_complex_awgn(signal, snr_db):\n",
    "    signal_power = np.mean(np.abs(signal) ** 2)\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = signal_power / snr_linear\n",
    "    noise_std = np.sqrt(noise_power / 2)\n",
    "    noise = np.random.normal(0, noise_std, signal.shape) + 1j*np.random.normal(0, noise_std, signal.shape)\n",
    "    return signal + noise, noise\n",
    "\n",
    "def preprocess_iq_data(data_real_imag, snr_db=None, fd=None, fs=None, add_noise=True, add_diff=True, add_doppler=True, verify_snr=True):\n",
    "    if add_noise and snr_db is None:\n",
    "        raise ValueError(\"当add_noise=True时，必须提供snr_db参数\")\n",
    "    if add_doppler and (fd is None or fs is None):\n",
    "        raise ValueError(\"当add_doppler=True时，必须提供fd和fs参数\")\n",
    "    if add_noise:\n",
    "        print(\"数据集已应用IQ差分处理\")\n",
    "        \n",
    "    data_complex = data_real_imag[...,0] + 1j*data_real_imag[...,1]\n",
    "    processed = []\n",
    "    snr_measured_list = []\n",
    "    for i, sig in enumerate(data_complex):\n",
    "        # 原始信号归一化\n",
    "        sig = sig / (np.sqrt(np.mean(np.abs(sig)**2)) + 1e-12)\n",
    "        current_sig = sig.copy()\n",
    "        if add_diff:\n",
    "            diff_sig = add_iq_differential(current_sig)\n",
    "            current_sig = diff_sig\n",
    "        if add_doppler:\n",
    "            current_sig = add_doppler_shift(current_sig, fd, fs)\n",
    "        if add_noise:\n",
    "            noisy_sig, _ = add_complex_awgn(current_sig, snr_db)\n",
    "            current_sig = noisy_sig\n",
    "            if verify_snr:\n",
    "                measured_snr = measure_snr(sig, noisy_sig)\n",
    "                snr_measured_list.append(measured_snr)\n",
    "        processed.append(current_sig)\n",
    "    processed = np.array(processed)\n",
    "    processed_real_imag = np.stack([processed.real, processed.imag], axis=-1)\n",
    "    return processed_real_imag, None\n",
    "\n",
    "# === ResNet 1D 模型定义 ===\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# === 训练超参数 ===\n",
    "batch_size   = 64\n",
    "num_epochs   = 200\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "in_planes    = 64\n",
    "dropout      = 0.5\n",
    "patience     = 5\n",
    "n_splits     = 5\n",
    "num_classes  = len(np.unique(y_train))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def compute_grad_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            total_norm += (p.grad.data.norm(2).item() ** 2)\n",
    "    return total_norm ** 0.5\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "# === SNR 循环 ===\n",
    "snr_list = list(range(20, -45, -5))  # 20,15,...,-40\n",
    "all_results = {}\n",
    "\n",
    "for SNR_dB in snr_list:\n",
    "    print(f\"\\n===== 开始 SNR={SNR_dB} dB 实验 =====\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    script_name = \"wisig_DCTF\"\n",
    "    folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{int(fd)}_classes_{num_classes}_ResNet18\"\n",
    "    save_folder = os.path.join(os.getcwd(), \"training_results\", folder_name)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    results_file = os.path.join(save_folder, \"results.txt\")\n",
    "    with open(results_file, \"w\") as f:\n",
    "        f.write(f\"=== Experiment Summary ===\\n\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "        f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "        f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "        f.write(f\"equalized: {equalized}\\n\")\n",
    "        f.write(f\"diff:{Add_diff}\\n\")\n",
    "        f.write(f\"训练集所选日期: {train_dates}\")\n",
    "        f.write(f\"测试集所选日期：{test_dates}\")\n",
    "\n",
    "    # === 数据处理 ===\n",
    "    X_train_processed, _ = preprocess_iq_data(\n",
    "        X_train, snr_db=SNR_dB, fd=fd, fs=fs, add_noise=Add_noise, add_diff=Add_diff, add_doppler=Add_doppler, verify_snr=False\n",
    "    )\n",
    "    X_test_processed, _ = preprocess_iq_data(\n",
    "        X_test, snr_db=SNR_dB, fd=fd, fs=fs, add_noise=Add_noise, add_diff=Add_diff, add_doppler=Add_doppler, verify_snr=False\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train_processed,dtype=torch.float32),\n",
    "                                  torch.tensor(y_train,dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test_processed,dtype=torch.float32),\n",
    "                                 torch.tensor(y_test,dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    test_results = []\n",
    "    avg_grad_norms_per_fold = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "        print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
    "        train_subset = Subset(train_dataset, train_idx)\n",
    "        val_subset = Subset(train_dataset, val_idx)\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        model = ResNet18_1D(num_classes=num_classes, in_planes=in_planes, dropout=dropout).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        train_accuracies, val_accuracies = [], []\n",
    "        grad_norms = []\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "            batch_grad_norms = []\n",
    "            with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "                for inputs, labels in tepoch:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    grad_norm = compute_grad_norm(model)\n",
    "                    batch_grad_norms.append(grad_norm)\n",
    "                    optimizer.step()\n",
    "                    running_train_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total_train += labels.size(0)\n",
    "                    correct_train += (predicted == labels).sum().item()\n",
    "                    tepoch.set_postfix(loss=running_train_loss/len(train_loader),\n",
    "                                       accuracy=100*correct_train/total_train,\n",
    "                                       grad_norm=grad_norm)\n",
    "\n",
    "            epoch_train_loss = running_train_loss/len(train_loader)\n",
    "            train_losses.append(epoch_train_loss)\n",
    "            train_accuracies.append(100*correct_train/total_train)\n",
    "            avg_grad_norm = np.mean(batch_grad_norms)\n",
    "            grad_norms.append(avg_grad_norm)\n",
    "\n",
    "            # 验证\n",
    "            model.eval()\n",
    "            running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_labels)\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    _, val_predicted = torch.max(val_outputs, 1)\n",
    "                    total_val += val_labels.size(0)\n",
    "                    correct_val += (val_predicted == val_labels).sum().item()\n",
    "            epoch_val_loss = running_val_loss / len(val_loader)\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accuracies.append(100*correct_val/total_val)\n",
    "\n",
    "            with open(results_file,'a') as f:\n",
    "                f.write(f\"Fold{fold+1} Epoch{epoch+1} | TrainAcc={train_accuracies[-1]:.2f}% | ValAcc={val_accuracies[-1]:.2f}% | \"\n",
    "                        f\"TrainLoss={train_losses[-1]:.4f} | ValLoss={val_losses[-1]:.4f} | AvgGrad={avg_grad_norm:.4f}\\n\")\n",
    "\n",
    "            if epoch_val_loss < best_val_loss:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            scheduler.step()\n",
    "\n",
    "        fold_results.append(max(val_accuracies))\n",
    "        avg_grad_norms_per_fold.append(grad_norms)\n",
    "\n",
    "        # 绘图\n",
    "        plt.figure()\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.plot(moving_average(train_losses), label='Train Loss Smooth', linestyle='--')\n",
    "        plt.plot(moving_average(val_losses), label='Val Loss Smooth', linestyle='--')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Fold {fold+1} Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_loss_curve.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(grad_norms, label='Grad Norm')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Grad Norm')\n",
    "        plt.title(f'Fold {fold+1} Grad Norm')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_grad_norm.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # 测试集评估\n",
    "        model.eval()\n",
    "        test_preds, test_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for test_inputs, test_labels in test_loader:\n",
    "                test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "                test_outputs = model(test_inputs)\n",
    "                _, predicted = torch.max(test_outputs, 1)\n",
    "                test_preds.extend(predicted.cpu().numpy())\n",
    "                test_true.extend(test_labels.cpu().numpy())\n",
    "        test_preds = np.array(test_preds)\n",
    "        test_true = np.array(test_true)\n",
    "        test_accuracy = 100*np.sum(test_preds==test_true)/len(test_true)\n",
    "        test_results.append(test_accuracy)\n",
    "\n",
    "        print(f\"Fold {fold+1} Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(f\"Fold {fold+1} Test Acc: {test_accuracy:.2f}%\\n\")\n",
    "\n",
    "        cm = confusion_matrix(test_true, test_preds)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Fold {fold+1} Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_confusion_matrix.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    avg_val = np.mean(fold_results)\n",
    "    avg_test = np.mean(test_results)\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(f\"\\n=== SNR={SNR_dB} Summary ===\\n\")\n",
    "        f.write(f\"Avg Val Acc: {avg_val:.2f}%, Avg Test Acc: {avg_test:.2f}%\\n\")\n",
    "    print(f\"SNR={SNR_dB} 完成: Avg Val={avg_val:.2f}%, Avg Test={avg_test:.2f}%\")\n",
    "    all_results[SNR_dB] = save_folder\n",
    "\n",
    "print(\"\\n===== 所有 SNR 实验完成 =====\")\n",
    "for snr, folder in all_results.items():\n",
    "    print(f\"SNR={snr} 结果保存在: {folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from  data_utilities import *\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # 引入垃圾回收模块\n",
    "from tqdm.auto import tqdm  # 自动适配环境 导入tqdm进度条库\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_name = 'ManySig'\n",
    "dataset_path='../ManySig.pkl/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "print(\"数据集发射机数量：\",len(compact_dataset['tx_list']),\"具体为：\",compact_dataset['tx_list'])\n",
    "print(\"数据集接收机数量：\",len(compact_dataset['rx_list']),\"具体为：\",compact_dataset['rx_list'])\n",
    "print(\"数据集采集天数：\",len(compact_dataset['capture_date_list']),\"具体为：\",compact_dataset['capture_date_list'])\n",
    "\n",
    "\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "equalized = 0\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "\n",
    "\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "print(n_tx,n_rx)\n",
    "\n",
    "\n",
    "train_dates = ['2021_03_01', '2021_03_08', '2021_03_15']  # 设定你想用的训练日期\n",
    "X_train, y_train, X_test, y_test = preprocess_dataset_for_classification(\n",
    "    compact_dataset, tx_list, rx_list, train_dates, max_sig=None, equalized = equalized, use_phase_differential=True)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  # (num_blocks, 256, 250, 2)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# === 参数设置 ===\n",
    "SNR_dB = 10           # 信噪比\n",
    "fs = 20e6             # 采样率 (Hz)\n",
    "fc = 2.4e9            # 载波频率 (Hz)\n",
    "v = 120               # 速度 (km/h)\n",
    "Add_noise = True     # 是否添加噪声\n",
    "Add_doppler = True   # 是否添加多普勒频移\n",
    "Add_diff = True      # 是否进行差分\n",
    "\n",
    "# === 多普勒频移计算 ===\n",
    "def compute_doppler_shift(v, fc):\n",
    "    c = 3e8  # 光速\n",
    "    v = v / 3.6 # 转换为m/s\n",
    "    return (v / c) * fc\n",
    "\n",
    "fd = compute_doppler_shift(v, fc)\n",
    "print(f\"[INFO] 多普勒频移 fd = {fd:.2f} Hz\")\n",
    "\n",
    "# === 多普勒变换 ===\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    num_samples = signal.shape[-1]\n",
    "    t = np.arange(num_samples) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "# === SNR测量函数 ===\n",
    "def measure_snr(clean_signal, noisy_signal):\n",
    "    \"\"\"\n",
    "    测量实际SNR\n",
    "    \"\"\"\n",
    "    signal_power = np.mean(np.abs(clean_signal) ** 2)\n",
    "    noise = noisy_signal - clean_signal\n",
    "    noise_power = np.mean(np.abs(noise) ** 2)\n",
    "    \n",
    "    if noise_power == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    snr_measured = 10 * np.log10(signal_power / noise_power)\n",
    "    return snr_measured\n",
    "\n",
    "# === 复数AWGN噪声添加函数 ===\n",
    "def add_complex_awgn(signal, snr_db):\n",
    "    \"\"\"\n",
    "    为复数信号添加AWGN噪声\n",
    "    \"\"\"\n",
    "    # 计算信号功率\n",
    "    signal_power = np.mean(np.abs(signal) ** 2)\n",
    "    \n",
    "    # 计算噪声功率\n",
    "    snr_linear = 10 ** (snr_db / 10)\n",
    "    noise_power = signal_power / snr_linear\n",
    "    \n",
    "    # 生成复数噪声（实部和虚部独立，各占一半功率）\n",
    "    noise_std = np.sqrt(noise_power / 2)\n",
    "    noise_real = np.random.normal(0, noise_std, signal.shape)\n",
    "    noise_imag = np.random.normal(0, noise_std, signal.shape)\n",
    "    noise = noise_real + 1j * noise_imag\n",
    "    \n",
    "    return signal + noise, noise\n",
    "\n",
    "# === IQ信号差分处理 ===\n",
    "def add_iq_differential(signal):\n",
    "    \"\"\"\n",
    "    对IQ信号进行差分处理\n",
    "    输入: 复数信号数组\n",
    "    输出: 差分后的复数信号数组（长度减1）\n",
    "    \"\"\"\n",
    "    # 对复数信号进行一阶差分\n",
    "    diff_signal = np.diff(signal)\n",
    "    return diff_signal\n",
    "\n",
    "# === 带验证的预处理函数 ===\n",
    "def preprocess_iq_data(data_real_imag, snr_db=None, fd=None, fs=None, \n",
    "                       add_noise=True, add_diff=True, add_doppler=True, verify_snr=True):\n",
    "    \"\"\"\n",
    "    预处理IQ数据：可选择性地添加噪声和多普勒频移\n",
    "    \n",
    "    参数:\n",
    "    - data_real_imag: 输入数据，shape (N, T, 2)\n",
    "    - snr_db: 目标信噪比(dB)，当add_noise=True时必需\n",
    "    - fd: 多普勒频移(Hz)，当add_doppler=True时必需\n",
    "    - fs: 采样率(Hz)，当add_doppler=True时必需\n",
    "    - add_noise: 是否添加噪声 (默认True)\n",
    "    - add_doppler: 是否添加多普勒频移 (默认True)\n",
    "    - verify_snr: 是否验证SNR (仅当add_noise=True时有效)\n",
    "    \n",
    "    返回:\n",
    "    - processed_real_imag: 处理后的数据，shape (N, T, 2)\n",
    "    - snr_info: SNR验证信息（如果verify_snr=True且add_noise=True）\n",
    "    \"\"\"\n",
    "    # 参数检查\n",
    "    if add_noise and snr_db is None:\n",
    "        raise ValueError(\"当add_noise=True时，必须提供snr_db参数\")\n",
    "    \n",
    "    if add_doppler and (fd is None or fs is None):\n",
    "        raise ValueError(\"当add_doppler=True时，必须提供fd和fs参数\")\n",
    "    \n",
    "    if Add_diff:\n",
    "        print(\"应用IQ差分处理\")\n",
    "    \n",
    "    # Step 1: 转为复数 IQ，shape: (N, T, 2) → (N, T)\n",
    "    data_complex = data_real_imag[..., 0] + 1j * data_real_imag[..., 1]\n",
    "\n",
    "    processed = []\n",
    "    snr_measured_list = []\n",
    "    \n",
    "    for i, sig in enumerate(data_complex):\n",
    "        current_sig = sig.copy()\n",
    "        \n",
    "        # Step 2: 添加 AWGN 噪声（可选）\n",
    "        if add_noise:\n",
    "            noisy_sig, noise = add_complex_awgn(current_sig, snr_db)\n",
    "            current_sig = noisy_sig\n",
    "            \n",
    "            # SNR验证（可选）\n",
    "            if verify_snr:\n",
    "                measured_snr = measure_snr(sig, noisy_sig)\n",
    "                snr_measured_list.append(measured_snr)\n",
    "                \n",
    "                # 每10000个样本打印一次进度\n",
    "                if i % 10000 == 0 and i > 0:\n",
    "                    avg_snr = np.mean(snr_measured_list[-10000:])\n",
    "                    print(f\"[验证] 样本 {i}, 平均实测SNR: {avg_snr:.2f} dB\")\n",
    "        \n",
    "        # Step 3: 添加多普勒频移（可选）\n",
    "        if add_doppler:\n",
    "            shifted = add_doppler_shift(current_sig, fd, fs)\n",
    "            current_sig = shifted\n",
    "        \n",
    "        # 应用IQ差分\n",
    "        if Add_diff:\n",
    "            diffed = add_iq_differential(current_sig)\n",
    "            current_sig = diffed\n",
    "\n",
    "        processed.append(current_sig)\n",
    "\n",
    "    processed = np.array(processed)\n",
    "    \n",
    "    # Step 4: 转回 [I, Q] 实数格式\n",
    "    processed_real_imag = np.stack([processed.real, processed.imag], axis=-1)\n",
    "    \n",
    "    # SNR验证总结（仅当添加噪声且启用验证时）\n",
    "    snr_info = None\n",
    "    if add_noise and verify_snr and snr_measured_list:\n",
    "        snr_measured_array = np.array(snr_measured_list)\n",
    "        snr_info = {\n",
    "            'target_snr': snr_db,\n",
    "            'measured_mean': np.mean(snr_measured_array),\n",
    "            'measured_std': np.std(snr_measured_array),\n",
    "            'measured_min': np.min(snr_measured_array),\n",
    "            'measured_max': np.max(snr_measured_array),\n",
    "            'samples_count': len(snr_measured_array)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n=== SNR验证结果 ===\")\n",
    "        print(f\"目标SNR: {snr_info['target_snr']} dB\")\n",
    "        print(f\"实测平均SNR: {snr_info['measured_mean']:.2f} dB\")\n",
    "        print(f\"实测标准差: {snr_info['measured_std']:.2f} dB\")\n",
    "        print(f\"实测范围: [{snr_info['measured_min']:.2f}, {snr_info['measured_max']:.2f}] dB\")\n",
    "        print(f\"验证样本数: {snr_info['samples_count']}\")\n",
    "    \n",
    "    return processed_real_imag, snr_info\n",
    "\n",
    "# === 单样本测试函数 ===\n",
    "def test_single_sample_snr(data_real_imag, snr_db, num_tests=10):\n",
    "    \"\"\"\n",
    "    对单个样本进行多次SNR测试，确保噪声添加的正确性\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== 单样本SNR测试 (测试{num_tests}次) ===\")\n",
    "    \n",
    "    # 取第一个样本\n",
    "    sample_complex = data_real_imag[0, :, 0] + 1j * data_real_imag[0, :, 1]\n",
    "    \n",
    "    measured_snrs = []\n",
    "    for i in range(num_tests):\n",
    "        noisy_sample, _ = add_complex_awgn(sample_complex, snr_db)\n",
    "        measured_snr = measure_snr(sample_complex, noisy_sample)\n",
    "        measured_snrs.append(measured_snr)\n",
    "        print(f\"测试 {i+1}: 目标SNR={snr_db} dB, 实测SNR={measured_snr:.2f} dB\")\n",
    "    \n",
    "    measured_snrs = np.array(measured_snrs)\n",
    "    print(f\"\\n测试统计:\")\n",
    "    print(f\"平均值: {np.mean(measured_snrs):.2f} dB\")\n",
    "    print(f\"标准差: {np.std(measured_snrs):.2f} dB\")\n",
    "    print(f\"误差范围: ±{np.abs(np.mean(measured_snrs) - snr_db):.2f} dB\")\n",
    "\n",
    "# === 使用示例 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设 X_train, X_test 已定义\n",
    "    \n",
    "    # 使用全局变量控制处理选项\n",
    "    X_train_processed, _ = preprocess_iq_data(\n",
    "        X_train, snr_db=SNR_dB, fd=fd, fs=fs, \n",
    "        add_noise=Add_noise, add_diff=Add_diff, add_doppler=Add_doppler, verify_snr=False\n",
    "    )\n",
    "    \n",
    "    # 单样本测试（只有当Add_noise=True时才有意义）\n",
    "    if Add_noise:\n",
    "        test_single_sample_snr(X_train, SNR_dB, num_tests=5)\n",
    "    else:\n",
    "        print(\"\\n=== 跳过单样本SNR测试（未启用噪声添加）===\")\n",
    "    \n",
    "    # 处理测试集（可以根据需要设置不同的选项）\n",
    "    print(f\"\\n=== 处理测试集 ===\")\n",
    "    X_test_processed, test_snr_info = preprocess_iq_data(\n",
    "        X_test, snr_db=SNR_dB, fd=fd, fs=fs, \n",
    "        add_noise=Add_noise, add_diff=Add_diff, add_doppler=Add_doppler, verify_snr=False\n",
    "    )\n",
    "    \n",
    "    # 查看处理前后前10个点\n",
    "    print(f\"\\n=== 信号对比 ===\")\n",
    "    print(\"原始信号 I 分量：\", X_train[0, :10, 0])\n",
    "    print(\"处理后信号 I 分量：\", X_train_processed[0, :10, 0])\n",
    "    \n",
    "    # 验证多普勒频移效果（只有当Add_doppler=True时才有意义）\n",
    "    if Add_doppler:\n",
    "        print(f\"\\n=== 多普勒频移验证 ===\")\n",
    "        original_phase = np.angle(X_train[0, :10, 0] + 1j * X_train[0, :10, 1])\n",
    "        processed_phase = np.angle(X_train_processed[0, :10, 0] + 1j * X_train_processed[0, :10, 1])\n",
    "        phase_diff = processed_phase - original_phase\n",
    "        print(\"相位变化:\", phase_diff)\n",
    "    else:\n",
    "        print(f\"\\n=== 跳过多普勒频移验证（未启用多普勒频移）===\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# 假设 SNR_dB 和 fd 已经定义\n",
    "SNR_dB = globals().get('SNR_dB', 'no')\n",
    "fd = globals().get('fd', 'no')\n",
    "\n",
    "# === 模型与训练参数设置 ===\n",
    "raw_input_dim = 2         # 每个时间步是 I/Q 两个值\n",
    "model_dim = 128           # Transformer 模型内部维度\n",
    "num_heads = 4\n",
    "num_layers = 3\n",
    "num_classes = len(np.unique(y_train))  # 或 len(tx_list)\n",
    "dropout = 0.1\n",
    "batch_size = 512\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "patience = 5\n",
    "\n",
    "# === 创建保存目录 ===\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "script_name = \"wisig_DCTF\"\n",
    "folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{fd}_classes_{num_classes}_Transformer\"\n",
    "save_folder = os.path.join(os.getcwd(), \"training_results\", folder_name)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "results_file = os.path.join(save_folder, \"results.txt\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    f.write(f\"=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "    f.write(f\"equalized: {equalized}\\n\")\n",
    "\n",
    "# === 模型定义 ===\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(raw_input_dim, model_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# === 假设 X_train, y_train, X_test, y_test 都已定义并 shape 为 (N, L, 2) ===\n",
    "# 若还未定义，可自行加载并 reshape\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_processed, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.long))\n",
    "\n",
    "# === K折交叉验证训练 ===\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "test_results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def compute_grad_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    return total_norm ** 0.5\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "avg_grad_norms_per_fold = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"\\n====== Fold {fold+1}/{n_splits} ======\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = SignalTransformer(raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    grad_norms = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        batch_grad_norms = []\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "            for inputs, labels in tepoch:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                grad_norm = compute_grad_norm(model)\n",
    "                batch_grad_norms.append(grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "                tepoch.set_postfix(loss=running_train_loss / (len(train_loader)),\n",
    "                                   accuracy=100 * correct_train / total_train,\n",
    "                                   grad_norm=grad_norm)\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(100 * correct_train / total_train)\n",
    "        avg_grad_norm = np.mean(batch_grad_norms)\n",
    "        grad_norms.append(avg_grad_norm)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Average Gradient Norm: {avg_grad_norm:.4f}\")\n",
    "\n",
    "        # === 验证 ===\n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(100 * correct_val / total_val)\n",
    "\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch+1} | Train Acc: {train_accuracies[-1]:.2f}% | Val Acc: {val_accuracies[-1]:.2f}%\\n\")\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    fold_results.append(max(val_accuracies))\n",
    "    avg_grad_norms_per_fold.append(grad_norms)\n",
    "\n",
    "    # === 绘制 loss 曲线 ===\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.plot(moving_average(train_losses), label='Train Loss (Smooth)', linestyle='--')\n",
    "    plt.plot(moving_average(val_losses), label='Val Loss (Smooth)', linestyle='--')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {fold+1} Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # === 绘制 Gradient Norm 曲线 ===\n",
    "    plt.figure()\n",
    "    plt.plot(grad_norms, label='Gradient Norm')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.title(f'Fold {fold+1} Gradient Norm')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_grad_norm.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # === 测试集评估 ===\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs = test_inputs.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "\n",
    "            test_outputs = model(test_inputs)\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            test_true.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_preds = np.array(test_preds)\n",
    "    test_true = np.array(test_true)\n",
    "    test_accuracy = 100.0 * np.sum(test_preds == test_true) / len(test_true)\n",
    "    test_results.append(test_accuracy)\n",
    "\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(f\"Fold {fold+1} Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
    "\n",
    "    cm = confusion_matrix(test_true, test_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Test Confusion Matrix Fold {fold+1}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_test_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# === 总结结果 ===\n",
    "avg_val = np.mean(fold_results)\n",
    "avg_test = np.mean(test_results)\n",
    "\n",
    "with open(results_file, \"a\") as f:\n",
    "    f.write(\"\\n=== Summary ===\\n\")\n",
    "    for i in range(n_splits):\n",
    "        f.write(f\"Fold {i+1}: Val Acc = {fold_results[i]:.2f}%, Test Acc = {test_results[i]:.2f}%\\n\")\n",
    "    f.write(f\"\\nAverage Validation Accuracy: {avg_val:.2f}%\\n\")\n",
    "    f.write(f\"Average Test Accuracy: {avg_test:.2f}%\\n\")\n",
    "\n",
    "print(\"\\n=== Final Summary ===\")\n",
    "for i in range(n_splits):\n",
    "    print(f\"Fold {i+1}: Val = {fold_results[i]:.2f}%, Test = {test_results[i]:.2f}%\")\n",
    "print(f\"Average Val Accuracy: {avg_val:.2f}%\")\n",
    "print(f\"Average Test Accuracy: {avg_test:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
