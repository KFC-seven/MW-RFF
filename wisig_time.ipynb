{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09fffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集发射机数量： 6 具体为： ['14-10', '14-7', '20-15', '20-19', '6-15', '8-20']\n",
      "数据集接收机数量： 12 具体为： ['1-1', '1-19', '14-7', '18-2', '19-2', '2-1', '2-19', '20-1', '3-19', '7-14', '7-7', '8-8']\n",
      "数据集采集天数： 4 具体为： ['2021_03_01', '2021_03_08', '2021_03_15', '2021_03_23']\n",
      "6 12\n",
      "✅ 训练样本数: 216000, 测试样本数: 72000\n",
      "X_train shape: (216000, 256, 2)\n",
      "y_train shape: (216000,)\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from  data_utilities import *\n",
    "import cv2  # OpenCV 用于调整图像大小和颜色处理\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # 引入垃圾回收模块\n",
    "from tqdm.auto import tqdm  # 自动适配环境 导入tqdm进度条库\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_name = 'ManySig'\n",
    "dataset_path='../ManySig.pkl/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "print(\"数据集发射机数量：\",len(compact_dataset['tx_list']),\"具体为：\",compact_dataset['tx_list'])\n",
    "print(\"数据集接收机数量：\",len(compact_dataset['rx_list']),\"具体为：\",compact_dataset['rx_list'])\n",
    "print(\"数据集采集天数：\",len(compact_dataset['capture_date_list']),\"具体为：\",compact_dataset['capture_date_list'])\n",
    "\n",
    "\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "equalized = 0\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "\n",
    "\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "print(n_tx,n_rx)\n",
    "\n",
    "\n",
    "train_dates = ['2021_03_01', '2021_03_08', '2021_03_15']  # 设定你想用的训练日期\n",
    "X_train, y_train, X_test, y_test = preprocess_dataset_for_classification(\n",
    "    compact_dataset, tx_list, rx_list, train_dates, max_sig=None, equalized = equalized)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)  # (num_blocks, 256, 250, 2)\n",
    "print(\"y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a1bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 多普勒频移 fd = 960.00 Hz\n",
      "原始信号 I 分量： [ 0.00445568 -0.00589004 -0.0109866   0.01052883  0.01196319 -0.00201421\n",
      " -0.00106814 -0.00387583 -0.01409948  0.000824  ]\n",
      "处理后信号 I 分量： [ 0.00218009 -0.00354658 -0.01052414  0.00091308  0.02281909 -0.00102891\n",
      " -0.00206321 -0.00131955 -0.01368751 -0.00507219]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# === 参数设置 ===\n",
    "SNR_dB = 10           # 信噪比\n",
    "fs = 20e6             # 采样率 (Hz)\n",
    "fc = 2.4e9            # 载波频率 (Hz)\n",
    "v = 120               # 速度 (m/s)\n",
    "\n",
    "# === 多普勒频移计算 ===\n",
    "def compute_doppler_shift(v, fc):\n",
    "    c = 3e8  # 光速\n",
    "    return (v / c) * fc\n",
    "\n",
    "fd = compute_doppler_shift(v, fc)\n",
    "print(f\"[INFO] 多普勒频移 fd = {fd:.2f} Hz\")\n",
    "\n",
    "# === 多普勒变换 ===\n",
    "def add_doppler_shift(signal, fd, fs):\n",
    "    num_samples = signal.shape[-1]\n",
    "    t = np.arange(num_samples) / fs\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "# === 加噪声 + 多普勒 的主流程 ===\n",
    "def preprocess_iq_data(data_real_imag, snr_db, fd, fs):\n",
    "    # Step 1: 转为复数 IQ，shape: (N, T, 2) → (N, T)\n",
    "    data_complex = data_real_imag[..., 0] + 1j * data_real_imag[..., 1]\n",
    "\n",
    "    processed = []\n",
    "    for sig in data_complex:\n",
    "        # Step 2: 添加 AWGN 噪声\n",
    "        signal_std = np.std(sig)\n",
    "        noise_std = signal_std / (10 ** (snr_db / 20))\n",
    "        noise = np.random.normal(0, noise_std, sig.shape) + 1j * np.random.normal(0, noise_std, sig.shape)\n",
    "        noisy = sig + noise\n",
    "\n",
    "        # Step 3: 添加多普勒频移\n",
    "        shifted = add_doppler_shift(noisy, fd, fs)\n",
    "\n",
    "        processed.append(shifted)\n",
    "\n",
    "    processed = np.array(processed)  # shape: (N, T), complex\n",
    "\n",
    "    # Step 4: 转回 [I, Q] 实数格式\n",
    "    processed_real_imag = np.stack([processed.real, processed.imag], axis=-1)  # shape: (N, T, 2)\n",
    "\n",
    "    return processed_real_imag\n",
    "\n",
    "\n",
    "X_train_processed = preprocess_iq_data(X_train, snr_db=SNR_dB, fd=fd, fs=fs)\n",
    "X_test_processed  = preprocess_iq_data(X_test,  snr_db=SNR_dB, fd=fd, fs=fs)\n",
    "\n",
    "# 查看处理前后前10个点\n",
    "print(\"原始信号 I 分量：\", X_train[0, :10, 0])\n",
    "print(\"处理后信号 I 分量：\", X_train_processed[0, :10, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b0d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "====== Fold 1/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 337/337 [01:09<00:00,  4.87batch/s, accuracy=21.3, grad_norm=4.51, loss=1.74]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Gradient Norm: 1.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 337/337 [01:02<00:00,  5.43batch/s, accuracy=31.1, grad_norm=3.32, loss=1.59]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Gradient Norm: 4.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 337/337 [01:08<00:00,  4.92batch/s, accuracy=35.6, grad_norm=9.29, loss=1.51]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Gradient Norm: 5.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 337/337 [01:12<00:00,  4.63batch/s, accuracy=40, grad_norm=11.9, loss=1.43]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Gradient Norm: 8.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 337/337 [01:16<00:00,  4.43batch/s, accuracy=43.4, grad_norm=9.18, loss=1.35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Gradient Norm: 9.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 337/337 [01:16<00:00,  4.43batch/s, accuracy=46.2, grad_norm=12.7, loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Gradient Norm: 12.4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 337/337 [01:16<00:00,  4.39batch/s, accuracy=48.5, grad_norm=4.82, loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Gradient Norm: 14.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 337/337 [01:17<00:00,  4.34batch/s, accuracy=50.2, grad_norm=6.29, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Gradient Norm: 14.3769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 337/337 [01:18<00:00,  4.30batch/s, accuracy=51.7, grad_norm=5.46, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Gradient Norm: 15.6338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 337/337 [01:16<00:00,  4.41batch/s, accuracy=53.1, grad_norm=13, loss=1.13]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Gradient Norm: 17.1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 337/337 [01:16<00:00,  4.40batch/s, accuracy=55.2, grad_norm=15.8, loss=1.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Gradient Norm: 12.7828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 337/337 [01:17<00:00,  4.34batch/s, accuracy=55.8, grad_norm=18.2, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Gradient Norm: 17.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 337/337 [01:17<00:00,  4.34batch/s, accuracy=56.6, grad_norm=17.9, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Gradient Norm: 16.8391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 337/337 [01:17<00:00,  4.36batch/s, accuracy=57.1, grad_norm=24.3, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Gradient Norm: 19.2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 337/337 [01:18<00:00,  4.27batch/s, accuracy=57.9, grad_norm=6.86, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Gradient Norm: 16.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 337/337 [01:24<00:00,  3.98batch/s, accuracy=58.1, grad_norm=12.2, loss=1.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Gradient Norm: 18.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 337/337 [01:24<00:00,  3.97batch/s, accuracy=58.5, grad_norm=22.1, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Gradient Norm: 18.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 337/337 [01:25<00:00,  3.95batch/s, accuracy=58.9, grad_norm=23.5, loss=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Gradient Norm: 18.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 337/337 [01:24<00:00,  3.97batch/s, accuracy=59.2, grad_norm=9.54, loss=0.998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Gradient Norm: 19.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 337/337 [01:21<00:00,  4.14batch/s, accuracy=59.4, grad_norm=25.4, loss=0.992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Gradient Norm: 20.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 337/337 [01:22<00:00,  4.11batch/s, accuracy=60.4, grad_norm=14.4, loss=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Gradient Norm: 14.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 337/337 [01:20<00:00,  4.16batch/s, accuracy=60.6, grad_norm=24.7, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Gradient Norm: 15.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 337/337 [01:20<00:00,  4.21batch/s, accuracy=60.6, grad_norm=18.9, loss=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Gradient Norm: 16.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 337/337 [01:21<00:00,  4.13batch/s, accuracy=60.6, grad_norm=6.74, loss=0.965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Gradient Norm: 16.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 337/337 [01:14<00:00,  4.55batch/s, accuracy=60.9, grad_norm=30.8, loss=0.959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Gradient Norm: 15.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 337/337 [01:16<00:00,  4.38batch/s, accuracy=61, grad_norm=16.6, loss=0.96]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Gradient Norm: 17.4715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 337/337 [01:17<00:00,  4.34batch/s, accuracy=61.2, grad_norm=21.6, loss=0.954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Gradient Norm: 16.6809\n",
      "Early stopping\n",
      "\n",
      "====== Fold 2/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 337/337 [01:17<00:00,  4.36batch/s, accuracy=18, grad_norm=0.922, loss=1.79]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Gradient Norm: 0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 337/337 [01:17<00:00,  4.35batch/s, accuracy=30.2, grad_norm=4.91, loss=1.6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Gradient Norm: 4.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 337/337 [01:18<00:00,  4.27batch/s, accuracy=35.7, grad_norm=1.72, loss=1.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Gradient Norm: 4.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 337/337 [01:16<00:00,  4.43batch/s, accuracy=41.3, grad_norm=4.46, loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Gradient Norm: 7.5779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 337/337 [01:13<00:00,  4.58batch/s, accuracy=45, grad_norm=4.44, loss=1.32]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Gradient Norm: 9.0596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 337/337 [01:16<00:00,  4.40batch/s, accuracy=47.4, grad_norm=15.8, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Gradient Norm: 9.0986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 337/337 [01:16<00:00,  4.39batch/s, accuracy=48.9, grad_norm=8.56, loss=1.22] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Gradient Norm: 10.1137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 337/337 [01:16<00:00,  4.39batch/s, accuracy=50.4, grad_norm=16.8, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Gradient Norm: 10.2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 337/337 [01:17<00:00,  4.35batch/s, accuracy=51.3, grad_norm=4.41, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Gradient Norm: 11.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 337/337 [01:17<00:00,  4.33batch/s, accuracy=52.6, grad_norm=12.9, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Gradient Norm: 12.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 337/337 [01:18<00:00,  4.29batch/s, accuracy=54.7, grad_norm=11.6, loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Gradient Norm: 10.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 337/337 [01:03<00:00,  5.27batch/s, accuracy=55.5, grad_norm=13.7, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Gradient Norm: 12.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=56.5, grad_norm=9.54, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Gradient Norm: 11.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=57.1, grad_norm=12.6, loss=1.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Gradient Norm: 12.3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=57.9, grad_norm=13.7, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Gradient Norm: 15.1021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=58.4, grad_norm=18.2, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Gradient Norm: 15.8090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=59.2, grad_norm=19.9, loss=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Gradient Norm: 17.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=59.5, grad_norm=21.9, loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Gradient Norm: 19.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=60.3, grad_norm=13.7, loss=0.975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Gradient Norm: 20.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=60.8, grad_norm=31.9, loss=0.965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Gradient Norm: 25.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=62.4, grad_norm=46, loss=0.933]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Gradient Norm: 19.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=62.8, grad_norm=11.6, loss=0.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Gradient Norm: 22.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=63.2, grad_norm=14.8, loss=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Gradient Norm: 26.7069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 337/337 [01:00<00:00,  5.62batch/s, accuracy=63.8, grad_norm=25.3, loss=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Gradient Norm: 30.7398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=63.9, grad_norm=24.5, loss=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Gradient Norm: 34.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=64.6, grad_norm=6.7, loss=0.883] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Gradient Norm: 34.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=65, grad_norm=37.3, loss=0.872]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Gradient Norm: 35.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=65.4, grad_norm=24.3, loss=0.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Gradient Norm: 39.9141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=65.8, grad_norm=19.6, loss=0.855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Gradient Norm: 43.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=66.3, grad_norm=17.7, loss=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Gradient Norm: 42.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=66.9, grad_norm=92.3, loss=0.83] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Gradient Norm: 37.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=67.3, grad_norm=88.7, loss=0.823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Gradient Norm: 43.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=67.3, grad_norm=85.2, loss=0.819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Gradient Norm: 45.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=67.5, grad_norm=71.8, loss=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Gradient Norm: 45.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=67.7, grad_norm=117, loss=0.809] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Gradient Norm: 38.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=68, grad_norm=34.8, loss=0.807]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Gradient Norm: 44.9280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=68.2, grad_norm=61.5, loss=0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Gradient Norm: 44.6442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=68.2, grad_norm=27.6, loss=0.798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Gradient Norm: 45.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=68.5, grad_norm=61.5, loss=0.794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Gradient Norm: 43.4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=68.6, grad_norm=97.8, loss=0.79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Gradient Norm: 48.0723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=69, grad_norm=36.9, loss=0.78]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Gradient Norm: 38.3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=69.1, grad_norm=23.3, loss=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Gradient Norm: 36.4150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=69.1, grad_norm=22, loss=0.778]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Gradient Norm: 41.3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=69.2, grad_norm=95.2, loss=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Gradient Norm: 43.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=69.4, grad_norm=39.7, loss=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Gradient Norm: 38.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=69.5, grad_norm=42.1, loss=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Gradient Norm: 42.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=69.6, grad_norm=47.7, loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Gradient Norm: 42.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=69.5, grad_norm=74.5, loss=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Gradient Norm: 46.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=69.8, grad_norm=22.2, loss=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Gradient Norm: 45.4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=69.8, grad_norm=16.5, loss=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Gradient Norm: 43.9134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=69.9, grad_norm=67, loss=0.758]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Average Gradient Norm: 33.7863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=70.1, grad_norm=85.4, loss=0.755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Average Gradient Norm: 35.1751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.2, grad_norm=26.3, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Average Gradient Norm: 34.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.2, grad_norm=27.4, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Average Gradient Norm: 39.2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=70.2, grad_norm=79, loss=0.754]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Average Gradient Norm: 37.8157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=70.2, grad_norm=22.4, loss=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Average Gradient Norm: 38.2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.3, grad_norm=13.5, loss=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Average Gradient Norm: 38.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.4, grad_norm=44.7, loss=0.749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Average Gradient Norm: 35.4943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.3, grad_norm=33.4, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Average Gradient Norm: 44.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=70.4, grad_norm=13.8, loss=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Average Gradient Norm: 39.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.5, grad_norm=23.9, loss=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Average Gradient Norm: 34.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.6, grad_norm=38.6, loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Average Gradient Norm: 32.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.6, grad_norm=19.2, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Average Gradient Norm: 33.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.7, grad_norm=23.8, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Average Gradient Norm: 34.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.7, grad_norm=30.9, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Average Gradient Norm: 36.3472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.7, grad_norm=32.5, loss=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Average Gradient Norm: 37.1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.8, grad_norm=19.5, loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Average Gradient Norm: 31.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=70.8, grad_norm=27.4, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Average Gradient Norm: 34.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.8, grad_norm=44.7, loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Average Gradient Norm: 33.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.7, grad_norm=37.4, loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Average Gradient Norm: 34.9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=70.9, grad_norm=32.7, loss=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Average Gradient Norm: 31.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=70.9, grad_norm=32.1, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Average Gradient Norm: 32.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.9, grad_norm=34.7, loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Average Gradient Norm: 32.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.9, grad_norm=19.4, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Average Gradient Norm: 34.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.9, grad_norm=71.7, loss=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Average Gradient Norm: 30.6504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=70.8, grad_norm=11, loss=0.738]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Average Gradient Norm: 31.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=70.8, grad_norm=34.6, loss=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Average Gradient Norm: 30.1578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=42.7, loss=0.735]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Average Gradient Norm: 33.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.9, grad_norm=39.9, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Average Gradient Norm: 33.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=21.8, loss=0.736]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Average Gradient Norm: 31.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=71.1, grad_norm=18.7, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Average Gradient Norm: 29.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=28, loss=0.735]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Average Gradient Norm: 29.7575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.9, grad_norm=11.8, loss=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Average Gradient Norm: 31.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=71, grad_norm=45.7, loss=0.735]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Average Gradient Norm: 28.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=71.2, grad_norm=17.7, loss=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Average Gradient Norm: 30.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 337/337 [01:00<00:00,  5.56batch/s, accuracy=71.1, grad_norm=29.5, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Average Gradient Norm: 30.2130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=70.9, grad_norm=30.1, loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Average Gradient Norm: 31.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=39.7, loss=0.734]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Average Gradient Norm: 29.9301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=71, grad_norm=10.9, loss=0.735]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Average Gradient Norm: 31.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=70.9, grad_norm=16.8, loss=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Average Gradient Norm: 31.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71.1, grad_norm=9.7, loss=0.734] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Average Gradient Norm: 29.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 337/337 [01:00<00:00,  5.56batch/s, accuracy=71.1, grad_norm=31.2, loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Average Gradient Norm: 29.6149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=71, grad_norm=32.6, loss=0.734]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Average Gradient Norm: 28.3345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71.2, grad_norm=30.6, loss=0.733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Average Gradient Norm: 28.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=71, grad_norm=10.4, loss=0.733]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Average Gradient Norm: 30.6085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=71.1, grad_norm=39.5, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Average Gradient Norm: 28.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=28.9, loss=0.734]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Average Gradient Norm: 29.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=71.2, grad_norm=16.8, loss=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Average Gradient Norm: 29.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=71, grad_norm=21.8, loss=0.733]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Average Gradient Norm: 27.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=71.1, grad_norm=20.4, loss=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Average Gradient Norm: 29.4694\n",
      "\n",
      "====== Fold 3/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=20.4, grad_norm=2.65, loss=1.76]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Gradient Norm: 1.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=31.5, grad_norm=7.58, loss=1.58]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Gradient Norm: 4.4236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=36.6, grad_norm=7.97, loss=1.49]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Gradient Norm: 5.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=41.1, grad_norm=13.4, loss=1.4]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Gradient Norm: 7.9146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=44.4, grad_norm=9.58, loss=1.34] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Gradient Norm: 10.4024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=46.3, grad_norm=24.9, loss=1.29] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Gradient Norm: 13.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=48.1, grad_norm=16.5, loss=1.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Gradient Norm: 12.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=49.3, grad_norm=10.5, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Gradient Norm: 14.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=50.5, grad_norm=8.67, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Gradient Norm: 13.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=51.3, grad_norm=11.9, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Gradient Norm: 14.1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=53.2, grad_norm=13.5, loss=1.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Gradient Norm: 11.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=53.5, grad_norm=17.5, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Gradient Norm: 13.8433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=54.2, grad_norm=6.63, loss=1.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Gradient Norm: 12.8265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=54.8, grad_norm=12.2, loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Gradient Norm: 13.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=55.3, grad_norm=3.67, loss=1.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Gradient Norm: 13.8452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=55.6, grad_norm=16.4, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Gradient Norm: 14.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=56.3, grad_norm=6.7, loss=1.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Gradient Norm: 14.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=56.7, grad_norm=17.4, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Gradient Norm: 14.5440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=57.1, grad_norm=23.3, loss=1.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Gradient Norm: 13.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=57.4, grad_norm=14.3, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Gradient Norm: 14.0721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=58.3, grad_norm=19, loss=1.02]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Gradient Norm: 12.6375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=58.5, grad_norm=11.3, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Gradient Norm: 11.4094\n",
      "Early stopping\n",
      "\n",
      "====== Fold 4/5 ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=19.2, grad_norm=1.29, loss=1.77]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Gradient Norm: 1.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=32, grad_norm=1.69, loss=1.57]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Average Gradient Norm: 2.2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=37.9, grad_norm=6.1, loss=1.47]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Average Gradient Norm: 3.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=42.6, grad_norm=3.82, loss=1.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Average Gradient Norm: 4.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=45.4, grad_norm=4.64, loss=1.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Average Gradient Norm: 6.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=47.4, grad_norm=5.16, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Average Gradient Norm: 6.6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=48.8, grad_norm=5.19, loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Average Gradient Norm: 8.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 337/337 [01:00<00:00,  5.62batch/s, accuracy=50.1, grad_norm=18.3, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Average Gradient Norm: 8.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=51.2, grad_norm=21.9, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Average Gradient Norm: 9.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=52.2, grad_norm=8.46, loss=1.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Average Gradient Norm: 11.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=54.2, grad_norm=5.84, loss=1.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Average Gradient Norm: 8.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=54.6, grad_norm=10.9, loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Average Gradient Norm: 10.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=55.2, grad_norm=14.9, loss=1.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Average Gradient Norm: 11.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=55.9, grad_norm=10.6, loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Average Gradient Norm: 10.5746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=56.4, grad_norm=10.2, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Average Gradient Norm: 11.6035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=56.8, grad_norm=11.4, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Average Gradient Norm: 12.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=57.2, grad_norm=19, loss=1.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Average Gradient Norm: 11.9586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=57.7, grad_norm=28.1, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Average Gradient Norm: 12.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=58, grad_norm=7.38, loss=1.02]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Average Gradient Norm: 13.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=58.5, grad_norm=7.71, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Average Gradient Norm: 13.6282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=59.3, grad_norm=8.28, loss=0.996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Average Gradient Norm: 9.8665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=59.5, grad_norm=18.7, loss=0.991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Average Gradient Norm: 11.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 337/337 [01:00<00:00,  5.61batch/s, accuracy=60, grad_norm=6.13, loss=0.983]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Average Gradient Norm: 11.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=60.2, grad_norm=8.6, loss=0.98]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Average Gradient Norm: 12.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=60.5, grad_norm=24.9, loss=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Average Gradient Norm: 15.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=60.9, grad_norm=26.8, loss=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Average Gradient Norm: 16.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=61.4, grad_norm=6.21, loss=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Average Gradient Norm: 17.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=62, grad_norm=18.3, loss=0.943]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Average Gradient Norm: 20.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=62.5, grad_norm=51, loss=0.931]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Average Gradient Norm: 24.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=63, grad_norm=26.1, loss=0.922]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Average Gradient Norm: 28.9767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=63.6, grad_norm=23.1, loss=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Average Gradient Norm: 24.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=63.9, grad_norm=15.8, loss=0.897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Average Gradient Norm: 27.5734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=64.2, grad_norm=48.6, loss=0.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Average Gradient Norm: 26.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 337/337 [00:59<00:00,  5.62batch/s, accuracy=64.2, grad_norm=18.5, loss=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Average Gradient Norm: 36.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=64.5, grad_norm=22.6, loss=0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Average Gradient Norm: 32.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=64.6, grad_norm=60.7, loss=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Average Gradient Norm: 38.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=64.9, grad_norm=46.1, loss=0.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Average Gradient Norm: 34.3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=64.8, grad_norm=13, loss=0.88]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Average Gradient Norm: 41.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=65, grad_norm=71.4, loss=0.876]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Average Gradient Norm: 38.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 337/337 [01:00<00:00,  5.57batch/s, accuracy=65.1, grad_norm=31.2, loss=0.871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Average Gradient Norm: 39.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=65.4, grad_norm=7.59, loss=0.865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Average Gradient Norm: 30.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 337/337 [01:00<00:00,  5.59batch/s, accuracy=65.6, grad_norm=30.7, loss=0.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Average Gradient Norm: 29.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=65.6, grad_norm=63.3, loss=0.863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Average Gradient Norm: 31.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=65.7, grad_norm=13.1, loss=0.858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Average Gradient Norm: 30.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 337/337 [01:00<00:00,  5.58batch/s, accuracy=65.7, grad_norm=19.8, loss=0.862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Average Gradient Norm: 37.7638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 337/337 [01:00<00:00,  5.60batch/s, accuracy=65.7, grad_norm=41.5, loss=0.859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Average Gradient Norm: 33.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 337/337 [01:03<00:00,  5.29batch/s, accuracy=65.8, grad_norm=17.8, loss=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Average Gradient Norm: 31.8954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 337/337 [01:03<00:00,  5.34batch/s, accuracy=65.8, grad_norm=30.7, loss=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Average Gradient Norm: 38.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 337/337 [01:09<00:00,  4.82batch/s, accuracy=65.9, grad_norm=55.9, loss=0.855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Average Gradient Norm: 34.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 337/337 [01:10<00:00,  4.77batch/s, accuracy=66, grad_norm=11.7, loss=0.854]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Average Gradient Norm: 37.5984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 337/337 [01:12<00:00,  4.63batch/s, accuracy=66.2, grad_norm=18.2, loss=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Average Gradient Norm: 26.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 337/337 [01:14<00:00,  4.55batch/s, accuracy=66.3, grad_norm=11, loss=0.85]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Average Gradient Norm: 29.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 337/337 [01:13<00:00,  4.61batch/s, accuracy=66.1, grad_norm=21.1, loss=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Average Gradient Norm: 28.3815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 337/337 [01:13<00:00,  4.60batch/s, accuracy=66.4, grad_norm=9.96, loss=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Average Gradient Norm: 28.4419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 337/337 [01:13<00:00,  4.58batch/s, accuracy=66.4, grad_norm=68.6, loss=0.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Average Gradient Norm: 29.5374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 337/337 [01:14<00:00,  4.55batch/s, accuracy=66.2, grad_norm=8.16, loss=0.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Average Gradient Norm: 27.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 337/337 [01:15<00:00,  4.47batch/s, accuracy=66.1, grad_norm=28, loss=0.848]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Average Gradient Norm: 32.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100:  91%|█████████ | 307/337 [01:19<00:07,  3.84batch/s, accuracy=66.1, grad_norm=21.1, loss=0.771]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 132\u001b[0m\n\u001b[0;32m    129\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    130\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 132\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_grad_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m batch_grad_norms\u001b[38;5;241m.\u001b[39mappend(grad_norm)\n\u001b[0;32m    135\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[11], line 88\u001b[0m, in \u001b[0;36mcompute_grad_norm\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m         param_norm \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m         total_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mparam_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# 假设 SNR_dB 和 fd 已经定义\n",
    "SNR_dB = globals().get('SNR_dB', 'no')\n",
    "fd = globals().get('fd', 'no')\n",
    "\n",
    "# === 模型与训练参数设置 ===\n",
    "raw_input_dim = 2         # 每个时间步是 I/Q 两个值\n",
    "model_dim = 128           # Transformer 模型内部维度\n",
    "num_heads = 4\n",
    "num_layers = 3\n",
    "num_classes = len(np.unique(y_train))  # 或 len(tx_list)\n",
    "dropout = 0.1\n",
    "batch_size = 512\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "patience = 5\n",
    "\n",
    "# === 创建保存目录 ===\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "script_name = \"wisig_time\"\n",
    "folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}dB_fd{fd}_classes_{num_classes}_Transformer\"\n",
    "save_folder = os.path.join(os.getcwd(), \"training_results\", folder_name)\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "results_file = os.path.join(save_folder, \"results.txt\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    f.write(f\"=== Experiment Summary ===\\n\")\n",
    "    f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "    f.write(f\"Total Classes: {num_classes}\\n\")\n",
    "    f.write(f\"SNR: {SNR_dB} dB\\n\")\n",
    "    f.write(f\"fd (Doppler shift): {fd} Hz\\n\")\n",
    "    f.write(f\"equalized: {equalized}\\n\")\n",
    "\n",
    "# === 模型定义 ===\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(raw_input_dim, model_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# === 假设 X_train, y_train, X_test, y_test 都已定义并 shape 为 (N, L, 2) ===\n",
    "# 若还未定义，可自行加载并 reshape\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_processed, dtype=torch.float32),\n",
    "                               torch.tensor(y_train, dtype=torch.long))\n",
    "\n",
    "# === K折交叉验证训练 ===\n",
    "n_splits = 5\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "test_results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def compute_grad_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    return total_norm ** 0.5\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "avg_grad_norms_per_fold = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "    print(f\"\\n====== Fold {fold+1}/{n_splits} ======\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = SignalTransformer(raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    grad_norms = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        batch_grad_norms = []\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "            for inputs, labels in tepoch:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                grad_norm = compute_grad_norm(model)\n",
    "                batch_grad_norms.append(grad_norm)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "                tepoch.set_postfix(loss=running_train_loss / (len(train_loader)),\n",
    "                                   accuracy=100 * correct_train / total_train,\n",
    "                                   grad_norm=grad_norm)\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accuracies.append(100 * correct_train / total_train)\n",
    "        avg_grad_norm = np.mean(batch_grad_norms)\n",
    "        grad_norms.append(avg_grad_norm)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Average Gradient Norm: {avg_grad_norm:.4f}\")\n",
    "\n",
    "        # === 验证 ===\n",
    "        model.eval()\n",
    "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs = val_inputs.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "                _, val_predicted = torch.max(val_outputs, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(100 * correct_val / total_val)\n",
    "\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(f\"Epoch {epoch+1} | Train Acc: {train_accuracies[-1]:.2f}% | Val Acc: {val_accuracies[-1]:.2f}%\\n\")\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    fold_results.append(max(val_accuracies))\n",
    "    avg_grad_norms_per_fold.append(grad_norms)\n",
    "\n",
    "    # === 绘制 loss 曲线 ===\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.plot(moving_average(train_losses), label='Train Loss (Smooth)', linestyle='--')\n",
    "    plt.plot(moving_average(val_losses), label='Val Loss (Smooth)', linestyle='--')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Fold {fold+1} Loss Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # === 绘制 Gradient Norm 曲线 ===\n",
    "    plt.figure()\n",
    "    plt.plot(grad_norms, label='Gradient Norm')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Gradient Norm')\n",
    "    plt.title(f'Fold {fold+1} Gradient Norm')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_grad_norm.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # === 测试集评估 ===\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs = test_inputs.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "\n",
    "            test_outputs = model(test_inputs)\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            test_true.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_preds = np.array(test_preds)\n",
    "    test_true = np.array(test_true)\n",
    "    test_accuracy = 100.0 * np.sum(test_preds == test_true) / len(test_true)\n",
    "    test_results.append(test_accuracy)\n",
    "\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(f\"Fold {fold+1} Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
    "\n",
    "    cm = confusion_matrix(test_true, test_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Test Confusion Matrix Fold {fold+1}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(save_folder, f\"fold_{fold+1}_test_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# === 总结结果 ===\n",
    "avg_val = np.mean(fold_results)\n",
    "avg_test = np.mean(test_results)\n",
    "\n",
    "with open(results_file, \"a\") as f:\n",
    "    f.write(\"\\n=== Summary ===\\n\")\n",
    "    for i in range(n_splits):\n",
    "        f.write(f\"Fold {i+1}: Val Acc = {fold_results[i]:.2f}%, Test Acc = {test_results[i]:.2f}%\\n\")\n",
    "    f.write(f\"\\nAverage Validation Accuracy: {avg_val:.2f}%\\n\")\n",
    "    f.write(f\"Average Test Accuracy: {avg_test:.2f}%\\n\")\n",
    "\n",
    "print(\"\\n=== Final Summary ===\")\n",
    "for i in range(n_splits):\n",
    "    print(f\"Fold {i+1}: Val = {fold_results[i]:.2f}%, Test = {test_results[i]:.2f}%\")\n",
    "print(f\"Average Val Accuracy: {avg_val:.2f}%\")\n",
    "print(f\"Average Test Accuracy: {avg_test:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495844b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "=== Random Search 1/50 ===\n",
      "Params: {'model_dim': 512, 'num_heads': 4, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 0.0005, 'batch_size': 512}\n",
      "Early stopping at epoch 19\n",
      "[Result] Config 1/50 - Val Acc: 33.79%, Test Acc: 33.01%\n",
      "\n",
      "=== Random Search 2/50 ===\n",
      "Params: {'model_dim': 128, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 128}\n",
      "Early stopping at epoch 7\n",
      "[Result] Config 2/50 - Val Acc: 16.47%, Test Acc: 16.67%\n",
      "\n",
      "=== Random Search 3/50 ===\n",
      "Params: {'model_dim': 512, 'num_heads': 2, 'num_layers': 1, 'dropout': 0.3, 'learning_rate': 0.0005, 'batch_size': 512}\n",
      "Early stopping at epoch 16\n",
      "[Result] Config 3/50 - Val Acc: 36.00%, Test Acc: 33.45%\n",
      "\n",
      "=== Random Search 4/50 ===\n",
      "Params: {'model_dim': 256, 'num_heads': 8, 'num_layers': 2, 'dropout': 0.5, 'learning_rate': 0.001, 'batch_size': 256}\n",
      "Early stopping at epoch 6\n",
      "[Result] Config 4/50 - Val Acc: 16.56%, Test Acc: 16.67%\n",
      "\n",
      "=== Random Search 5/50 ===\n",
      "Params: {'model_dim': 512, 'num_heads': 2, 'num_layers': 3, 'dropout': 0.3, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Early stopping at epoch 32\n",
      "[Result] Config 5/50 - Val Acc: 43.94%, Test Acc: 44.33%\n",
      "\n",
      "=== Random Search 6/50 ===\n",
      "Params: {'model_dim': 256, 'num_heads': 8, 'num_layers': 1, 'dropout': 0.5, 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "Early stopping at epoch 23\n",
      "[Result] Config 6/50 - Val Acc: 35.73%, Test Acc: 35.52%\n",
      "\n",
      "=== Random Search 7/50 ===\n",
      "Params: {'model_dim': 128, 'num_heads': 4, 'num_layers': 3, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 512}\n",
      "Early stopping at epoch 62\n",
      "[Result] Config 7/50 - Val Acc: 71.19%, Test Acc: 62.86%\n",
      "\n",
      "=== Random Search 8/50 ===\n",
      "Params: {'model_dim': 128, 'num_heads': 8, 'num_layers': 3, 'dropout': 0.5, 'learning_rate': 0.0005, 'batch_size': 256}\n",
      "Early stopping at epoch 6\n",
      "[Result] Config 8/50 - Val Acc: 16.67%, Test Acc: 16.67%\n",
      "\n",
      "=== Random Search 9/50 ===\n",
      "Params: {'model_dim': 256, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 512}\n",
      "Early stopping at epoch 49\n",
      "[Result] Config 9/50 - Val Acc: 69.77%, Test Acc: 62.34%\n",
      "\n",
      "=== Random Search 10/50 ===\n",
      "Params: {'model_dim': 128, 'num_heads': 4, 'num_layers': 2, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 256}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 139\u001b[0m\n\u001b[0;32m    137\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m    138\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 139\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_grad_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m batch_grad_norms\u001b[38;5;241m.\u001b[39mappend(grad_norm)\n\u001b[0;32m    141\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[3], line 83\u001b[0m, in \u001b[0;36mcompute_grad_norm\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         param_norm \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m         total_norm \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mparam_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假设 SNR_dB, fd, equalized 已定义\n",
    "SNR_dB = globals().get('SNR_dB', 'no')\n",
    "fd = globals().get('fd', 'no')\n",
    "equalized = globals().get('equalized', 'no')\n",
    "\n",
    "# 假设 X_train_processed, y_train, X_test_processed, y_test 已定义\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === 模型定义 ===\n",
    "class SignalTransformer(nn.Module):\n",
    "    def __init__(self, raw_input_dim, model_dim, num_heads, num_layers, num_classes, dropout=0.1):\n",
    "        super(SignalTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(raw_input_dim, model_dim)\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(model_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# === 数据准备 ===\n",
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_processed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# 划分训练集 / 验证集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# === 参数空间 ===\n",
    "param_space = {\n",
    "    \"model_dim\": [128, 256, 512],\n",
    "    \"num_heads\": [2, 4, 8],\n",
    "    \"num_layers\": [1, 2, 3],\n",
    "    \"dropout\": [0.1, 0.3, 0.5],\n",
    "    \"learning_rate\": [1e-3, 5e-4, 1e-4],\n",
    "    \"batch_size\": [128, 256, 512]\n",
    "}\n",
    "num_search = 50  # 随机搜索次数\n",
    "patience = 5\n",
    "raw_input_dim = 2\n",
    "num_epochs = 300\n",
    "\n",
    "results_summary = []\n",
    "best_config = None\n",
    "best_val_acc = 0\n",
    "\n",
    "# 计算梯度范数\n",
    "def compute_grad_norm(model):\n",
    "    total_norm = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    return total_norm ** 0.5\n",
    "\n",
    "# 平滑曲线\n",
    "def moving_average(x, w=5):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "# === 随机搜索 ===\n",
    "for search_idx in range(num_search):\n",
    "    config = {k: random.choice(v) for k, v in param_space.items()}\n",
    "    print(f\"\\n=== Random Search {search_idx+1}/{num_search} ===\")\n",
    "    print(f\"Params: {config}\")\n",
    "\n",
    "    # 创建保存目录\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    script_name = \"wisig_time_random\"\n",
    "    folder_name = f\"{timestamp}_{script_name}_SNR{SNR_dB}\"\n",
    "    save_folder = os.path.join(\"search_results\", folder_name)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    results_file = os.path.join(save_folder, \"results.txt\")\n",
    "\n",
    "    with open(results_file, \"w\") as f:\n",
    "        f.write(f\"=== Hyperparameters ===\\n{config}\\n\")\n",
    "\n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # 模型 & 优化器\n",
    "    model = SignalTransformer(raw_input_dim, config[\"model_dim\"], config[\"num_heads\"],\n",
    "                              config[\"num_layers\"], num_classes, config[\"dropout\"]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    grad_norms = []\n",
    "\n",
    "    best_val = 0\n",
    "    patience_counter = 0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "    # 训练\n",
    "        model.train()\n",
    "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
    "        batch_grad_norms = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            grad_norm = compute_grad_norm(model)\n",
    "            batch_grad_norms.append(grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(100 * correct_train / total_train)\n",
    "        grad_norms.append(np.mean(batch_grad_norms))\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        correct_val, total_val = 0, 0\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for val_inputs, val_labels in val_loader:\n",
    "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                val_outputs = model(val_inputs)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                val_loss_sum += val_loss.item()\n",
    "                _, val_pred = torch.max(val_outputs, 1)\n",
    "                total_val += val_labels.size(0)\n",
    "                correct_val += (val_pred == val_labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_losses.append(val_loss_sum / len(val_loader))\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # 早停\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            patience_counter = 0\n",
    "            best_model_wts = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    # 恢复最佳权重\n",
    "    if best_model_wts:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # 测试集\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in test_loader:\n",
    "            test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "            test_outputs = model(test_inputs)\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            test_preds.extend(predicted.cpu().numpy())\n",
    "            test_true.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_acc = 100 * np.sum(np.array(test_preds) == np.array(test_true)) / len(test_true)\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(f\"\\nVal Acc: {val_acc:.2f}% | Test Acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "    # 控制台即时输出\n",
    "    print(f\"[Result] Config {search_idx+1}/{num_search} - Val Acc: {val_acc:.2f}%, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # 记录结果\n",
    "    results_summary.append((config, best_val, test_acc))\n",
    "    if best_val > best_val_acc:\n",
    "        best_val_acc = best_val\n",
    "        best_config = (config, test_acc)\n",
    "\n",
    "\n",
    "# === 最佳结果 ===\n",
    "print(\"\\n=== Best Hyperparameters ===\")\n",
    "print(best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
