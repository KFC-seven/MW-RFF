{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce8446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êï∞ÊçÆÈõÜÂèëÂ∞ÑÊú∫Êï∞ÈáèÔºö 6 ÂÖ∑‰Ωì‰∏∫Ôºö ['14-10', '14-7', '20-15', '20-19', '6-15', '8-20']\n",
      "Êï∞ÊçÆÈõÜÊé•Êî∂Êú∫Êï∞ÈáèÔºö 12 ÂÖ∑‰Ωì‰∏∫Ôºö ['1-1', '1-19', '14-7', '18-2', '19-2', '2-1', '2-19', '20-1', '3-19', '7-14', '7-7', '8-8']\n",
      "Êï∞ÊçÆÈõÜÈááÈõÜÂ§©Êï∞Ôºö 4 ÂÖ∑‰Ωì‰∏∫Ôºö ['2021_03_01', '2021_03_08', '2021_03_15', '2021_03_23']\n",
      "6 12\n",
      "ËÆ≠ÁªÉÈõÜÊâÄÈÄâÊó•ÊúüÔºö ['2021_03_15'] ÊµãËØïÈõÜÊâÄÈÄâÊó•ÊúüÔºö ['2021_03_01']\n",
      "X_train shape: (768000, 24, 2)\n",
      "y_train shape: (768000,)\n",
      "X_test  shape: (768000, 24, 2)\n",
      "y_test  shape: (768000,)\n",
      "Preprocessing (per-sample normalization)...\n",
      "Prepared tensors: torch.Size([768000, 24, 2]) torch.Size([768000, 24, 2]) num_classes= 6\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = 20 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=93.73% | ValAcc=95.92% | TrainLoss=0.1754 | ValLoss=0.1157 | AvgGrad=0.0905\n",
      "Epoch 2/200 | TrainAcc=96.40% | ValAcc=96.57% | TrainLoss=0.1044 | ValLoss=0.0994 | AvgGrad=0.0591\n",
      "Epoch 3/200 | TrainAcc=97.03% | ValAcc=96.93% | TrainLoss=0.0869 | ValLoss=0.0904 | AvgGrad=0.0511\n",
      "Epoch 4/200 | TrainAcc=97.44% | ValAcc=97.21% | TrainLoss=0.0744 | ValLoss=0.0830 | AvgGrad=0.0472\n",
      "Epoch 5/200 | TrainAcc=97.77% | ValAcc=97.41% | TrainLoss=0.0649 | ValLoss=0.0784 | AvgGrad=0.0452\n",
      "Epoch 6/200 | TrainAcc=98.06% | ValAcc=97.60% | TrainLoss=0.0564 | ValLoss=0.0747 | AvgGrad=0.0435\n",
      "Epoch 7/200 | TrainAcc=98.30% | ValAcc=97.59% | TrainLoss=0.0491 | ValLoss=0.0774 | AvgGrad=0.0427\n",
      "Epoch 8/200 | TrainAcc=98.49% | ValAcc=97.59% | TrainLoss=0.0429 | ValLoss=0.0780 | AvgGrad=0.0423\n",
      "Epoch 9/200 | TrainAcc=98.68% | ValAcc=97.75% | TrainLoss=0.0378 | ValLoss=0.0765 | AvgGrad=0.0418\n",
      "Epoch 10/200 | TrainAcc=98.83% | ValAcc=97.64% | TrainLoss=0.0332 | ValLoss=0.0866 | AvgGrad=0.0418\n",
      "Epoch 11/200 | TrainAcc=99.38% | ValAcc=97.98% | TrainLoss=0.0177 | ValLoss=0.0896 | AvgGrad=0.0355\n",
      "Epoch 12/200 | TrainAcc=99.54% | ValAcc=97.91% | TrainLoss=0.0132 | ValLoss=0.0989 | AvgGrad=0.0358\n",
      "Epoch 13/200 | TrainAcc=99.59% | ValAcc=97.92% | TrainLoss=0.0114 | ValLoss=0.1089 | AvgGrad=0.0361\n",
      "Epoch 14/200 | TrainAcc=99.64% | ValAcc=97.99% | TrainLoss=0.0102 | ValLoss=0.1079 | AvgGrad=0.0359\n",
      "Epoch 15/200 | TrainAcc=99.67% | ValAcc=97.96% | TrainLoss=0.0091 | ValLoss=0.1183 | AvgGrad=0.0355\n",
      "Epoch 16/200 | TrainAcc=99.69% | ValAcc=97.91% | TrainLoss=0.0085 | ValLoss=0.1242 | AvgGrad=0.0351\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 88.97%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=93.61% | ValAcc=96.05% | TrainLoss=0.1784 | ValLoss=0.1137 | AvgGrad=0.0923\n",
      "Epoch 2/200 | TrainAcc=96.31% | ValAcc=96.57% | TrainLoss=0.1060 | ValLoss=0.0984 | AvgGrad=0.0605\n",
      "Epoch 3/200 | TrainAcc=96.96% | ValAcc=97.05% | TrainLoss=0.0881 | ValLoss=0.0870 | AvgGrad=0.0521\n",
      "Epoch 4/200 | TrainAcc=97.42% | ValAcc=97.34% | TrainLoss=0.0758 | ValLoss=0.0799 | AvgGrad=0.0476\n",
      "Epoch 5/200 | TrainAcc=97.76% | ValAcc=97.42% | TrainLoss=0.0655 | ValLoss=0.0786 | AvgGrad=0.0456\n",
      "Epoch 6/200 | TrainAcc=98.04% | ValAcc=97.59% | TrainLoss=0.0574 | ValLoss=0.0747 | AvgGrad=0.0442\n",
      "Epoch 7/200 | TrainAcc=98.25% | ValAcc=97.66% | TrainLoss=0.0504 | ValLoss=0.0749 | AvgGrad=0.0435\n",
      "Epoch 8/200 | TrainAcc=98.46% | ValAcc=97.72% | TrainLoss=0.0441 | ValLoss=0.0742 | AvgGrad=0.0430\n",
      "Epoch 9/200 | TrainAcc=98.66% | ValAcc=97.72% | TrainLoss=0.0385 | ValLoss=0.0815 | AvgGrad=0.0430\n",
      "Epoch 10/200 | TrainAcc=98.81% | ValAcc=97.77% | TrainLoss=0.0340 | ValLoss=0.0795 | AvgGrad=0.0425\n",
      "Epoch 11/200 | TrainAcc=99.38% | ValAcc=98.01% | TrainLoss=0.0179 | ValLoss=0.0870 | AvgGrad=0.0367\n",
      "Epoch 12/200 | TrainAcc=99.51% | ValAcc=98.01% | TrainLoss=0.0134 | ValLoss=0.1005 | AvgGrad=0.0373\n",
      "Epoch 13/200 | TrainAcc=99.58% | ValAcc=97.96% | TrainLoss=0.0116 | ValLoss=0.1020 | AvgGrad=0.0372\n",
      "Epoch 14/200 | TrainAcc=99.64% | ValAcc=97.93% | TrainLoss=0.0101 | ValLoss=0.1078 | AvgGrad=0.0370\n",
      "Epoch 15/200 | TrainAcc=99.67% | ValAcc=97.99% | TrainLoss=0.0092 | ValLoss=0.1138 | AvgGrad=0.0359\n",
      "Epoch 16/200 | TrainAcc=99.68% | ValAcc=97.97% | TrainLoss=0.0088 | ValLoss=0.1140 | AvgGrad=0.0360\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 88.96%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=93.64% | ValAcc=95.97% | TrainLoss=0.1780 | ValLoss=0.1153 | AvgGrad=0.0912\n",
      "Epoch 2/200 | TrainAcc=96.31% | ValAcc=96.70% | TrainLoss=0.1062 | ValLoss=0.0944 | AvgGrad=0.0600\n",
      "Epoch 3/200 | TrainAcc=96.99% | ValAcc=96.91% | TrainLoss=0.0880 | ValLoss=0.0917 | AvgGrad=0.0522\n",
      "Epoch 4/200 | TrainAcc=97.44% | ValAcc=97.06% | TrainLoss=0.0759 | ValLoss=0.0856 | AvgGrad=0.0481\n",
      "Epoch 5/200 | TrainAcc=97.77% | ValAcc=97.30% | TrainLoss=0.0654 | ValLoss=0.0828 | AvgGrad=0.0462\n",
      "Epoch 6/200 | TrainAcc=98.05% | ValAcc=97.44% | TrainLoss=0.0572 | ValLoss=0.0777 | AvgGrad=0.0449\n",
      "Epoch 7/200 | TrainAcc=98.27% | ValAcc=97.49% | TrainLoss=0.0503 | ValLoss=0.0772 | AvgGrad=0.0445\n",
      "Epoch 8/200 | TrainAcc=98.50% | ValAcc=97.59% | TrainLoss=0.0435 | ValLoss=0.0784 | AvgGrad=0.0435\n",
      "Epoch 9/200 | TrainAcc=98.66% | ValAcc=97.64% | TrainLoss=0.0384 | ValLoss=0.0792 | AvgGrad=0.0433\n",
      "Epoch 10/200 | TrainAcc=98.81% | ValAcc=97.70% | TrainLoss=0.0338 | ValLoss=0.0800 | AvgGrad=0.0429\n",
      "Epoch 11/200 | TrainAcc=99.39% | ValAcc=97.90% | TrainLoss=0.0176 | ValLoss=0.0890 | AvgGrad=0.0364\n",
      "Epoch 12/200 | TrainAcc=99.53% | ValAcc=97.87% | TrainLoss=0.0133 | ValLoss=0.1022 | AvgGrad=0.0367\n",
      "Epoch 13/200 | TrainAcc=99.59% | ValAcc=97.86% | TrainLoss=0.0115 | ValLoss=0.1040 | AvgGrad=0.0370\n",
      "Epoch 14/200 | TrainAcc=99.63% | ValAcc=97.92% | TrainLoss=0.0103 | ValLoss=0.1126 | AvgGrad=0.0360\n",
      "Epoch 15/200 | TrainAcc=99.66% | ValAcc=97.85% | TrainLoss=0.0096 | ValLoss=0.1159 | AvgGrad=0.0369\n",
      "Epoch 16/200 | TrainAcc=99.70% | ValAcc=97.86% | TrainLoss=0.0086 | ValLoss=0.1202 | AvgGrad=0.0353\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 88.73%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=93.72% | ValAcc=96.00% | TrainLoss=0.1761 | ValLoss=0.1137 | AvgGrad=0.0935\n",
      "Epoch 2/200 | TrainAcc=96.37% | ValAcc=96.71% | TrainLoss=0.1045 | ValLoss=0.0952 | AvgGrad=0.0597\n",
      "Epoch 3/200 | TrainAcc=97.00% | ValAcc=96.89% | TrainLoss=0.0871 | ValLoss=0.0924 | AvgGrad=0.0514\n",
      "Epoch 4/200 | TrainAcc=97.43% | ValAcc=97.37% | TrainLoss=0.0750 | ValLoss=0.0808 | AvgGrad=0.0477\n",
      "Epoch 5/200 | TrainAcc=97.75% | ValAcc=97.44% | TrainLoss=0.0653 | ValLoss=0.0793 | AvgGrad=0.0453\n",
      "Epoch 6/200 | TrainAcc=98.03% | ValAcc=97.57% | TrainLoss=0.0570 | ValLoss=0.0756 | AvgGrad=0.0441\n",
      "Epoch 7/200 | TrainAcc=98.28% | ValAcc=97.55% | TrainLoss=0.0496 | ValLoss=0.0777 | AvgGrad=0.0428\n",
      "Epoch 8/200 | TrainAcc=98.48% | ValAcc=97.75% | TrainLoss=0.0437 | ValLoss=0.0752 | AvgGrad=0.0428\n",
      "Epoch 9/200 | TrainAcc=98.66% | ValAcc=97.74% | TrainLoss=0.0385 | ValLoss=0.0791 | AvgGrad=0.0425\n",
      "Epoch 10/200 | TrainAcc=98.80% | ValAcc=97.66% | TrainLoss=0.0336 | ValLoss=0.0840 | AvgGrad=0.0426\n",
      "Epoch 11/200 | TrainAcc=99.36% | ValAcc=97.90% | TrainLoss=0.0184 | ValLoss=0.0903 | AvgGrad=0.0365\n",
      "Epoch 12/200 | TrainAcc=99.52% | ValAcc=97.96% | TrainLoss=0.0135 | ValLoss=0.0969 | AvgGrad=0.0370\n",
      "Epoch 13/200 | TrainAcc=99.59% | ValAcc=97.94% | TrainLoss=0.0114 | ValLoss=0.1052 | AvgGrad=0.0370\n",
      "Epoch 14/200 | TrainAcc=99.63% | ValAcc=97.87% | TrainLoss=0.0103 | ValLoss=0.1189 | AvgGrad=0.0374\n",
      "Epoch 15/200 | TrainAcc=99.67% | ValAcc=97.91% | TrainLoss=0.0092 | ValLoss=0.1143 | AvgGrad=0.0364\n",
      "Epoch 16/200 | TrainAcc=99.69% | ValAcc=97.96% | TrainLoss=0.0087 | ValLoss=0.1176 | AvgGrad=0.0360\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 88.28%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=93.66% | ValAcc=96.02% | TrainLoss=0.1775 | ValLoss=0.1164 | AvgGrad=0.0920\n",
      "Epoch 2/200 | TrainAcc=96.32% | ValAcc=96.69% | TrainLoss=0.1057 | ValLoss=0.0978 | AvgGrad=0.0598\n",
      "Epoch 3/200 | TrainAcc=96.99% | ValAcc=97.10% | TrainLoss=0.0876 | ValLoss=0.0844 | AvgGrad=0.0514\n",
      "Epoch 4/200 | TrainAcc=97.42% | ValAcc=97.39% | TrainLoss=0.0750 | ValLoss=0.0778 | AvgGrad=0.0475\n",
      "Epoch 5/200 | TrainAcc=97.77% | ValAcc=97.48% | TrainLoss=0.0654 | ValLoss=0.0759 | AvgGrad=0.0451\n",
      "Epoch 6/200 | TrainAcc=98.04% | ValAcc=97.62% | TrainLoss=0.0571 | ValLoss=0.0734 | AvgGrad=0.0441\n",
      "Epoch 7/200 | TrainAcc=98.28% | ValAcc=97.66% | TrainLoss=0.0498 | ValLoss=0.0741 | AvgGrad=0.0434\n",
      "Epoch 8/200 | TrainAcc=98.48% | ValAcc=97.71% | TrainLoss=0.0439 | ValLoss=0.0742 | AvgGrad=0.0431\n",
      "Epoch 9/200 | TrainAcc=98.66% | ValAcc=97.72% | TrainLoss=0.0385 | ValLoss=0.0775 | AvgGrad=0.0425\n",
      "Epoch 10/200 | TrainAcc=98.81% | ValAcc=97.73% | TrainLoss=0.0342 | ValLoss=0.0762 | AvgGrad=0.0424\n",
      "Epoch 11/200 | TrainAcc=99.36% | ValAcc=97.96% | TrainLoss=0.0183 | ValLoss=0.0868 | AvgGrad=0.0365\n",
      "Epoch 12/200 | TrainAcc=99.53% | ValAcc=97.89% | TrainLoss=0.0133 | ValLoss=0.1022 | AvgGrad=0.0366\n",
      "Epoch 13/200 | TrainAcc=99.59% | ValAcc=97.91% | TrainLoss=0.0114 | ValLoss=0.1033 | AvgGrad=0.0373\n",
      "Epoch 14/200 | TrainAcc=99.63% | ValAcc=97.91% | TrainLoss=0.0102 | ValLoss=0.1051 | AvgGrad=0.0367\n",
      "Epoch 15/200 | TrainAcc=99.67% | ValAcc=97.85% | TrainLoss=0.0093 | ValLoss=0.1175 | AvgGrad=0.0361\n",
      "Epoch 16/200 | TrainAcc=99.69% | ValAcc=97.87% | TrainLoss=0.0087 | ValLoss=0.1241 | AvgGrad=0.0359\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 88.57%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 97.91 ¬± 0.05\n",
      "Test Acc: 88.70 ¬± 0.26\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_19-02-50_wisig_XFR_blocksize24_SNR20dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=20 dB, results saved in: ./training_results\\2026-01-17_19-02-50_wisig_XFR_blocksize24_SNR20dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = 15 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=92.71% | ValAcc=94.95% | TrainLoss=0.2004 | ValLoss=0.1406 | AvgGrad=0.0948\n",
      "Epoch 2/200 | TrainAcc=95.58% | ValAcc=95.75% | TrainLoss=0.1257 | ValLoss=0.1210 | AvgGrad=0.0618\n",
      "Epoch 3/200 | TrainAcc=96.23% | ValAcc=96.21% | TrainLoss=0.1072 | ValLoss=0.1082 | AvgGrad=0.0531\n",
      "Epoch 4/200 | TrainAcc=96.70% | ValAcc=96.38% | TrainLoss=0.0945 | ValLoss=0.1051 | AvgGrad=0.0492\n",
      "Epoch 5/200 | TrainAcc=97.05% | ValAcc=96.55% | TrainLoss=0.0841 | ValLoss=0.1004 | AvgGrad=0.0470\n",
      "Epoch 6/200 | TrainAcc=97.38% | ValAcc=96.80% | TrainLoss=0.0746 | ValLoss=0.0949 | AvgGrad=0.0464\n",
      "Epoch 7/200 | TrainAcc=97.66% | ValAcc=96.83% | TrainLoss=0.0669 | ValLoss=0.0972 | AvgGrad=0.0461\n",
      "Epoch 8/200 | TrainAcc=97.90% | ValAcc=96.92% | TrainLoss=0.0593 | ValLoss=0.1001 | AvgGrad=0.0458\n",
      "Epoch 9/200 | TrainAcc=98.10% | ValAcc=96.75% | TrainLoss=0.0532 | ValLoss=0.0999 | AvgGrad=0.0461\n",
      "Epoch 10/200 | TrainAcc=98.29% | ValAcc=96.90% | TrainLoss=0.0475 | ValLoss=0.1056 | AvgGrad=0.0459\n",
      "Epoch 11/200 | TrainAcc=99.00% | ValAcc=97.20% | TrainLoss=0.0280 | ValLoss=0.1128 | AvgGrad=0.0423\n",
      "Epoch 12/200 | TrainAcc=99.24% | ValAcc=97.18% | TrainLoss=0.0212 | ValLoss=0.1223 | AvgGrad=0.0437\n",
      "Epoch 13/200 | TrainAcc=99.34% | ValAcc=97.13% | TrainLoss=0.0180 | ValLoss=0.1363 | AvgGrad=0.0446\n",
      "Epoch 14/200 | TrainAcc=99.44% | ValAcc=97.15% | TrainLoss=0.0154 | ValLoss=0.1442 | AvgGrad=0.0449\n",
      "Epoch 15/200 | TrainAcc=99.49% | ValAcc=97.14% | TrainLoss=0.0140 | ValLoss=0.1531 | AvgGrad=0.0453\n",
      "Epoch 16/200 | TrainAcc=99.53% | ValAcc=97.18% | TrainLoss=0.0130 | ValLoss=0.1582 | AvgGrad=0.0457\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 87.78%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=92.83% | ValAcc=95.39% | TrainLoss=0.1985 | ValLoss=0.1287 | AvgGrad=0.0939\n",
      "Epoch 2/200 | TrainAcc=95.67% | ValAcc=95.74% | TrainLoss=0.1234 | ValLoss=0.1211 | AvgGrad=0.0604\n",
      "Epoch 3/200 | TrainAcc=96.29% | ValAcc=96.38% | TrainLoss=0.1060 | ValLoss=0.1070 | AvgGrad=0.0520\n",
      "Epoch 4/200 | TrainAcc=96.72% | ValAcc=96.67% | TrainLoss=0.0937 | ValLoss=0.0971 | AvgGrad=0.0481\n",
      "Epoch 5/200 | TrainAcc=97.08% | ValAcc=96.66% | TrainLoss=0.0832 | ValLoss=0.0970 | AvgGrad=0.0462\n",
      "Epoch 6/200 | TrainAcc=97.39% | ValAcc=96.59% | TrainLoss=0.0744 | ValLoss=0.1019 | AvgGrad=0.0455\n",
      "Epoch 7/200 | TrainAcc=97.68% | ValAcc=96.88% | TrainLoss=0.0659 | ValLoss=0.0976 | AvgGrad=0.0454\n",
      "Epoch 8/200 | TrainAcc=97.94% | ValAcc=96.93% | TrainLoss=0.0583 | ValLoss=0.0953 | AvgGrad=0.0452\n",
      "Epoch 9/200 | TrainAcc=98.16% | ValAcc=96.99% | TrainLoss=0.0521 | ValLoss=0.0985 | AvgGrad=0.0457\n",
      "Epoch 10/200 | TrainAcc=98.34% | ValAcc=97.04% | TrainLoss=0.0463 | ValLoss=0.0976 | AvgGrad=0.0461\n",
      "Epoch 11/200 | TrainAcc=99.00% | ValAcc=97.23% | TrainLoss=0.0273 | ValLoss=0.1125 | AvgGrad=0.0425\n",
      "Epoch 12/200 | TrainAcc=99.26% | ValAcc=97.21% | TrainLoss=0.0206 | ValLoss=0.1241 | AvgGrad=0.0434\n",
      "Epoch 13/200 | TrainAcc=99.37% | ValAcc=97.21% | TrainLoss=0.0173 | ValLoss=0.1384 | AvgGrad=0.0447\n",
      "Epoch 14/200 | TrainAcc=99.44% | ValAcc=97.21% | TrainLoss=0.0153 | ValLoss=0.1401 | AvgGrad=0.0453\n",
      "Epoch 15/200 | TrainAcc=99.50% | ValAcc=97.14% | TrainLoss=0.0137 | ValLoss=0.1545 | AvgGrad=0.0451\n",
      "Epoch 16/200 | TrainAcc=99.55% | ValAcc=97.19% | TrainLoss=0.0124 | ValLoss=0.1541 | AvgGrad=0.0447\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 88.08%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=92.79% | ValAcc=95.03% | TrainLoss=0.1993 | ValLoss=0.1404 | AvgGrad=0.0936\n",
      "Epoch 2/200 | TrainAcc=95.61% | ValAcc=95.79% | TrainLoss=0.1258 | ValLoss=0.1197 | AvgGrad=0.0614\n",
      "Epoch 3/200 | TrainAcc=96.23% | ValAcc=95.80% | TrainLoss=0.1082 | ValLoss=0.1188 | AvgGrad=0.0533\n",
      "Epoch 4/200 | TrainAcc=96.67% | ValAcc=96.44% | TrainLoss=0.0953 | ValLoss=0.1032 | AvgGrad=0.0496\n",
      "Epoch 5/200 | TrainAcc=97.03% | ValAcc=96.60% | TrainLoss=0.0848 | ValLoss=0.0996 | AvgGrad=0.0476\n",
      "Epoch 6/200 | TrainAcc=97.38% | ValAcc=96.76% | TrainLoss=0.0750 | ValLoss=0.0961 | AvgGrad=0.0467\n",
      "Epoch 7/200 | TrainAcc=97.63% | ValAcc=96.67% | TrainLoss=0.0671 | ValLoss=0.1005 | AvgGrad=0.0465\n",
      "Epoch 8/200 | TrainAcc=97.89% | ValAcc=96.86% | TrainLoss=0.0594 | ValLoss=0.1009 | AvgGrad=0.0465\n",
      "Epoch 9/200 | TrainAcc=98.12% | ValAcc=96.93% | TrainLoss=0.0527 | ValLoss=0.0988 | AvgGrad=0.0466\n",
      "Epoch 10/200 | TrainAcc=98.32% | ValAcc=96.98% | TrainLoss=0.0471 | ValLoss=0.1019 | AvgGrad=0.0467\n",
      "Epoch 11/200 | TrainAcc=99.02% | ValAcc=97.10% | TrainLoss=0.0273 | ValLoss=0.1143 | AvgGrad=0.0428\n",
      "Epoch 12/200 | TrainAcc=99.25% | ValAcc=97.23% | TrainLoss=0.0208 | ValLoss=0.1186 | AvgGrad=0.0439\n",
      "Epoch 13/200 | TrainAcc=99.35% | ValAcc=97.12% | TrainLoss=0.0176 | ValLoss=0.1329 | AvgGrad=0.0457\n",
      "Epoch 14/200 | TrainAcc=99.46% | ValAcc=97.15% | TrainLoss=0.0150 | ValLoss=0.1385 | AvgGrad=0.0447\n",
      "Epoch 15/200 | TrainAcc=99.50% | ValAcc=97.16% | TrainLoss=0.0138 | ValLoss=0.1473 | AvgGrad=0.0450\n",
      "Epoch 16/200 | TrainAcc=99.55% | ValAcc=97.13% | TrainLoss=0.0125 | ValLoss=0.1528 | AvgGrad=0.0446\n",
      "Epoch 17/200 | TrainAcc=99.58% | ValAcc=97.16% | TrainLoss=0.0116 | ValLoss=0.1671 | AvgGrad=0.0446\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 87.75%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=92.81% | ValAcc=95.22% | TrainLoss=0.1981 | ValLoss=0.1349 | AvgGrad=0.0939\n",
      "Epoch 2/200 | TrainAcc=95.65% | ValAcc=95.79% | TrainLoss=0.1233 | ValLoss=0.1197 | AvgGrad=0.0608\n",
      "Epoch 3/200 | TrainAcc=96.26% | ValAcc=95.76% | TrainLoss=0.1064 | ValLoss=0.1215 | AvgGrad=0.0525\n",
      "Epoch 4/200 | TrainAcc=96.69% | ValAcc=96.40% | TrainLoss=0.0944 | ValLoss=0.1034 | AvgGrad=0.0486\n",
      "Epoch 5/200 | TrainAcc=97.05% | ValAcc=96.55% | TrainLoss=0.0840 | ValLoss=0.1004 | AvgGrad=0.0466\n",
      "Epoch 6/200 | TrainAcc=97.39% | ValAcc=96.68% | TrainLoss=0.0751 | ValLoss=0.0984 | AvgGrad=0.0460\n",
      "Epoch 7/200 | TrainAcc=97.67% | ValAcc=96.72% | TrainLoss=0.0668 | ValLoss=0.1008 | AvgGrad=0.0455\n",
      "Epoch 8/200 | TrainAcc=97.90% | ValAcc=96.87% | TrainLoss=0.0595 | ValLoss=0.0967 | AvgGrad=0.0458\n",
      "Epoch 9/200 | TrainAcc=98.12% | ValAcc=96.96% | TrainLoss=0.0529 | ValLoss=0.1033 | AvgGrad=0.0456\n",
      "Epoch 10/200 | TrainAcc=98.32% | ValAcc=96.93% | TrainLoss=0.0470 | ValLoss=0.1013 | AvgGrad=0.0463\n",
      "Epoch 11/200 | TrainAcc=99.00% | ValAcc=97.16% | TrainLoss=0.0279 | ValLoss=0.1163 | AvgGrad=0.0426\n",
      "Epoch 12/200 | TrainAcc=99.24% | ValAcc=97.05% | TrainLoss=0.0213 | ValLoss=0.1289 | AvgGrad=0.0439\n",
      "Epoch 13/200 | TrainAcc=99.35% | ValAcc=97.05% | TrainLoss=0.0177 | ValLoss=0.1398 | AvgGrad=0.0444\n",
      "Epoch 14/200 | TrainAcc=99.42% | ValAcc=97.10% | TrainLoss=0.0157 | ValLoss=0.1486 | AvgGrad=0.0459\n",
      "Epoch 15/200 | TrainAcc=99.49% | ValAcc=97.09% | TrainLoss=0.0136 | ValLoss=0.1553 | AvgGrad=0.0450\n",
      "Epoch 16/200 | TrainAcc=99.53% | ValAcc=97.13% | TrainLoss=0.0127 | ValLoss=0.1601 | AvgGrad=0.0454\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 87.81%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=92.93% | ValAcc=95.29% | TrainLoss=0.1963 | ValLoss=0.1330 | AvgGrad=0.0928\n",
      "Epoch 2/200 | TrainAcc=95.61% | ValAcc=95.85% | TrainLoss=0.1245 | ValLoss=0.1175 | AvgGrad=0.0604\n",
      "Epoch 3/200 | TrainAcc=96.28% | ValAcc=95.39% | TrainLoss=0.1070 | ValLoss=0.1311 | AvgGrad=0.0522\n",
      "Epoch 4/200 | TrainAcc=96.74% | ValAcc=96.41% | TrainLoss=0.0943 | ValLoss=0.1036 | AvgGrad=0.0485\n",
      "Epoch 5/200 | TrainAcc=97.04% | ValAcc=96.64% | TrainLoss=0.0841 | ValLoss=0.0978 | AvgGrad=0.0467\n",
      "Epoch 6/200 | TrainAcc=97.38% | ValAcc=96.73% | TrainLoss=0.0750 | ValLoss=0.0963 | AvgGrad=0.0457\n",
      "Epoch 7/200 | TrainAcc=97.66% | ValAcc=96.83% | TrainLoss=0.0664 | ValLoss=0.0964 | AvgGrad=0.0457\n",
      "Epoch 8/200 | TrainAcc=97.87% | ValAcc=96.89% | TrainLoss=0.0593 | ValLoss=0.0960 | AvgGrad=0.0458\n",
      "Epoch 9/200 | TrainAcc=98.14% | ValAcc=96.99% | TrainLoss=0.0523 | ValLoss=0.0948 | AvgGrad=0.0457\n",
      "Epoch 10/200 | TrainAcc=98.34% | ValAcc=97.02% | TrainLoss=0.0466 | ValLoss=0.0993 | AvgGrad=0.0460\n",
      "Epoch 11/200 | TrainAcc=99.01% | ValAcc=97.24% | TrainLoss=0.0275 | ValLoss=0.1091 | AvgGrad=0.0423\n",
      "Epoch 12/200 | TrainAcc=99.24% | ValAcc=97.24% | TrainLoss=0.0209 | ValLoss=0.1190 | AvgGrad=0.0440\n",
      "Epoch 13/200 | TrainAcc=99.36% | ValAcc=97.14% | TrainLoss=0.0173 | ValLoss=0.1331 | AvgGrad=0.0443\n",
      "Epoch 14/200 | TrainAcc=99.44% | ValAcc=97.23% | TrainLoss=0.0151 | ValLoss=0.1407 | AvgGrad=0.0446\n",
      "Epoch 15/200 | TrainAcc=99.50% | ValAcc=97.21% | TrainLoss=0.0137 | ValLoss=0.1436 | AvgGrad=0.0447\n",
      "Epoch 16/200 | TrainAcc=99.53% | ValAcc=97.16% | TrainLoss=0.0129 | ValLoss=0.1541 | AvgGrad=0.0452\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 87.61%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 97.16 ¬± 0.02\n",
      "Test Acc: 87.80 ¬± 0.16\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_19-39-20_wisig_XFR_blocksize24_SNR15dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=15 dB, results saved in: ./training_results\\2026-01-17_19-39-20_wisig_XFR_blocksize24_SNR15dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = 10 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=90.03% | ValAcc=92.55% | TrainLoss=0.2704 | ValLoss=0.2040 | AvgGrad=0.0981\n",
      "Epoch 2/200 | TrainAcc=93.06% | ValAcc=93.14% | TrainLoss=0.1928 | ValLoss=0.1869 | AvgGrad=0.0648\n",
      "Epoch 3/200 | TrainAcc=93.77% | ValAcc=93.79% | TrainLoss=0.1733 | ValLoss=0.1735 | AvgGrad=0.0556\n",
      "Epoch 4/200 | TrainAcc=94.20% | ValAcc=93.90% | TrainLoss=0.1602 | ValLoss=0.1710 | AvgGrad=0.0516\n",
      "Epoch 5/200 | TrainAcc=94.67% | ValAcc=93.84% | TrainLoss=0.1481 | ValLoss=0.1736 | AvgGrad=0.0502\n",
      "Epoch 6/200 | TrainAcc=95.02% | ValAcc=94.13% | TrainLoss=0.1378 | ValLoss=0.1662 | AvgGrad=0.0496\n",
      "Epoch 7/200 | TrainAcc=95.35% | ValAcc=94.06% | TrainLoss=0.1279 | ValLoss=0.1709 | AvgGrad=0.0502\n",
      "Epoch 8/200 | TrainAcc=95.68% | ValAcc=94.24% | TrainLoss=0.1184 | ValLoss=0.1694 | AvgGrad=0.0514\n",
      "Epoch 9/200 | TrainAcc=96.02% | ValAcc=94.15% | TrainLoss=0.1086 | ValLoss=0.1752 | AvgGrad=0.0523\n",
      "Epoch 10/200 | TrainAcc=96.29% | ValAcc=94.27% | TrainLoss=0.1005 | ValLoss=0.1803 | AvgGrad=0.0541\n",
      "Epoch 11/200 | TrainAcc=97.36% | ValAcc=94.54% | TrainLoss=0.0723 | ValLoss=0.1849 | AvgGrad=0.0550\n",
      "Epoch 12/200 | TrainAcc=97.78% | ValAcc=94.48% | TrainLoss=0.0604 | ValLoss=0.2081 | AvgGrad=0.0593\n",
      "Epoch 13/200 | TrainAcc=98.05% | ValAcc=94.39% | TrainLoss=0.0526 | ValLoss=0.2187 | AvgGrad=0.0625\n",
      "Epoch 14/200 | TrainAcc=98.30% | ValAcc=94.38% | TrainLoss=0.0457 | ValLoss=0.2351 | AvgGrad=0.0654\n",
      "Epoch 15/200 | TrainAcc=98.49% | ValAcc=94.34% | TrainLoss=0.0408 | ValLoss=0.2580 | AvgGrad=0.0672\n",
      "Epoch 16/200 | TrainAcc=98.65% | ValAcc=94.33% | TrainLoss=0.0363 | ValLoss=0.2665 | AvgGrad=0.0684\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 85.09%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=89.92% | ValAcc=92.27% | TrainLoss=0.2734 | ValLoss=0.2138 | AvgGrad=0.0993\n",
      "Epoch 2/200 | TrainAcc=93.07% | ValAcc=93.28% | TrainLoss=0.1926 | ValLoss=0.1871 | AvgGrad=0.0659\n",
      "Epoch 3/200 | TrainAcc=93.75% | ValAcc=93.67% | TrainLoss=0.1737 | ValLoss=0.1746 | AvgGrad=0.0565\n",
      "Epoch 4/200 | TrainAcc=94.21% | ValAcc=94.07% | TrainLoss=0.1603 | ValLoss=0.1681 | AvgGrad=0.0527\n",
      "Epoch 5/200 | TrainAcc=94.62% | ValAcc=94.19% | TrainLoss=0.1493 | ValLoss=0.1649 | AvgGrad=0.0509\n",
      "Epoch 6/200 | TrainAcc=94.95% | ValAcc=94.38% | TrainLoss=0.1385 | ValLoss=0.1582 | AvgGrad=0.0507\n",
      "Epoch 7/200 | TrainAcc=95.34% | ValAcc=94.42% | TrainLoss=0.1286 | ValLoss=0.1574 | AvgGrad=0.0513\n",
      "Epoch 8/200 | TrainAcc=95.66% | ValAcc=94.51% | TrainLoss=0.1184 | ValLoss=0.1591 | AvgGrad=0.0522\n",
      "Epoch 9/200 | TrainAcc=96.00% | ValAcc=94.58% | TrainLoss=0.1092 | ValLoss=0.1608 | AvgGrad=0.0534\n",
      "Epoch 10/200 | TrainAcc=96.31% | ValAcc=94.47% | TrainLoss=0.0999 | ValLoss=0.1752 | AvgGrad=0.0551\n",
      "Epoch 11/200 | TrainAcc=97.36% | ValAcc=94.74% | TrainLoss=0.0717 | ValLoss=0.1756 | AvgGrad=0.0560\n",
      "Epoch 12/200 | TrainAcc=97.78% | ValAcc=94.61% | TrainLoss=0.0593 | ValLoss=0.1972 | AvgGrad=0.0605\n",
      "Epoch 13/200 | TrainAcc=98.08% | ValAcc=94.64% | TrainLoss=0.0515 | ValLoss=0.2090 | AvgGrad=0.0642\n",
      "Epoch 14/200 | TrainAcc=98.31% | ValAcc=94.57% | TrainLoss=0.0450 | ValLoss=0.2257 | AvgGrad=0.0667\n",
      "Epoch 15/200 | TrainAcc=98.52% | ValAcc=94.45% | TrainLoss=0.0395 | ValLoss=0.2460 | AvgGrad=0.0681\n",
      "Epoch 16/200 | TrainAcc=98.67% | ValAcc=94.51% | TrainLoss=0.0353 | ValLoss=0.2672 | AvgGrad=0.0707\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 85.08%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=90.11% | ValAcc=92.74% | TrainLoss=0.2692 | ValLoss=0.1990 | AvgGrad=0.0962\n",
      "Epoch 2/200 | TrainAcc=93.13% | ValAcc=93.43% | TrainLoss=0.1913 | ValLoss=0.1828 | AvgGrad=0.0649\n",
      "Epoch 3/200 | TrainAcc=93.74% | ValAcc=93.75% | TrainLoss=0.1737 | ValLoss=0.1732 | AvgGrad=0.0561\n",
      "Epoch 4/200 | TrainAcc=94.23% | ValAcc=93.91% | TrainLoss=0.1605 | ValLoss=0.1684 | AvgGrad=0.0525\n",
      "Epoch 5/200 | TrainAcc=94.62% | ValAcc=94.17% | TrainLoss=0.1486 | ValLoss=0.1628 | AvgGrad=0.0509\n",
      "Epoch 6/200 | TrainAcc=95.00% | ValAcc=94.36% | TrainLoss=0.1381 | ValLoss=0.1605 | AvgGrad=0.0507\n",
      "Epoch 7/200 | TrainAcc=95.37% | ValAcc=94.46% | TrainLoss=0.1276 | ValLoss=0.1571 | AvgGrad=0.0515\n",
      "Epoch 8/200 | TrainAcc=95.71% | ValAcc=94.31% | TrainLoss=0.1177 | ValLoss=0.1659 | AvgGrad=0.0522\n",
      "Epoch 9/200 | TrainAcc=96.03% | ValAcc=94.41% | TrainLoss=0.1087 | ValLoss=0.1649 | AvgGrad=0.0536\n",
      "Epoch 10/200 | TrainAcc=96.34% | ValAcc=94.38% | TrainLoss=0.0998 | ValLoss=0.1707 | AvgGrad=0.0552\n",
      "Epoch 11/200 | TrainAcc=97.39% | ValAcc=94.59% | TrainLoss=0.0718 | ValLoss=0.1783 | AvgGrad=0.0558\n",
      "Epoch 12/200 | TrainAcc=97.79% | ValAcc=94.58% | TrainLoss=0.0600 | ValLoss=0.1965 | AvgGrad=0.0603\n",
      "Epoch 13/200 | TrainAcc=98.08% | ValAcc=94.52% | TrainLoss=0.0519 | ValLoss=0.2131 | AvgGrad=0.0635\n",
      "Epoch 14/200 | TrainAcc=98.31% | ValAcc=94.50% | TrainLoss=0.0458 | ValLoss=0.2315 | AvgGrad=0.0665\n",
      "Epoch 15/200 | TrainAcc=98.51% | ValAcc=94.36% | TrainLoss=0.0402 | ValLoss=0.2496 | AvgGrad=0.0680\n",
      "Epoch 16/200 | TrainAcc=98.65% | ValAcc=94.41% | TrainLoss=0.0361 | ValLoss=0.2787 | AvgGrad=0.0698\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 84.73%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=90.11% | ValAcc=92.11% | TrainLoss=0.2682 | ValLoss=0.2145 | AvgGrad=0.0996\n",
      "Epoch 2/200 | TrainAcc=93.09% | ValAcc=93.19% | TrainLoss=0.1927 | ValLoss=0.1865 | AvgGrad=0.0661\n",
      "Epoch 3/200 | TrainAcc=93.73% | ValAcc=93.61% | TrainLoss=0.1743 | ValLoss=0.1750 | AvgGrad=0.0571\n",
      "Epoch 4/200 | TrainAcc=94.25% | ValAcc=93.94% | TrainLoss=0.1605 | ValLoss=0.1704 | AvgGrad=0.0531\n",
      "Epoch 5/200 | TrainAcc=94.63% | ValAcc=94.05% | TrainLoss=0.1488 | ValLoss=0.1669 | AvgGrad=0.0516\n",
      "Epoch 6/200 | TrainAcc=95.01% | ValAcc=94.17% | TrainLoss=0.1378 | ValLoss=0.1642 | AvgGrad=0.0512\n",
      "Epoch 7/200 | TrainAcc=95.39% | ValAcc=94.16% | TrainLoss=0.1272 | ValLoss=0.1663 | AvgGrad=0.0518\n",
      "Epoch 8/200 | TrainAcc=95.73% | ValAcc=94.38% | TrainLoss=0.1170 | ValLoss=0.1654 | AvgGrad=0.0528\n",
      "Epoch 9/200 | TrainAcc=96.08% | ValAcc=94.32% | TrainLoss=0.1075 | ValLoss=0.1711 | AvgGrad=0.0541\n",
      "Epoch 10/200 | TrainAcc=96.34% | ValAcc=94.43% | TrainLoss=0.0993 | ValLoss=0.1695 | AvgGrad=0.0557\n",
      "Epoch 11/200 | TrainAcc=97.40% | ValAcc=94.57% | TrainLoss=0.0705 | ValLoss=0.1825 | AvgGrad=0.0563\n",
      "Epoch 12/200 | TrainAcc=97.86% | ValAcc=94.51% | TrainLoss=0.0584 | ValLoss=0.2003 | AvgGrad=0.0599\n",
      "Epoch 13/200 | TrainAcc=98.12% | ValAcc=94.47% | TrainLoss=0.0508 | ValLoss=0.2235 | AvgGrad=0.0637\n",
      "Epoch 14/200 | TrainAcc=98.37% | ValAcc=94.44% | TrainLoss=0.0443 | ValLoss=0.2396 | AvgGrad=0.0662\n",
      "Epoch 15/200 | TrainAcc=98.53% | ValAcc=94.39% | TrainLoss=0.0394 | ValLoss=0.2513 | AvgGrad=0.0686\n",
      "Epoch 16/200 | TrainAcc=98.70% | ValAcc=94.31% | TrainLoss=0.0354 | ValLoss=0.2666 | AvgGrad=0.0688\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 84.94%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=90.05% | ValAcc=92.43% | TrainLoss=0.2703 | ValLoss=0.2087 | AvgGrad=0.0976\n",
      "Epoch 2/200 | TrainAcc=93.04% | ValAcc=93.36% | TrainLoss=0.1935 | ValLoss=0.1825 | AvgGrad=0.0651\n",
      "Epoch 3/200 | TrainAcc=93.70% | ValAcc=93.63% | TrainLoss=0.1748 | ValLoss=0.1761 | AvgGrad=0.0564\n",
      "Epoch 4/200 | TrainAcc=94.17% | ValAcc=93.73% | TrainLoss=0.1615 | ValLoss=0.1727 | AvgGrad=0.0524\n",
      "Epoch 5/200 | TrainAcc=94.59% | ValAcc=94.20% | TrainLoss=0.1501 | ValLoss=0.1628 | AvgGrad=0.0509\n",
      "Epoch 6/200 | TrainAcc=94.97% | ValAcc=94.35% | TrainLoss=0.1393 | ValLoss=0.1596 | AvgGrad=0.0505\n",
      "Epoch 7/200 | TrainAcc=95.31% | ValAcc=94.38% | TrainLoss=0.1295 | ValLoss=0.1596 | AvgGrad=0.0509\n",
      "Epoch 8/200 | TrainAcc=95.65% | ValAcc=94.36% | TrainLoss=0.1190 | ValLoss=0.1645 | AvgGrad=0.0515\n",
      "Epoch 9/200 | TrainAcc=95.98% | ValAcc=94.27% | TrainLoss=0.1105 | ValLoss=0.1666 | AvgGrad=0.0530\n",
      "Epoch 10/200 | TrainAcc=96.30% | ValAcc=94.36% | TrainLoss=0.1013 | ValLoss=0.1677 | AvgGrad=0.0543\n",
      "Epoch 11/200 | TrainAcc=97.31% | ValAcc=94.60% | TrainLoss=0.0731 | ValLoss=0.1803 | AvgGrad=0.0557\n",
      "Epoch 12/200 | TrainAcc=97.76% | ValAcc=94.56% | TrainLoss=0.0609 | ValLoss=0.1973 | AvgGrad=0.0603\n",
      "Epoch 13/200 | TrainAcc=98.04% | ValAcc=94.45% | TrainLoss=0.0530 | ValLoss=0.2101 | AvgGrad=0.0639\n",
      "Epoch 14/200 | TrainAcc=98.32% | ValAcc=94.54% | TrainLoss=0.0458 | ValLoss=0.2292 | AvgGrad=0.0660\n",
      "Epoch 15/200 | TrainAcc=98.48% | ValAcc=94.44% | TrainLoss=0.0408 | ValLoss=0.2388 | AvgGrad=0.0689\n",
      "Epoch 16/200 | TrainAcc=98.65% | ValAcc=94.43% | TrainLoss=0.0366 | ValLoss=0.2547 | AvgGrad=0.0708\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 84.96%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 94.40 ¬± 0.07\n",
      "Test Acc: 84.96 ¬± 0.13\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_20-15-44_wisig_XFR_blocksize24_SNR10dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=10 dB, results saved in: ./training_results\\2026-01-17_20-15-44_wisig_XFR_blocksize24_SNR10dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = 5 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=81.34% | ValAcc=83.80% | TrainLoss=0.4877 | ValLoss=0.4248 | AvgGrad=0.1009\n",
      "Epoch 2/200 | TrainAcc=84.41% | ValAcc=84.76% | TrainLoss=0.4124 | ValLoss=0.4015 | AvgGrad=0.0704\n",
      "Epoch 3/200 | TrainAcc=85.12% | ValAcc=85.01% | TrainLoss=0.3928 | ValLoss=0.3983 | AvgGrad=0.0617\n",
      "Epoch 4/200 | TrainAcc=85.66% | ValAcc=85.11% | TrainLoss=0.3794 | ValLoss=0.3950 | AvgGrad=0.0575\n",
      "Epoch 5/200 | TrainAcc=86.06% | ValAcc=85.48% | TrainLoss=0.3681 | ValLoss=0.3875 | AvgGrad=0.0556\n",
      "Epoch 6/200 | TrainAcc=86.45% | ValAcc=85.39% | TrainLoss=0.3571 | ValLoss=0.3854 | AvgGrad=0.0552\n",
      "Epoch 7/200 | TrainAcc=86.81% | ValAcc=85.52% | TrainLoss=0.3463 | ValLoss=0.3856 | AvgGrad=0.0559\n",
      "Epoch 8/200 | TrainAcc=87.20% | ValAcc=85.53% | TrainLoss=0.3359 | ValLoss=0.3874 | AvgGrad=0.0570\n",
      "Epoch 9/200 | TrainAcc=87.56% | ValAcc=85.57% | TrainLoss=0.3255 | ValLoss=0.3900 | AvgGrad=0.0585\n",
      "Epoch 10/200 | TrainAcc=87.95% | ValAcc=85.51% | TrainLoss=0.3142 | ValLoss=0.3936 | AvgGrad=0.0606\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 78.47%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=81.31% | ValAcc=84.10% | TrainLoss=0.4863 | ValLoss=0.4181 | AvgGrad=0.1029\n",
      "Epoch 2/200 | TrainAcc=84.45% | ValAcc=84.85% | TrainLoss=0.4113 | ValLoss=0.3984 | AvgGrad=0.0715\n",
      "Epoch 3/200 | TrainAcc=85.19% | ValAcc=85.32% | TrainLoss=0.3919 | ValLoss=0.3903 | AvgGrad=0.0621\n",
      "Epoch 4/200 | TrainAcc=85.65% | ValAcc=85.42% | TrainLoss=0.3790 | ValLoss=0.3866 | AvgGrad=0.0576\n",
      "Epoch 5/200 | TrainAcc=86.09% | ValAcc=85.45% | TrainLoss=0.3675 | ValLoss=0.3862 | AvgGrad=0.0557\n",
      "Epoch 6/200 | TrainAcc=86.48% | ValAcc=85.56% | TrainLoss=0.3564 | ValLoss=0.3839 | AvgGrad=0.0551\n",
      "Epoch 7/200 | TrainAcc=86.80% | ValAcc=85.73% | TrainLoss=0.3460 | ValLoss=0.3814 | AvgGrad=0.0555\n",
      "Epoch 8/200 | TrainAcc=87.20% | ValAcc=85.72% | TrainLoss=0.3355 | ValLoss=0.3816 | AvgGrad=0.0568\n",
      "Epoch 9/200 | TrainAcc=87.55% | ValAcc=85.70% | TrainLoss=0.3247 | ValLoss=0.3838 | AvgGrad=0.0584\n",
      "Epoch 10/200 | TrainAcc=87.97% | ValAcc=85.65% | TrainLoss=0.3138 | ValLoss=0.3902 | AvgGrad=0.0610\n",
      "Epoch 11/200 | TrainAcc=89.26% | ValAcc=85.68% | TrainLoss=0.2789 | ValLoss=0.4091 | AvgGrad=0.0658\n",
      "Epoch 12/200 | TrainAcc=89.79% | ValAcc=85.57% | TrainLoss=0.2622 | ValLoss=0.4174 | AvgGrad=0.0729\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 77.73%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=81.32% | ValAcc=83.84% | TrainLoss=0.4883 | ValLoss=0.4227 | AvgGrad=0.1026\n",
      "Epoch 2/200 | TrainAcc=84.47% | ValAcc=84.36% | TrainLoss=0.4108 | ValLoss=0.4124 | AvgGrad=0.0706\n",
      "Epoch 3/200 | TrainAcc=85.16% | ValAcc=84.83% | TrainLoss=0.3930 | ValLoss=0.3970 | AvgGrad=0.0610\n",
      "Epoch 4/200 | TrainAcc=85.63% | ValAcc=85.37% | TrainLoss=0.3794 | ValLoss=0.3847 | AvgGrad=0.0565\n",
      "Epoch 5/200 | TrainAcc=86.05% | ValAcc=85.47% | TrainLoss=0.3690 | ValLoss=0.3847 | AvgGrad=0.0548\n",
      "Epoch 6/200 | TrainAcc=86.39% | ValAcc=85.57% | TrainLoss=0.3582 | ValLoss=0.3834 | AvgGrad=0.0540\n",
      "Epoch 7/200 | TrainAcc=86.78% | ValAcc=85.60% | TrainLoss=0.3484 | ValLoss=0.3848 | AvgGrad=0.0544\n",
      "Epoch 8/200 | TrainAcc=87.10% | ValAcc=85.73% | TrainLoss=0.3382 | ValLoss=0.3836 | AvgGrad=0.0554\n",
      "Epoch 9/200 | TrainAcc=87.47% | ValAcc=85.67% | TrainLoss=0.3278 | ValLoss=0.3889 | AvgGrad=0.0573\n",
      "Epoch 10/200 | TrainAcc=87.82% | ValAcc=85.64% | TrainLoss=0.3177 | ValLoss=0.3881 | AvgGrad=0.0592\n",
      "Epoch 11/200 | TrainAcc=89.04% | ValAcc=85.69% | TrainLoss=0.2843 | ValLoss=0.3971 | AvgGrad=0.0638\n",
      "Epoch 12/200 | TrainAcc=89.56% | ValAcc=85.54% | TrainLoss=0.2688 | ValLoss=0.4148 | AvgGrad=0.0707\n",
      "Epoch 13/200 | TrainAcc=89.99% | ValAcc=85.38% | TrainLoss=0.2563 | ValLoss=0.4246 | AvgGrad=0.0766\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 77.68%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=81.27% | ValAcc=83.68% | TrainLoss=0.4877 | ValLoss=0.4276 | AvgGrad=0.1016\n",
      "Epoch 2/200 | TrainAcc=84.48% | ValAcc=84.62% | TrainLoss=0.4103 | ValLoss=0.4034 | AvgGrad=0.0703\n",
      "Epoch 3/200 | TrainAcc=85.17% | ValAcc=84.54% | TrainLoss=0.3920 | ValLoss=0.4035 | AvgGrad=0.0611\n",
      "Epoch 4/200 | TrainAcc=85.67% | ValAcc=85.44% | TrainLoss=0.3788 | ValLoss=0.3881 | AvgGrad=0.0571\n",
      "Epoch 5/200 | TrainAcc=86.10% | ValAcc=85.41% | TrainLoss=0.3670 | ValLoss=0.3860 | AvgGrad=0.0550\n",
      "Epoch 6/200 | TrainAcc=86.48% | ValAcc=85.59% | TrainLoss=0.3561 | ValLoss=0.3839 | AvgGrad=0.0546\n",
      "Epoch 7/200 | TrainAcc=86.87% | ValAcc=85.55% | TrainLoss=0.3454 | ValLoss=0.3840 | AvgGrad=0.0551\n",
      "Epoch 8/200 | TrainAcc=87.20% | ValAcc=85.42% | TrainLoss=0.3356 | ValLoss=0.3866 | AvgGrad=0.0564\n",
      "Epoch 9/200 | TrainAcc=87.60% | ValAcc=85.58% | TrainLoss=0.3251 | ValLoss=0.3861 | AvgGrad=0.0579\n",
      "Epoch 10/200 | TrainAcc=87.95% | ValAcc=85.50% | TrainLoss=0.3143 | ValLoss=0.3948 | AvgGrad=0.0605\n",
      "Epoch 11/200 | TrainAcc=89.21% | ValAcc=85.57% | TrainLoss=0.2804 | ValLoss=0.4018 | AvgGrad=0.0651\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 78.09%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=81.12% | ValAcc=83.98% | TrainLoss=0.4927 | ValLoss=0.4198 | AvgGrad=0.1032\n",
      "Epoch 2/200 | TrainAcc=84.33% | ValAcc=84.76% | TrainLoss=0.4141 | ValLoss=0.4005 | AvgGrad=0.0708\n",
      "Epoch 3/200 | TrainAcc=85.09% | ValAcc=85.13% | TrainLoss=0.3946 | ValLoss=0.3917 | AvgGrad=0.0616\n",
      "Epoch 4/200 | TrainAcc=85.60% | ValAcc=85.29% | TrainLoss=0.3810 | ValLoss=0.3884 | AvgGrad=0.0576\n",
      "Epoch 5/200 | TrainAcc=86.00% | ValAcc=85.61% | TrainLoss=0.3700 | ValLoss=0.3789 | AvgGrad=0.0557\n",
      "Epoch 6/200 | TrainAcc=86.41% | ValAcc=85.40% | TrainLoss=0.3590 | ValLoss=0.3864 | AvgGrad=0.0551\n",
      "Epoch 7/200 | TrainAcc=86.75% | ValAcc=85.52% | TrainLoss=0.3490 | ValLoss=0.3834 | AvgGrad=0.0555\n",
      "Epoch 8/200 | TrainAcc=87.08% | ValAcc=85.53% | TrainLoss=0.3389 | ValLoss=0.3849 | AvgGrad=0.0566\n",
      "Epoch 9/200 | TrainAcc=87.51% | ValAcc=85.76% | TrainLoss=0.3284 | ValLoss=0.3830 | AvgGrad=0.0581\n",
      "Epoch 10/200 | TrainAcc=87.83% | ValAcc=85.65% | TrainLoss=0.3176 | ValLoss=0.3875 | AvgGrad=0.0603\n",
      "Epoch 11/200 | TrainAcc=89.09% | ValAcc=85.71% | TrainLoss=0.2835 | ValLoss=0.3975 | AvgGrad=0.0647\n",
      "Epoch 12/200 | TrainAcc=89.68% | ValAcc=85.53% | TrainLoss=0.2680 | ValLoss=0.4110 | AvgGrad=0.0713\n",
      "Epoch 13/200 | TrainAcc=90.09% | ValAcc=85.54% | TrainLoss=0.2550 | ValLoss=0.4231 | AvgGrad=0.0770\n",
      "Epoch 14/200 | TrainAcc=90.61% | ValAcc=85.35% | TrainLoss=0.2427 | ValLoss=0.4406 | AvgGrad=0.0826\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 77.33%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 85.48 ¬± 0.10\n",
      "Test Acc: 77.86 ¬± 0.39\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_20-51-54_wisig_XFR_blocksize24_SNR5dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=5 dB, results saved in: ./training_results\\2026-01-17_20-51-54_wisig_XFR_blocksize24_SNR5dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = 0 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=61.47% | ValAcc=63.68% | TrainLoss=0.9693 | ValLoss=0.9143 | AvgGrad=0.0921\n",
      "Epoch 2/200 | TrainAcc=64.03% | ValAcc=63.76% | TrainLoss=0.9113 | ValLoss=0.9128 | AvgGrad=0.0633\n",
      "Epoch 3/200 | TrainAcc=64.50% | ValAcc=64.40% | TrainLoss=0.8989 | ValLoss=0.9031 | AvgGrad=0.0553\n",
      "Epoch 4/200 | TrainAcc=64.87% | ValAcc=64.60% | TrainLoss=0.8891 | ValLoss=0.8951 | AvgGrad=0.0514\n",
      "Epoch 5/200 | TrainAcc=65.17% | ValAcc=64.53% | TrainLoss=0.8810 | ValLoss=0.8938 | AvgGrad=0.0494\n",
      "Epoch 6/200 | TrainAcc=65.46% | ValAcc=64.49% | TrainLoss=0.8742 | ValLoss=0.8972 | AvgGrad=0.0489\n",
      "Epoch 7/200 | TrainAcc=65.74% | ValAcc=64.76% | TrainLoss=0.8666 | ValLoss=0.8930 | AvgGrad=0.0490\n",
      "Epoch 8/200 | TrainAcc=65.97% | ValAcc=64.79% | TrainLoss=0.8599 | ValLoss=0.8966 | AvgGrad=0.0500\n",
      "Epoch 9/200 | TrainAcc=66.23% | ValAcc=64.88% | TrainLoss=0.8519 | ValLoss=0.8951 | AvgGrad=0.0512\n",
      "Epoch 10/200 | TrainAcc=66.49% | ValAcc=64.72% | TrainLoss=0.8446 | ValLoss=0.8960 | AvgGrad=0.0531\n",
      "Epoch 11/200 | TrainAcc=67.43% | ValAcc=64.82% | TrainLoss=0.8184 | ValLoss=0.9051 | AvgGrad=0.0570\n",
      "Epoch 12/200 | TrainAcc=67.83% | ValAcc=64.40% | TrainLoss=0.8061 | ValLoss=0.9102 | AvgGrad=0.0624\n",
      "Epoch 13/200 | TrainAcc=68.17% | ValAcc=64.56% | TrainLoss=0.7960 | ValLoss=0.9210 | AvgGrad=0.0671\n",
      "Epoch 14/200 | TrainAcc=68.53% | ValAcc=64.33% | TrainLoss=0.7858 | ValLoss=0.9307 | AvgGrad=0.0718\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 59.58%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=61.34% | ValAcc=63.42% | TrainLoss=0.9711 | ValLoss=0.9212 | AvgGrad=0.0913\n",
      "Epoch 2/200 | TrainAcc=63.91% | ValAcc=64.21% | TrainLoss=0.9131 | ValLoss=0.9081 | AvgGrad=0.0638\n",
      "Epoch 3/200 | TrainAcc=64.43% | ValAcc=64.36% | TrainLoss=0.8999 | ValLoss=0.8971 | AvgGrad=0.0555\n",
      "Epoch 4/200 | TrainAcc=64.82% | ValAcc=64.38% | TrainLoss=0.8905 | ValLoss=0.9000 | AvgGrad=0.0519\n",
      "Epoch 5/200 | TrainAcc=65.13% | ValAcc=64.80% | TrainLoss=0.8828 | ValLoss=0.8895 | AvgGrad=0.0500\n",
      "Epoch 6/200 | TrainAcc=65.42% | ValAcc=64.48% | TrainLoss=0.8756 | ValLoss=0.9012 | AvgGrad=0.0494\n",
      "Epoch 7/200 | TrainAcc=65.76% | ValAcc=64.68% | TrainLoss=0.8679 | ValLoss=0.8949 | AvgGrad=0.0494\n",
      "Epoch 8/200 | TrainAcc=65.96% | ValAcc=64.46% | TrainLoss=0.8611 | ValLoss=0.8977 | AvgGrad=0.0502\n",
      "Epoch 9/200 | TrainAcc=66.26% | ValAcc=64.62% | TrainLoss=0.8538 | ValLoss=0.8943 | AvgGrad=0.0515\n",
      "Epoch 10/200 | TrainAcc=66.52% | ValAcc=64.51% | TrainLoss=0.8461 | ValLoss=0.8981 | AvgGrad=0.0531\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 60.17%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=61.31% | ValAcc=63.69% | TrainLoss=0.9731 | ValLoss=0.9144 | AvgGrad=0.0916\n",
      "Epoch 2/200 | TrainAcc=63.93% | ValAcc=63.81% | TrainLoss=0.9141 | ValLoss=0.9099 | AvgGrad=0.0632\n",
      "Epoch 3/200 | TrainAcc=64.49% | ValAcc=64.44% | TrainLoss=0.9001 | ValLoss=0.8967 | AvgGrad=0.0553\n",
      "Epoch 4/200 | TrainAcc=64.83% | ValAcc=64.65% | TrainLoss=0.8897 | ValLoss=0.8944 | AvgGrad=0.0515\n",
      "Epoch 5/200 | TrainAcc=65.23% | ValAcc=64.51% | TrainLoss=0.8815 | ValLoss=0.8955 | AvgGrad=0.0500\n",
      "Epoch 6/200 | TrainAcc=65.52% | ValAcc=64.71% | TrainLoss=0.8738 | ValLoss=0.8916 | AvgGrad=0.0496\n",
      "Epoch 7/200 | TrainAcc=65.77% | ValAcc=64.34% | TrainLoss=0.8661 | ValLoss=0.9012 | AvgGrad=0.0496\n",
      "Epoch 8/200 | TrainAcc=66.02% | ValAcc=64.75% | TrainLoss=0.8592 | ValLoss=0.8935 | AvgGrad=0.0509\n",
      "Epoch 9/200 | TrainAcc=66.35% | ValAcc=64.48% | TrainLoss=0.8514 | ValLoss=0.8987 | AvgGrad=0.0521\n",
      "Epoch 10/200 | TrainAcc=66.68% | ValAcc=64.43% | TrainLoss=0.8439 | ValLoss=0.8996 | AvgGrad=0.0539\n",
      "Epoch 11/200 | TrainAcc=67.60% | ValAcc=64.42% | TrainLoss=0.8173 | ValLoss=0.9071 | AvgGrad=0.0578\n",
      "Epoch 12/200 | TrainAcc=68.06% | ValAcc=64.43% | TrainLoss=0.8055 | ValLoss=0.9109 | AvgGrad=0.0631\n",
      "Epoch 13/200 | TrainAcc=68.39% | ValAcc=64.39% | TrainLoss=0.7954 | ValLoss=0.9188 | AvgGrad=0.0680\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 59.73%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=61.35% | ValAcc=63.55% | TrainLoss=0.9724 | ValLoss=0.9168 | AvgGrad=0.0937\n",
      "Epoch 2/200 | TrainAcc=63.98% | ValAcc=63.88% | TrainLoss=0.9130 | ValLoss=0.9090 | AvgGrad=0.0648\n",
      "Epoch 3/200 | TrainAcc=64.46% | ValAcc=64.33% | TrainLoss=0.8999 | ValLoss=0.8982 | AvgGrad=0.0567\n",
      "Epoch 4/200 | TrainAcc=64.82% | ValAcc=64.33% | TrainLoss=0.8894 | ValLoss=0.8995 | AvgGrad=0.0527\n",
      "Epoch 5/200 | TrainAcc=65.18% | ValAcc=64.61% | TrainLoss=0.8808 | ValLoss=0.8932 | AvgGrad=0.0507\n",
      "Epoch 6/200 | TrainAcc=65.52% | ValAcc=64.64% | TrainLoss=0.8731 | ValLoss=0.8914 | AvgGrad=0.0500\n",
      "Epoch 7/200 | TrainAcc=65.81% | ValAcc=64.51% | TrainLoss=0.8657 | ValLoss=0.8955 | AvgGrad=0.0503\n",
      "Epoch 8/200 | TrainAcc=66.11% | ValAcc=64.40% | TrainLoss=0.8578 | ValLoss=0.8996 | AvgGrad=0.0511\n",
      "Epoch 9/200 | TrainAcc=66.33% | ValAcc=64.59% | TrainLoss=0.8495 | ValLoss=0.8963 | AvgGrad=0.0524\n",
      "Epoch 10/200 | TrainAcc=66.66% | ValAcc=64.35% | TrainLoss=0.8409 | ValLoss=0.9061 | AvgGrad=0.0547\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 60.04%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=61.23% | ValAcc=63.30% | TrainLoss=0.9733 | ValLoss=0.9250 | AvgGrad=0.0911\n",
      "Epoch 2/200 | TrainAcc=63.93% | ValAcc=63.96% | TrainLoss=0.9131 | ValLoss=0.9112 | AvgGrad=0.0630\n",
      "Epoch 3/200 | TrainAcc=64.49% | ValAcc=64.35% | TrainLoss=0.8986 | ValLoss=0.8974 | AvgGrad=0.0549\n",
      "Epoch 4/200 | TrainAcc=64.84% | ValAcc=64.65% | TrainLoss=0.8895 | ValLoss=0.8914 | AvgGrad=0.0511\n",
      "Epoch 5/200 | TrainAcc=65.12% | ValAcc=64.61% | TrainLoss=0.8816 | ValLoss=0.8960 | AvgGrad=0.0492\n",
      "Epoch 6/200 | TrainAcc=65.48% | ValAcc=64.64% | TrainLoss=0.8742 | ValLoss=0.8911 | AvgGrad=0.0486\n",
      "Epoch 7/200 | TrainAcc=65.71% | ValAcc=64.57% | TrainLoss=0.8673 | ValLoss=0.8959 | AvgGrad=0.0490\n",
      "Epoch 8/200 | TrainAcc=65.98% | ValAcc=64.48% | TrainLoss=0.8601 | ValLoss=0.8963 | AvgGrad=0.0495\n",
      "Epoch 9/200 | TrainAcc=66.28% | ValAcc=64.47% | TrainLoss=0.8527 | ValLoss=0.9013 | AvgGrad=0.0508\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 60.31%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 64.41 ¬± 0.07\n",
      "Test Acc: 59.97 ¬± 0.27\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_21-19-25_wisig_XFR_blocksize24_SNR0dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=0 dB, results saved in: ./training_results\\2026-01-17_21-19-25_wisig_XFR_blocksize24_SNR0dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -5 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=37.32% | ValAcc=39.44% | TrainLoss=1.5305 | ValLoss=1.4927 | AvgGrad=0.0623\n",
      "Epoch 2/200 | TrainAcc=39.27% | ValAcc=39.53% | TrainLoss=1.4951 | ValLoss=1.4894 | AvgGrad=0.0429\n",
      "Epoch 3/200 | TrainAcc=39.61% | ValAcc=39.77% | TrainLoss=1.4867 | ValLoss=1.4829 | AvgGrad=0.0377\n",
      "Epoch 4/200 | TrainAcc=39.86% | ValAcc=39.62% | TrainLoss=1.4821 | ValLoss=1.4857 | AvgGrad=0.0352\n",
      "Epoch 5/200 | TrainAcc=40.06% | ValAcc=39.74% | TrainLoss=1.4784 | ValLoss=1.4822 | AvgGrad=0.0343\n",
      "Epoch 6/200 | TrainAcc=40.24% | ValAcc=39.77% | TrainLoss=1.4739 | ValLoss=1.4824 | AvgGrad=0.0340\n",
      "Epoch 7/200 | TrainAcc=40.40% | ValAcc=39.75% | TrainLoss=1.4695 | ValLoss=1.4843 | AvgGrad=0.0346\n",
      "Epoch 8/200 | TrainAcc=40.66% | ValAcc=39.71% | TrainLoss=1.4653 | ValLoss=1.4857 | AvgGrad=0.0357\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 37.44%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=37.46% | ValAcc=39.15% | TrainLoss=1.5302 | ValLoss=1.4938 | AvgGrad=0.0618\n",
      "Epoch 2/200 | TrainAcc=39.31% | ValAcc=39.40% | TrainLoss=1.4946 | ValLoss=1.4900 | AvgGrad=0.0431\n",
      "Epoch 3/200 | TrainAcc=39.72% | ValAcc=39.51% | TrainLoss=1.4862 | ValLoss=1.4860 | AvgGrad=0.0378\n",
      "Epoch 4/200 | TrainAcc=39.96% | ValAcc=39.74% | TrainLoss=1.4813 | ValLoss=1.4849 | AvgGrad=0.0354\n",
      "Epoch 5/200 | TrainAcc=40.14% | ValAcc=39.77% | TrainLoss=1.4772 | ValLoss=1.4846 | AvgGrad=0.0343\n",
      "Epoch 6/200 | TrainAcc=40.30% | ValAcc=39.58% | TrainLoss=1.4730 | ValLoss=1.4854 | AvgGrad=0.0342\n",
      "Epoch 7/200 | TrainAcc=40.50% | ValAcc=39.74% | TrainLoss=1.4688 | ValLoss=1.4862 | AvgGrad=0.0346\n",
      "Epoch 8/200 | TrainAcc=40.67% | ValAcc=39.59% | TrainLoss=1.4646 | ValLoss=1.4848 | AvgGrad=0.0354\n",
      "Epoch 9/200 | TrainAcc=40.87% | ValAcc=39.57% | TrainLoss=1.4599 | ValLoss=1.4889 | AvgGrad=0.0368\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 37.59%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=37.38% | ValAcc=39.00% | TrainLoss=1.5297 | ValLoss=1.4996 | AvgGrad=0.0635\n",
      "Epoch 2/200 | TrainAcc=39.37% | ValAcc=39.41% | TrainLoss=1.4939 | ValLoss=1.4914 | AvgGrad=0.0434\n",
      "Epoch 3/200 | TrainAcc=39.69% | ValAcc=39.46% | TrainLoss=1.4863 | ValLoss=1.4891 | AvgGrad=0.0381\n",
      "Epoch 4/200 | TrainAcc=39.97% | ValAcc=39.34% | TrainLoss=1.4808 | ValLoss=1.4895 | AvgGrad=0.0356\n",
      "Epoch 5/200 | TrainAcc=40.18% | ValAcc=39.53% | TrainLoss=1.4770 | ValLoss=1.4851 | AvgGrad=0.0344\n",
      "Epoch 6/200 | TrainAcc=40.32% | ValAcc=39.54% | TrainLoss=1.4725 | ValLoss=1.4858 | AvgGrad=0.0343\n",
      "Epoch 7/200 | TrainAcc=40.52% | ValAcc=39.68% | TrainLoss=1.4684 | ValLoss=1.4841 | AvgGrad=0.0348\n",
      "Epoch 8/200 | TrainAcc=40.74% | ValAcc=39.63% | TrainLoss=1.4642 | ValLoss=1.4896 | AvgGrad=0.0358\n",
      "Epoch 9/200 | TrainAcc=40.96% | ValAcc=39.43% | TrainLoss=1.4590 | ValLoss=1.4917 | AvgGrad=0.0373\n",
      "Epoch 10/200 | TrainAcc=41.16% | ValAcc=39.48% | TrainLoss=1.4537 | ValLoss=1.4908 | AvgGrad=0.0393\n",
      "Epoch 11/200 | TrainAcc=41.89% | ValAcc=39.41% | TrainLoss=1.4362 | ValLoss=1.4964 | AvgGrad=0.0435\n",
      "Epoch 12/200 | TrainAcc=42.24% | ValAcc=39.11% | TrainLoss=1.4271 | ValLoss=1.5048 | AvgGrad=0.0486\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 37.24%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=37.40% | ValAcc=39.25% | TrainLoss=1.5295 | ValLoss=1.4969 | AvgGrad=0.0620\n",
      "Epoch 2/200 | TrainAcc=39.40% | ValAcc=39.13% | TrainLoss=1.4937 | ValLoss=1.4899 | AvgGrad=0.0427\n",
      "Epoch 3/200 | TrainAcc=39.69% | ValAcc=39.62% | TrainLoss=1.4858 | ValLoss=1.4858 | AvgGrad=0.0375\n",
      "Epoch 4/200 | TrainAcc=39.93% | ValAcc=39.58% | TrainLoss=1.4811 | ValLoss=1.4861 | AvgGrad=0.0352\n",
      "Epoch 5/200 | TrainAcc=40.20% | ValAcc=39.61% | TrainLoss=1.4769 | ValLoss=1.4843 | AvgGrad=0.0343\n",
      "Epoch 6/200 | TrainAcc=40.33% | ValAcc=39.81% | TrainLoss=1.4725 | ValLoss=1.4836 | AvgGrad=0.0341\n",
      "Epoch 7/200 | TrainAcc=40.55% | ValAcc=39.67% | TrainLoss=1.4691 | ValLoss=1.4857 | AvgGrad=0.0345\n",
      "Epoch 8/200 | TrainAcc=40.73% | ValAcc=39.47% | TrainLoss=1.4647 | ValLoss=1.4897 | AvgGrad=0.0356\n",
      "Epoch 9/200 | TrainAcc=40.93% | ValAcc=39.63% | TrainLoss=1.4605 | ValLoss=1.4889 | AvgGrad=0.0369\n",
      "Epoch 10/200 | TrainAcc=41.13% | ValAcc=39.37% | TrainLoss=1.4556 | ValLoss=1.4906 | AvgGrad=0.0388\n",
      "Epoch 11/200 | TrainAcc=41.83% | ValAcc=39.23% | TrainLoss=1.4386 | ValLoss=1.4960 | AvgGrad=0.0425\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 37.35%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=37.45% | ValAcc=38.92% | TrainLoss=1.5296 | ValLoss=1.4970 | AvgGrad=0.0625\n",
      "Epoch 2/200 | TrainAcc=39.35% | ValAcc=39.27% | TrainLoss=1.4940 | ValLoss=1.4918 | AvgGrad=0.0435\n",
      "Epoch 3/200 | TrainAcc=39.69% | ValAcc=39.47% | TrainLoss=1.4865 | ValLoss=1.4895 | AvgGrad=0.0382\n",
      "Epoch 4/200 | TrainAcc=39.95% | ValAcc=39.67% | TrainLoss=1.4814 | ValLoss=1.4857 | AvgGrad=0.0358\n",
      "Epoch 5/200 | TrainAcc=40.16% | ValAcc=39.55% | TrainLoss=1.4772 | ValLoss=1.4859 | AvgGrad=0.0349\n",
      "Epoch 6/200 | TrainAcc=40.30% | ValAcc=39.47% | TrainLoss=1.4731 | ValLoss=1.4879 | AvgGrad=0.0346\n",
      "Epoch 7/200 | TrainAcc=40.54% | ValAcc=39.57% | TrainLoss=1.4692 | ValLoss=1.4866 | AvgGrad=0.0351\n",
      "Epoch 8/200 | TrainAcc=40.74% | ValAcc=39.48% | TrainLoss=1.4648 | ValLoss=1.4897 | AvgGrad=0.0360\n",
      "Epoch 9/200 | TrainAcc=40.92% | ValAcc=39.29% | TrainLoss=1.4597 | ValLoss=1.4925 | AvgGrad=0.0375\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 37.24%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 39.38 ¬± 0.22\n",
      "Test Acc: 37.37 ¬± 0.13\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_21-44-49_wisig_XFR_blocksize24_SNR-5dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-5 dB, results saved in: ./training_results\\2026-01-17_21-44-49_wisig_XFR_blocksize24_SNR-5dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -10 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=22.90% | ValAcc=24.18% | TrainLoss=1.7597 | ValLoss=1.7486 | AvgGrad=0.0321\n",
      "Epoch 2/200 | TrainAcc=24.37% | ValAcc=24.38% | TrainLoss=1.7462 | ValLoss=1.7447 | AvgGrad=0.0222\n",
      "Epoch 3/200 | TrainAcc=24.78% | ValAcc=24.50% | TrainLoss=1.7424 | ValLoss=1.7446 | AvgGrad=0.0197\n",
      "Epoch 4/200 | TrainAcc=25.00% | ValAcc=24.84% | TrainLoss=1.7399 | ValLoss=1.7420 | AvgGrad=0.0189\n",
      "Epoch 5/200 | TrainAcc=25.13% | ValAcc=24.82% | TrainLoss=1.7374 | ValLoss=1.7418 | AvgGrad=0.0189\n",
      "Epoch 6/200 | TrainAcc=25.32% | ValAcc=24.94% | TrainLoss=1.7353 | ValLoss=1.7414 | AvgGrad=0.0194\n",
      "Epoch 7/200 | TrainAcc=25.47% | ValAcc=24.73% | TrainLoss=1.7327 | ValLoss=1.7437 | AvgGrad=0.0202\n",
      "Epoch 8/200 | TrainAcc=25.73% | ValAcc=24.72% | TrainLoss=1.7300 | ValLoss=1.7447 | AvgGrad=0.0215\n",
      "Epoch 9/200 | TrainAcc=25.97% | ValAcc=24.60% | TrainLoss=1.7270 | ValLoss=1.7469 | AvgGrad=0.0231\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 23.84%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=23.00% | ValAcc=23.88% | TrainLoss=1.7597 | ValLoss=1.7500 | AvgGrad=0.0322\n",
      "Epoch 2/200 | TrainAcc=24.46% | ValAcc=24.60% | TrainLoss=1.7463 | ValLoss=1.7440 | AvgGrad=0.0223\n",
      "Epoch 3/200 | TrainAcc=24.83% | ValAcc=24.62% | TrainLoss=1.7425 | ValLoss=1.7422 | AvgGrad=0.0201\n",
      "Epoch 4/200 | TrainAcc=24.98% | ValAcc=24.68% | TrainLoss=1.7399 | ValLoss=1.7419 | AvgGrad=0.0192\n",
      "Epoch 5/200 | TrainAcc=25.19% | ValAcc=24.60% | TrainLoss=1.7376 | ValLoss=1.7421 | AvgGrad=0.0192\n",
      "Epoch 6/200 | TrainAcc=25.34% | ValAcc=24.64% | TrainLoss=1.7354 | ValLoss=1.7426 | AvgGrad=0.0197\n",
      "Epoch 7/200 | TrainAcc=25.59% | ValAcc=24.62% | TrainLoss=1.7327 | ValLoss=1.7433 | AvgGrad=0.0207\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 23.87%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=22.84% | ValAcc=24.33% | TrainLoss=1.7604 | ValLoss=1.7470 | AvgGrad=0.0311\n",
      "Epoch 2/200 | TrainAcc=24.29% | ValAcc=24.74% | TrainLoss=1.7466 | ValLoss=1.7454 | AvgGrad=0.0218\n",
      "Epoch 3/200 | TrainAcc=24.69% | ValAcc=24.75% | TrainLoss=1.7430 | ValLoss=1.7424 | AvgGrad=0.0196\n",
      "Epoch 4/200 | TrainAcc=24.94% | ValAcc=24.88% | TrainLoss=1.7402 | ValLoss=1.7411 | AvgGrad=0.0188\n",
      "Epoch 5/200 | TrainAcc=25.12% | ValAcc=24.85% | TrainLoss=1.7379 | ValLoss=1.7411 | AvgGrad=0.0189\n",
      "Epoch 6/200 | TrainAcc=25.31% | ValAcc=24.76% | TrainLoss=1.7358 | ValLoss=1.7417 | AvgGrad=0.0193\n",
      "Epoch 7/200 | TrainAcc=25.55% | ValAcc=24.71% | TrainLoss=1.7333 | ValLoss=1.7432 | AvgGrad=0.0202\n",
      "Epoch 8/200 | TrainAcc=25.76% | ValAcc=24.55% | TrainLoss=1.7305 | ValLoss=1.7440 | AvgGrad=0.0216\n",
      "Epoch 9/200 | TrainAcc=26.09% | ValAcc=24.51% | TrainLoss=1.7269 | ValLoss=1.7464 | AvgGrad=0.0234\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 23.85%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=22.96% | ValAcc=24.04% | TrainLoss=1.7600 | ValLoss=1.7479 | AvgGrad=0.0313\n",
      "Epoch 2/200 | TrainAcc=24.46% | ValAcc=24.57% | TrainLoss=1.7466 | ValLoss=1.7442 | AvgGrad=0.0216\n",
      "Epoch 3/200 | TrainAcc=24.75% | ValAcc=24.75% | TrainLoss=1.7429 | ValLoss=1.7423 | AvgGrad=0.0193\n",
      "Epoch 4/200 | TrainAcc=25.01% | ValAcc=24.73% | TrainLoss=1.7404 | ValLoss=1.7415 | AvgGrad=0.0186\n",
      "Epoch 5/200 | TrainAcc=25.18% | ValAcc=24.65% | TrainLoss=1.7382 | ValLoss=1.7415 | AvgGrad=0.0185\n",
      "Epoch 6/200 | TrainAcc=25.29% | ValAcc=24.67% | TrainLoss=1.7361 | ValLoss=1.7417 | AvgGrad=0.0190\n",
      "Epoch 7/200 | TrainAcc=25.58% | ValAcc=24.74% | TrainLoss=1.7335 | ValLoss=1.7432 | AvgGrad=0.0198\n",
      "Epoch 8/200 | TrainAcc=25.70% | ValAcc=24.42% | TrainLoss=1.7309 | ValLoss=1.7438 | AvgGrad=0.0210\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 23.81%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=22.97% | ValAcc=24.02% | TrainLoss=1.7601 | ValLoss=1.7491 | AvgGrad=0.0315\n",
      "Epoch 2/200 | TrainAcc=24.50% | ValAcc=24.45% | TrainLoss=1.7460 | ValLoss=1.7440 | AvgGrad=0.0217\n",
      "Epoch 3/200 | TrainAcc=24.89% | ValAcc=24.42% | TrainLoss=1.7420 | ValLoss=1.7440 | AvgGrad=0.0196\n",
      "Epoch 4/200 | TrainAcc=25.12% | ValAcc=24.63% | TrainLoss=1.7395 | ValLoss=1.7424 | AvgGrad=0.0189\n",
      "Epoch 5/200 | TrainAcc=25.25% | ValAcc=24.46% | TrainLoss=1.7374 | ValLoss=1.7440 | AvgGrad=0.0189\n",
      "Epoch 6/200 | TrainAcc=25.44% | ValAcc=24.63% | TrainLoss=1.7349 | ValLoss=1.7425 | AvgGrad=0.0195\n",
      "Epoch 7/200 | TrainAcc=25.58% | ValAcc=24.47% | TrainLoss=1.7325 | ValLoss=1.7435 | AvgGrad=0.0204\n",
      "Epoch 8/200 | TrainAcc=25.84% | ValAcc=24.50% | TrainLoss=1.7295 | ValLoss=1.7441 | AvgGrad=0.0219\n",
      "Epoch 9/200 | TrainAcc=26.07% | ValAcc=24.34% | TrainLoss=1.7263 | ValLoss=1.7473 | AvgGrad=0.0235\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 23.81%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 24.50 ¬± 0.10\n",
      "Test Acc: 23.84 ¬± 0.02\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_22-07-25_wisig_XFR_blocksize24_SNR-10dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-10 dB, results saved in: ./training_results\\2026-01-17_22-07-25_wisig_XFR_blocksize24_SNR-10dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -15 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=17.43% | ValAcc=18.30% | TrainLoss=1.7918 | ValLoss=1.7894 | AvgGrad=0.0153\n",
      "Epoch 2/200 | TrainAcc=18.38% | ValAcc=18.55% | TrainLoss=1.7891 | ValLoss=1.7887 | AvgGrad=0.0092\n",
      "Epoch 3/200 | TrainAcc=18.67% | ValAcc=18.73% | TrainLoss=1.7880 | ValLoss=1.7883 | AvgGrad=0.0081\n",
      "Epoch 4/200 | TrainAcc=18.94% | ValAcc=18.84% | TrainLoss=1.7872 | ValLoss=1.7878 | AvgGrad=0.0079\n",
      "Epoch 5/200 | TrainAcc=19.15% | ValAcc=18.61% | TrainLoss=1.7864 | ValLoss=1.7880 | AvgGrad=0.0081\n",
      "Epoch 6/200 | TrainAcc=19.31% | ValAcc=18.69% | TrainLoss=1.7856 | ValLoss=1.7881 | AvgGrad=0.0085\n",
      "Epoch 7/200 | TrainAcc=19.49% | ValAcc=18.80% | TrainLoss=1.7846 | ValLoss=1.7884 | AvgGrad=0.0092\n",
      "Epoch 8/200 | TrainAcc=19.76% | ValAcc=18.79% | TrainLoss=1.7834 | ValLoss=1.7892 | AvgGrad=0.0104\n",
      "Epoch 9/200 | TrainAcc=20.03% | ValAcc=18.71% | TrainLoss=1.7820 | ValLoss=1.7899 | AvgGrad=0.0117\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 18.54%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=17.48% | ValAcc=18.21% | TrainLoss=1.7918 | ValLoss=1.7897 | AvgGrad=0.0144\n",
      "Epoch 2/200 | TrainAcc=18.36% | ValAcc=18.58% | TrainLoss=1.7893 | ValLoss=1.7883 | AvgGrad=0.0087\n",
      "Epoch 3/200 | TrainAcc=18.64% | ValAcc=18.77% | TrainLoss=1.7883 | ValLoss=1.7876 | AvgGrad=0.0078\n",
      "Epoch 4/200 | TrainAcc=18.84% | ValAcc=18.76% | TrainLoss=1.7874 | ValLoss=1.7878 | AvgGrad=0.0076\n",
      "Epoch 5/200 | TrainAcc=19.16% | ValAcc=18.99% | TrainLoss=1.7867 | ValLoss=1.7873 | AvgGrad=0.0078\n",
      "Epoch 6/200 | TrainAcc=19.24% | ValAcc=18.97% | TrainLoss=1.7859 | ValLoss=1.7873 | AvgGrad=0.0082\n",
      "Epoch 7/200 | TrainAcc=19.49% | ValAcc=18.68% | TrainLoss=1.7850 | ValLoss=1.7877 | AvgGrad=0.0089\n",
      "Epoch 8/200 | TrainAcc=19.77% | ValAcc=18.82% | TrainLoss=1.7838 | ValLoss=1.7885 | AvgGrad=0.0100\n",
      "Epoch 9/200 | TrainAcc=20.00% | ValAcc=18.82% | TrainLoss=1.7825 | ValLoss=1.7883 | AvgGrad=0.0114\n",
      "Epoch 10/200 | TrainAcc=20.33% | ValAcc=18.72% | TrainLoss=1.7807 | ValLoss=1.7898 | AvgGrad=0.0131\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 18.46%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=17.55% | ValAcc=18.11% | TrainLoss=1.7917 | ValLoss=1.7897 | AvgGrad=0.0162\n",
      "Epoch 2/200 | TrainAcc=18.32% | ValAcc=18.47% | TrainLoss=1.7892 | ValLoss=1.7887 | AvgGrad=0.0092\n",
      "Epoch 3/200 | TrainAcc=18.65% | ValAcc=18.54% | TrainLoss=1.7883 | ValLoss=1.7888 | AvgGrad=0.0083\n",
      "Epoch 4/200 | TrainAcc=18.98% | ValAcc=18.90% | TrainLoss=1.7873 | ValLoss=1.7876 | AvgGrad=0.0082\n",
      "Epoch 5/200 | TrainAcc=19.17% | ValAcc=18.93% | TrainLoss=1.7865 | ValLoss=1.7876 | AvgGrad=0.0081\n",
      "Epoch 6/200 | TrainAcc=19.41% | ValAcc=19.03% | TrainLoss=1.7856 | ValLoss=1.7874 | AvgGrad=0.0086\n",
      "Epoch 7/200 | TrainAcc=19.64% | ValAcc=18.97% | TrainLoss=1.7846 | ValLoss=1.7875 | AvgGrad=0.0093\n",
      "Epoch 8/200 | TrainAcc=19.83% | ValAcc=18.94% | TrainLoss=1.7831 | ValLoss=1.7885 | AvgGrad=0.0106\n",
      "Epoch 9/200 | TrainAcc=20.15% | ValAcc=18.84% | TrainLoss=1.7815 | ValLoss=1.7892 | AvgGrad=0.0122\n",
      "Epoch 10/200 | TrainAcc=20.56% | ValAcc=18.61% | TrainLoss=1.7793 | ValLoss=1.7909 | AvgGrad=0.0142\n",
      "Epoch 11/200 | TrainAcc=21.44% | ValAcc=18.53% | TrainLoss=1.7725 | ValLoss=1.7968 | AvgGrad=0.0190\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 18.20%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=17.64% | ValAcc=18.19% | TrainLoss=1.7915 | ValLoss=1.7895 | AvgGrad=0.0152\n",
      "Epoch 2/200 | TrainAcc=18.44% | ValAcc=18.53% | TrainLoss=1.7889 | ValLoss=1.7885 | AvgGrad=0.0090\n",
      "Epoch 3/200 | TrainAcc=18.71% | ValAcc=18.47% | TrainLoss=1.7880 | ValLoss=1.7881 | AvgGrad=0.0079\n",
      "Epoch 4/200 | TrainAcc=18.98% | ValAcc=18.56% | TrainLoss=1.7872 | ValLoss=1.7878 | AvgGrad=0.0077\n",
      "Epoch 5/200 | TrainAcc=19.14% | ValAcc=18.58% | TrainLoss=1.7865 | ValLoss=1.7882 | AvgGrad=0.0080\n",
      "Epoch 6/200 | TrainAcc=19.31% | ValAcc=18.66% | TrainLoss=1.7856 | ValLoss=1.7878 | AvgGrad=0.0084\n",
      "Epoch 7/200 | TrainAcc=19.57% | ValAcc=18.74% | TrainLoss=1.7847 | ValLoss=1.7879 | AvgGrad=0.0092\n",
      "Epoch 8/200 | TrainAcc=19.74% | ValAcc=18.70% | TrainLoss=1.7834 | ValLoss=1.7887 | AvgGrad=0.0105\n",
      "Epoch 9/200 | TrainAcc=20.09% | ValAcc=18.61% | TrainLoss=1.7816 | ValLoss=1.7898 | AvgGrad=0.0121\n",
      "Epoch 10/200 | TrainAcc=20.40% | ValAcc=18.53% | TrainLoss=1.7796 | ValLoss=1.7916 | AvgGrad=0.0142\n",
      "Epoch 11/200 | TrainAcc=21.35% | ValAcc=18.29% | TrainLoss=1.7725 | ValLoss=1.7973 | AvgGrad=0.0192\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 18.09%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=17.51% | ValAcc=18.25% | TrainLoss=1.7917 | ValLoss=1.7897 | AvgGrad=0.0154\n",
      "Epoch 2/200 | TrainAcc=18.21% | ValAcc=18.09% | TrainLoss=1.7894 | ValLoss=1.7898 | AvgGrad=0.0090\n",
      "Epoch 3/200 | TrainAcc=18.80% | ValAcc=18.59% | TrainLoss=1.7883 | ValLoss=1.7880 | AvgGrad=0.0080\n",
      "Epoch 4/200 | TrainAcc=18.96% | ValAcc=18.60% | TrainLoss=1.7874 | ValLoss=1.7885 | AvgGrad=0.0077\n",
      "Epoch 5/200 | TrainAcc=19.12% | ValAcc=18.89% | TrainLoss=1.7867 | ValLoss=1.7872 | AvgGrad=0.0078\n",
      "Epoch 6/200 | TrainAcc=19.30% | ValAcc=18.81% | TrainLoss=1.7858 | ValLoss=1.7874 | AvgGrad=0.0082\n",
      "Epoch 7/200 | TrainAcc=19.56% | ValAcc=18.78% | TrainLoss=1.7849 | ValLoss=1.7883 | AvgGrad=0.0088\n",
      "Epoch 8/200 | TrainAcc=19.75% | ValAcc=18.83% | TrainLoss=1.7839 | ValLoss=1.7883 | AvgGrad=0.0098\n",
      "Epoch 9/200 | TrainAcc=20.05% | ValAcc=18.77% | TrainLoss=1.7824 | ValLoss=1.7888 | AvgGrad=0.0113\n",
      "Epoch 10/200 | TrainAcc=20.33% | ValAcc=18.70% | TrainLoss=1.7808 | ValLoss=1.7896 | AvgGrad=0.0129\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 18.52%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 18.59 ¬± 0.17\n",
      "Test Acc: 18.36 ¬± 0.18\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_22-27-08_wisig_XFR_blocksize24_SNR-15dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-15 dB, results saved in: ./training_results\\2026-01-17_22-27-08_wisig_XFR_blocksize24_SNR-15dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -20 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.67% | ValAcc=16.80% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0100\n",
      "Epoch 2/200 | TrainAcc=16.72% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0021\n",
      "Epoch 3/200 | TrainAcc=16.64% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.65% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0016\n",
      "Epoch 5/200 | TrainAcc=16.61% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.71% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.72% | ValAcc=16.81% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0105\n",
      "Epoch 2/200 | TrainAcc=16.55% | ValAcc=16.80% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0030\n",
      "Epoch 3/200 | TrainAcc=16.63% | ValAcc=16.80% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 4/200 | TrainAcc=16.68% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 5/200 | TrainAcc=16.73% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.70% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.62% | ValAcc=16.64% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0100\n",
      "Epoch 2/200 | TrainAcc=16.67% | ValAcc=16.74% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0025\n",
      "Epoch 3/200 | TrainAcc=16.58% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.59% | ValAcc=16.74% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.64% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.72% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0013\n",
      "Epoch 7/200 | TrainAcc=16.71% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.62% | ValAcc=16.60% | TrainLoss=1.7926 | ValLoss=1.7921 | AvgGrad=0.0091\n",
      "Epoch 2/200 | TrainAcc=16.66% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0022\n",
      "Epoch 3/200 | TrainAcc=16.60% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.61% | ValAcc=16.54% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0016\n",
      "Epoch 5/200 | TrainAcc=16.63% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.64% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.69% | ValAcc=16.64% | TrainLoss=1.7927 | ValLoss=1.7919 | AvgGrad=0.0107\n",
      "Epoch 2/200 | TrainAcc=16.64% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0020\n",
      "Epoch 3/200 | TrainAcc=16.65% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.70% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.60% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.74% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 16.67%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 16.65 ¬± 0.07\n",
      "Test Acc: 16.67 ¬± 0.00\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_22-50-29_wisig_XFR_blocksize24_SNR-20dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-20 dB, results saved in: ./training_results\\2026-01-17_22-50-29_wisig_XFR_blocksize24_SNR-20dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -25 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.63% | ValAcc=16.48% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0098\n",
      "Epoch 2/200 | TrainAcc=16.61% | ValAcc=16.49% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.66% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 4/200 | TrainAcc=16.67% | ValAcc=16.49% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.61% | ValAcc=16.79% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.63% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.73% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.59% | ValAcc=16.49% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 9/200 | TrainAcc=16.62% | ValAcc=16.79% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 10/200 | TrainAcc=16.63% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7922 | AvgGrad=0.0015\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 16.73%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.58% | ValAcc=16.61% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0113\n",
      "Epoch 2/200 | TrainAcc=16.66% | ValAcc=16.84% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0027\n",
      "Epoch 3/200 | TrainAcc=16.57% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.67% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 5/200 | TrainAcc=16.68% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0016\n",
      "Epoch 6/200 | TrainAcc=16.63% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.70% | ValAcc=16.80% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.63% | ValAcc=16.63% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0088\n",
      "Epoch 2/200 | TrainAcc=16.65% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0020\n",
      "Epoch 3/200 | TrainAcc=16.64% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.59% | ValAcc=16.62% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.63% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.56% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.57% | ValAcc=16.80% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0096\n",
      "Epoch 2/200 | TrainAcc=16.72% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0022\n",
      "Epoch 3/200 | TrainAcc=16.70% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0014\n",
      "Epoch 4/200 | TrainAcc=16.68% | ValAcc=16.54% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.64% | ValAcc=16.54% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.62% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.62% | ValAcc=16.62% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0096\n",
      "Epoch 2/200 | TrainAcc=16.68% | ValAcc=16.62% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0026\n",
      "Epoch 3/200 | TrainAcc=16.60% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.73% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.63% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 6/200 | TrainAcc=16.64% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 16.67%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 16.69 ¬± 0.07\n",
      "Test Acc: 16.68 ¬± 0.02\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_23-05-45_wisig_XFR_blocksize24_SNR-25dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-25 dB, results saved in: ./training_results\\2026-01-17_23-05-45_wisig_XFR_blocksize24_SNR-25dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -30 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.60% | ValAcc=16.58% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0083\n",
      "Epoch 2/200 | TrainAcc=16.71% | ValAcc=16.59% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0025\n",
      "Epoch 3/200 | TrainAcc=16.53% | ValAcc=16.84% | TrainLoss=1.7918 | ValLoss=1.7917 | AvgGrad=0.0016\n",
      "Epoch 4/200 | TrainAcc=16.60% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.75% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.67% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0013\n",
      "Epoch 7/200 | TrainAcc=16.63% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.67% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.70% | ValAcc=16.69% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0111\n",
      "Epoch 2/200 | TrainAcc=16.75% | ValAcc=16.70% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0027\n",
      "Epoch 3/200 | TrainAcc=16.61% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.67% | ValAcc=16.51% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0018\n",
      "Epoch 5/200 | TrainAcc=16.72% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.64% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.72% | ValAcc=16.64% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0107\n",
      "Epoch 2/200 | TrainAcc=16.64% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.76% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.71% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0016\n",
      "Epoch 5/200 | TrainAcc=16.69% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.62% | ValAcc=16.62% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.72% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.65% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 9/200 | TrainAcc=16.70% | ValAcc=16.62% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.73% | ValAcc=16.71% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0106\n",
      "Epoch 2/200 | TrainAcc=16.64% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0025\n",
      "Epoch 3/200 | TrainAcc=16.66% | ValAcc=16.54% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0019\n",
      "Epoch 4/200 | TrainAcc=16.65% | ValAcc=16.54% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.64% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.65% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0013\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.68% | ValAcc=16.58% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0111\n",
      "Epoch 2/200 | TrainAcc=16.64% | ValAcc=16.62% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.61% | ValAcc=16.71% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.56% | ValAcc=16.71% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 5/200 | TrainAcc=16.66% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.63% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.71% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0013\n",
      "Epoch 8/200 | TrainAcc=16.70% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 16.67%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 16.64 ¬± 0.05\n",
      "Test Acc: 16.67 ¬± 0.00\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_23-22-40_wisig_XFR_blocksize24_SNR-30dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-30 dB, results saved in: ./training_results\\2026-01-17_23-22-40_wisig_XFR_blocksize24_SNR-30dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -35 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.62% | ValAcc=16.77% | TrainLoss=1.7927 | ValLoss=1.7921 | AvgGrad=0.0100\n",
      "Epoch 2/200 | TrainAcc=16.67% | ValAcc=16.59% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0029\n",
      "Epoch 3/200 | TrainAcc=16.68% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 4/200 | TrainAcc=16.67% | ValAcc=16.79% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 5/200 | TrainAcc=16.56% | ValAcc=16.49% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.55% | ValAcc=16.49% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.68% | ValAcc=16.73% | TrainLoss=1.7928 | ValLoss=1.7918 | AvgGrad=0.0114\n",
      "Epoch 2/200 | TrainAcc=16.67% | ValAcc=16.76% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0030\n",
      "Epoch 3/200 | TrainAcc=16.63% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.64% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.68% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.65% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.59% | ValAcc=16.82% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0106\n",
      "Epoch 2/200 | TrainAcc=16.63% | ValAcc=16.63% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.70% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.65% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 5/200 | TrainAcc=16.65% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0013\n",
      "Epoch 6/200 | TrainAcc=16.61% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.73% | ValAcc=16.53% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0101\n",
      "Epoch 2/200 | TrainAcc=16.69% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.71% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.65% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.60% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.63% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.69% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.70% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.64% | ValAcc=16.61% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0091\n",
      "Epoch 2/200 | TrainAcc=16.63% | ValAcc=16.60% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0021\n",
      "Epoch 3/200 | TrainAcc=16.62% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.63% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.70% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.68% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 16.67%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 16.61 ¬± 0.07\n",
      "Test Acc: 16.67 ¬± 0.00\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_23-40-25_wisig_XFR_blocksize24_SNR-35dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-35 dB, results saved in: ./training_results\\2026-01-17_23-40-25_wisig_XFR_blocksize24_SNR-35dB_fd266_classes_6_ResNet\n",
      "\n",
      "============================================================\n",
      "üöÄ Running experiment with SNR = -40 dB\n",
      "============================================================\n",
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.60% | ValAcc=16.49% | TrainLoss=1.7926 | ValLoss=1.7919 | AvgGrad=0.0098\n",
      "Epoch 2/200 | TrainAcc=16.72% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.70% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 4/200 | TrainAcc=16.66% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 5/200 | TrainAcc=16.70% | ValAcc=16.59% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.69% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.70% | ValAcc=16.84% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.67% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 9/200 | TrainAcc=16.70% | ValAcc=16.49% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 10/200 | TrainAcc=16.64% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 11/200 | TrainAcc=16.62% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 12/200 | TrainAcc=16.68% | ValAcc=16.58% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 1 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.65% | ValAcc=16.59% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0094\n",
      "Epoch 2/200 | TrainAcc=16.60% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 3/200 | TrainAcc=16.73% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 4/200 | TrainAcc=16.69% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 5/200 | TrainAcc=16.63% | ValAcc=16.61% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 6/200 | TrainAcc=16.72% | ValAcc=16.51% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.70% | ValAcc=16.51% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 2 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.65% | ValAcc=16.53% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0102\n",
      "Epoch 2/200 | TrainAcc=16.64% | ValAcc=16.65% | TrainLoss=1.7919 | ValLoss=1.7918 | AvgGrad=0.0025\n",
      "Epoch 3/200 | TrainAcc=16.67% | ValAcc=16.55% | TrainLoss=1.7918 | ValLoss=1.7919 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.59% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0018\n",
      "Epoch 5/200 | TrainAcc=16.56% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.74% | ValAcc=16.64% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.62% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 3 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.68% | ValAcc=16.72% | TrainLoss=1.7926 | ValLoss=1.7918 | AvgGrad=0.0098\n",
      "Epoch 2/200 | TrainAcc=16.66% | ValAcc=16.74% | TrainLoss=1.7919 | ValLoss=1.7921 | AvgGrad=0.0024\n",
      "Epoch 3/200 | TrainAcc=16.70% | ValAcc=16.70% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0017\n",
      "Epoch 4/200 | TrainAcc=16.62% | ValAcc=16.72% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0015\n",
      "Epoch 5/200 | TrainAcc=16.67% | ValAcc=16.63% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.64% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 4 Test Accuracy: 16.67%\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1/200 | TrainAcc=16.62% | ValAcc=16.57% | TrainLoss=1.7927 | ValLoss=1.7918 | AvgGrad=0.0105\n",
      "Epoch 2/200 | TrainAcc=16.59% | ValAcc=16.60% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0022\n",
      "Epoch 3/200 | TrainAcc=16.59% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0016\n",
      "Epoch 4/200 | TrainAcc=16.67% | ValAcc=16.69% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0013\n",
      "Epoch 5/200 | TrainAcc=16.70% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 6/200 | TrainAcc=16.58% | ValAcc=16.81% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 7/200 | TrainAcc=16.71% | ValAcc=16.57% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Epoch 8/200 | TrainAcc=16.65% | ValAcc=16.71% | TrainLoss=1.7918 | ValLoss=1.7918 | AvgGrad=0.0014\n",
      "Early stopping.\n",
      "Fold 5 Test Accuracy: 16.67%\n",
      "\n",
      "=== Overall Summary ===\n",
      "Val Acc: 16.61 ¬± 0.07\n",
      "Test Acc: 16.67 ¬± 0.00\n",
      "\n",
      "All results saved in ./training_results\\2026-01-17_23-56-12_wisig_XFR_blocksize24_SNR-40dB_fd266_classes_6_ResNet\n",
      "üéâ Finished SNR=-40 dB, results saved in: ./training_results\\2026-01-17_23-56-12_wisig_XFR_blocksize24_SNR-40dB_fd266_classes_6_ResNet\n",
      "\n",
      "\n",
      "================ FINAL SUMMARY ================\n",
      "SNR  20 dB ‚Üí results in: ./training_results\\2026-01-17_19-02-50_wisig_XFR_blocksize24_SNR20dB_fd266_classes_6_ResNet\n",
      "SNR  15 dB ‚Üí results in: ./training_results\\2026-01-17_19-39-20_wisig_XFR_blocksize24_SNR15dB_fd266_classes_6_ResNet\n",
      "SNR  10 dB ‚Üí results in: ./training_results\\2026-01-17_20-15-44_wisig_XFR_blocksize24_SNR10dB_fd266_classes_6_ResNet\n",
      "SNR   5 dB ‚Üí results in: ./training_results\\2026-01-17_20-51-54_wisig_XFR_blocksize24_SNR5dB_fd266_classes_6_ResNet\n",
      "SNR   0 dB ‚Üí results in: ./training_results\\2026-01-17_21-19-25_wisig_XFR_blocksize24_SNR0dB_fd266_classes_6_ResNet\n",
      "SNR  -5 dB ‚Üí results in: ./training_results\\2026-01-17_21-44-49_wisig_XFR_blocksize24_SNR-5dB_fd266_classes_6_ResNet\n",
      "SNR -10 dB ‚Üí results in: ./training_results\\2026-01-17_22-07-25_wisig_XFR_blocksize24_SNR-10dB_fd266_classes_6_ResNet\n",
      "SNR -15 dB ‚Üí results in: ./training_results\\2026-01-17_22-27-08_wisig_XFR_blocksize24_SNR-15dB_fd266_classes_6_ResNet\n",
      "SNR -20 dB ‚Üí results in: ./training_results\\2026-01-17_22-50-29_wisig_XFR_blocksize24_SNR-20dB_fd266_classes_6_ResNet\n",
      "SNR -25 dB ‚Üí results in: ./training_results\\2026-01-17_23-05-45_wisig_XFR_blocksize24_SNR-25dB_fd266_classes_6_ResNet\n",
      "SNR -30 dB ‚Üí results in: ./training_results\\2026-01-17_23-22-40_wisig_XFR_blocksize24_SNR-30dB_fd266_classes_6_ResNet\n",
      "SNR -35 dB ‚Üí results in: ./training_results\\2026-01-17_23-40-25_wisig_XFR_blocksize24_SNR-35dB_fd266_classes_6_ResNet\n",
      "SNR -40 dB ‚Üí results in: ./training_results\\2026-01-17_23-56-12_wisig_XFR_blocksize24_SNR-40dB_fd266_classes_6_ResNet\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "# Ë∑®Êó•Êúü ResNet18 Âæ™ÁéØSNR 6‰∏™ËÆæÂ§á\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from  data_utilities import *\n",
    "import cv2  # OpenCV Áî®‰∫éË∞ÉÊï¥ÂõæÂÉèÂ§ßÂ∞èÂíåÈ¢úËâ≤Â§ÑÁêÜ\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # ÂºïÂÖ•ÂûÉÂúæÂõûÊî∂Ê®°Âùó\n",
    "from tqdm.auto import tqdm  # Ëá™Âä®ÈÄÇÈÖçÁéØÂ¢É ÂØºÂÖ•tqdmËøõÂ∫¶Êù°Â∫ì\n",
    "from collections import defaultdict\n",
    "\n",
    "dataset_name = 'ManySig'\n",
    "dataset_path='../ManySig.pkl/'\n",
    "\n",
    "compact_dataset = load_compact_pkl_dataset(dataset_path,dataset_name)\n",
    "\n",
    "print(\"Êï∞ÊçÆÈõÜÂèëÂ∞ÑÊú∫Êï∞ÈáèÔºö\",len(compact_dataset['tx_list']),\"ÂÖ∑‰Ωì‰∏∫Ôºö\",compact_dataset['tx_list'])\n",
    "print(\"Êï∞ÊçÆÈõÜÊé•Êî∂Êú∫Êï∞ÈáèÔºö\",len(compact_dataset['rx_list']),\"ÂÖ∑‰Ωì‰∏∫Ôºö\",compact_dataset['rx_list'])\n",
    "print(\"Êï∞ÊçÆÈõÜÈááÈõÜÂ§©Êï∞Ôºö\",len(compact_dataset['capture_date_list']),\"ÂÖ∑‰Ωì‰∏∫Ôºö\",compact_dataset['capture_date_list'])\n",
    "tx_list = compact_dataset['tx_list']\n",
    "rx_list = compact_dataset['rx_list']\n",
    "capture_date_list = compact_dataset['capture_date_list']\n",
    "\n",
    "\n",
    "n_tx = len(tx_list)\n",
    "n_rx = len(rx_list)\n",
    "print(n_tx,n_rx)\n",
    "\n",
    "\n",
    "# ÂèÇÊï∞ËÆæÁΩÆ\n",
    "equalized = 0\n",
    "max_sig = None         # ÊØè‰∏™ TX-RX-Êó•ÊúüÊúÄÂ§ö‰ΩøÁî®ÁöÑ‰ø°Âè∑Êï∞\n",
    "block_size = 96        # ÊØè‰∏™ block ÁöÑ‰ø°Âè∑Êï∞\n",
    "y = 1                  # ÊãºÊé•Êó∂ÊØèÁªÑÂ§öÂ∞ëÊù°‰ø°Âè∑\n",
    "\n",
    "train_dates = ['2021_03_15']  # ËÆæÂÆöËÆ≠ÁªÉÊó•Êúü\n",
    "test_dates  = ['2021_03_01']  # ËÆæÂÆöÊµãËØïÊó•Êúü\n",
    "# Ë∞ÉÁî®ÂáΩÊï∞\n",
    "\n",
    "X_train, y_train, X_test, y_test = preprocess_dataset_cross_IQ_blocks_single_date_per_rx_cyclic(\n",
    "    compact_dataset=compact_dataset,\n",
    "    tx_list=tx_list,\n",
    "    train_dates=train_dates,\n",
    "    test_dates=test_dates,\n",
    "    max_sig=max_sig,        # ÊØè‰∏™ RX ÊúÄÂ§öÂèñÂ§öÂ∞ëÊù°‰ø°Âè∑ÔºåÂèØÈÄâ\n",
    "    equalized=equalized,        # ÊòØÂê¶‰ΩøÁî®ÂùáË°°Âåñ‰ø°Âè∑\n",
    "    block_size=block_size,     # ÊØè‰∏™ block ÁöÑÊ†∑Êú¨Êï∞\n",
    "    y=y                # ÊØèÊ¨°Âæ™ÁéØ‰ªé RX ÊäΩÂèñÁöÑ‰ø°Âè∑Êï∞\n",
    ")\n",
    "\n",
    "print(\"ËÆ≠ÁªÉÈõÜÊâÄÈÄâÊó•ÊúüÔºö\",train_dates, \"ÊµãËØïÈõÜÊâÄÈÄâÊó•ÊúüÔºö\", test_dates)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape) \n",
    "print(\"y_test  shape:\", y_test.shape)\n",
    "\n",
    "# ---------- PyTorch & ËÆ≠ÁªÉÈÖçÁΩÆ ----------\n",
    "import torch\n",
    "torch._dynamo.disable()\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pywt  # ‰øùÁïôÔºåËã•ÈúÄÊâ©Â±ï\n",
    "import math\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Êï∞ÊçÆÂ¢ûÂº∫ / ‰ø°ÈÅìËÆæÁΩÆÔºàÁõÆÂâçÈªòËÆ§ÂÖ≥Èó≠Ôºâ\n",
    "FS = 20e6\n",
    "FC = 2.4e9\n",
    "SNR_DB = 20\n",
    "VELOCITY_KMH = 120\n",
    "ADD_NOISE = True\n",
    "ADD_DOPPLER = True\n",
    "\n",
    "# ËÆ≠ÁªÉÂèÇÊï∞\n",
    "BATCH_SIZE = 256   # Êõ¥Â§ß batch Êõ¥Á®≥ÂÆöÔºà‰Ω†Êï∞ÊçÆÂæàÂ§öÔºâ\n",
    "EPOCHS = 200\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "N_SPLITS = 5\n",
    "PATIENCE = 5\n",
    "MIN_DELTA = 0.1   # early stopping ÁöÑÊúÄÂ∞èËøõÊ≠•Ôºà%Ôºâ\n",
    "\n",
    "SAVE_ROOT = \"./training_results\"\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "script_name = \"wisig_XFR\"\n",
    "\n",
    "# ---------- ÂèØÈÄâÔºöAWGN / DopplerÔºà‰øùÁïôÔºâ ----------\n",
    "def compute_doppler_shift(v_kmh, fc_hz):\n",
    "    if not v_kmh:\n",
    "        return 0.0\n",
    "    c = 3e8\n",
    "    v = v_kmh / 3.6\n",
    "    return fc_hz * v / c\n",
    "\n",
    "def add_complex_awgn(signal, snr_db):\n",
    "    if snr_db is None:\n",
    "        return signal\n",
    "    power = np.mean(np.abs(signal)**2)\n",
    "    noise_power = power / (10**(snr_db/10))\n",
    "    noise_std = np.sqrt(noise_power/2)\n",
    "    noise = noise_std * (np.random.randn(*signal.shape) + 1j*np.random.randn(*signal.shape))\n",
    "    return signal + noise\n",
    "\n",
    "def apply_doppler_shift(signal, fd_hz, fs_hz):\n",
    "    if fd_hz is None or fd_hz == 0:\n",
    "        return signal\n",
    "    t = np.arange(len(signal)) / fs_hz\n",
    "    return signal * np.exp(1j * 2 * np.pi * fd_hz * t)\n",
    "\n",
    "# ---------- Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºöÈíàÂØπ‰∫§ÈîôÊ†∑Êú¨ÔºåÁî® per-sample Ê†áÂáÜÂåñ----------\n",
    "def preprocess_for_pointcloud_cnn(data_real_imag, add_noise=False, snr_db=None,\n",
    "                                  add_doppler=False, fd_hz=None, fs_hz=FS):\n",
    "    \"\"\"\n",
    "    ËæìÂÖ• data_real_imag: np.array [N, L, 2] (I,Q)\n",
    "    ËæìÂá∫ torch.tensor [N, L, 2] (float32)ÔºåÊØè‰∏™Ê†∑Êú¨ÂÅö zero-mean unit-std Ê†áÂáÜÂåñÔºàÊåâÊ†∑Êú¨Ôºâ\n",
    "    \"\"\"\n",
    "    data = data_real_imag.astype(np.float32).copy()\n",
    "    N, L, C = data.shape\n",
    "    out = np.empty_like(data, dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        iq = data[i]  # (L,2)\n",
    "        # ÁªÑÂêàÊàê complex\n",
    "        sigc = iq[...,0] + 1j * iq[...,1]\n",
    "\n",
    "        # step1 ÂΩí‰∏ÄÂåñÂäüÁéá\n",
    "        sigc = sigc / (np.sqrt(np.mean(np.abs(sigc)**2)) + 1e-12)\n",
    "\n",
    "        # step2 ÂèØÈÄâÂ§öÊôÆÂãí\n",
    "        if add_doppler:\n",
    "            sigc = apply_doppler_shift(sigc, fd_hz, fs_hz)\n",
    "\n",
    "        # step3 ÂèØÈÄâÂô™Â£∞\n",
    "        if add_noise:\n",
    "            sigc = add_complex_awgn(sigc, snr_db)\n",
    "\n",
    "        # ËΩ¨Âõû IQ\n",
    "        iq = np.stack([np.real(sigc), np.imag(sigc)], axis=-1).astype(np.float32)\n",
    "\n",
    "        # per-sample Ê†áÂáÜÂåñ\n",
    "        mu = iq.mean(axis=(0,))\n",
    "        sigma = iq.std(axis=(0,))\n",
    "        sigma[sigma < 1e-8] = 1.0\n",
    "        iq_norm = (iq - mu) / sigma\n",
    "        out[i] = iq_norm\n",
    "\n",
    "    return torch.tensor(out, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ---------- Êñ∞ÁöÑ RF1DCNN ----------\n",
    "class ResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=1):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x); out = self.bn1(out); out = self.relu(out)\n",
    "        out = self.conv2(out); out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class RF1DCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.3, input_length=256):\n",
    "        super().__init__()\n",
    "        self.layer1 = ResidualBlock1D(2, 32, kernel_size=7); self.pool1 = nn.MaxPool1d(2)\n",
    "        self.layer2 = ResidualBlock1D(32, 64, kernel_size=5); self.pool2 = nn.MaxPool1d(2)\n",
    "        self.layer3 = ResidualBlock1D(64, 128, kernel_size=5); self.pool3 = nn.MaxPool1d(2)\n",
    "        self.layer4 = ResidualBlock1D(128, 256, kernel_size=3); self.pool4 = nn.MaxPool1d(2)\n",
    "\n",
    "        # Âä®ÊÄÅËÆ°ÁÆó flatten ÂêéÈïøÂ∫¶\n",
    "        L = input_length\n",
    "        for _ in range(4):  # 4‰∏™ MaxPool1d(2)\n",
    "            L = L // 2\n",
    "        self.flattened_length = 256 * L\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.flattened_length, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1)  # [B,L,2] -> [B,2,L]\n",
    "        x = self.layer1(x); x = self.pool1(x)\n",
    "        x = self.layer2(x); x = self.pool2(x)\n",
    "        x = self.layer3(x); x = self.pool3(x)\n",
    "        x = self.layer4(x); x = self.pool4(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# ---------- ËæÖÂä©ÁªòÂõæ/ËØÑ‰º∞ÂáΩÊï∞ ----------\n",
    "def evaluate_model(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataloader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            _, p = torch.max(out, 1)\n",
    "            correct += (p == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "            all_preds.extend(p.cpu().numpy())\n",
    "    acc = 100.0 * correct / total if total>0 else 0.0\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, fold, save_folder, dataset_type='Test'):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{dataset_type} Confusion Matrix Fold{fold}')\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig(os.path.join(save_folder, f'{dataset_type.lower()}_cm_fold{fold}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_curves(train_losses, val_losses, train_acc, val_acc, fold, save_folder):\n",
    "    plt.figure(); plt.plot(train_losses, label='Train Loss'); plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Fold {fold} Loss'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f'loss_fold{fold}.png')); plt.close()\n",
    "    plt.figure(); plt.plot(train_acc, label='Train Acc'); plt.plot(val_acc, label='Val Acc')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)'); plt.title(f'Fold {fold} Accuracy'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_folder, f'acc_fold{fold}.png')); plt.close()\n",
    "\n",
    "# ---------- K-Fold ËÆ≠ÁªÉ‰∏ªÂáΩÊï∞Ôºà‰ΩøÁî® RF1DCNNÔºâ ----------\n",
    "def train_kfold_pointcloud(X_train, y_train, X_test, y_test, num_classes, device=DEVICE,\n",
    "                           batch_size=BATCH_SIZE, epochs=EPOCHS, lr=LR, weight_decay=WEIGHT_DECAY,\n",
    "                           n_splits=N_SPLITS, patience=PATIENCE, min_delta=MIN_DELTA,\n",
    "                           script_name=script_name):\n",
    "    fd = int(compute_doppler_shift(VELOCITY_KMH, FC))\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    save_dir = f\"{timestamp}_{script_name}_blocksize{block_size}_SNR{SNR_DB}dB_fd{fd}_classes_{num_classes}_ResNet\"\n",
    "    save_folder = os.path.join(SAVE_ROOT, save_dir)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    results_file = os.path.join(save_folder, \"results.txt\")\n",
    "\n",
    "    # ‰øùÂ≠òÂèÇÊï∞\n",
    "    with open(results_file, 'w') as f:\n",
    "        f.write(\"=== Experiment Parameters ===\\n\")\n",
    "        f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "        f.write(f\"SNR_dB: {SNR_DB}, ADD_NOISE: {ADD_NOISE}, ADD_DOPPLER: {ADD_DOPPLER}\\n\")\n",
    "        f.write(f\"FS: {FS}, FC: {FC}, Velocity_kmh: {VELOCITY_KMH}\\n\")\n",
    "        f.write(f\"Batch: {batch_size}, Epochs: {epochs}, LR: {lr}, WD: {weight_decay}\\n\")\n",
    "        f.write(f\"Num classes: {num_classes}, K-Fold: {n_splits}, Patience: {patience}, MinDelta: {min_delta}\\n\")\n",
    "        f.write(\"============================\\n\\n\")\n",
    "\n",
    "    # test loader\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    # full dataset for K-Fold\n",
    "    full_dataset = TensorDataset(X_train, y_train)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    indices = np.arange(len(full_dataset))\n",
    "\n",
    "    val_scores, test_scores = [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(indices)):\n",
    "        print(f\"\\n=== Fold {fold+1}/{n_splits} ===\")\n",
    "        tr_sub = Subset(full_dataset, tr_idx)\n",
    "        va_sub = Subset(full_dataset, va_idx)\n",
    "        tr_loader = DataLoader(tr_sub, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        va_loader = DataLoader(va_sub, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = RF1DCNN(num_classes=num_classes, dropout=0.3, input_length=block_size).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        best_val = 0.0\n",
    "        best_wts = None\n",
    "        patience_cnt = 0\n",
    "\n",
    "        train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "        avg_grad_list = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss, correct, total = 0.0, 0, 0\n",
    "            total_grad, cnt_grad = 0.0, 0\n",
    "            for xb, yb in tr_loader:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                # grad norm\n",
    "                grad_norms = [p.grad.norm().item() for p in model.parameters() if p.grad is not None]\n",
    "                if grad_norms:\n",
    "                    total_grad += np.mean(grad_norms); cnt_grad += 1\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                _, p = torch.max(out, 1)\n",
    "                correct += (p == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "            avg_grad = total_grad / max(cnt_grad, 1)\n",
    "            avg_grad_list.append(avg_grad)\n",
    "\n",
    "            train_loss = running_loss / max(1, len(tr_loader))\n",
    "            train_acc = 100.0 * correct / max(1, total)\n",
    "            train_losses.append(train_loss); train_accs.append(train_acc)\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            vloss, vcorrect, vtotal = 0.0, 0, 0\n",
    "            all_labels, all_preds = [], []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in va_loader:\n",
    "                    xb = xb.to(device); yb = yb.to(device)\n",
    "                    out = model(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    vloss += loss.item()\n",
    "                    _, p = torch.max(out, 1)\n",
    "                    vcorrect += (p == yb).sum().item()\n",
    "                    vtotal += yb.size(0)\n",
    "                    all_labels.extend(yb.cpu().numpy()); all_preds.extend(p.cpu().numpy())\n",
    "            val_loss = vloss / max(1, len(va_loader))\n",
    "            val_acc = 100.0 * vcorrect / max(1, vtotal)\n",
    "            val_losses.append(val_loss); val_accs.append(val_acc)\n",
    "            val_cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "            np.save(os.path.join(save_folder, f'val_cm_fold{fold+1}.npy'), val_cm)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | TrainAcc={train_acc:.2f}% | ValAcc={val_acc:.2f}% | \"\n",
    "                  f\"TrainLoss={train_loss:.4f} | ValLoss={val_loss:.4f} | AvgGrad={avg_grad:.4f}\")\n",
    "            with open(results_file, 'a') as f:\n",
    "                f.write(f\"Fold{fold+1} Epoch{epoch+1} | TrainAcc={train_acc:.2f}% | ValAcc={val_acc:.2f}% | \"\n",
    "                        f\"TrainLoss={train_loss:.4f} | ValLoss={val_loss:.4f} | AvgGrad={avg_grad:.4f}\\n\")\n",
    "\n",
    "            # Early stopping on validation accuracy with min_delta (percentage points)\n",
    "            if val_acc > best_val + min_delta:\n",
    "                best_val = val_acc\n",
    "                best_wts = model.state_dict()\n",
    "                patience_cnt = 0\n",
    "            else:\n",
    "                patience_cnt += 1\n",
    "                if patience_cnt >= patience:\n",
    "                    print(\"Early stopping.\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        # restore best\n",
    "        if best_wts is not None:\n",
    "            model.load_state_dict(best_wts)\n",
    "\n",
    "        # ‰øùÂ≠ò train/val Ê∑∑Ê∑ÜÁü©Èòµ\n",
    "        train_acc, train_cm = evaluate_model(model, tr_loader, device, num_classes)\n",
    "        np.save(os.path.join(save_folder, f'train_cm_fold{fold+1}.npy'), train_cm)\n",
    "        plot_confusion_matrix(train_cm, classes=list(range(num_classes)), fold=fold+1, save_folder=save_folder, dataset_type='Train')\n",
    "\n",
    "        val_acc, val_cm = evaluate_model(model, va_loader, device, num_classes)\n",
    "        np.save(os.path.join(save_folder, f'val_cm_fold{fold+1}.npy'), val_cm)\n",
    "        plot_confusion_matrix(val_cm, classes=list(range(num_classes)), fold=fold+1, save_folder=save_folder, dataset_type='Val')\n",
    "\n",
    "        # test eval\n",
    "        test_acc, test_cm = evaluate_model(model, test_loader, device, num_classes)\n",
    "        np.save(os.path.join(save_folder, f'test_cm_fold{fold+1}.npy'), test_cm)\n",
    "        plot_confusion_matrix(test_cm, classes=list(range(num_classes)), fold=fold+1, save_folder=save_folder, dataset_type='Test')\n",
    "\n",
    "        print(f\"Fold {fold+1} Test Accuracy: {test_acc:.2f}%\")\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write(f\"Fold{fold+1} TestAcc={test_acc:.2f}%\\n\")\n",
    "\n",
    "        # ‰øùÂ≠òÊõ≤Á∫ø & Ê®°Âûã\n",
    "        plot_curves(train_losses, val_losses, train_accs, val_accs, fold+1, save_folder)\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, f'model_fold{fold+1}.pth'))\n",
    "\n",
    "        val_scores.append(val_acc)\n",
    "        test_scores.append(test_acc)\n",
    "\n",
    "    # summary\n",
    "    print(\"\\n=== Overall Summary ===\")\n",
    "    print(f\"Val Acc: {np.mean(val_scores):.2f} ¬± {np.std(val_scores):.2f}\")\n",
    "    print(f\"Test Acc: {np.mean(test_scores):.2f} ¬± {np.std(test_scores):.2f}\")\n",
    "    with open(results_file, 'a') as f:\n",
    "        f.write(f\"\\n=== Overall Summary ===\\nVal Acc: {np.mean(val_scores):.2f} ¬± {np.std(val_scores):.2f}\\nTest Acc: {np.mean(test_scores):.2f} ¬± {np.std(test_scores):.2f}\\n\")\n",
    "\n",
    "    print(f\"\\nAll results saved in {save_folder}\")\n",
    "    return save_folder\n",
    "\n",
    "# ---------- ËøêË°åÂâçÁöÑÂáÜÂ§áÔºàÈ¢ÑÂ§ÑÁêÜÂπ∂ËΩ¨Êç¢‰∏∫Âº†ÈáèÔºâ ----------\n",
    "# X_train, X_test ÁõÆÂâç shape: [N, 240, 2] (numpy)\n",
    "# Êàë‰ª¨ÂØπÊØè‰∏™Ê†∑Êú¨ÂÅö per-sample Ê†áÂáÜÂåñÔºàzero-mean unit-stdÔºâ\n",
    "print(\"Preprocessing (per-sample normalization)...\")\n",
    "# ---------- ËΩ¨‰∏∫ torch.tensor Âπ∂ÂÅö per-sample Ê†áÂáÜÂåñ ----------\n",
    "\n",
    "X_train_torch = preprocess_for_pointcloud_cnn(X_train, add_noise=False)\n",
    "X_test_torch  = preprocess_for_pointcloud_cnn(X_test, add_noise=False)\n",
    "\n",
    "y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_torch  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "num_classes = len(torch.unique(y_train_torch))\n",
    "print(\"Prepared tensors:\", X_train_torch.shape, X_test_torch.shape, \"num_classes=\", num_classes)\n",
    "\n",
    "# ---------- K-Fold ËÆ≠ÁªÉ ----------\n",
    "# train_kfold_pointcloud ÂÜÖÈÉ®‰ºöÊääËÆ≠ÁªÉÈõÜÂÜçÂàíÂàÜ‰∏∫ËÆ≠ÁªÉ+È™åËØÅÈõÜ\n",
    "# save_folder = train_kfold_pointcloud(\n",
    "#    X_train_torch, \n",
    "#    y_train_torch,\n",
    "#    X_test_torch, \n",
    "#    y_test_torch,\n",
    "#    num_classes=num_classes\n",
    "# )\n",
    "\n",
    "#print(\"Done. Results in:\", save_folder)\n",
    "\n",
    "# ##########################################################\n",
    "# #=== ÂÆö‰πâ‰∏Ä‰∏™Áªü‰∏ÄÂÖ•Âè£ÂáΩÊï∞ÔºåÁî®‰∫éË∑ë‰∏ÄÊ¨° SNR ÂÆûÈ™å ===\n",
    "# ##########################################################\n",
    "def run_experiment_with_snr(snr_db):\n",
    "    global SNR_DB, ADD_NOISE\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üöÄ Running experiment with SNR = {snr_db} dB\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # ËÆæÁΩÆÂΩìÂâçÂÆûÈ™å SNR\n",
    "    SNR_DB = snr_db\n",
    "    ADD_NOISE = True   # ÊâìÂºÄ AWGN\n",
    "    \n",
    "    # --- ÈáçÊñ∞È¢ÑÂ§ÑÁêÜÊï∞ÊçÆÔºà‰ºöË∞ÉÁî® add_noise=TrueÔºâ ---\n",
    "    X_train_torch_snr = preprocess_for_pointcloud_cnn(\n",
    "        X_train, add_noise=True, add_doppler = ADD_DOPPLER, snr_db=snr_db\n",
    "    )\n",
    "    X_test_torch_snr = preprocess_for_pointcloud_cnn(\n",
    "        X_test, add_noise=True, add_doppler = ADD_DOPPLER, snr_db=snr_db\n",
    "    )\n",
    "\n",
    "    y_train_torch_snr = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test_torch_snr  = torch.tensor(y_test,  dtype=torch.long)\n",
    "\n",
    "    num_classes = len(torch.unique(y_train_torch_snr))\n",
    "\n",
    "    # --- Ë∞ÉÁî®‰Ω†ÁöÑ K-Fold ËÆ≠ÁªÉ ---\n",
    "    save_folder = train_kfold_pointcloud(\n",
    "        X_train_torch_snr,\n",
    "        y_train_torch_snr,\n",
    "        X_test_torch_snr,\n",
    "        y_test_torch_snr,\n",
    "        script_name=script_name,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "    print(f\"üéâ Finished SNR={snr_db} dB, results saved in: {save_folder}\")\n",
    "    return save_folder\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# === ÊâπÈáèÊâßË°å SNR Sweep: 20, 10, 0, -10, ... -40 dB ===\n",
    "###########################################################\n",
    "snr_list = list(range(20, -45, -5))\n",
    "# [20, 15, 10, 5, 0, -5, -10, -15, -20, -25, -30, -35, -40]\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for snr in snr_list:\n",
    "    folder = run_experiment_with_snr(snr)\n",
    "    all_results[snr] = folder\n",
    "\n",
    "print(\"\\n\\n================ FINAL SUMMARY ================\")\n",
    "for snr, folder in all_results.items():\n",
    "    print(f\"SNR {snr:>3} dB ‚Üí results in: {folder}\")\n",
    "print(\"==============================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
