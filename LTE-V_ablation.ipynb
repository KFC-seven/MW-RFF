{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa643ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] device=cuda | method=XFR_BASE | backbone=ResNet18_1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=XFR_BASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== XFR_BASE | ResNet18_1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 0.6236 acc 78.25% | Val loss 0.0317 acc_row 99.15% | train_time 11.729s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 0.0366 acc 99.08% | Val loss 0.0201 acc_row 99.46% | train_time 11.915s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 0.0197 acc 99.51% | Val loss 0.0164 acc_row 99.47% | train_time 11.724s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 0.0141 acc 99.69% | Val loss 0.0145 acc_row 99.58% | train_time 11.518s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 0.0116 acc 99.78% | Val loss 0.0164 acc_row 99.46% | train_time 11.472s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 0.0108 acc 99.83% | Val loss 0.0107 acc_row 99.67% | train_time 11.451s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.0100 acc 99.86% | Val loss 0.0082 acc_row 99.73% | train_time 11.663s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 0.0094 acc 99.87% | Val loss 0.0089 acc_row 99.70% | train_time 11.723s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 0.0083 acc 99.89% | Val loss 0.0086 acc_row 99.75% | train_time 12.021s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 0.0080 acc 99.89% | Val loss 0.0080 acc_row 99.72% | train_time 12.018s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 0.0044 acc 99.97% | Val loss 0.0053 acc_row 99.83% | train_time 11.268s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 0.0050 acc 99.97% | Val loss 0.0081 acc_row 99.71% | train_time 11.246s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 0.0046 acc 99.97% | Val loss 0.0084 acc_row 99.72% | train_time 11.503s | lr 5e-05\n",
      "Fold 1 Ep 14 | Train loss 0.0049 acc 99.96% | Val loss 0.0076 acc_row 99.76% | train_time 11.810s | lr 5e-05\n",
      "Fold 1 Ep 15 | Train loss 0.0048 acc 99.96% | Val loss 0.0047 acc_row 99.88% | train_time 11.628s | lr 5e-05\n",
      "Fold 1 Ep 16 | Train loss 0.0044 acc 99.97% | Val loss 0.0044 acc_row 99.88% | train_time 11.869s | lr 5e-05\n",
      "Fold 1 Ep 17 | Train loss 0.0043 acc 99.97% | Val loss 0.0062 acc_row 99.78% | train_time 12.631s | lr 5e-05\n",
      "Fold 1 Ep 18 | Train loss 0.0047 acc 99.96% | Val loss 0.0044 acc_row 99.87% | train_time 11.653s | lr 5e-05\n",
      "Fold 1 Ep 19 | Train loss 0.0044 acc 99.96% | Val loss 0.0048 acc_row 99.89% | train_time 11.267s | lr 5e-05\n",
      "Fold 1 Ep 20 | Train loss 0.0040 acc 99.97% | Val loss 0.0049 acc_row 99.83% | train_time 11.336s | lr 5e-05\n",
      "Fold 1 Ep 21 | Train loss 0.0031 acc 99.99% | Val loss 0.0060 acc_row 99.81% | train_time 11.497s | lr 2.5e-05\n",
      "Fold 1 Ep 22 | Train loss 0.0035 acc 99.98% | Val loss 0.0061 acc_row 99.80% | train_time 11.515s | lr 2.5e-05\n",
      "Fold 1 Ep 23 | Train loss 0.0032 acc 99.99% | Val loss 0.0058 acc_row 99.82% | train_time 11.747s | lr 2.5e-05\n",
      "Fold 1 Ep 24 | Train loss 0.0031 acc 99.99% | Val loss 0.0050 acc_row 99.86% | train_time 11.694s | lr 2.5e-05\n",
      "Early stop at epoch 24 (best_val_acc_row=99.89%)\n",
      "[FOLD1] test_row=99.64% test_block=100.00% | epochs=24 | train_time(s) min/med/max=11.246/11.658/12.631 | params=3.849M | model=14.76MB | infer_row_mean=1.389ms infer_block_mean=1.906ms\n",
      "\n",
      "====== XFR_BASE | ResNet18_1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 0.7335 acc 74.43% | Val loss 0.0295 acc_row 99.16% | train_time 12.393s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 0.0407 acc 98.99% | Val loss 0.0070 acc_row 99.84% | train_time 11.735s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 0.0183 acc 99.57% | Val loss 0.0087 acc_row 99.75% | train_time 11.387s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 0.0126 acc 99.76% | Val loss 0.0036 acc_row 99.92% | train_time 11.991s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 0.0109 acc 99.80% | Val loss 0.0060 acc_row 99.88% | train_time 11.834s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 0.0101 acc 99.86% | Val loss 0.0042 acc_row 99.94% | train_time 11.490s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 0.0090 acc 99.89% | Val loss 0.0028 acc_row 99.96% | train_time 11.834s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.0083 acc 99.90% | Val loss 0.0026 acc_row 99.97% | train_time 11.696s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.0076 acc 99.91% | Val loss 0.0109 acc_row 99.76% | train_time 11.466s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 0.0077 acc 99.89% | Val loss 0.0074 acc_row 99.84% | train_time 12.720s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 0.0046 acc 99.97% | Val loss 0.0021 acc_row 99.98% | train_time 11.811s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 0.0044 acc 99.98% | Val loss 0.0021 acc_row 99.97% | train_time 11.490s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 0.0049 acc 99.95% | Val loss 0.0016 acc_row 99.99% | train_time 11.783s | lr 5e-05\n",
      "Fold 2 Ep 14 | Train loss 0.0045 acc 99.97% | Val loss 0.0016 acc_row 99.99% | train_time 11.351s | lr 5e-05\n",
      "Fold 2 Ep 15 | Train loss 0.0043 acc 99.97% | Val loss 0.0016 acc_row 99.98% | train_time 11.993s | lr 5e-05\n",
      "Fold 2 Ep 16 | Train loss 0.0043 acc 99.97% | Val loss 0.0015 acc_row 99.98% | train_time 11.995s | lr 5e-05\n",
      "Early stop at epoch 16 (best_val_acc_row=99.98%)\n",
      "[FOLD2] test_row=99.75% test_block=100.00% | epochs=16 | train_time(s) min/med/max=11.351/11.797/12.720 | params=3.849M | model=14.76MB | infer_row_mean=1.422ms infer_block_mean=1.884ms\n",
      "\n",
      "====== XFR_BASE | ResNet18_1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 0.6438 acc 77.47% | Val loss 0.0416 acc_row 98.91% | train_time 11.836s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 0.0377 acc 99.04% | Val loss 0.0239 acc_row 99.36% | train_time 12.485s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 0.0189 acc 99.55% | Val loss 0.0198 acc_row 99.43% | train_time 11.670s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 0.0140 acc 99.69% | Val loss 0.0125 acc_row 99.63% | train_time 11.334s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 0.0120 acc 99.76% | Val loss 0.0070 acc_row 99.83% | train_time 11.506s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 0.0107 acc 99.83% | Val loss 0.0072 acc_row 99.86% | train_time 12.001s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 0.0097 acc 99.87% | Val loss 0.0278 acc_row 99.27% | train_time 11.351s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 0.0091 acc 99.88% | Val loss 0.0084 acc_row 99.76% | train_time 11.463s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 0.0083 acc 99.88% | Val loss 0.0065 acc_row 99.84% | train_time 11.619s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 0.0080 acc 99.89% | Val loss 0.0106 acc_row 99.85% | train_time 11.757s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 0.0045 acc 99.96% | Val loss 0.0030 acc_row 99.97% | train_time 12.267s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 0.0050 acc 99.96% | Val loss 0.0070 acc_row 99.84% | train_time 11.672s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 0.0050 acc 99.96% | Val loss 0.0056 acc_row 99.91% | train_time 11.948s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 0.0043 acc 99.98% | Val loss 0.0039 acc_row 99.93% | train_time 11.805s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 0.0042 acc 99.97% | Val loss 0.0043 acc_row 99.92% | train_time 11.503s | lr 5e-05\n",
      "Fold 3 Ep 16 | Train loss 0.0045 acc 99.97% | Val loss 0.0058 acc_row 99.83% | train_time 11.306s | lr 5e-05\n",
      "Early stop at epoch 16 (best_val_acc_row=99.97%)\n",
      "[FOLD3] test_row=99.68% test_block=100.00% | epochs=16 | train_time(s) min/med/max=11.306/11.671/12.485 | params=3.849M | model=14.76MB | infer_row_mean=1.386ms infer_block_mean=1.860ms\n",
      "\n",
      "====== XFR_BASE | ResNet18_1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 0.6918 acc 75.46% | Val loss 0.0451 acc_row 98.51% | train_time 11.370s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 0.0386 acc 99.03% | Val loss 0.0169 acc_row 99.48% | train_time 11.647s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 0.0190 acc 99.54% | Val loss 0.0183 acc_row 99.47% | train_time 12.478s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 0.0135 acc 99.72% | Val loss 0.0123 acc_row 99.66% | train_time 12.490s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 0.0111 acc 99.80% | Val loss 0.0091 acc_row 99.79% | train_time 11.651s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 0.0101 acc 99.86% | Val loss 0.0116 acc_row 99.73% | train_time 11.610s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 0.0088 acc 99.90% | Val loss 0.0065 acc_row 99.87% | train_time 11.462s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 0.0090 acc 99.87% | Val loss 0.0105 acc_row 99.76% | train_time 11.496s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 0.0079 acc 99.90% | Val loss 0.0075 acc_row 99.84% | train_time 11.342s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 0.0079 acc 99.90% | Val loss 0.0244 acc_row 99.35% | train_time 11.580s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 0.0045 acc 99.97% | Val loss 0.0076 acc_row 99.79% | train_time 12.186s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 0.0046 acc 99.96% | Val loss 0.0060 acc_row 99.85% | train_time 12.133s | lr 5e-05\n",
      "Early stop at epoch 12 (best_val_acc_row=99.87%)\n",
      "[FOLD4] test_row=99.41% test_block=100.00% | epochs=12 | train_time(s) min/med/max=11.342/11.629/12.490 | params=3.849M | model=14.76MB | infer_row_mean=1.472ms infer_block_mean=2.276ms\n",
      "\n",
      "====== XFR_BASE | ResNet18_1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 0.6488 acc 77.17% | Val loss 0.0431 acc_row 98.76% | train_time 11.935s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 0.0366 acc 99.07% | Val loss 0.0139 acc_row 99.55% | train_time 11.687s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 0.0195 acc 99.53% | Val loss 0.0181 acc_row 99.44% | train_time 11.512s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 0.0136 acc 99.71% | Val loss 0.0086 acc_row 99.77% | train_time 11.479s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 0.0117 acc 99.80% | Val loss 0.0114 acc_row 99.67% | train_time 11.547s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 0.0104 acc 99.84% | Val loss 0.0088 acc_row 99.81% | train_time 12.632s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 0.0095 acc 99.86% | Val loss 0.0117 acc_row 99.70% | train_time 12.516s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 0.0091 acc 99.88% | Val loss 0.0070 acc_row 99.80% | train_time 11.928s | lr 0.0001\n",
      "Fold 5 Ep 9 | Train loss 0.0079 acc 99.91% | Val loss 0.0070 acc_row 99.79% | train_time 11.614s | lr 0.0001\n",
      "Fold 5 Ep 10 | Train loss 0.0073 acc 99.91% | Val loss 0.0073 acc_row 99.79% | train_time 11.735s | lr 0.0001\n",
      "Fold 5 Ep 11 | Train loss 0.0045 acc 99.96% | Val loss 0.0041 acc_row 99.93% | train_time 11.650s | lr 5e-05\n",
      "Fold 5 Ep 12 | Train loss 0.0047 acc 99.97% | Val loss 0.0049 acc_row 99.90% | train_time 11.617s | lr 5e-05\n",
      "Fold 5 Ep 13 | Train loss 0.0052 acc 99.96% | Val loss 0.0060 acc_row 99.85% | train_time 12.122s | lr 5e-05\n",
      "Fold 5 Ep 14 | Train loss 0.0048 acc 99.96% | Val loss 0.0033 acc_row 99.93% | train_time 12.343s | lr 5e-05\n",
      "Fold 5 Ep 15 | Train loss 0.0046 acc 99.97% | Val loss 0.0024 acc_row 99.96% | train_time 11.768s | lr 5e-05\n",
      "Fold 5 Ep 16 | Train loss 0.0042 acc 99.98% | Val loss 0.0032 acc_row 99.96% | train_time 12.330s | lr 5e-05\n",
      "Fold 5 Ep 17 | Train loss 0.0053 acc 99.94% | Val loss 0.0056 acc_row 99.89% | train_time 11.386s | lr 5e-05\n",
      "Fold 5 Ep 18 | Train loss 0.0039 acc 99.98% | Val loss 0.0039 acc_row 99.94% | train_time 11.582s | lr 5e-05\n",
      "Fold 5 Ep 19 | Train loss 0.0046 acc 99.96% | Val loss 0.0025 acc_row 99.97% | train_time 11.466s | lr 5e-05\n",
      "Fold 5 Ep 20 | Train loss 0.0040 acc 99.97% | Val loss 0.0047 acc_row 99.91% | train_time 11.536s | lr 5e-05\n",
      "Early stop at epoch 20 (best_val_acc_row=99.96%)\n",
      "[FOLD5] test_row=99.71% test_block=100.00% | epochs=20 | train_time(s) min/med/max=11.386/11.669/12.632 | params=3.849M | model=14.76MB | infer_row_mean=1.419ms infer_block_mean=1.884ms\n",
      "[INFO] device=cuda | method=XFR_BASE | backbone=CNN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=XFR_BASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== XFR_BASE | CNN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 0.4273 acc 91.50% | Val loss 0.1341 acc_row 97.52% | train_time 4.285s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 0.0336 acc 99.80% | Val loss 0.0852 acc_row 98.24% | train_time 4.416s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 0.0150 acc 99.97% | Val loss 0.0626 acc_row 98.67% | train_time 4.244s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 0.0108 acc 99.99% | Val loss 0.0630 acc_row 98.75% | train_time 4.156s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 0.0104 acc 99.99% | Val loss 0.0569 acc_row 99.05% | train_time 4.462s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 0.0097 acc 100.00% | Val loss 0.0477 acc_row 99.45% | train_time 4.267s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.0094 acc 99.99% | Val loss 0.0478 acc_row 99.59% | train_time 4.205s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 0.0087 acc 100.00% | Val loss 0.0430 acc_row 99.56% | train_time 4.181s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 0.0085 acc 100.00% | Val loss 0.0478 acc_row 99.42% | train_time 4.111s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 0.0080 acc 100.00% | Val loss 0.0404 acc_row 99.76% | train_time 4.069s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 0.0067 acc 100.00% | Val loss 0.0413 acc_row 99.74% | train_time 4.082s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 0.0070 acc 100.00% | Val loss 0.0428 acc_row 99.69% | train_time 4.050s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 0.0069 acc 100.00% | Val loss 0.0408 acc_row 99.79% | train_time 4.241s | lr 5e-05\n",
      "Fold 1 Ep 14 | Train loss 0.0067 acc 100.00% | Val loss 0.0426 acc_row 99.73% | train_time 4.405s | lr 5e-05\n",
      "Fold 1 Ep 15 | Train loss 0.0068 acc 100.00% | Val loss 0.0510 acc_row 99.61% | train_time 4.143s | lr 5e-05\n",
      "Fold 1 Ep 16 | Train loss 0.0066 acc 100.00% | Val loss 0.0405 acc_row 99.77% | train_time 4.127s | lr 5e-05\n",
      "Fold 1 Ep 17 | Train loss 0.0066 acc 100.00% | Val loss 0.0395 acc_row 99.82% | train_time 4.073s | lr 5e-05\n",
      "Fold 1 Ep 18 | Train loss 0.0067 acc 100.00% | Val loss 0.0436 acc_row 99.80% | train_time 4.095s | lr 5e-05\n",
      "Fold 1 Ep 19 | Train loss 0.0065 acc 100.00% | Val loss 0.0383 acc_row 99.86% | train_time 4.182s | lr 5e-05\n",
      "Fold 1 Ep 20 | Train loss 0.0065 acc 100.00% | Val loss 0.0397 acc_row 99.82% | train_time 4.148s | lr 5e-05\n",
      "Fold 1 Ep 21 | Train loss 0.0058 acc 100.00% | Val loss 0.0360 acc_row 99.89% | train_time 4.136s | lr 2.5e-05\n",
      "Fold 1 Ep 22 | Train loss 0.0061 acc 100.00% | Val loss 0.0378 acc_row 99.87% | train_time 4.254s | lr 2.5e-05\n",
      "Fold 1 Ep 23 | Train loss 0.0060 acc 100.00% | Val loss 0.0377 acc_row 99.88% | train_time 4.344s | lr 2.5e-05\n",
      "Fold 1 Ep 24 | Train loss 0.0061 acc 100.00% | Val loss 0.0401 acc_row 99.86% | train_time 4.162s | lr 2.5e-05\n",
      "Fold 1 Ep 25 | Train loss 0.0061 acc 100.00% | Val loss 0.0389 acc_row 99.87% | train_time 4.518s | lr 2.5e-05\n",
      "Fold 1 Ep 26 | Train loss 0.0060 acc 100.00% | Val loss 0.0354 acc_row 99.88% | train_time 4.412s | lr 2.5e-05\n",
      "Early stop at epoch 26 (best_val_acc_row=99.89%)\n",
      "[FOLD1] test_row=98.88% test_block=100.00% | epochs=26 | train_time(s) min/med/max=4.050/4.181/4.518 | params=0.540M | model=2.08MB | infer_row_mean=0.374ms infer_block_mean=0.400ms\n",
      "\n",
      "====== XFR_BASE | CNN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 0.4324 acc 91.18% | Val loss 0.1372 acc_row 97.26% | train_time 4.206s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 0.0349 acc 99.76% | Val loss 0.0851 acc_row 98.07% | train_time 4.101s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 0.0159 acc 99.95% | Val loss 0.0707 acc_row 98.48% | train_time 4.022s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 0.0114 acc 99.98% | Val loss 0.0696 acc_row 98.45% | train_time 4.379s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 0.0103 acc 99.99% | Val loss 0.0822 acc_row 98.22% | train_time 4.282s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 0.0100 acc 100.00% | Val loss 0.0706 acc_row 98.64% | train_time 4.144s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 0.0096 acc 100.00% | Val loss 0.0585 acc_row 99.04% | train_time 4.016s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.0091 acc 100.00% | Val loss 0.0596 acc_row 98.96% | train_time 4.094s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.0082 acc 100.00% | Val loss 0.0580 acc_row 99.20% | train_time 4.267s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 0.0081 acc 100.00% | Val loss 0.0522 acc_row 99.38% | train_time 4.213s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 0.0067 acc 100.00% | Val loss 0.0537 acc_row 99.19% | train_time 4.085s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 0.0070 acc 100.00% | Val loss 0.0542 acc_row 99.40% | train_time 4.068s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 0.0069 acc 100.00% | Val loss 0.0487 acc_row 99.43% | train_time 4.088s | lr 5e-05\n",
      "Fold 2 Ep 14 | Train loss 0.0068 acc 100.00% | Val loss 0.0499 acc_row 99.40% | train_time 4.074s | lr 5e-05\n",
      "Fold 2 Ep 15 | Train loss 0.0067 acc 100.00% | Val loss 0.0510 acc_row 99.28% | train_time 4.094s | lr 5e-05\n",
      "Fold 2 Ep 16 | Train loss 0.0067 acc 100.00% | Val loss 0.0459 acc_row 99.67% | train_time 4.072s | lr 5e-05\n",
      "Fold 2 Ep 17 | Train loss 0.0066 acc 100.00% | Val loss 0.0453 acc_row 99.57% | train_time 4.003s | lr 5e-05\n",
      "Fold 2 Ep 18 | Train loss 0.0065 acc 100.00% | Val loss 0.0451 acc_row 99.70% | train_time 4.270s | lr 5e-05\n",
      "Fold 2 Ep 19 | Train loss 0.0066 acc 100.00% | Val loss 0.0459 acc_row 99.56% | train_time 4.710s | lr 5e-05\n",
      "Fold 2 Ep 20 | Train loss 0.0065 acc 100.00% | Val loss 0.0452 acc_row 99.60% | train_time 4.182s | lr 5e-05\n",
      "Fold 2 Ep 21 | Train loss 0.0058 acc 100.00% | Val loss 0.0436 acc_row 99.71% | train_time 4.334s | lr 2.5e-05\n",
      "Fold 2 Ep 22 | Train loss 0.0061 acc 100.00% | Val loss 0.0428 acc_row 99.75% | train_time 4.375s | lr 2.5e-05\n",
      "Fold 2 Ep 23 | Train loss 0.0061 acc 100.00% | Val loss 0.0447 acc_row 99.56% | train_time 4.169s | lr 2.5e-05\n",
      "Fold 2 Ep 24 | Train loss 0.0061 acc 100.00% | Val loss 0.0440 acc_row 99.62% | train_time 4.139s | lr 2.5e-05\n",
      "Fold 2 Ep 25 | Train loss 0.0060 acc 100.00% | Val loss 0.0484 acc_row 99.56% | train_time 4.208s | lr 2.5e-05\n",
      "Fold 2 Ep 26 | Train loss 0.0061 acc 100.00% | Val loss 0.0451 acc_row 99.49% | train_time 4.096s | lr 2.5e-05\n",
      "Fold 2 Ep 27 | Train loss 0.0061 acc 100.00% | Val loss 0.0497 acc_row 99.33% | train_time 4.031s | lr 2.5e-05\n",
      "Early stop at epoch 27 (best_val_acc_row=99.75%)\n",
      "[FOLD2] test_row=98.92% test_block=100.00% | epochs=27 | train_time(s) min/med/max=4.003/4.139/4.710 | params=0.540M | model=2.08MB | infer_row_mean=0.345ms infer_block_mean=0.433ms\n",
      "\n",
      "====== XFR_BASE | CNN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 0.4252 acc 91.50% | Val loss 0.1704 acc_row 95.85% | train_time 4.086s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 0.0319 acc 99.84% | Val loss 0.1289 acc_row 96.75% | train_time 4.045s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 0.0141 acc 99.97% | Val loss 0.1169 acc_row 97.09% | train_time 4.028s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 0.0104 acc 99.99% | Val loss 0.1131 acc_row 97.44% | train_time 4.085s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 0.0099 acc 100.00% | Val loss 0.0895 acc_row 97.94% | train_time 4.194s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 0.0095 acc 100.00% | Val loss 0.0916 acc_row 98.00% | train_time 4.123s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 0.0092 acc 100.00% | Val loss 0.0967 acc_row 97.78% | train_time 4.094s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 0.0085 acc 100.00% | Val loss 0.0843 acc_row 98.40% | train_time 4.267s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 0.0083 acc 100.00% | Val loss 0.0793 acc_row 98.39% | train_time 4.155s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 0.0079 acc 100.00% | Val loss 0.0817 acc_row 98.49% | train_time 4.034s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 0.0064 acc 100.00% | Val loss 0.0741 acc_row 98.73% | train_time 4.631s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 0.0069 acc 100.00% | Val loss 0.0878 acc_row 98.18% | train_time 4.494s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 0.0068 acc 100.00% | Val loss 0.0710 acc_row 98.79% | train_time 4.256s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 0.0068 acc 100.00% | Val loss 0.0745 acc_row 98.77% | train_time 4.200s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 0.0066 acc 100.00% | Val loss 0.0748 acc_row 98.72% | train_time 3.976s | lr 5e-05\n",
      "Fold 3 Ep 16 | Train loss 0.0066 acc 100.00% | Val loss 0.0744 acc_row 98.72% | train_time 4.023s | lr 5e-05\n",
      "Fold 3 Ep 17 | Train loss 0.0066 acc 100.00% | Val loss 0.0917 acc_row 98.16% | train_time 4.064s | lr 5e-05\n",
      "Fold 3 Ep 18 | Train loss 0.0065 acc 100.00% | Val loss 0.0693 acc_row 98.78% | train_time 4.024s | lr 5e-05\n",
      "Early stop at epoch 18 (best_val_acc_row=98.79%)\n",
      "[FOLD3] test_row=98.72% test_block=100.00% | epochs=18 | train_time(s) min/med/max=3.976/4.090/4.631 | params=0.540M | model=2.08MB | infer_row_mean=0.339ms infer_block_mean=0.412ms\n",
      "\n",
      "====== XFR_BASE | CNN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 0.4153 acc 91.83% | Val loss 0.1842 acc_row 95.74% | train_time 4.033s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 0.0325 acc 99.81% | Val loss 0.1208 acc_row 97.15% | train_time 3.981s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 0.0150 acc 99.96% | Val loss 0.1114 acc_row 97.30% | train_time 4.013s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 0.0108 acc 99.98% | Val loss 0.1009 acc_row 97.83% | train_time 3.993s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 0.0098 acc 100.00% | Val loss 0.1022 acc_row 97.81% | train_time 4.046s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 0.0099 acc 99.99% | Val loss 0.0897 acc_row 98.46% | train_time 4.049s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 0.0092 acc 100.00% | Val loss 0.1177 acc_row 97.61% | train_time 4.138s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 0.0087 acc 100.00% | Val loss 0.0834 acc_row 98.50% | train_time 4.078s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 0.0081 acc 100.00% | Val loss 0.0854 acc_row 98.52% | train_time 4.147s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 0.0079 acc 100.00% | Val loss 0.1079 acc_row 98.10% | train_time 4.367s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 0.0065 acc 100.00% | Val loss 0.0797 acc_row 98.88% | train_time 4.192s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 0.0069 acc 100.00% | Val loss 0.0734 acc_row 99.09% | train_time 4.194s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 0.0067 acc 100.00% | Val loss 0.0752 acc_row 99.05% | train_time 4.458s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 0.0067 acc 100.00% | Val loss 0.0875 acc_row 98.93% | train_time 4.200s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 0.0066 acc 100.00% | Val loss 0.0746 acc_row 99.04% | train_time 4.057s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 0.0066 acc 100.00% | Val loss 0.0705 acc_row 99.12% | train_time 4.002s | lr 5e-05\n",
      "Fold 4 Ep 17 | Train loss 0.0064 acc 100.00% | Val loss 0.0742 acc_row 99.24% | train_time 3.996s | lr 5e-05\n",
      "Fold 4 Ep 18 | Train loss 0.0065 acc 100.00% | Val loss 0.0695 acc_row 99.33% | train_time 4.036s | lr 5e-05\n",
      "Fold 4 Ep 19 | Train loss 0.0064 acc 100.00% | Val loss 0.0784 acc_row 99.05% | train_time 4.021s | lr 5e-05\n",
      "Fold 4 Ep 20 | Train loss 0.0064 acc 100.00% | Val loss 0.0692 acc_row 99.32% | train_time 4.008s | lr 5e-05\n",
      "Fold 4 Ep 21 | Train loss 0.0059 acc 100.00% | Val loss 0.0708 acc_row 99.26% | train_time 4.108s | lr 2.5e-05\n",
      "Fold 4 Ep 22 | Train loss 0.0060 acc 100.00% | Val loss 0.0672 acc_row 99.34% | train_time 4.117s | lr 2.5e-05\n",
      "Fold 4 Ep 23 | Train loss 0.0060 acc 100.00% | Val loss 0.0697 acc_row 99.39% | train_time 4.060s | lr 2.5e-05\n",
      "Fold 4 Ep 24 | Train loss 0.0060 acc 100.00% | Val loss 0.0760 acc_row 99.19% | train_time 4.174s | lr 2.5e-05\n",
      "Fold 4 Ep 25 | Train loss 0.0060 acc 100.00% | Val loss 0.0697 acc_row 99.39% | train_time 4.101s | lr 2.5e-05\n",
      "Fold 4 Ep 26 | Train loss 0.0059 acc 100.00% | Val loss 0.0670 acc_row 99.42% | train_time 4.073s | lr 2.5e-05\n",
      "Fold 4 Ep 27 | Train loss 0.0060 acc 100.00% | Val loss 0.0657 acc_row 99.36% | train_time 4.334s | lr 2.5e-05\n",
      "Fold 4 Ep 28 | Train loss 0.0060 acc 100.00% | Val loss 0.0685 acc_row 99.35% | train_time 4.268s | lr 2.5e-05\n",
      "Fold 4 Ep 29 | Train loss 0.0059 acc 100.00% | Val loss 0.0692 acc_row 99.31% | train_time 4.125s | lr 2.5e-05\n",
      "Fold 4 Ep 30 | Train loss 0.0059 acc 100.00% | Val loss 0.0651 acc_row 99.42% | train_time 4.126s | lr 2.5e-05\n",
      "Fold 4 Ep 31 | Train loss 0.0055 acc 100.00% | Val loss 0.0652 acc_row 99.42% | train_time 4.041s | lr 1.25e-05\n",
      "Early stop at epoch 31 (best_val_acc_row=99.42%)\n",
      "[FOLD4] test_row=98.87% test_block=100.00% | epochs=31 | train_time(s) min/med/max=3.981/4.078/4.458 | params=0.540M | model=2.08MB | infer_row_mean=0.343ms infer_block_mean=0.386ms\n",
      "\n",
      "====== XFR_BASE | CNN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 0.4252 acc 91.30% | Val loss 0.1639 acc_row 96.40% | train_time 4.458s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 0.0334 acc 99.80% | Val loss 0.1230 acc_row 96.76% | train_time 4.399s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 0.0150 acc 99.96% | Val loss 0.1080 acc_row 97.18% | train_time 4.378s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 0.0108 acc 99.99% | Val loss 0.1061 acc_row 97.30% | train_time 4.143s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 0.0101 acc 99.99% | Val loss 0.1023 acc_row 97.41% | train_time 4.046s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 0.0098 acc 100.00% | Val loss 0.1098 acc_row 97.25% | train_time 4.050s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 0.0094 acc 100.00% | Val loss 0.0813 acc_row 98.09% | train_time 4.211s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 0.0087 acc 100.00% | Val loss 0.0884 acc_row 97.96% | train_time 4.222s | lr 0.0001\n",
      "Fold 5 Ep 9 | Train loss 0.0085 acc 100.00% | Val loss 0.0819 acc_row 98.17% | train_time 4.116s | lr 0.0001\n",
      "Fold 5 Ep 10 | Train loss 0.0078 acc 100.00% | Val loss 0.0882 acc_row 97.96% | train_time 4.298s | lr 0.0001\n",
      "Fold 5 Ep 11 | Train loss 0.0067 acc 100.00% | Val loss 0.0852 acc_row 98.06% | train_time 4.193s | lr 5e-05\n",
      "Fold 5 Ep 12 | Train loss 0.0070 acc 100.00% | Val loss 0.0784 acc_row 98.34% | train_time 4.289s | lr 5e-05\n",
      "Fold 5 Ep 13 | Train loss 0.0069 acc 100.00% | Val loss 0.0822 acc_row 98.29% | train_time 4.327s | lr 5e-05\n",
      "Fold 5 Ep 14 | Train loss 0.0068 acc 100.00% | Val loss 0.0744 acc_row 98.45% | train_time 4.153s | lr 5e-05\n",
      "Fold 5 Ep 15 | Train loss 0.0067 acc 100.00% | Val loss 0.0803 acc_row 98.29% | train_time 4.086s | lr 5e-05\n",
      "Fold 5 Ep 16 | Train loss 0.0067 acc 100.00% | Val loss 0.0816 acc_row 98.24% | train_time 4.030s | lr 5e-05\n",
      "Fold 5 Ep 17 | Train loss 0.0067 acc 100.00% | Val loss 0.0827 acc_row 98.23% | train_time 4.119s | lr 5e-05\n",
      "Fold 5 Ep 18 | Train loss 0.0066 acc 100.00% | Val loss 0.0805 acc_row 98.32% | train_time 4.355s | lr 5e-05\n",
      "Fold 5 Ep 19 | Train loss 0.0064 acc 100.00% | Val loss 0.0779 acc_row 98.43% | train_time 4.224s | lr 5e-05\n",
      "Early stop at epoch 19 (best_val_acc_row=98.45%)\n",
      "[FOLD5] test_row=98.60% test_block=99.49% | epochs=19 | train_time(s) min/med/max=4.030/4.211/4.458 | params=0.540M | model=2.08MB | infer_row_mean=0.454ms infer_block_mean=0.482ms\n",
      "[INFO] device=cuda | method=XFR_BASE | backbone=TCN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=XFR_BASE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== XFR_BASE | TCN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 0.2899 acc 91.57% | Val loss 0.0290 acc_row 99.14% | train_time 63.458s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 0.0181 acc 99.77% | Val loss 0.0148 acc_row 99.55% | train_time 61.653s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 0.0096 acc 99.90% | Val loss 0.0064 acc_row 99.86% | train_time 63.411s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 0.0081 acc 99.91% | Val loss 0.0101 acc_row 99.65% | train_time 61.611s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 0.0073 acc 99.93% | Val loss 0.0092 acc_row 99.69% | train_time 64.342s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 0.0072 acc 99.94% | Val loss 0.0111 acc_row 99.69% | train_time 61.872s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.0063 acc 99.96% | Val loss 0.0044 acc_row 99.90% | train_time 63.684s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 0.0060 acc 99.94% | Val loss 0.0025 acc_row 99.97% | train_time 61.923s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 0.0056 acc 99.96% | Val loss 0.0075 acc_row 99.77% | train_time 64.290s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 0.0056 acc 99.95% | Val loss 0.0039 acc_row 99.89% | train_time 61.580s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 0.0035 acc 99.99% | Val loss 0.0036 acc_row 99.90% | train_time 64.004s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 0.0041 acc 99.99% | Val loss 0.0043 acc_row 99.85% | train_time 61.493s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 0.0039 acc 99.99% | Val loss 0.0030 acc_row 99.92% | train_time 63.356s | lr 5e-05\n",
      "Early stop at epoch 13 (best_val_acc_row=99.97%)\n",
      "[FOLD1] test_row=99.71% test_block=100.00% | epochs=13 | train_time(s) min/med/max=61.493/63.356/64.342 | params=0.596M | model=2.31MB | infer_row_mean=1.002ms infer_block_mean=43.636ms\n",
      "\n",
      "====== XFR_BASE | TCN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 0.3005 acc 91.21% | Val loss 0.0137 acc_row 99.68% | train_time 61.995s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 0.0180 acc 99.74% | Val loss 0.0067 acc_row 99.86% | train_time 64.493s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 0.0101 acc 99.86% | Val loss 0.0033 acc_row 99.94% | train_time 61.693s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 0.0080 acc 99.91% | Val loss 0.0034 acc_row 99.93% | train_time 64.174s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 0.0070 acc 99.95% | Val loss 0.0049 acc_row 99.90% | train_time 61.786s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 0.0074 acc 99.93% | Val loss 0.0056 acc_row 99.87% | train_time 63.929s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 0.0061 acc 99.96% | Val loss 0.0034 acc_row 99.94% | train_time 61.630s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.0069 acc 99.94% | Val loss 0.0018 acc_row 99.99% | train_time 63.980s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.0058 acc 99.95% | Val loss 0.0034 acc_row 99.94% | train_time 61.556s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 0.0051 acc 99.96% | Val loss 0.0088 acc_row 99.82% | train_time 63.191s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 0.0035 acc 99.99% | Val loss 0.0017 acc_row 99.98% | train_time 62.976s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 0.0043 acc 99.97% | Val loss 0.0019 acc_row 99.97% | train_time 63.306s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 0.0042 acc 99.97% | Val loss 0.0017 acc_row 99.97% | train_time 63.632s | lr 5e-05\n",
      "Early stop at epoch 13 (best_val_acc_row=99.99%)\n",
      "[FOLD2] test_row=99.62% test_block=100.00% | epochs=13 | train_time(s) min/med/max=61.556/63.191/64.493 | params=0.596M | model=2.31MB | infer_row_mean=1.066ms infer_block_mean=42.478ms\n",
      "\n",
      "====== XFR_BASE | TCN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 0.2913 acc 91.63% | Val loss 0.0146 acc_row 99.62% | train_time 63.065s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 0.0183 acc 99.75% | Val loss 0.0075 acc_row 99.80% | train_time 62.679s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 0.0097 acc 99.89% | Val loss 0.0093 acc_row 99.66% | train_time 64.175s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 0.0075 acc 99.94% | Val loss 0.0033 acc_row 99.96% | train_time 62.946s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 0.0072 acc 99.93% | Val loss 0.0063 acc_row 99.87% | train_time 64.607s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 0.0074 acc 99.93% | Val loss 0.0046 acc_row 99.92% | train_time 64.125s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 0.0060 acc 99.96% | Val loss 0.0249 acc_row 99.22% | train_time 63.463s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 0.0057 acc 99.97% | Val loss 0.0061 acc_row 99.88% | train_time 62.243s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 0.0062 acc 99.95% | Val loss 0.0043 acc_row 99.87% | train_time 62.672s | lr 0.0001\n",
      "Early stop at epoch 9 (best_val_acc_row=99.96%)\n",
      "[FOLD3] test_row=99.80% test_block=100.00% | epochs=9 | train_time(s) min/med/max=62.243/63.065/64.607 | params=0.596M | model=2.31MB | infer_row_mean=1.055ms infer_block_mean=43.452ms\n",
      "\n",
      "====== XFR_BASE | TCN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 0.2810 acc 91.99% | Val loss 0.0229 acc_row 99.36% | train_time 62.607s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 0.0162 acc 99.81% | Val loss 0.0105 acc_row 99.74% | train_time 62.899s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 0.0096 acc 99.90% | Val loss 0.0134 acc_row 99.64% | train_time 62.861s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 0.0075 acc 99.93% | Val loss 0.0173 acc_row 99.60% | train_time 63.334s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 0.0072 acc 99.93% | Val loss 0.0175 acc_row 99.53% | train_time 62.351s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 0.0068 acc 99.95% | Val loss 0.0136 acc_row 99.74% | train_time 63.470s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 0.0067 acc 99.94% | Val loss 0.0092 acc_row 99.78% | train_time 61.991s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 0.0059 acc 99.95% | Val loss 0.0081 acc_row 99.84% | train_time 62.299s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 0.0058 acc 99.95% | Val loss 0.0045 acc_row 99.90% | train_time 62.161s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 0.0052 acc 99.96% | Val loss 0.0047 acc_row 99.89% | train_time 62.465s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 0.0032 acc 99.99% | Val loss 0.0030 acc_row 99.95% | train_time 62.820s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 0.0040 acc 99.98% | Val loss 0.0042 acc_row 99.91% | train_time 62.615s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 0.0042 acc 99.98% | Val loss 0.0037 acc_row 99.92% | train_time 63.191s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 0.0041 acc 99.98% | Val loss 0.0040 acc_row 99.92% | train_time 63.037s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 0.0039 acc 99.98% | Val loss 0.0037 acc_row 99.92% | train_time 63.503s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 0.0039 acc 99.98% | Val loss 0.0032 acc_row 99.94% | train_time 62.586s | lr 5e-05\n",
      "Early stop at epoch 16 (best_val_acc_row=99.95%)\n",
      "[FOLD4] test_row=99.67% test_block=100.00% | epochs=16 | train_time(s) min/med/max=61.991/62.717/63.503 | params=0.596M | model=2.31MB | infer_row_mean=1.057ms infer_block_mean=45.164ms\n",
      "\n",
      "====== XFR_BASE | TCN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 0.2946 acc 91.42% | Val loss 0.0288 acc_row 99.16% | train_time 63.129s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 0.0187 acc 99.74% | Val loss 0.0179 acc_row 99.40% | train_time 61.825s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 0.0098 acc 99.89% | Val loss 0.0125 acc_row 99.60% | train_time 63.476s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 0.0084 acc 99.91% | Val loss 0.0141 acc_row 99.64% | train_time 61.522s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 0.0072 acc 99.93% | Val loss 0.0087 acc_row 99.83% | train_time 63.463s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 0.0070 acc 99.94% | Val loss 0.0083 acc_row 99.82% | train_time 61.747s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 0.0064 acc 99.94% | Val loss 0.0084 acc_row 99.74% | train_time 63.749s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 0.0065 acc 99.94% | Val loss 0.0040 acc_row 99.95% | train_time 62.309s | lr 0.0001\n",
      "Fold 5 Ep 9 | Train loss 0.0054 acc 99.96% | Val loss 0.0035 acc_row 99.96% | train_time 63.307s | lr 0.0001\n",
      "Fold 5 Ep 10 | Train loss 0.0060 acc 99.94% | Val loss 0.0038 acc_row 99.95% | train_time 62.596s | lr 0.0001\n",
      "Fold 5 Ep 11 | Train loss 0.0035 acc 99.99% | Val loss 0.0038 acc_row 99.92% | train_time 63.528s | lr 5e-05\n",
      "Fold 5 Ep 12 | Train loss 0.0044 acc 99.98% | Val loss 0.0050 acc_row 99.92% | train_time 62.445s | lr 5e-05\n",
      "Fold 5 Ep 13 | Train loss 0.0038 acc 99.99% | Val loss 0.0036 acc_row 99.94% | train_time 62.123s | lr 5e-05\n",
      "Early stop at epoch 13 (best_val_acc_row=99.95%)\n",
      "[FOLD5] test_row=99.87% test_block=100.00% | epochs=13 | train_time(s) min/med/max=61.522/62.596/63.749 | params=0.596M | model=2.31MB | infer_row_mean=1.052ms infer_block_mean=43.624ms\n",
      "[INFO] device=cuda | method=SHUFFLE_IN_BLOCK | backbone=ResNet18_1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=SHUFFLE_IN_BLOCK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | ResNet18_1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.1604 acc 16.20% | Val loss 2.4719 acc_row 13.85% | train_time 11.553s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 2.0357 acc 23.56% | Val loss 2.2685 acc_row 19.69% | train_time 11.424s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.8837 acc 31.12% | Val loss 2.3709 acc_row 19.12% | train_time 12.671s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.6596 acc 40.90% | Val loss 2.4984 acc_row 18.21% | train_time 11.973s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.4006 acc 50.84% | Val loss 2.7232 acc_row 17.24% | train_time 11.516s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.1500 acc 60.26% | Val loss 2.9178 acc_row 17.15% | train_time 11.358s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.9339 acc 68.23% | Val loss 3.0693 acc_row 16.59% | train_time 11.435s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=19.69%)\n",
      "[FOLD1] test_row=18.63% test_block=29.29% | epochs=7 | train_time(s) min/med/max=11.358/11.516/12.671 | params=3.849M | model=14.76MB | infer_row_mean=1.414ms infer_block_mean=1.875ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | ResNet18_1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1563 acc 16.22% | Val loss 2.6630 acc_row 14.03% | train_time 11.340s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 2.0368 acc 23.42% | Val loss 2.2906 acc_row 18.03% | train_time 11.337s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.9082 acc 29.85% | Val loss 2.3187 acc_row 18.42% | train_time 11.472s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.6985 acc 39.28% | Val loss 2.3970 acc_row 18.26% | train_time 12.679s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.4425 acc 49.64% | Val loss 2.5678 acc_row 18.45% | train_time 11.493s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.1803 acc 59.39% | Val loss 2.7458 acc_row 17.45% | train_time 11.243s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 0.9489 acc 67.68% | Val loss 2.9068 acc_row 18.26% | train_time 11.345s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.7641 acc 74.31% | Val loss 3.1304 acc_row 16.44% | train_time 11.371s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.6197 acc 79.26% | Val loss 3.2272 acc_row 17.31% | train_time 11.374s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 0.5107 acc 82.94% | Val loss 3.3040 acc_row 17.50% | train_time 11.322s | lr 0.0001\n",
      "Early stop at epoch 10 (best_val_acc_row=18.45%)\n",
      "[FOLD2] test_row=16.51% test_block=25.76% | epochs=10 | train_time(s) min/med/max=11.243/11.358/12.679 | params=3.849M | model=14.76MB | infer_row_mean=1.398ms infer_block_mean=1.882ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | ResNet18_1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.1493 acc 16.86% | Val loss 2.7870 acc_row 12.20% | train_time 12.091s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 2.0252 acc 23.93% | Val loss 2.4221 acc_row 15.82% | train_time 12.207s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.8911 acc 30.51% | Val loss 2.4224 acc_row 16.17% | train_time 11.797s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.6599 acc 40.77% | Val loss 2.5452 acc_row 16.32% | train_time 11.448s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.3821 acc 51.79% | Val loss 2.7658 acc_row 15.53% | train_time 11.351s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.1135 acc 61.72% | Val loss 2.9216 acc_row 14.87% | train_time 11.312s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 0.8892 acc 69.80% | Val loss 3.0743 acc_row 15.20% | train_time 11.237s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 0.7073 acc 76.30% | Val loss 3.2918 acc_row 14.99% | train_time 11.469s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 0.5774 acc 80.56% | Val loss 3.4839 acc_row 15.09% | train_time 11.685s | lr 0.0001\n",
      "Early stop at epoch 9 (best_val_acc_row=16.32%)\n",
      "[FOLD3] test_row=16.81% test_block=26.77% | epochs=9 | train_time(s) min/med/max=11.237/11.469/12.207 | params=3.849M | model=14.76MB | infer_row_mean=1.405ms infer_block_mean=1.881ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | ResNet18_1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.1549 acc 16.07% | Val loss 2.5292 acc_row 14.83% | train_time 11.767s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 2.0321 acc 23.68% | Val loss 2.2535 acc_row 19.65% | train_time 11.853s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.8994 acc 30.10% | Val loss 2.2828 acc_row 19.50% | train_time 11.232s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.7005 acc 38.91% | Val loss 2.4279 acc_row 18.82% | train_time 11.230s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.4401 acc 49.38% | Val loss 2.5681 acc_row 19.02% | train_time 11.274s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.1667 acc 59.70% | Val loss 2.7407 acc_row 18.08% | train_time 11.638s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 0.9293 acc 68.42% | Val loss 2.9300 acc_row 17.28% | train_time 11.870s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=19.65%)\n",
      "[FOLD4] test_row=18.19% test_block=25.76% | epochs=7 | train_time(s) min/med/max=11.230/11.638/11.870 | params=3.849M | model=14.76MB | infer_row_mean=1.415ms infer_block_mean=1.879ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | ResNet18_1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.1582 acc 16.23% | Val loss 2.4379 acc_row 11.03% | train_time 11.426s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 2.0871 acc 20.78% | Val loss 2.3287 acc_row 17.32% | train_time 11.411s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.9458 acc 28.00% | Val loss 2.3414 acc_row 18.95% | train_time 12.262s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.7348 acc 37.60% | Val loss 2.4835 acc_row 17.55% | train_time 11.303s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.4665 acc 48.37% | Val loss 2.5924 acc_row 18.36% | train_time 11.490s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.1944 acc 58.63% | Val loss 2.7955 acc_row 17.52% | train_time 11.738s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 0.9507 acc 67.69% | Val loss 3.0366 acc_row 16.81% | train_time 11.622s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 0.7553 acc 74.47% | Val loss 3.2021 acc_row 15.85% | train_time 11.174s | lr 0.0001\n",
      "Early stop at epoch 8 (best_val_acc_row=18.95%)\n",
      "[FOLD5] test_row=17.96% test_block=26.77% | epochs=8 | train_time(s) min/med/max=11.174/11.458/12.262 | params=3.849M | model=14.76MB | infer_row_mean=1.393ms infer_block_mean=1.937ms\n",
      "[INFO] device=cuda | method=SHUFFLE_IN_BLOCK | backbone=CNN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=SHUFFLE_IN_BLOCK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | CNN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 1.8943 acc 31.70% | Val loss 2.3167 acc_row 16.73% | train_time 4.176s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.4149 acc 52.07% | Val loss 2.6339 acc_row 16.95% | train_time 4.161s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.0806 acc 64.01% | Val loss 2.8199 acc_row 15.89% | train_time 4.540s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 0.8628 acc 71.50% | Val loss 3.0259 acc_row 15.89% | train_time 4.255s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 0.7086 acc 76.86% | Val loss 3.2478 acc_row 15.33% | train_time 4.110s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 0.5977 acc 80.67% | Val loss 3.3620 acc_row 15.92% | train_time 4.049s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.5104 acc 83.52% | Val loss 3.5353 acc_row 15.25% | train_time 4.052s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=16.95%)\n",
      "[FOLD1] test_row=16.93% test_block=27.27% | epochs=7 | train_time(s) min/med/max=4.049/4.161/4.540 | params=0.540M | model=2.08MB | infer_row_mean=0.328ms infer_block_mean=0.389ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | CNN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 1.9086 acc 30.98% | Val loss 2.3234 acc_row 14.06% | train_time 4.392s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.4230 acc 51.83% | Val loss 2.5964 acc_row 15.43% | train_time 4.175s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.0898 acc 63.83% | Val loss 2.7939 acc_row 15.95% | train_time 4.099s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 0.8733 acc 71.31% | Val loss 2.9458 acc_row 16.53% | train_time 4.033s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 0.7199 acc 76.53% | Val loss 3.2143 acc_row 15.19% | train_time 4.012s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 0.6067 acc 80.30% | Val loss 3.2744 acc_row 15.36% | train_time 4.021s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 0.5204 acc 83.18% | Val loss 3.5172 acc_row 16.19% | train_time 4.084s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.4527 acc 85.41% | Val loss 3.6268 acc_row 14.84% | train_time 4.033s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.3991 acc 87.21% | Val loss 3.8956 acc_row 15.15% | train_time 4.107s | lr 0.0001\n",
      "Early stop at epoch 9 (best_val_acc_row=16.53%)\n",
      "[FOLD2] test_row=15.40% test_block=22.22% | epochs=9 | train_time(s) min/med/max=4.012/4.084/4.392 | params=0.540M | model=2.08MB | infer_row_mean=0.339ms infer_block_mean=0.381ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | CNN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 1.8962 acc 31.39% | Val loss 2.2989 acc_row 15.97% | train_time 4.101s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 1.4067 acc 52.30% | Val loss 2.5956 acc_row 15.27% | train_time 4.165s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.0770 acc 64.12% | Val loss 2.8514 acc_row 14.19% | train_time 4.124s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 0.8588 acc 71.65% | Val loss 3.0653 acc_row 14.26% | train_time 4.041s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 0.7109 acc 76.61% | Val loss 3.2349 acc_row 14.64% | train_time 4.241s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 0.5981 acc 80.51% | Val loss 3.4682 acc_row 14.20% | train_time 4.519s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=15.97%)\n",
      "[FOLD3] test_row=16.59% test_block=28.79% | epochs=6 | train_time(s) min/med/max=4.041/4.144/4.519 | params=0.540M | model=2.08MB | infer_row_mean=0.352ms infer_block_mean=0.528ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | CNN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 1.8981 acc 31.39% | Val loss 2.2767 acc_row 16.47% | train_time 4.347s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.4147 acc 51.99% | Val loss 2.5685 acc_row 15.09% | train_time 4.342s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.0824 acc 64.04% | Val loss 2.7747 acc_row 15.69% | train_time 4.147s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 0.8623 acc 71.66% | Val loss 3.0088 acc_row 14.80% | train_time 4.076s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 0.7115 acc 76.69% | Val loss 3.3243 acc_row 14.95% | train_time 4.055s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 0.5982 acc 80.60% | Val loss 3.4148 acc_row 15.08% | train_time 4.004s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=16.47%)\n",
      "[FOLD4] test_row=15.80% test_block=17.17% | epochs=6 | train_time(s) min/med/max=4.004/4.112/4.347 | params=0.540M | model=2.08MB | infer_row_mean=0.347ms infer_block_mean=0.419ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | CNN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 1.9061 acc 30.90% | Val loss 2.2344 acc_row 18.55% | train_time 4.202s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.4223 acc 51.88% | Val loss 2.5215 acc_row 16.35% | train_time 4.067s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.0832 acc 63.92% | Val loss 2.7673 acc_row 15.62% | train_time 4.050s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 0.8614 acc 71.62% | Val loss 3.0161 acc_row 15.77% | train_time 3.999s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 0.7112 acc 76.81% | Val loss 3.0979 acc_row 16.47% | train_time 4.033s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 0.5975 acc 80.68% | Val loss 3.2800 acc_row 16.53% | train_time 4.005s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=18.55%)\n",
      "[FOLD5] test_row=16.51% test_block=24.24% | epochs=6 | train_time(s) min/med/max=3.999/4.041/4.202 | params=0.540M | model=2.08MB | infer_row_mean=0.345ms infer_block_mean=0.391ms\n",
      "[INFO] device=cuda | method=SHUFFLE_IN_BLOCK | backbone=TCN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=SHUFFLE_IN_BLOCK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 256, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | TCN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.0528 acc 22.51% | Val loss 2.3158 acc_row 19.79% | train_time 64.468s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.8824 acc 30.74% | Val loss 2.2075 acc_row 24.88% | train_time 61.409s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.7635 acc 35.98% | Val loss 2.5280 acc_row 23.98% | train_time 64.305s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.6454 acc 40.76% | Val loss 2.7801 acc_row 24.01% | train_time 61.343s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.5381 acc 45.22% | Val loss 2.5826 acc_row 24.18% | train_time 63.958s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.4441 acc 48.81% | Val loss 2.8531 acc_row 23.89% | train_time 62.773s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 1.3614 acc 51.90% | Val loss 2.8838 acc_row 22.76% | train_time 62.222s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=24.88%)\n",
      "[FOLD1] test_row=22.15% test_block=35.86% | epochs=7 | train_time(s) min/med/max=61.343/62.773/64.468 | params=0.596M | model=2.31MB | infer_row_mean=1.049ms infer_block_mean=44.460ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | TCN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.0541 acc 22.46% | Val loss 2.2222 acc_row 23.32% | train_time 62.272s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.8893 acc 30.27% | Val loss 2.2968 acc_row 24.87% | train_time 63.826s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.7834 acc 35.03% | Val loss 2.5747 acc_row 23.37% | train_time 61.913s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.6824 acc 39.26% | Val loss 2.9226 acc_row 22.59% | train_time 64.958s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.5897 acc 42.86% | Val loss 2.8730 acc_row 23.13% | train_time 61.776s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.5033 acc 46.30% | Val loss 2.9054 acc_row 23.50% | train_time 64.564s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.4249 acc 49.34% | Val loss 3.0421 acc_row 22.47% | train_time 61.885s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=24.87%)\n",
      "[FOLD2] test_row=23.09% test_block=35.86% | epochs=7 | train_time(s) min/med/max=61.776/62.272/64.958 | params=0.596M | model=2.31MB | infer_row_mean=1.062ms infer_block_mean=44.829ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | TCN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.0357 acc 23.24% | Val loss 2.4072 acc_row 20.33% | train_time 61.712s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 1.8664 acc 31.37% | Val loss 2.6199 acc_row 21.58% | train_time 64.047s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.7530 acc 36.26% | Val loss 3.0049 acc_row 19.77% | train_time 61.487s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.6477 acc 40.60% | Val loss 3.0258 acc_row 20.54% | train_time 62.430s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.5512 acc 44.37% | Val loss 2.8181 acc_row 21.26% | train_time 61.974s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.4628 acc 47.93% | Val loss 2.7945 acc_row 22.15% | train_time 60.505s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 1.3747 acc 51.56% | Val loss 2.8867 acc_row 22.10% | train_time 62.510s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 1.2912 acc 54.73% | Val loss 2.6372 acc_row 23.72% | train_time 60.319s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 1.2169 acc 57.54% | Val loss 2.6856 acc_row 23.29% | train_time 63.282s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 1.1439 acc 60.17% | Val loss 2.6924 acc_row 23.81% | train_time 60.313s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 1.0511 acc 63.94% | Val loss 2.7505 acc_row 23.99% | train_time 60.918s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 1.0077 acc 65.55% | Val loss 2.7680 acc_row 24.68% | train_time 60.850s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 0.9673 acc 66.88% | Val loss 2.9638 acc_row 22.75% | train_time 60.715s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 0.9340 acc 68.08% | Val loss 2.9559 acc_row 23.77% | train_time 62.749s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 0.9004 acc 69.43% | Val loss 2.9608 acc_row 23.87% | train_time 60.816s | lr 5e-05\n",
      "Fold 3 Ep 16 | Train loss 0.8680 acc 70.42% | Val loss 2.8990 acc_row 24.23% | train_time 62.039s | lr 5e-05\n",
      "Fold 3 Ep 17 | Train loss 0.8409 acc 71.48% | Val loss 2.9675 acc_row 24.30% | train_time 61.825s | lr 5e-05\n",
      "Early stop at epoch 17 (best_val_acc_row=24.68%)\n",
      "[FOLD3] test_row=24.47% test_block=35.86% | epochs=17 | train_time(s) min/med/max=60.313/61.712/64.047 | params=0.596M | model=2.31MB | infer_row_mean=1.045ms infer_block_mean=44.838ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | TCN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.0443 acc 22.75% | Val loss 2.3406 acc_row 22.31% | train_time 61.910s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.8759 acc 30.88% | Val loss 2.4129 acc_row 24.00% | train_time 61.080s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.7672 acc 35.63% | Val loss 3.1578 acc_row 18.92% | train_time 62.247s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.6645 acc 39.74% | Val loss 3.2593 acc_row 19.40% | train_time 60.594s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.5724 acc 43.46% | Val loss 3.4666 acc_row 16.54% | train_time 64.078s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.4879 acc 46.76% | Val loss 3.4234 acc_row 17.71% | train_time 60.010s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.4086 acc 50.14% | Val loss 3.5031 acc_row 18.33% | train_time 63.087s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=24.00%)\n",
      "[FOLD4] test_row=22.37% test_block=32.83% | epochs=7 | train_time(s) min/med/max=60.010/61.910/64.078 | params=0.596M | model=2.31MB | infer_row_mean=1.052ms infer_block_mean=52.494ms\n",
      "\n",
      "====== SHUFFLE_IN_BLOCK | TCN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.0569 acc 22.23% | Val loss 2.4149 acc_row 19.33% | train_time 63.781s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.8895 acc 30.28% | Val loss 2.2942 acc_row 24.31% | train_time 61.040s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.7700 acc 35.62% | Val loss 2.5474 acc_row 23.39% | train_time 62.349s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.6605 acc 39.96% | Val loss 2.7894 acc_row 22.87% | train_time 62.020s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.5658 acc 43.90% | Val loss 2.6722 acc_row 22.98% | train_time 62.122s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.4766 acc 47.53% | Val loss 2.7182 acc_row 23.24% | train_time 61.956s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 1.3877 acc 51.00% | Val loss 2.6510 acc_row 22.70% | train_time 61.689s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=24.31%)\n",
      "[FOLD5] test_row=22.06% test_block=33.33% | epochs=7 | train_time(s) min/med/max=61.040/62.020/63.781 | params=0.596M | model=2.31MB | infer_row_mean=1.066ms infer_block_mean=42.615ms\n",
      "[INFO] device=cuda | method=CONCAT_M_FRAMES | backbone=ResNet18_1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=CONCAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 65536, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== CONCAT_M_FRAMES | ResNet18_1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.0581 acc 22.03% | Val loss 4.1562 acc_row 10.08% | train_time 2.916s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.7054 acc 40.25% | Val loss 1.6691 acc_row 36.97% | train_time 2.803s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.4437 acc 57.84% | Val loss 2.1195 acc_row 26.05% | train_time 2.883s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.2325 acc 67.80% | Val loss 1.0822 acc_row 60.50% | train_time 2.975s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.1558 acc 77.12% | Val loss 1.5402 acc_row 36.97% | train_time 2.877s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 0.9858 acc 81.36% | Val loss 1.0157 acc_row 53.78% | train_time 2.806s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 0.8758 acc 84.96% | Val loss 0.8460 acc_row 63.87% | train_time 2.792s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 0.7448 acc 87.50% | Val loss 0.5775 acc_row 80.67% | train_time 2.788s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 0.6949 acc 89.83% | Val loss 0.4232 acc_row 94.96% | train_time 2.795s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 0.5760 acc 91.31% | Val loss 0.4434 acc_row 84.87% | train_time 2.823s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 0.5022 acc 95.34% | Val loss 0.4299 acc_row 87.39% | train_time 2.883s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 0.4569 acc 94.28% | Val loss 0.4932 acc_row 87.39% | train_time 2.891s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 0.4107 acc 97.25% | Val loss 0.3162 acc_row 95.80% | train_time 2.824s | lr 5e-05\n",
      "Fold 1 Ep 14 | Train loss 0.3876 acc 96.82% | Val loss 0.6885 acc_row 68.07% | train_time 2.828s | lr 5e-05\n",
      "Fold 1 Ep 15 | Train loss 0.3249 acc 97.03% | Val loss 0.3810 acc_row 89.08% | train_time 2.852s | lr 5e-05\n",
      "Fold 1 Ep 16 | Train loss 0.3177 acc 97.88% | Val loss 0.3836 acc_row 87.39% | train_time 2.872s | lr 5e-05\n",
      "Fold 1 Ep 17 | Train loss 0.3049 acc 98.31% | Val loss 0.4309 acc_row 86.55% | train_time 2.826s | lr 5e-05\n",
      "Fold 1 Ep 18 | Train loss 0.2753 acc 98.09% | Val loss 0.4847 acc_row 84.03% | train_time 2.830s | lr 5e-05\n",
      "Early stop at epoch 18 (best_val_acc_row=95.80%)\n",
      "[FOLD1] test_row=92.93% test_block=92.93% | epochs=18 | train_time(s) min/med/max=2.788/2.829/2.975 | params=3.849M | model=14.76MB | infer_row_mean=1.729ms infer_block_mean=1.783ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | ResNet18_1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1264 acc 15.01% | Val loss 3.6814 acc_row 12.71% | train_time 2.852s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.7890 acc 37.00% | Val loss 2.3685 acc_row 22.03% | train_time 2.842s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.5322 acc 48.63% | Val loss 2.2669 acc_row 27.12% | train_time 2.819s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.4238 acc 59.20% | Val loss 2.8641 acc_row 23.73% | train_time 2.833s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.2256 acc 71.46% | Val loss 2.4126 acc_row 36.44% | train_time 2.851s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.1582 acc 77.80% | Val loss 1.7345 acc_row 50.85% | train_time 2.852s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.0013 acc 78.86% | Val loss 1.1538 acc_row 61.02% | train_time 2.774s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 0.8851 acc 83.09% | Val loss 1.2278 acc_row 49.15% | train_time 2.808s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 0.8178 acc 86.89% | Val loss 0.5090 acc_row 83.05% | train_time 2.808s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 0.7018 acc 90.70% | Val loss 1.5408 acc_row 33.05% | train_time 2.804s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 0.6135 acc 91.54% | Val loss 0.6804 acc_row 70.34% | train_time 2.813s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 0.5414 acc 94.71% | Val loss 1.0484 acc_row 56.78% | train_time 2.796s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 0.5191 acc 94.08% | Val loss 1.4344 acc_row 45.76% | train_time 2.830s | lr 5e-05\n",
      "Fold 2 Ep 14 | Train loss 0.4772 acc 95.14% | Val loss 0.4516 acc_row 83.90% | train_time 2.834s | lr 5e-05\n",
      "Fold 2 Ep 15 | Train loss 0.4270 acc 95.56% | Val loss 0.6325 acc_row 71.19% | train_time 2.859s | lr 5e-05\n",
      "Fold 2 Ep 16 | Train loss 0.3943 acc 96.83% | Val loss 0.6133 acc_row 72.03% | train_time 2.827s | lr 5e-05\n",
      "Fold 2 Ep 17 | Train loss 0.3723 acc 97.25% | Val loss 0.3726 acc_row 89.83% | train_time 2.818s | lr 5e-05\n",
      "Fold 2 Ep 18 | Train loss 0.3516 acc 96.83% | Val loss 0.4514 acc_row 81.36% | train_time 2.845s | lr 5e-05\n",
      "Fold 2 Ep 19 | Train loss 0.3535 acc 97.46% | Val loss 0.4198 acc_row 79.66% | train_time 2.810s | lr 5e-05\n",
      "Fold 2 Ep 20 | Train loss 0.3268 acc 97.25% | Val loss 0.4374 acc_row 85.59% | train_time 2.836s | lr 5e-05\n",
      "Fold 2 Ep 21 | Train loss 0.2326 acc 98.73% | Val loss 0.3183 acc_row 87.29% | train_time 2.929s | lr 2.5e-05\n",
      "Fold 2 Ep 22 | Train loss 0.2189 acc 98.94% | Val loss 0.2605 acc_row 95.76% | train_time 2.899s | lr 2.5e-05\n",
      "Fold 2 Ep 23 | Train loss 0.2231 acc 98.94% | Val loss 0.2341 acc_row 95.76% | train_time 2.829s | lr 2.5e-05\n",
      "Fold 2 Ep 24 | Train loss 0.2093 acc 98.31% | Val loss 0.2642 acc_row 92.37% | train_time 2.839s | lr 2.5e-05\n",
      "Fold 2 Ep 25 | Train loss 0.1933 acc 99.79% | Val loss 0.2853 acc_row 94.07% | train_time 2.839s | lr 2.5e-05\n",
      "Fold 2 Ep 26 | Train loss 0.2137 acc 98.94% | Val loss 0.1901 acc_row 97.46% | train_time 2.847s | lr 2.5e-05\n",
      "Fold 2 Ep 27 | Train loss 0.1892 acc 99.15% | Val loss 0.2321 acc_row 91.53% | train_time 2.808s | lr 2.5e-05\n",
      "Fold 2 Ep 28 | Train loss 0.1741 acc 99.37% | Val loss 0.3128 acc_row 91.53% | train_time 2.824s | lr 2.5e-05\n",
      "Fold 2 Ep 29 | Train loss 0.1543 acc 98.94% | Val loss 0.1623 acc_row 97.46% | train_time 2.815s | lr 2.5e-05\n",
      "Fold 2 Ep 30 | Train loss 0.1608 acc 99.79% | Val loss 0.2399 acc_row 95.76% | train_time 2.821s | lr 2.5e-05\n",
      "Fold 2 Ep 31 | Train loss 0.1559 acc 99.37% | Val loss 0.3091 acc_row 96.61% | train_time 2.789s | lr 1.25e-05\n",
      "Early stop at epoch 31 (best_val_acc_row=97.46%)\n",
      "[FOLD2] test_row=91.41% test_block=91.41% | epochs=31 | train_time(s) min/med/max=2.774/2.829/2.929 | params=3.849M | model=14.76MB | infer_row_mean=1.718ms infer_block_mean=1.730ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | ResNet18_1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.1048 acc 20.72% | Val loss 2.7226 acc_row 11.86% | train_time 2.806s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 1.7508 acc 39.11% | Val loss 1.5132 acc_row 35.59% | train_time 2.811s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.4889 acc 54.76% | Val loss 1.5561 acc_row 43.22% | train_time 2.858s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.3395 acc 63.64% | Val loss 1.6474 acc_row 33.05% | train_time 2.886s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.1824 acc 68.92% | Val loss 1.4069 acc_row 39.83% | train_time 2.929s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.0812 acc 74.42% | Val loss 1.3009 acc_row 50.00% | train_time 2.886s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 0.9675 acc 79.07% | Val loss 1.2407 acc_row 51.69% | train_time 2.802s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 0.8140 acc 86.68% | Val loss 1.5433 acc_row 36.44% | train_time 2.773s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 0.6867 acc 89.01% | Val loss 1.3500 acc_row 44.07% | train_time 2.778s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 0.6500 acc 90.06% | Val loss 1.4249 acc_row 45.76% | train_time 2.792s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 0.5067 acc 96.83% | Val loss 1.1536 acc_row 51.69% | train_time 2.779s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 0.4648 acc 95.98% | Val loss 1.0183 acc_row 55.08% | train_time 2.779s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 0.4370 acc 94.50% | Val loss 1.0359 acc_row 56.78% | train_time 2.773s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 0.4055 acc 96.41% | Val loss 0.6754 acc_row 68.64% | train_time 2.834s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 0.3719 acc 96.19% | Val loss 0.8265 acc_row 64.41% | train_time 2.817s | lr 5e-05\n",
      "Fold 3 Ep 16 | Train loss 0.3365 acc 97.67% | Val loss 0.8113 acc_row 62.71% | train_time 2.818s | lr 5e-05\n",
      "Fold 3 Ep 17 | Train loss 0.3048 acc 98.31% | Val loss 0.5909 acc_row 72.88% | train_time 2.821s | lr 5e-05\n",
      "Fold 3 Ep 18 | Train loss 0.2708 acc 98.52% | Val loss 0.5865 acc_row 77.12% | train_time 2.920s | lr 5e-05\n",
      "Fold 3 Ep 19 | Train loss 0.2754 acc 97.67% | Val loss 0.4240 acc_row 94.92% | train_time 2.925s | lr 5e-05\n",
      "Fold 3 Ep 20 | Train loss 0.2657 acc 98.94% | Val loss 0.4729 acc_row 84.75% | train_time 2.937s | lr 5e-05\n",
      "Fold 3 Ep 21 | Train loss 0.2008 acc 99.15% | Val loss 0.5099 acc_row 85.59% | train_time 2.871s | lr 2.5e-05\n",
      "Fold 3 Ep 22 | Train loss 0.2101 acc 98.73% | Val loss 0.4266 acc_row 85.59% | train_time 2.775s | lr 2.5e-05\n",
      "Fold 3 Ep 23 | Train loss 0.1841 acc 99.58% | Val loss 0.5248 acc_row 85.59% | train_time 2.786s | lr 2.5e-05\n",
      "Fold 3 Ep 24 | Train loss 0.1696 acc 98.94% | Val loss 0.5181 acc_row 77.97% | train_time 2.860s | lr 2.5e-05\n",
      "Early stop at epoch 24 (best_val_acc_row=94.92%)\n",
      "[FOLD3] test_row=90.91% test_block=90.91% | epochs=24 | train_time(s) min/med/max=2.773/2.818/2.937 | params=3.849M | model=14.76MB | infer_row_mean=1.676ms infer_block_mean=1.671ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | ResNet18_1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.0781 acc 17.97% | Val loss 5.3108 acc_row 11.86% | train_time 2.733s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.7046 acc 39.96% | Val loss 1.9445 acc_row 17.80% | train_time 2.718s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.5120 acc 50.53% | Val loss 1.7137 acc_row 25.42% | train_time 2.760s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.3986 acc 54.97% | Val loss 1.7089 acc_row 20.34% | train_time 2.742s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.2524 acc 64.06% | Val loss 1.9113 acc_row 21.19% | train_time 2.722s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.0872 acc 75.26% | Val loss 1.7171 acc_row 36.44% | train_time 2.851s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.0420 acc 76.96% | Val loss 1.2566 acc_row 46.61% | train_time 2.829s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 0.9165 acc 78.65% | Val loss 1.5378 acc_row 34.75% | train_time 2.882s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 0.8058 acc 86.26% | Val loss 0.9489 acc_row 62.71% | train_time 2.893s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 0.7277 acc 89.01% | Val loss 1.1000 acc_row 50.85% | train_time 2.866s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 0.5975 acc 93.66% | Val loss 1.3127 acc_row 44.07% | train_time 2.875s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 0.5466 acc 94.29% | Val loss 1.7918 acc_row 34.75% | train_time 2.833s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 0.5066 acc 94.29% | Val loss 0.9232 acc_row 60.17% | train_time 2.839s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 0.4703 acc 95.77% | Val loss 0.7480 acc_row 69.49% | train_time 2.841s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 0.4424 acc 94.71% | Val loss 0.7358 acc_row 65.25% | train_time 2.816s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 0.3925 acc 97.25% | Val loss 0.8023 acc_row 68.64% | train_time 2.807s | lr 5e-05\n",
      "Fold 4 Ep 17 | Train loss 0.3641 acc 96.41% | Val loss 0.9749 acc_row 56.78% | train_time 2.799s | lr 5e-05\n",
      "Fold 4 Ep 18 | Train loss 0.3421 acc 97.04% | Val loss 0.5116 acc_row 86.44% | train_time 2.825s | lr 5e-05\n",
      "Fold 4 Ep 19 | Train loss 0.3496 acc 97.04% | Val loss 0.7331 acc_row 73.73% | train_time 2.830s | lr 5e-05\n",
      "Fold 4 Ep 20 | Train loss 0.2644 acc 98.10% | Val loss 0.3975 acc_row 86.44% | train_time 2.781s | lr 5e-05\n",
      "Fold 4 Ep 21 | Train loss 0.2573 acc 98.52% | Val loss 0.5400 acc_row 83.05% | train_time 2.857s | lr 2.5e-05\n",
      "Fold 4 Ep 22 | Train loss 0.2260 acc 98.73% | Val loss 0.4609 acc_row 85.59% | train_time 2.815s | lr 2.5e-05\n",
      "Fold 4 Ep 23 | Train loss 0.2108 acc 98.94% | Val loss 0.6323 acc_row 74.58% | train_time 2.846s | lr 2.5e-05\n",
      "Early stop at epoch 23 (best_val_acc_row=86.44%)\n",
      "[FOLD4] test_row=85.35% test_block=85.35% | epochs=23 | train_time(s) min/med/max=2.718/2.829/2.893 | params=3.849M | model=14.76MB | infer_row_mean=2.039ms infer_block_mean=2.165ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | ResNet18_1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.0691 acc 21.35% | Val loss 4.1887 acc_row 8.47% | train_time 2.814s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.7790 acc 35.10% | Val loss 1.9521 acc_row 35.59% | train_time 2.819s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.5431 acc 49.89% | Val loss 1.6926 acc_row 32.20% | train_time 2.833s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.4212 acc 58.35% | Val loss 2.3172 acc_row 25.42% | train_time 2.816s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.2568 acc 64.90% | Val loss 2.1400 acc_row 27.97% | train_time 2.811s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.1889 acc 69.77% | Val loss 2.6748 acc_row 27.12% | train_time 2.871s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 1.0371 acc 76.11% | Val loss 1.7579 acc_row 33.90% | train_time 2.836s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=35.59%)\n",
      "[FOLD5] test_row=35.35% test_block=35.35% | epochs=7 | train_time(s) min/med/max=2.811/2.819/2.871 | params=3.849M | model=14.76MB | infer_row_mean=1.745ms infer_block_mean=1.956ms\n",
      "[INFO] device=cuda | method=CONCAT_M_FRAMES | backbone=CNN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=CONCAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 65536, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== CONCAT_M_FRAMES | CNN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.1411 acc 20.55% | Val loss 1.9072 acc_row 48.74% | train_time 0.728s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.9730 acc 44.07% | Val loss 1.7062 acc_row 63.87% | train_time 0.564s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.8541 acc 51.69% | Val loss 1.5746 acc_row 82.35% | train_time 0.566s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.7788 acc 61.23% | Val loss 1.4828 acc_row 78.99% | train_time 0.569s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.7266 acc 65.04% | Val loss 1.4155 acc_row 75.63% | train_time 0.564s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.6311 acc 74.79% | Val loss 1.3487 acc_row 87.39% | train_time 0.589s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 1.5645 acc 77.33% | Val loss 1.2723 acc_row 85.71% | train_time 0.580s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 1.5075 acc 78.18% | Val loss 1.1920 acc_row 95.80% | train_time 0.580s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 1.4421 acc 83.05% | Val loss 1.1445 acc_row 90.76% | train_time 0.587s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 1.3967 acc 85.38% | Val loss 1.1206 acc_row 94.96% | train_time 0.594s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 1.3471 acc 88.77% | Val loss 1.0274 acc_row 92.44% | train_time 0.581s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 1.3170 acc 88.14% | Val loss 1.0502 acc_row 97.48% | train_time 0.597s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 1.2967 acc 92.16% | Val loss 1.0033 acc_row 98.32% | train_time 0.586s | lr 5e-05\n",
      "Fold 1 Ep 14 | Train loss 1.2615 acc 91.74% | Val loss 0.9786 acc_row 95.80% | train_time 0.582s | lr 5e-05\n",
      "Fold 1 Ep 15 | Train loss 1.2013 acc 94.92% | Val loss 0.9762 acc_row 100.00% | train_time 0.598s | lr 5e-05\n",
      "Fold 1 Ep 16 | Train loss 1.1864 acc 93.64% | Val loss 0.8817 acc_row 96.64% | train_time 0.582s | lr 5e-05\n",
      "Fold 1 Ep 17 | Train loss 1.1536 acc 93.86% | Val loss 0.9103 acc_row 94.12% | train_time 0.567s | lr 5e-05\n",
      "Fold 1 Ep 18 | Train loss 1.1193 acc 93.22% | Val loss 0.8780 acc_row 100.00% | train_time 0.566s | lr 5e-05\n",
      "Fold 1 Ep 19 | Train loss 1.0825 acc 93.43% | Val loss 0.8386 acc_row 100.00% | train_time 0.590s | lr 5e-05\n",
      "Fold 1 Ep 20 | Train loss 1.0857 acc 94.92% | Val loss 0.8220 acc_row 100.00% | train_time 0.571s | lr 5e-05\n",
      "Early stop at epoch 20 (best_val_acc_row=100.00%)\n",
      "[FOLD1] test_row=96.97% test_block=96.97% | epochs=20 | train_time(s) min/med/max=0.564/0.582/0.728 | params=0.540M | model=2.08MB | infer_row_mean=0.361ms infer_block_mean=0.346ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | CNN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1364 acc 21.56% | Val loss 1.8933 acc_row 55.93% | train_time 0.571s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.9988 acc 38.05% | Val loss 1.6796 acc_row 88.14% | train_time 0.570s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.8696 acc 51.80% | Val loss 1.5588 acc_row 72.03% | train_time 0.581s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.7738 acc 62.37% | Val loss 1.4311 acc_row 95.76% | train_time 0.576s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.7005 acc 71.67% | Val loss 1.3647 acc_row 88.98% | train_time 0.579s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.6429 acc 74.21% | Val loss 1.3092 acc_row 96.61% | train_time 0.583s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.5713 acc 80.97% | Val loss 1.2317 acc_row 99.15% | train_time 0.577s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 1.5018 acc 84.14% | Val loss 1.1921 acc_row 99.15% | train_time 0.574s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 1.4588 acc 84.36% | Val loss 1.1378 acc_row 99.15% | train_time 0.574s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 1.3998 acc 86.89% | Val loss 1.0804 acc_row 97.46% | train_time 0.568s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 1.3388 acc 91.12% | Val loss 1.0508 acc_row 98.31% | train_time 0.571s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 1.3024 acc 89.85% | Val loss 0.9895 acc_row 99.15% | train_time 0.582s | lr 5e-05\n",
      "Early stop at epoch 12 (best_val_acc_row=99.15%)\n",
      "[FOLD2] test_row=96.46% test_block=96.46% | epochs=12 | train_time(s) min/med/max=0.568/0.575/0.583 | params=0.540M | model=2.08MB | infer_row_mean=0.341ms infer_block_mean=0.365ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | CNN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.1453 acc 23.04% | Val loss 1.9332 acc_row 43.22% | train_time 0.581s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 2.0196 acc 39.75% | Val loss 1.6951 acc_row 69.49% | train_time 0.569s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.8670 acc 52.22% | Val loss 1.5454 acc_row 73.73% | train_time 0.566s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.8095 acc 61.95% | Val loss 1.4713 acc_row 69.49% | train_time 0.567s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.7245 acc 68.50% | Val loss 1.4108 acc_row 93.22% | train_time 0.567s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.6393 acc 78.22% | Val loss 1.3020 acc_row 88.14% | train_time 0.569s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 1.5881 acc 79.92% | Val loss 1.2402 acc_row 88.14% | train_time 0.563s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 1.5452 acc 78.65% | Val loss 1.1833 acc_row 93.22% | train_time 0.572s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 1.4647 acc 87.32% | Val loss 1.1234 acc_row 94.92% | train_time 0.564s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 1.3930 acc 87.32% | Val loss 1.0402 acc_row 98.31% | train_time 0.565s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 1.3484 acc 91.12% | Val loss 1.0177 acc_row 98.31% | train_time 0.559s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 1.3115 acc 90.91% | Val loss 1.0176 acc_row 97.46% | train_time 0.557s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 1.2734 acc 92.81% | Val loss 0.9299 acc_row 99.15% | train_time 0.567s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 1.2351 acc 92.60% | Val loss 0.9334 acc_row 97.46% | train_time 0.568s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 1.2109 acc 95.56% | Val loss 0.9291 acc_row 98.31% | train_time 0.561s | lr 5e-05\n",
      "Fold 3 Ep 16 | Train loss 1.2004 acc 91.12% | Val loss 0.8580 acc_row 99.15% | train_time 0.559s | lr 5e-05\n",
      "Fold 3 Ep 17 | Train loss 1.1355 acc 95.98% | Val loss 0.8567 acc_row 99.15% | train_time 0.555s | lr 5e-05\n",
      "Fold 3 Ep 18 | Train loss 1.1346 acc 93.02% | Val loss 0.8352 acc_row 98.31% | train_time 0.567s | lr 5e-05\n",
      "Early stop at epoch 18 (best_val_acc_row=99.15%)\n",
      "[FOLD3] test_row=96.97% test_block=96.97% | epochs=18 | train_time(s) min/med/max=0.555/0.567/0.581 | params=0.540M | model=2.08MB | infer_row_mean=0.343ms infer_block_mean=0.343ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | CNN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.1414 acc 25.37% | Val loss 1.9131 acc_row 63.56% | train_time 0.580s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 2.0119 acc 38.69% | Val loss 1.7184 acc_row 75.42% | train_time 0.587s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.8664 acc 58.14% | Val loss 1.5603 acc_row 82.20% | train_time 0.558s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.7902 acc 64.48% | Val loss 1.4430 acc_row 86.44% | train_time 0.563s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.7039 acc 70.19% | Val loss 1.3651 acc_row 93.22% | train_time 0.567s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.6477 acc 76.74% | Val loss 1.3117 acc_row 97.46% | train_time 0.558s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.5560 acc 81.40% | Val loss 1.1890 acc_row 97.46% | train_time 0.558s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 1.5156 acc 83.51% | Val loss 1.1903 acc_row 94.92% | train_time 0.561s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 1.4251 acc 88.58% | Val loss 1.0862 acc_row 94.92% | train_time 0.563s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 1.3964 acc 83.30% | Val loss 1.0847 acc_row 96.61% | train_time 0.556s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 1.3273 acc 91.97% | Val loss 0.9865 acc_row 96.61% | train_time 0.582s | lr 5e-05\n",
      "Early stop at epoch 11 (best_val_acc_row=97.46%)\n",
      "[FOLD4] test_row=94.44% test_block=94.44% | epochs=11 | train_time(s) min/med/max=0.556/0.563/0.587 | params=0.540M | model=2.08MB | infer_row_mean=0.441ms infer_block_mean=0.470ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | CNN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.1402 acc 21.78% | Val loss 1.9043 acc_row 50.85% | train_time 0.595s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.9897 acc 37.63% | Val loss 1.7062 acc_row 81.36% | train_time 0.590s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.8667 acc 53.28% | Val loss 1.6036 acc_row 82.20% | train_time 0.588s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.7849 acc 58.14% | Val loss 1.4640 acc_row 91.53% | train_time 0.601s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.7135 acc 68.92% | Val loss 1.4102 acc_row 93.22% | train_time 0.597s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.6456 acc 72.30% | Val loss 1.3678 acc_row 92.37% | train_time 0.592s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 1.5881 acc 75.48% | Val loss 1.2633 acc_row 94.07% | train_time 0.593s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 1.5278 acc 83.30% | Val loss 1.1883 acc_row 98.31% | train_time 0.578s | lr 0.0001\n",
      "Fold 5 Ep 9 | Train loss 1.4673 acc 84.14% | Val loss 1.1590 acc_row 96.61% | train_time 0.593s | lr 0.0001\n",
      "Fold 5 Ep 10 | Train loss 1.3830 acc 86.89% | Val loss 1.0648 acc_row 96.61% | train_time 0.583s | lr 0.0001\n",
      "Fold 5 Ep 11 | Train loss 1.3355 acc 92.18% | Val loss 1.0757 acc_row 97.46% | train_time 0.599s | lr 5e-05\n",
      "Fold 5 Ep 12 | Train loss 1.3013 acc 90.91% | Val loss 1.0170 acc_row 97.46% | train_time 0.569s | lr 5e-05\n",
      "Fold 5 Ep 13 | Train loss 1.2821 acc 91.97% | Val loss 0.9935 acc_row 97.46% | train_time 0.573s | lr 5e-05\n",
      "Early stop at epoch 13 (best_val_acc_row=98.31%)\n",
      "[FOLD5] test_row=96.97% test_block=96.97% | epochs=13 | train_time(s) min/med/max=0.569/0.592/0.601 | params=0.540M | model=2.08MB | infer_row_mean=0.348ms infer_block_mean=0.342ms\n",
      "[INFO] device=cuda | method=CONCAT_M_FRAMES | backbone=TCN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=CONCAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 65536, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== CONCAT_M_FRAMES | TCN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.1989 acc 16.31% | Val loss 1.8739 acc_row 23.53% | train_time 7.796s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.8990 acc 35.59% | Val loss 1.5245 acc_row 45.38% | train_time 7.734s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.7054 acc 45.13% | Val loss 1.3002 acc_row 58.82% | train_time 7.706s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.5732 acc 53.81% | Val loss 1.0139 acc_row 79.83% | train_time 7.841s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.4383 acc 62.50% | Val loss 0.8766 acc_row 90.76% | train_time 7.676s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.3551 acc 70.34% | Val loss 0.8084 acc_row 84.03% | train_time 7.703s | lr 0.0001\n",
      "Fold 1 Ep 7 | Train loss 1.3684 acc 64.41% | Val loss 0.6895 acc_row 96.64% | train_time 7.712s | lr 0.0001\n",
      "Fold 1 Ep 8 | Train loss 1.2216 acc 74.36% | Val loss 0.6003 acc_row 96.64% | train_time 7.707s | lr 0.0001\n",
      "Fold 1 Ep 9 | Train loss 1.1482 acc 80.08% | Val loss 0.5208 acc_row 97.48% | train_time 7.675s | lr 0.0001\n",
      "Fold 1 Ep 10 | Train loss 1.0605 acc 82.42% | Val loss 0.5017 acc_row 96.64% | train_time 7.713s | lr 0.0001\n",
      "Fold 1 Ep 11 | Train loss 0.9884 acc 89.83% | Val loss 0.4172 acc_row 97.48% | train_time 7.701s | lr 5e-05\n",
      "Fold 1 Ep 12 | Train loss 0.9546 acc 91.10% | Val loss 0.4143 acc_row 96.64% | train_time 7.708s | lr 5e-05\n",
      "Fold 1 Ep 13 | Train loss 0.9663 acc 90.89% | Val loss 0.3922 acc_row 97.48% | train_time 7.699s | lr 5e-05\n",
      "Fold 1 Ep 14 | Train loss 0.9147 acc 90.25% | Val loss 0.3315 acc_row 100.00% | train_time 7.713s | lr 5e-05\n",
      "Fold 1 Ep 15 | Train loss 0.8962 acc 89.83% | Val loss 0.3698 acc_row 99.16% | train_time 7.701s | lr 5e-05\n",
      "Fold 1 Ep 16 | Train loss 0.8542 acc 91.95% | Val loss 0.2940 acc_row 100.00% | train_time 7.700s | lr 5e-05\n",
      "Fold 1 Ep 17 | Train loss 0.8104 acc 93.64% | Val loss 0.3326 acc_row 98.32% | train_time 7.672s | lr 5e-05\n",
      "Fold 1 Ep 18 | Train loss 0.7889 acc 94.92% | Val loss 0.2955 acc_row 100.00% | train_time 7.696s | lr 5e-05\n",
      "Fold 1 Ep 19 | Train loss 0.7868 acc 93.43% | Val loss 0.3165 acc_row 97.48% | train_time 7.701s | lr 5e-05\n",
      "Early stop at epoch 19 (best_val_acc_row=100.00%)\n",
      "[FOLD1] test_row=97.47% test_block=97.47% | epochs=19 | train_time(s) min/med/max=7.672/7.703/7.841 | params=0.596M | model=2.31MB | infer_row_mean=3.516ms infer_block_mean=3.446ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | TCN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1561 acc 19.24% | Val loss 1.8781 acc_row 27.12% | train_time 7.700s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.8264 acc 41.65% | Val loss 1.4020 acc_row 64.41% | train_time 7.691s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.6600 acc 48.41% | Val loss 1.2611 acc_row 62.71% | train_time 7.789s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.5552 acc 57.08% | Val loss 1.1174 acc_row 72.03% | train_time 7.715s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.4855 acc 60.68% | Val loss 0.9551 acc_row 85.59% | train_time 7.831s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.3327 acc 71.67% | Val loss 0.8076 acc_row 84.75% | train_time 7.661s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.3088 acc 68.29% | Val loss 0.6482 acc_row 94.92% | train_time 7.684s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 1.2168 acc 76.74% | Val loss 0.6362 acc_row 90.68% | train_time 7.686s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 1.1701 acc 77.59% | Val loss 0.5214 acc_row 98.31% | train_time 7.711s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 1.0928 acc 83.30% | Val loss 0.4985 acc_row 94.07% | train_time 7.755s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 1.0365 acc 84.78% | Val loss 0.5130 acc_row 93.22% | train_time 7.715s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 0.9689 acc 89.85% | Val loss 0.4287 acc_row 99.15% | train_time 7.700s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 0.9609 acc 90.27% | Val loss 0.4148 acc_row 94.92% | train_time 7.772s | lr 5e-05\n",
      "Fold 2 Ep 14 | Train loss 0.9509 acc 89.01% | Val loss 0.3553 acc_row 99.15% | train_time 7.710s | lr 5e-05\n",
      "Fold 2 Ep 15 | Train loss 0.9124 acc 89.43% | Val loss 0.3681 acc_row 97.46% | train_time 7.717s | lr 5e-05\n",
      "Fold 2 Ep 16 | Train loss 0.8889 acc 92.18% | Val loss 0.3161 acc_row 97.46% | train_time 7.766s | lr 5e-05\n",
      "Fold 2 Ep 17 | Train loss 0.8420 acc 92.39% | Val loss 0.4189 acc_row 96.61% | train_time 7.920s | lr 5e-05\n",
      "Early stop at epoch 17 (best_val_acc_row=99.15%)\n",
      "[FOLD2] test_row=95.96% test_block=95.96% | epochs=17 | train_time(s) min/med/max=7.661/7.715/7.920 | params=0.596M | model=2.31MB | infer_row_mean=3.469ms infer_block_mean=3.465ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | TCN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.1334 acc 19.24% | Val loss 2.0589 acc_row 15.25% | train_time 7.684s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 1.8179 acc 42.71% | Val loss 1.5029 acc_row 49.15% | train_time 7.713s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.6781 acc 49.68% | Val loss 1.3040 acc_row 55.08% | train_time 7.724s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.5767 acc 55.81% | Val loss 1.0538 acc_row 67.80% | train_time 7.742s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.4413 acc 61.95% | Val loss 0.8949 acc_row 76.27% | train_time 7.693s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.3366 acc 71.67% | Val loss 0.7897 acc_row 91.53% | train_time 7.904s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 1.2471 acc 77.17% | Val loss 0.7384 acc_row 81.36% | train_time 7.831s | lr 0.0001\n",
      "Fold 3 Ep 8 | Train loss 1.1851 acc 77.59% | Val loss 0.5403 acc_row 95.76% | train_time 7.828s | lr 0.0001\n",
      "Fold 3 Ep 9 | Train loss 1.1311 acc 80.55% | Val loss 0.5511 acc_row 88.98% | train_time 7.945s | lr 0.0001\n",
      "Fold 3 Ep 10 | Train loss 1.0074 acc 85.62% | Val loss 0.4479 acc_row 97.46% | train_time 7.842s | lr 0.0001\n",
      "Fold 3 Ep 11 | Train loss 0.9893 acc 88.58% | Val loss 0.4585 acc_row 95.76% | train_time 7.908s | lr 5e-05\n",
      "Fold 3 Ep 12 | Train loss 0.9373 acc 89.85% | Val loss 0.4036 acc_row 95.76% | train_time 7.812s | lr 5e-05\n",
      "Fold 3 Ep 13 | Train loss 0.9420 acc 90.70% | Val loss 0.4545 acc_row 95.76% | train_time 7.862s | lr 5e-05\n",
      "Fold 3 Ep 14 | Train loss 0.8641 acc 93.23% | Val loss 0.3911 acc_row 96.61% | train_time 7.853s | lr 5e-05\n",
      "Fold 3 Ep 15 | Train loss 0.8640 acc 91.12% | Val loss 0.3353 acc_row 96.61% | train_time 7.691s | lr 5e-05\n",
      "Early stop at epoch 15 (best_val_acc_row=97.46%)\n",
      "[FOLD3] test_row=96.46% test_block=96.46% | epochs=15 | train_time(s) min/med/max=7.684/7.828/7.945 | params=0.596M | model=2.31MB | infer_row_mean=3.488ms infer_block_mean=3.490ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | TCN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.1382 acc 18.39% | Val loss 2.1387 acc_row 17.80% | train_time 7.697s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.8277 acc 39.53% | Val loss 1.6099 acc_row 38.14% | train_time 7.840s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.6461 acc 49.26% | Val loss 1.2298 acc_row 81.36% | train_time 7.853s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.5250 acc 55.60% | Val loss 1.1289 acc_row 76.27% | train_time 7.734s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.4621 acc 59.83% | Val loss 0.9734 acc_row 76.27% | train_time 7.824s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.3622 acc 65.96% | Val loss 0.8963 acc_row 90.68% | train_time 7.755s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.2599 acc 74.21% | Val loss 0.7416 acc_row 93.22% | train_time 7.835s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 1.1852 acc 79.28% | Val loss 0.7164 acc_row 86.44% | train_time 7.836s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 1.1041 acc 81.18% | Val loss 0.5483 acc_row 94.92% | train_time 7.857s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 1.0546 acc 82.03% | Val loss 0.5699 acc_row 93.22% | train_time 7.820s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 1.0341 acc 85.20% | Val loss 0.4918 acc_row 96.61% | train_time 7.773s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 0.9385 acc 90.06% | Val loss 0.4463 acc_row 96.61% | train_time 7.795s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 0.9191 acc 92.39% | Val loss 0.3910 acc_row 98.31% | train_time 7.744s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 0.9232 acc 87.53% | Val loss 0.4553 acc_row 96.61% | train_time 7.800s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 0.8972 acc 91.12% | Val loss 0.4096 acc_row 98.31% | train_time 7.802s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 0.8843 acc 91.97% | Val loss 0.4287 acc_row 96.61% | train_time 7.918s | lr 5e-05\n",
      "Fold 4 Ep 17 | Train loss 0.8328 acc 91.97% | Val loss 0.3715 acc_row 97.46% | train_time 7.834s | lr 5e-05\n",
      "Fold 4 Ep 18 | Train loss 0.8150 acc 91.75% | Val loss 0.4230 acc_row 96.61% | train_time 7.744s | lr 5e-05\n",
      "Early stop at epoch 18 (best_val_acc_row=98.31%)\n",
      "[FOLD4] test_row=95.96% test_block=95.96% | epochs=18 | train_time(s) min/med/max=7.697/7.811/7.918 | params=0.596M | model=2.31MB | infer_row_mean=3.534ms infer_block_mean=3.595ms\n",
      "\n",
      "====== CONCAT_M_FRAMES | TCN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.1257 acc 20.30% | Val loss 1.9381 acc_row 20.34% | train_time 7.731s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.8456 acc 33.19% | Val loss 1.4694 acc_row 45.76% | train_time 7.959s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.6710 acc 46.30% | Val loss 1.2098 acc_row 83.05% | train_time 7.868s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.5269 acc 56.45% | Val loss 0.9744 acc_row 83.05% | train_time 7.836s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.4108 acc 64.06% | Val loss 1.0023 acc_row 84.75% | train_time 7.713s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.3280 acc 69.77% | Val loss 0.7535 acc_row 98.31% | train_time 7.764s | lr 0.0001\n",
      "Fold 5 Ep 7 | Train loss 1.2476 acc 73.15% | Val loss 0.7060 acc_row 95.76% | train_time 7.695s | lr 0.0001\n",
      "Fold 5 Ep 8 | Train loss 1.1723 acc 79.07% | Val loss 0.6534 acc_row 91.53% | train_time 7.698s | lr 0.0001\n",
      "Fold 5 Ep 9 | Train loss 1.0797 acc 82.88% | Val loss 0.5507 acc_row 96.61% | train_time 7.693s | lr 0.0001\n",
      "Fold 5 Ep 10 | Train loss 1.0336 acc 81.82% | Val loss 0.5198 acc_row 96.61% | train_time 7.749s | lr 0.0001\n",
      "Fold 5 Ep 11 | Train loss 0.9863 acc 88.79% | Val loss 0.4635 acc_row 98.31% | train_time 7.807s | lr 5e-05\n",
      "Early stop at epoch 11 (best_val_acc_row=98.31%)\n",
      "[FOLD5] test_row=95.96% test_block=95.96% | epochs=11 | train_time(s) min/med/max=7.693/7.749/7.959 | params=0.596M | model=2.31MB | infer_row_mean=3.656ms infer_block_mean=3.535ms\n",
      "[INFO] device=cuda | method=MEAN_OVER_FRAMES | backbone=ResNet18_1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=MEAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== MEAN_OVER_FRAMES | ResNet18_1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.2312 acc 12.71% | Val loss 2.2434 acc_row 10.08% | train_time 0.077s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.9988 acc 18.43% | Val loss 2.6007 acc_row 10.08% | train_time 0.062s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.9318 acc 23.73% | Val loss 3.1713 acc_row 10.08% | train_time 0.060s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.8851 acc 25.64% | Val loss 3.6523 acc_row 10.08% | train_time 0.058s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.8581 acc 27.75% | Val loss 4.0037 acc_row 10.08% | train_time 0.059s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.8023 acc 31.78% | Val loss 4.1668 acc_row 10.08% | train_time 0.048s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=10.08%)\n",
      "[FOLD1] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.048/0.059/0.077 | params=3.849M | model=14.76MB | infer_row_mean=1.509ms infer_block_mean=1.971ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | ResNet18_1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1645 acc 13.95% | Val loss 2.2352 acc_row 11.02% | train_time 0.072s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.9842 acc 24.52% | Val loss 2.5977 acc_row 11.02% | train_time 0.056s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.9219 acc 23.47% | Val loss 3.1716 acc_row 11.02% | train_time 0.061s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.9119 acc 27.27% | Val loss 3.6613 acc_row 12.71% | train_time 0.050s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.8769 acc 24.52% | Val loss 4.0995 acc_row 12.71% | train_time 0.054s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.8717 acc 25.79% | Val loss 4.4216 acc_row 12.71% | train_time 0.052s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.7990 acc 29.81% | Val loss 4.8023 acc_row 12.71% | train_time 0.055s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 1.7690 acc 32.14% | Val loss 5.1707 acc_row 12.71% | train_time 0.052s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 1.7192 acc 35.10% | Val loss 5.2141 acc_row 12.71% | train_time 0.050s | lr 0.0001\n",
      "Early stop at epoch 9 (best_val_acc_row=12.71%)\n",
      "[FOLD2] test_row=11.11% test_block=11.11% | epochs=9 | train_time(s) min/med/max=0.050/0.054/0.072 | params=3.849M | model=14.76MB | infer_row_mean=1.452ms infer_block_mean=2.538ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | ResNet18_1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.2314 acc 11.63% | Val loss 2.2129 acc_row 10.17% | train_time 0.056s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 2.0356 acc 20.30% | Val loss 2.3965 acc_row 12.71% | train_time 0.051s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.9432 acc 21.99% | Val loss 2.8379 acc_row 12.71% | train_time 0.049s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.9210 acc 24.31% | Val loss 3.2542 acc_row 12.71% | train_time 0.050s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.8354 acc 29.60% | Val loss 3.5501 acc_row 12.71% | train_time 0.054s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.8267 acc 28.75% | Val loss 3.8107 acc_row 12.71% | train_time 0.048s | lr 0.0001\n",
      "Fold 3 Ep 7 | Train loss 1.8058 acc 31.08% | Val loss 4.0224 acc_row 12.71% | train_time 0.049s | lr 0.0001\n",
      "Early stop at epoch 7 (best_val_acc_row=12.71%)\n",
      "[FOLD3] test_row=11.11% test_block=11.11% | epochs=7 | train_time(s) min/med/max=0.048/0.050/0.056 | params=3.849M | model=14.76MB | infer_row_mean=1.443ms infer_block_mean=1.400ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | ResNet18_1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.2672 acc 13.95% | Val loss 2.2525 acc_row 11.86% | train_time 0.051s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 2.0394 acc 16.49% | Val loss 2.5765 acc_row 11.86% | train_time 0.049s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.9372 acc 21.14% | Val loss 3.1125 acc_row 11.86% | train_time 0.047s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.8959 acc 24.31% | Val loss 3.5720 acc_row 11.86% | train_time 0.049s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.8609 acc 29.60% | Val loss 3.9680 acc_row 11.86% | train_time 0.050s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.8271 acc 28.96% | Val loss 4.3462 acc_row 11.86% | train_time 0.052s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=11.86%)\n",
      "[FOLD4] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.047/0.049/0.052 | params=3.849M | model=14.76MB | infer_row_mean=1.425ms infer_block_mean=1.412ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | ResNet18_1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.1230 acc 17.12% | Val loss 2.2553 acc_row 9.32% | train_time 0.055s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.9582 acc 22.20% | Val loss 2.5996 acc_row 9.32% | train_time 0.051s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.9250 acc 21.99% | Val loss 3.1680 acc_row 8.47% | train_time 0.048s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.8867 acc 24.95% | Val loss 3.6285 acc_row 8.47% | train_time 0.050s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.8532 acc 26.00% | Val loss 3.9074 acc_row 8.47% | train_time 0.050s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.7965 acc 30.87% | Val loss 4.1608 acc_row 8.47% | train_time 0.050s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=9.32%)\n",
      "[FOLD5] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.048/0.050/0.055 | params=3.849M | model=14.76MB | infer_row_mean=1.924ms infer_block_mean=1.915ms\n",
      "[INFO] device=cuda | method=MEAN_OVER_FRAMES | backbone=CNN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=MEAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== MEAN_OVER_FRAMES | CNN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.1659 acc 16.95% | Val loss 2.2046 acc_row 10.08% | train_time 0.036s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 1.9695 acc 31.14% | Val loss 2.2568 acc_row 10.08% | train_time 0.034s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.8334 acc 36.23% | Val loss 2.4129 acc_row 10.08% | train_time 0.034s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.7365 acc 39.83% | Val loss 2.6899 acc_row 10.08% | train_time 0.030s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.6339 acc 47.88% | Val loss 2.9370 acc_row 10.08% | train_time 0.030s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.5827 acc 49.58% | Val loss 3.0157 acc_row 10.08% | train_time 0.023s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=10.08%)\n",
      "[FOLD1] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.023/0.032/0.036 | params=0.540M | model=2.08MB | infer_row_mean=0.372ms infer_block_mean=0.368ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | CNN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.1504 acc 17.76% | Val loss 2.1936 acc_row 12.71% | train_time 0.023s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 1.9283 acc 32.77% | Val loss 2.2141 acc_row 12.71% | train_time 0.025s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.8202 acc 38.90% | Val loss 2.3215 acc_row 12.71% | train_time 0.021s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.7395 acc 45.45% | Val loss 2.5430 acc_row 12.71% | train_time 0.022s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.6368 acc 52.43% | Val loss 2.7386 acc_row 12.71% | train_time 0.022s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.5938 acc 56.24% | Val loss 2.7126 acc_row 12.71% | train_time 0.021s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=12.71%)\n",
      "[FOLD2] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.021/0.022/0.025 | params=0.540M | model=2.08MB | infer_row_mean=0.377ms infer_block_mean=0.369ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | CNN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.1794 acc 14.16% | Val loss 2.1997 acc_row 12.71% | train_time 0.021s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 1.9622 acc 31.50% | Val loss 2.2161 acc_row 12.71% | train_time 0.022s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 1.8485 acc 38.27% | Val loss 2.2983 acc_row 12.71% | train_time 0.025s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.7387 acc 46.30% | Val loss 2.4605 acc_row 12.71% | train_time 0.020s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.6724 acc 45.67% | Val loss 2.6006 acc_row 12.71% | train_time 0.021s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.5830 acc 51.37% | Val loss 2.5665 acc_row 12.71% | train_time 0.021s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=12.71%)\n",
      "[FOLD3] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.020/0.021/0.025 | params=0.540M | model=2.08MB | infer_row_mean=0.394ms infer_block_mean=0.365ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | CNN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.1665 acc 14.80% | Val loss 2.1996 acc_row 10.17% | train_time 0.021s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.9609 acc 33.19% | Val loss 2.2236 acc_row 11.86% | train_time 0.022s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.8165 acc 43.76% | Val loss 2.3483 acc_row 11.86% | train_time 0.026s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.7261 acc 47.36% | Val loss 2.6380 acc_row 11.86% | train_time 0.020s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.6592 acc 49.47% | Val loss 2.9491 acc_row 11.86% | train_time 0.038s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.6039 acc 51.59% | Val loss 2.9868 acc_row 12.71% | train_time 0.024s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.5122 acc 55.39% | Val loss 2.6878 acc_row 15.25% | train_time 0.023s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 1.4862 acc 56.87% | Val loss 2.3117 acc_row 16.95% | train_time 0.028s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 1.4582 acc 57.72% | Val loss 1.9788 acc_row 18.64% | train_time 0.024s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 1.4029 acc 62.37% | Val loss 1.7643 acc_row 29.66% | train_time 0.021s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 1.3869 acc 62.79% | Val loss 1.6509 acc_row 39.83% | train_time 0.022s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 1.3371 acc 63.85% | Val loss 1.6090 acc_row 43.22% | train_time 0.021s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 1.3266 acc 68.08% | Val loss 1.5916 acc_row 39.83% | train_time 0.018s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 1.3315 acc 65.33% | Val loss 1.5774 acc_row 39.83% | train_time 0.018s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 1.2890 acc 66.81% | Val loss 1.5728 acc_row 39.83% | train_time 0.020s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 1.2585 acc 69.98% | Val loss 1.5642 acc_row 39.83% | train_time 0.019s | lr 5e-05\n",
      "Fold 4 Ep 17 | Train loss 1.2538 acc 72.30% | Val loss 1.5584 acc_row 39.83% | train_time 0.017s | lr 5e-05\n",
      "Early stop at epoch 17 (best_val_acc_row=43.22%)\n",
      "[FOLD4] test_row=43.43% test_block=43.43% | epochs=17 | train_time(s) min/med/max=0.017/0.021/0.038 | params=0.540M | model=2.08MB | infer_row_mean=0.479ms infer_block_mean=0.500ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | CNN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.1760 acc 16.70% | Val loss 2.2030 acc_row 9.32% | train_time 0.023s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 1.9614 acc 32.98% | Val loss 2.2485 acc_row 8.47% | train_time 0.019s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 1.8290 acc 40.17% | Val loss 2.4377 acc_row 8.47% | train_time 0.020s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.7343 acc 42.71% | Val loss 2.8325 acc_row 8.47% | train_time 0.020s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.6455 acc 45.88% | Val loss 3.1976 acc_row 8.47% | train_time 0.021s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.5830 acc 52.01% | Val loss 3.1589 acc_row 9.32% | train_time 0.019s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=9.32%)\n",
      "[FOLD5] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.019/0.020/0.023 | params=0.540M | model=2.08MB | infer_row_mean=0.350ms infer_block_mean=0.342ms\n",
      "[INFO] device=cuda | method=MEAN_OVER_FRAMES | backbone=TCN1D\n",
      "[INFO] Cross-domain loader | files=72 | fd=655.56 Hz | method=MEAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "读取数据: 100%|██████████| 72/72 [00:10<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] X_blocks: (789, 1, 256, 2) (B, sample_len, time_len, 2) | classes=9\n",
      "\n",
      "====== MEAN_OVER_FRAMES | TCN1D | Fold 1/5 ======\n",
      "Fold 1 Ep 1 | Train loss 2.3456 acc 11.02% | Val loss 2.2257 acc_row 10.08% | train_time 0.457s | lr 0.0001\n",
      "Fold 1 Ep 2 | Train loss 2.0360 acc 19.92% | Val loss 2.4438 acc_row 10.08% | train_time 0.264s | lr 0.0001\n",
      "Fold 1 Ep 3 | Train loss 1.9136 acc 28.60% | Val loss 2.9628 acc_row 10.08% | train_time 0.250s | lr 0.0001\n",
      "Fold 1 Ep 4 | Train loss 1.8325 acc 27.54% | Val loss 3.3904 acc_row 10.08% | train_time 0.250s | lr 0.0001\n",
      "Fold 1 Ep 5 | Train loss 1.8072 acc 31.99% | Val loss 3.5482 acc_row 10.08% | train_time 0.263s | lr 0.0001\n",
      "Fold 1 Ep 6 | Train loss 1.6926 acc 38.56% | Val loss 3.5106 acc_row 10.08% | train_time 0.252s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=10.08%)\n",
      "[FOLD1] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.250/0.257/0.457 | params=0.596M | model=2.31MB | infer_row_mean=1.072ms infer_block_mean=1.066ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | TCN1D | Fold 2/5 ======\n",
      "Fold 2 Ep 1 | Train loss 2.2755 acc 16.07% | Val loss 2.2433 acc_row 9.32% | train_time 0.261s | lr 0.0001\n",
      "Fold 2 Ep 2 | Train loss 2.0588 acc 21.35% | Val loss 2.3865 acc_row 11.02% | train_time 0.253s | lr 0.0001\n",
      "Fold 2 Ep 3 | Train loss 1.9224 acc 27.06% | Val loss 2.7297 acc_row 12.71% | train_time 0.261s | lr 0.0001\n",
      "Fold 2 Ep 4 | Train loss 1.8304 acc 30.66% | Val loss 3.1851 acc_row 12.71% | train_time 0.262s | lr 0.0001\n",
      "Fold 2 Ep 5 | Train loss 1.7792 acc 28.12% | Val loss 3.5250 acc_row 12.71% | train_time 0.270s | lr 0.0001\n",
      "Fold 2 Ep 6 | Train loss 1.7094 acc 39.11% | Val loss 3.6165 acc_row 12.71% | train_time 0.248s | lr 0.0001\n",
      "Fold 2 Ep 7 | Train loss 1.6745 acc 43.13% | Val loss 3.4736 acc_row 13.56% | train_time 0.246s | lr 0.0001\n",
      "Fold 2 Ep 8 | Train loss 1.5962 acc 45.67% | Val loss 3.2345 acc_row 16.10% | train_time 0.273s | lr 0.0001\n",
      "Fold 2 Ep 9 | Train loss 1.5534 acc 46.30% | Val loss 2.8764 acc_row 18.64% | train_time 0.252s | lr 0.0001\n",
      "Fold 2 Ep 10 | Train loss 1.4962 acc 46.93% | Val loss 2.2625 acc_row 27.12% | train_time 0.261s | lr 0.0001\n",
      "Fold 2 Ep 11 | Train loss 1.4797 acc 48.84% | Val loss 2.0009 acc_row 29.66% | train_time 0.260s | lr 5e-05\n",
      "Fold 2 Ep 12 | Train loss 1.4107 acc 48.84% | Val loss 1.8854 acc_row 33.90% | train_time 0.276s | lr 5e-05\n",
      "Fold 2 Ep 13 | Train loss 1.3939 acc 51.16% | Val loss 1.8268 acc_row 35.59% | train_time 0.248s | lr 5e-05\n",
      "Fold 2 Ep 14 | Train loss 1.3829 acc 51.16% | Val loss 1.8192 acc_row 33.90% | train_time 0.272s | lr 5e-05\n",
      "Fold 2 Ep 15 | Train loss 1.3590 acc 53.49% | Val loss 1.8045 acc_row 38.14% | train_time 0.261s | lr 5e-05\n",
      "Fold 2 Ep 16 | Train loss 1.3534 acc 52.85% | Val loss 1.7709 acc_row 38.14% | train_time 0.261s | lr 5e-05\n",
      "Fold 2 Ep 17 | Train loss 1.3509 acc 50.74% | Val loss 1.8084 acc_row 38.14% | train_time 0.257s | lr 5e-05\n",
      "Fold 2 Ep 18 | Train loss 1.3240 acc 52.85% | Val loss 1.8368 acc_row 36.44% | train_time 0.252s | lr 5e-05\n",
      "Fold 2 Ep 19 | Train loss 1.3073 acc 58.14% | Val loss 1.7949 acc_row 38.14% | train_time 0.279s | lr 5e-05\n",
      "Fold 2 Ep 20 | Train loss 1.3006 acc 54.97% | Val loss 1.8240 acc_row 38.14% | train_time 0.242s | lr 5e-05\n",
      "Early stop at epoch 20 (best_val_acc_row=38.14%)\n",
      "[FOLD2] test_row=29.80% test_block=29.80% | epochs=20 | train_time(s) min/med/max=0.242/0.261/0.279 | params=0.596M | model=2.31MB | infer_row_mean=1.059ms infer_block_mean=1.074ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | TCN1D | Fold 3/5 ======\n",
      "Fold 3 Ep 1 | Train loss 2.5089 acc 11.42% | Val loss 2.2297 acc_row 12.71% | train_time 0.267s | lr 0.0001\n",
      "Fold 3 Ep 2 | Train loss 2.2080 acc 13.11% | Val loss 2.3896 acc_row 12.71% | train_time 0.261s | lr 0.0001\n",
      "Fold 3 Ep 3 | Train loss 2.0400 acc 19.45% | Val loss 2.7243 acc_row 12.71% | train_time 0.274s | lr 0.0001\n",
      "Fold 3 Ep 4 | Train loss 1.9197 acc 24.31% | Val loss 3.0958 acc_row 12.71% | train_time 0.261s | lr 0.0001\n",
      "Fold 3 Ep 5 | Train loss 1.8603 acc 31.92% | Val loss 3.3460 acc_row 12.71% | train_time 0.270s | lr 0.0001\n",
      "Fold 3 Ep 6 | Train loss 1.7803 acc 36.15% | Val loss 3.4005 acc_row 12.71% | train_time 0.248s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=12.71%)\n",
      "[FOLD3] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.248/0.264/0.274 | params=0.596M | model=2.31MB | infer_row_mean=0.999ms infer_block_mean=0.995ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | TCN1D | Fold 4/5 ======\n",
      "Fold 4 Ep 1 | Train loss 2.2377 acc 19.24% | Val loss 2.2082 acc_row 11.86% | train_time 0.254s | lr 0.0001\n",
      "Fold 4 Ep 2 | Train loss 1.9997 acc 28.33% | Val loss 2.4099 acc_row 11.86% | train_time 0.246s | lr 0.0001\n",
      "Fold 4 Ep 3 | Train loss 1.8716 acc 26.85% | Val loss 2.8503 acc_row 11.86% | train_time 0.251s | lr 0.0001\n",
      "Fold 4 Ep 4 | Train loss 1.8151 acc 31.08% | Val loss 3.3113 acc_row 11.86% | train_time 0.244s | lr 0.0001\n",
      "Fold 4 Ep 5 | Train loss 1.7592 acc 37.21% | Val loss 3.5631 acc_row 11.86% | train_time 0.250s | lr 0.0001\n",
      "Fold 4 Ep 6 | Train loss 1.7165 acc 40.17% | Val loss 3.5809 acc_row 12.71% | train_time 0.253s | lr 0.0001\n",
      "Fold 4 Ep 7 | Train loss 1.6810 acc 45.03% | Val loss 3.4321 acc_row 14.41% | train_time 0.245s | lr 0.0001\n",
      "Fold 4 Ep 8 | Train loss 1.6014 acc 44.40% | Val loss 3.1808 acc_row 13.56% | train_time 0.254s | lr 0.0001\n",
      "Fold 4 Ep 9 | Train loss 1.5156 acc 45.24% | Val loss 2.8654 acc_row 14.41% | train_time 0.260s | lr 0.0001\n",
      "Fold 4 Ep 10 | Train loss 1.4373 acc 51.16% | Val loss 2.5028 acc_row 16.10% | train_time 0.255s | lr 0.0001\n",
      "Fold 4 Ep 11 | Train loss 1.4253 acc 51.37% | Val loss 2.2898 acc_row 21.19% | train_time 0.255s | lr 5e-05\n",
      "Fold 4 Ep 12 | Train loss 1.3725 acc 52.85% | Val loss 2.2087 acc_row 24.58% | train_time 0.240s | lr 5e-05\n",
      "Fold 4 Ep 13 | Train loss 1.3805 acc 52.85% | Val loss 2.1376 acc_row 27.12% | train_time 0.243s | lr 5e-05\n",
      "Fold 4 Ep 14 | Train loss 1.3721 acc 54.12% | Val loss 2.1292 acc_row 27.12% | train_time 0.245s | lr 5e-05\n",
      "Fold 4 Ep 15 | Train loss 1.3496 acc 56.24% | Val loss 2.1013 acc_row 27.12% | train_time 0.250s | lr 5e-05\n",
      "Fold 4 Ep 16 | Train loss 1.3394 acc 51.80% | Val loss 2.1344 acc_row 27.12% | train_time 0.246s | lr 5e-05\n",
      "Fold 4 Ep 17 | Train loss 1.3344 acc 54.76% | Val loss 2.1961 acc_row 26.27% | train_time 0.243s | lr 5e-05\n",
      "Fold 4 Ep 18 | Train loss 1.3054 acc 52.85% | Val loss 2.1850 acc_row 26.27% | train_time 0.267s | lr 5e-05\n",
      "Early stop at epoch 18 (best_val_acc_row=27.12%)\n",
      "[FOLD4] test_row=25.76% test_block=25.76% | epochs=18 | train_time(s) min/med/max=0.240/0.250/0.267 | params=0.596M | model=2.31MB | infer_row_mean=1.024ms infer_block_mean=1.026ms\n",
      "\n",
      "====== MEAN_OVER_FRAMES | TCN1D | Fold 5/5 ======\n",
      "Fold 5 Ep 1 | Train loss 2.6148 acc 10.36% | Val loss 2.2404 acc_row 13.56% | train_time 0.314s | lr 0.0001\n",
      "Fold 5 Ep 2 | Train loss 2.2469 acc 13.32% | Val loss 2.5244 acc_row 9.32% | train_time 0.252s | lr 0.0001\n",
      "Fold 5 Ep 3 | Train loss 2.0765 acc 22.83% | Val loss 3.0602 acc_row 8.47% | train_time 0.262s | lr 0.0001\n",
      "Fold 5 Ep 4 | Train loss 1.9504 acc 25.79% | Val loss 3.6487 acc_row 8.47% | train_time 0.255s | lr 0.0001\n",
      "Fold 5 Ep 5 | Train loss 1.8826 acc 27.91% | Val loss 3.9369 acc_row 8.47% | train_time 0.242s | lr 0.0001\n",
      "Fold 5 Ep 6 | Train loss 1.7946 acc 31.71% | Val loss 3.8667 acc_row 8.47% | train_time 0.250s | lr 0.0001\n",
      "Early stop at epoch 6 (best_val_acc_row=13.56%)\n",
      "[FOLD5] test_row=11.11% test_block=11.11% | epochs=6 | train_time(s) min/med/max=0.242/0.253/0.314 | params=0.596M | model=2.31MB | infer_row_mean=1.059ms infer_block_mean=1.051ms\n",
      "[DONE] root_folder: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-31_11-28-17_LTEV_CrossDomainXFR_Ablations_SNR20dB_fd655_m256\n",
      "[DONE] global_summary.csv: d:\\Program\\MW-RFF\\MW-RFF\\training_results\\2026-01-31_11-28-17_LTEV_CrossDomainXFR_Ablations_SNR20dB_fd655_m256\\global_summary.csv\n",
      "[DONE] aggregate_summary.json saved.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# LTE-V Cross-Domain XFR + Ablations + Backbone Plug-and-Play\n",
    "# Fixed SNR = 20 dB, one run outputs all results\n",
    "#\n",
    "# Methods:\n",
    "#   1) XFR_BASE           : cross-domain block -> transpose (L, m, 2)\n",
    "#   2) SHUFFLE_IN_BLOCK   : shuffle m (frame axis) within cross-domain block, then transpose\n",
    "#   3) CONCAT_M_FRAMES    : concatenate m frames along time -> (1, m*L, 2)\n",
    "#   4) MEAN_OVER_FRAMES   : mean over m frames pointwise -> (1, L, 2)\n",
    "#\n",
    "# Backbones:\n",
    "#   - ResNet18_1D\n",
    "#   - CNN1D\n",
    "#   - TCN1D\n",
    "#\n",
    "# Outputs per (method, backbone):\n",
    "#   - row-level + block-level accuracy (val/test)\n",
    "#   - epochs used, train epoch time range\n",
    "#   - params, model file size\n",
    "#   - inference time per row sample + per block decision\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "# ================= 参数设置 =================\n",
    "data_path = \"E:/rf_datasets_IQ_raw/\"  # 改成你的数据文件夹\n",
    "fs = 5e6\n",
    "fc = 5.9e9\n",
    "v_kmh = 120\n",
    "apply_doppler = True\n",
    "apply_awgn = True\n",
    "\n",
    "# cross-domain block 参数\n",
    "group_size = 256      # m\n",
    "SNR_FIXED = 20\n",
    "\n",
    "# 训练超参数\n",
    "base_batch_size = 64\n",
    "num_epochs = 300\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-3\n",
    "dropout = 0.5\n",
    "patience = 5\n",
    "n_splits = 5\n",
    "test_size = 0.25\n",
    "seed = 42\n",
    "\n",
    "# 训练集每 epoch 每 block 抽 K 行（仅对 sample_len>1 生效；对 CONCAT/MEAN 自动=1）\n",
    "train_rows_per_block = 256\n",
    "\n",
    "# 输出目录\n",
    "out_root = os.path.join(os.getcwd(), \"training_results\")\n",
    "\n",
    "# 方法 & backbone 列表\n",
    "METHODS = [\n",
    "    (\"XFR_BASE\", \"XFR_BASE\"),\n",
    "    (\"SHUFFLE_IN_BLOCK\", \"SHUFFLE_IN_BLOCK\"),\n",
    "    (\"CONCAT_M_FRAMES\", \"CONCAT\"),\n",
    "    (\"MEAN_OVER_FRAMES\", \"MEAN\"),\n",
    "]\n",
    "\n",
    "BACKBONES = [\n",
    "    (\"ResNet18_1D\", \"resnet\"),\n",
    "    (\"CNN1D\", \"cnn\"),\n",
    "    (\"TCN1D\", \"tcn\"),\n",
    "]\n",
    "\n",
    "\n",
    "# ================= 通用工具 =================\n",
    "def seed_everything(seed_: int = 42):\n",
    "    random.seed(seed_)\n",
    "    np.random.seed(seed_)\n",
    "    torch.manual_seed(seed_)\n",
    "    torch.cuda.manual_seed_all(seed_)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def stable_int_hash(s: str) -> int:\n",
    "    h = hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:8], 16)\n",
    "\n",
    "def auto_batch_size_for_T(T: int, base: int = 64) -> int:\n",
    "    # 保守：CONCAT 时 T=m*L 可能很大，自动降 batch 防 OOM\n",
    "    if T >= 50000:\n",
    "        return max(1, base // 32)\n",
    "    if T >= 20000:\n",
    "        return max(1, base // 16)\n",
    "    if T >= 10000:\n",
    "        return max(1, base // 8)\n",
    "    if T >= 5000:\n",
    "        return max(1, base // 4)\n",
    "    if T >= 2500:\n",
    "        return max(1, base // 2)\n",
    "    return base\n",
    "\n",
    "def count_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def sizeof_state_dict_bytes_est(model: nn.Module) -> int:\n",
    "    # 仅按参数 FP32 估算（不含 optimizer 等）\n",
    "    return count_params(model) * 4\n",
    "\n",
    "def cuda_sync_if_needed(device):\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def benchmark_inference(model: nn.Module, x: torch.Tensor, device, warmup=20, iters=100):\n",
    "    \"\"\"\n",
    "    x: (B, T, 2) on CPU or GPU; will move to device once.\n",
    "    Returns: mean_ms, p50_ms, p95_ms\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    # warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(x)\n",
    "        cuda_sync_if_needed(device)\n",
    "\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(iters):\n",
    "            t0 = time.perf_counter()\n",
    "            _ = model(x)\n",
    "            cuda_sync_if_needed(device)\n",
    "            t1 = time.perf_counter()\n",
    "            times.append((t1 - t0) * 1000.0)\n",
    "    times = np.array(times, dtype=np.float64)\n",
    "    return float(times.mean()), float(np.percentile(times, 50)), float(np.percentile(times, 95))\n",
    "\n",
    "def plot_confusion_matrix(cm, save_path, title=\"Confusion Matrix\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Reference\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def moving_average(x, w=5):\n",
    "    x = np.array(x, dtype=np.float64)\n",
    "    if len(x) == 0:\n",
    "        return np.array([])\n",
    "    w = max(1, min(int(w), len(x)))\n",
    "    return np.convolve(x, np.ones(w), \"valid\") / w\n",
    "\n",
    "def plot_training_curves(fold_results, save_folder):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i, res in enumerate(fold_results):\n",
    "        plt.plot(moving_average(res[\"train_loss\"]), label=f\"Fold{i+1} Train Loss\")\n",
    "        plt.plot(moving_average(res[\"val_loss\"]), label=f\"Fold{i+1} Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curves (moving avg)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_folder, \"loss_curves.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================= 信道处理 =================\n",
    "def compute_doppler_shift(v_kmh_, fc_hz):\n",
    "    c = 3e8\n",
    "    v = v_kmh_ / 3.6\n",
    "    return (v / c) * fc_hz\n",
    "\n",
    "def apply_doppler_shift(signal, fd, fs_):\n",
    "    t = np.arange(signal.shape[-1], dtype=np.float64) / fs_\n",
    "    doppler_phase = np.exp(1j * 2 * np.pi * fd * t)\n",
    "    return signal * doppler_phase\n",
    "\n",
    "def add_awgn(signal, snr_db):\n",
    "    sig_power = np.mean(np.abs(signal) ** 2)\n",
    "    noise_power = sig_power / (10 ** (snr_db / 10))\n",
    "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
    "    return signal + noise\n",
    "\n",
    "def power_normalize(sig):\n",
    "    return sig / (np.sqrt(np.mean(np.abs(sig) ** 2)) + 1e-12)\n",
    "\n",
    "\n",
    "# ================= H5 读取兼容 =================\n",
    "def read_dmrs_complex(rfDataset):\n",
    "    dmrs_obj = rfDataset[\"dmrs\"]\n",
    "    if isinstance(dmrs_obj, h5py.Dataset):\n",
    "        arr = dmrs_obj[:]\n",
    "        if hasattr(arr.dtype, \"names\") and arr.dtype.names is not None and (\"real\" in arr.dtype.names) and (\"imag\" in arr.dtype.names):\n",
    "            return arr[\"real\"] + 1j * arr[\"imag\"]\n",
    "        raise RuntimeError(\"dmrs dataset 不是预期的 compound(real/imag) 格式。\")\n",
    "    else:\n",
    "        real = dmrs_obj[\"real\"][:]\n",
    "        imag = dmrs_obj[\"imag\"][:]\n",
    "        return real + 1j * imag\n",
    "\n",
    "def read_txid_str(rfDataset):\n",
    "    txID_uint16 = rfDataset[\"txID\"][:].flatten()\n",
    "    chars = []\n",
    "    for c in txID_uint16:\n",
    "        ci = int(c)\n",
    "        if ci != 0:\n",
    "            chars.append(chr(ci))\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "# ================= Cross-domain block 构造 =================\n",
    "def load_and_preprocess_cross_domain_blocks(\n",
    "    mat_folder,\n",
    "    group_size_=256,\n",
    "    apply_doppler_=False,\n",
    "    target_velocity_kmh_=120,\n",
    "    apply_awgn_=False,\n",
    "    snr_db_=20,\n",
    "    fs_=5e6,\n",
    "    fc_=5.9e9,\n",
    "    method_key=\"XFR_BASE\",   # XFR_BASE | SHUFFLE_IN_BLOCK | CONCAT | MEAN\n",
    "    seed_=42\n",
    "):\n",
    "    \"\"\"\n",
    "    返回:\n",
    "      X_blocks: (num_blocks, sample_len, time_len, 2)\n",
    "      y_blocks: (num_blocks,)\n",
    "      label_to_idx: dict\n",
    "      meta: dict\n",
    "    cross-domain 逻辑：每个 TX(label) 下，把其多个文件视为不同 domain，\n",
    "    每个 block 从每个文件抽 samples_per_file 行拼接成 group_size 行，再进行表示变换。\n",
    "    \"\"\"\n",
    "    mat_files = sorted(glob.glob(os.path.join(mat_folder, \"*.mat\")))\n",
    "    if len(mat_files) == 0:\n",
    "        raise RuntimeError(f\"未找到 .mat 文件: {mat_folder}\")\n",
    "\n",
    "    fd = compute_doppler_shift(target_velocity_kmh_, fc_)\n",
    "    print(f\"[INFO] Cross-domain loader | files={len(mat_files)} | fd={fd:.2f} Hz | method={method_key}\")\n",
    "\n",
    "    # 先按文件读出 processed_signals，并按 tx 分组\n",
    "    # tx_to_signals[tx] = list of np.ndarray, each shape (num_frames_file, L, 2)\n",
    "    tx_to_signals = {}\n",
    "    skipped = 0\n",
    "    for file in tqdm(mat_files, desc=\"读取数据\"):\n",
    "        try:\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                if \"rfDataset\" not in f:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "                rfDataset = f[\"rfDataset\"]\n",
    "                if (\"dmrs\" not in rfDataset) or (\"txID\" not in rfDataset):\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                tx_id = read_txid_str(rfDataset)\n",
    "                if tx_id == \"\":\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "                dmrs_complex = read_dmrs_complex(rfDataset)  # (N, L)\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        processed_signals = []\n",
    "        for i in range(dmrs_complex.shape[0]):\n",
    "            sig = dmrs_complex[i, :]\n",
    "            sig = power_normalize(sig)\n",
    "            if apply_doppler_:\n",
    "                sig = apply_doppler_shift(sig, fd, fs_)\n",
    "            if apply_awgn_:\n",
    "                sig = add_awgn(sig, snr_db_)\n",
    "            iq = np.stack((sig.real, sig.imag), axis=-1)  # (L,2)\n",
    "            processed_signals.append(iq)\n",
    "\n",
    "        processed_signals = np.asarray(processed_signals, dtype=np.float32)  # (N,L,2)\n",
    "        tx_to_signals.setdefault(tx_id, []).append(processed_signals)\n",
    "\n",
    "    if len(tx_to_signals) == 0:\n",
    "        raise RuntimeError(\"未能从数据集中读取到任何 tx。\")\n",
    "\n",
    "    label_list = sorted(list(tx_to_signals.keys()))\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(label_list)}\n",
    "\n",
    "    X_blocks_list = []\n",
    "    y_blocks_list = []\n",
    "\n",
    "    # 每个 tx 构造 blocks\n",
    "    for tx_id in label_list:\n",
    "        files_signals = tx_to_signals[tx_id]\n",
    "        num_files = len(files_signals)\n",
    "        if num_files == 0:\n",
    "            continue\n",
    "        samples_per_file = group_size_ // num_files\n",
    "        if samples_per_file <= 0:\n",
    "            print(f\"[WARN] TX={tx_id}: num_files={num_files} > group_size={group_size_}, samples_per_file=0, skip\")\n",
    "            continue\n",
    "\n",
    "        min_samples = min(arr.shape[0] for arr in files_signals)\n",
    "        max_groups = min_samples // samples_per_file\n",
    "        if max_groups == 0:\n",
    "            print(f\"[WARN] TX={tx_id}: min_samples={min_samples}, samples_per_file={samples_per_file}, max_groups=0, skip\")\n",
    "            continue\n",
    "\n",
    "        for g in range(max_groups):\n",
    "            pieces = []\n",
    "            for arr in files_signals:\n",
    "                s = g * samples_per_file\n",
    "                e = s + samples_per_file\n",
    "                pieces.append(arr[s:e])  # (samples_per_file, L, 2)\n",
    "            big_block_frames = np.concatenate(pieces, axis=0)  # (m, L, 2) where m=group_size_\n",
    "\n",
    "            # 表示变换\n",
    "            if method_key == \"XFR_BASE\":\n",
    "                # (m,L,2)->(L,m,2)\n",
    "                out = np.transpose(big_block_frames, (1, 0, 2))\n",
    "            elif method_key == \"SHUFFLE_IN_BLOCK\":\n",
    "                # 在 cross-domain block 的 m 维度打乱，然后再 XFR transpose\n",
    "                rng = np.random.default_rng(seed_ + stable_int_hash(tx_id) + 10007 * (g + 1))\n",
    "                perm = rng.permutation(big_block_frames.shape[0])\n",
    "                shuffled = big_block_frames[perm]\n",
    "                out = np.transpose(shuffled, (1, 0, 2))  # (L,m,2)\n",
    "            elif method_key == \"CONCAT\":\n",
    "                # 拼接 m 帧: (m,L,2)->(1,m*L,2)\n",
    "                out = big_block_frames.reshape(-1, 2)[None, :, :]\n",
    "            elif method_key == \"MEAN\":\n",
    "                # 平均: (m,L,2)->(1,L,2)\n",
    "                out = np.mean(big_block_frames, axis=0, keepdims=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown method_key: {method_key}\")\n",
    "\n",
    "            X_blocks_list.append(out)\n",
    "            y_blocks_list.append(label_to_idx[tx_id])\n",
    "\n",
    "    if len(X_blocks_list) == 0:\n",
    "        raise RuntimeError(\"没有生成任何 block（检查 group_size / 文件数 / 样本数）。\")\n",
    "\n",
    "    X_blocks = np.stack(X_blocks_list, axis=0).astype(np.float32)\n",
    "    y_blocks = np.array(y_blocks_list, dtype=np.int64)\n",
    "\n",
    "    meta = {\n",
    "        \"method_key\": method_key,\n",
    "        \"num_files_total\": len(mat_files),\n",
    "        \"skipped_files\": skipped,\n",
    "        \"num_classes\": len(label_to_idx),\n",
    "        \"num_blocks\": int(X_blocks.shape[0]),\n",
    "        \"sample_len\": int(X_blocks.shape[1]),\n",
    "        \"time_len\": int(X_blocks.shape[2]),\n",
    "        \"group_size\": int(group_size_),\n",
    "        \"samples_per_file_rule\": \"group_size // num_files_per_tx\",\n",
    "    }\n",
    "\n",
    "    print(f\"[INFO] X_blocks: {X_blocks.shape} (B, sample_len, time_len, 2) | classes={len(label_to_idx)}\")\n",
    "    return X_blocks, y_blocks, label_to_idx, meta\n",
    "\n",
    "\n",
    "# ================= Row/Block 评估 =================\n",
    "def evaluate_rowlevel(model, dataloader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            all_labels.extend(y.cpu().numpy().tolist())\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "    acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    return acc, cm\n",
    "\n",
    "def evaluate_blocklevel(model, X_blocks, y_blocks, device, num_classes, rows_batch=512):\n",
    "    \"\"\"\n",
    "    对每个 block：把 sample_len 行作为 batch 一次/分批前向，logits 求均值 -> block 预测\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(X_blocks.shape[0]):\n",
    "            xb = torch.tensor(X_blocks[i], dtype=torch.float32, device=device)  # (S, T, 2)\n",
    "            yb = int(y_blocks[i])\n",
    "            S = xb.shape[0]\n",
    "            logits_list = []\n",
    "            for s in range(0, S, rows_batch):\n",
    "                e = min(S, s + rows_batch)\n",
    "                logits_list.append(model(xb[s:e]))\n",
    "            logits = torch.cat(logits_list, dim=0)  # (S, C)\n",
    "            agg = logits.mean(dim=0)                # (C,)\n",
    "            pred = int(torch.argmax(agg).item())\n",
    "            preds.append(pred)\n",
    "            labels.append(yb)\n",
    "    acc = 100.0 * (np.mean(np.array(preds) == np.array(labels)) if len(labels) else 0.0)\n",
    "    cm = confusion_matrix(labels, preds, labels=list(range(num_classes)))\n",
    "    return acc, cm\n",
    "\n",
    "\n",
    "# ================= 训练集每 epoch 每 block 抽 K 行 =================\n",
    "def sample_rows_per_block_epoch(X_train_blocks, y_train_blocks, K, rng):\n",
    "    \"\"\"\n",
    "    X_train_blocks: (B, sample_len, time_len, 2)\n",
    "    返回: X_train_ep: (B*K, time_len, 2), y_train_ep: (B*K,)\n",
    "    \"\"\"\n",
    "    B, S, T, C = X_train_blocks.shape\n",
    "    if S == 1:\n",
    "        K = 1\n",
    "    if (K is None) or (K >= S):\n",
    "        X = X_train_blocks.reshape(-1, T, C)\n",
    "        y = np.repeat(y_train_blocks, S)\n",
    "        return X, y\n",
    "\n",
    "    idx = np.empty((B, K), dtype=np.int64)\n",
    "    for b in range(B):\n",
    "        idx[b] = rng.choice(S, size=K, replace=False)\n",
    "    gather_idx = idx[:, :, None, None]  # (B,K,1,1)\n",
    "    X_sel = np.take_along_axis(X_train_blocks, gather_idx, axis=1)  # (B,K,T,C)\n",
    "    X = X_sel.reshape(-1, T, C)\n",
    "    y = np.repeat(y_train_blocks, K)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ================= Backbones =================\n",
    "class BasicBlock1D(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "class ResNet18_1D(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_planes=64, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.conv1 = nn.Conv1d(2, in_planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1, dropout=dropout)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, dropout=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride, dropout):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes)\n",
    "            )\n",
    "        layers = [BasicBlock1D(self.in_planes, planes, stride, downsample, dropout)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock1D(self.in_planes, planes, dropout=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B,T,2)->(B,2,T)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    \"\"\"\n",
    "    轻量 1D CNN：Conv-BN-ReLU-Pool 堆叠 + GAP\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, width=64, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(2, width, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(width),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(3, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv1d(width, width*2, kernel_size=5, stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(width*2),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv1d(width*2, width*4, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(width*4),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv1d(width*4, width*8, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(width*8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(width*8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.net(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, channels, dilation, dropout=0.0):\n",
    "        super().__init__()\n",
    "        pad = dilation\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=3, dilation=dilation, padding=pad, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=3, dilation=dilation, padding=pad, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.relu(self.bn1(self.conv1(x)))\n",
    "        y = self.drop(y)\n",
    "        y = self.bn2(self.conv2(y))\n",
    "        return self.relu(x + y)\n",
    "\n",
    "class TCN1D(nn.Module):\n",
    "    \"\"\"\n",
    "    Dilated TCN：先映射到 channels，再堆叠多层 dilation residual block + GAP\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, channels=128, levels=6, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(2, channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        blocks = []\n",
    "        for i in range(levels):\n",
    "            blocks.append(TCNBlock(channels, dilation=2**i, dropout=dropout))\n",
    "        self.tcn = nn.Sequential(*blocks)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.stem(x)\n",
    "        x = self.tcn(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "def build_model(backbone_key, num_classes, dropout_=0.5):\n",
    "    if backbone_key == \"resnet\":\n",
    "        return ResNet18_1D(num_classes=num_classes, in_planes=64, dropout=dropout_)\n",
    "    if backbone_key == \"cnn\":\n",
    "        return CNN1D(num_classes=num_classes, width=64, dropout=dropout_)\n",
    "    if backbone_key == \"tcn\":\n",
    "        return TCN1D(num_classes=num_classes, channels=128, levels=6, dropout=dropout_)\n",
    "    raise ValueError(f\"Unknown backbone: {backbone_key}\")\n",
    "\n",
    "\n",
    "# ================= 主训练（单个 method+backbone） =================\n",
    "def train_one_combo(method_name, method_key, backbone_name, backbone_key, save_folder):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] device={device} | method={method_name} | backbone={backbone_name}\")\n",
    "\n",
    "    # 1) 构造 cross-domain blocks\n",
    "    X_blocks, y_blocks, label_to_idx, meta = load_and_preprocess_cross_domain_blocks(\n",
    "        data_path,\n",
    "        group_size_=group_size,\n",
    "        apply_doppler_=apply_doppler,\n",
    "        target_velocity_kmh_=v_kmh,\n",
    "        apply_awgn_=apply_awgn,\n",
    "        snr_db_=SNR_FIXED,\n",
    "        fs_=fs,\n",
    "        fc_=fc,\n",
    "        method_key=method_key,\n",
    "        seed_=seed,\n",
    "    )\n",
    "    num_classes = len(label_to_idx)\n",
    "\n",
    "    # 2) block-level train/test split（stratify by y_blocks）\n",
    "    idx_all = np.arange(X_blocks.shape[0])\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        idx_all, test_size=test_size, stratify=y_blocks, random_state=seed\n",
    "    )\n",
    "\n",
    "    X_train_blocks_all = X_blocks[train_idx]\n",
    "    y_train_blocks_all = y_blocks[train_idx]\n",
    "    X_test_blocks = X_blocks[test_idx]\n",
    "    y_test_blocks = y_blocks[test_idx]\n",
    "\n",
    "    # row-level test loader\n",
    "    S_test = X_test_blocks.shape[1]\n",
    "    T_test = X_test_blocks.shape[2]\n",
    "    bs_test = auto_batch_size_for_T(int(T_test), base=base_batch_size)\n",
    "\n",
    "    X_test = X_test_blocks.reshape(-1, T_test, 2)\n",
    "    y_test = np.repeat(y_test_blocks, S_test)\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)),\n",
    "        batch_size=bs_test, shuffle=False\n",
    "    )\n",
    "\n",
    "    # 日志文件\n",
    "    results_txt = os.path.join(save_folder, \"results.txt\")\n",
    "    metrics_csv = os.path.join(save_folder, \"metrics.csv\")\n",
    "    with open(results_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps({\n",
    "            \"timestamp\": os.path.basename(save_folder),\n",
    "            \"method\": method_name,\n",
    "            \"backbone\": backbone_name,\n",
    "            \"SNR_dB\": SNR_FIXED,\n",
    "            \"group_size\": group_size,\n",
    "            \"meta\": meta\n",
    "        }, ensure_ascii=False, indent=2) + \"\\n\\n\")\n",
    "\n",
    "    with open(metrics_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"method,backbone,fold,epoch,train_loss,train_acc,val_loss,val_acc_row,train_time_s,lr\\n\")\n",
    "\n",
    "    # 3) KFold on train blocks\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    fold_summaries = []\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (tr_sub, va_sub) in enumerate(kfold.split(X_train_blocks_all)):\n",
    "        print(f\"\\n====== {method_name} | {backbone_name} | Fold {fold+1}/{n_splits} ======\")\n",
    "\n",
    "        X_tr_blocks = X_train_blocks_all[tr_sub]\n",
    "        y_tr_blocks = y_train_blocks_all[tr_sub]\n",
    "        X_va_blocks = X_train_blocks_all[va_sub]\n",
    "        y_va_blocks = y_train_blocks_all[va_sub]\n",
    "\n",
    "        # row-level val loader\n",
    "        S_va = X_va_blocks.shape[1]\n",
    "        T_va = X_va_blocks.shape[2]\n",
    "        bs_val = auto_batch_size_for_T(int(T_va), base=base_batch_size)\n",
    "\n",
    "        X_val = X_va_blocks.reshape(-1, T_va, 2)\n",
    "        y_val = np.repeat(y_va_blocks, S_va)\n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long)),\n",
    "            batch_size=bs_val, shuffle=False\n",
    "        )\n",
    "\n",
    "        # model\n",
    "        model = build_model(backbone_key, num_classes=num_classes, dropout_=dropout).to(device)\n",
    "        params = count_params(model)\n",
    "        params_bytes_est = sizeof_state_dict_bytes_est(model)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        best_val_acc = -1.0\n",
    "        patience_counter = 0\n",
    "        best_wts = None\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        train_times = []\n",
    "\n",
    "        # epoch loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # ======== build epoch train set by row sampling =========\n",
    "            rng = np.random.default_rng(seed + 100000*(fold+1) + (epoch+1))\n",
    "            X_tr_ep, y_tr_ep = sample_rows_per_block_epoch(X_tr_blocks, y_tr_blocks, train_rows_per_block, rng)\n",
    "\n",
    "            T_tr = int(X_tr_ep.shape[1])\n",
    "            bs_tr = auto_batch_size_for_T(T_tr, base=base_batch_size)\n",
    "            train_loader = DataLoader(\n",
    "                TensorDataset(torch.tensor(X_tr_ep, dtype=torch.float32), torch.tensor(y_tr_ep, dtype=torch.long)),\n",
    "                batch_size=bs_tr, shuffle=True\n",
    "            )\n",
    "\n",
    "            # ======== train epoch (time only training) =========\n",
    "            model.train()\n",
    "            t0 = time.perf_counter()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct, total = 0, 0\n",
    "            for xb, yb in train_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                pred = torch.argmax(logits, dim=1)\n",
    "                total += yb.size(0)\n",
    "                correct += (pred == yb).sum().item()\n",
    "\n",
    "            cuda_sync_if_needed(device)\n",
    "            t1 = time.perf_counter()\n",
    "            train_time = float(t1 - t0)\n",
    "            train_times.append(train_time)\n",
    "\n",
    "            train_loss = running_loss / max(1, len(train_loader))\n",
    "            train_acc = 100.0 * correct / max(1, total)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # ======== val (row-level) =========\n",
    "            model.eval()\n",
    "            vloss_sum = 0.0\n",
    "            vcorrect, vtotal = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb = xb.to(device)\n",
    "                    yb = yb.to(device)\n",
    "                    logits = model(xb)\n",
    "                    vloss = criterion(logits, yb)\n",
    "                    vloss_sum += vloss.item()\n",
    "                    pred = torch.argmax(logits, dim=1)\n",
    "                    vtotal += yb.size(0)\n",
    "                    vcorrect += (pred == yb).sum().item()\n",
    "            val_loss = vloss_sum / max(1, len(val_loader))\n",
    "            val_acc_row = 100.0 * vcorrect / max(1, vtotal)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "            log = (f\"Fold {fold+1} Ep {epoch+1} | \"\n",
    "                   f\"Train loss {train_loss:.4f} acc {train_acc:.2f}% | \"\n",
    "                   f\"Val loss {val_loss:.4f} acc_row {val_acc_row:.2f}% | \"\n",
    "                   f\"train_time {train_time:.3f}s | lr {lr_now:.3g}\")\n",
    "            print(log)\n",
    "            with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(log + \"\\n\")\n",
    "            with open(metrics_csv, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{method_name},{backbone_name},{fold+1},{epoch+1},\"\n",
    "                        f\"{train_loss:.6f},{train_acc:.4f},{val_loss:.6f},{val_acc_row:.4f},\"\n",
    "                        f\"{train_time:.6f},{lr_now:.10f}\\n\")\n",
    "\n",
    "            # early stopping by val_acc_row\n",
    "            if val_acc_row > best_val_acc + 0.01:\n",
    "                best_val_acc = val_acc_row\n",
    "                patience_counter = 0\n",
    "                best_wts = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    msg = f\"Early stop at epoch {epoch+1} (best_val_acc_row={best_val_acc:.2f}%)\"\n",
    "                    print(msg)\n",
    "                    with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(msg + \"\\n\")\n",
    "                    break\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        epochs_used = len(train_losses)\n",
    "\n",
    "        # load best\n",
    "        if best_wts is None:\n",
    "            best_wts = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        model.load_state_dict(best_wts, strict=True)\n",
    "        model.to(device)\n",
    "\n",
    "        # ======== final eval row + block =========\n",
    "        val_acc_row_final, val_cm_row = evaluate_rowlevel(model, val_loader, device, num_classes)\n",
    "        test_acc_row, test_cm_row = evaluate_rowlevel(model, test_loader, device, num_classes)\n",
    "\n",
    "        val_acc_block, val_cm_block = evaluate_blocklevel(model, X_va_blocks, y_va_blocks, device, num_classes)\n",
    "        test_acc_block, test_cm_block = evaluate_blocklevel(model, X_test_blocks, y_test_blocks, device, num_classes)\n",
    "\n",
    "        # save model\n",
    "        model_path = os.path.join(save_folder, f\"best_model_fold{fold+1}.pth\")\n",
    "        torch.save(best_wts, model_path)\n",
    "        model_file_bytes = int(os.path.getsize(model_path))\n",
    "\n",
    "        # confusion matrices\n",
    "        plot_confusion_matrix(val_cm_row, os.path.join(save_folder, f\"confmat_row_val_fold{fold+1}.png\"), \"Val Row-level\")\n",
    "        plot_confusion_matrix(test_cm_row, os.path.join(save_folder, f\"confmat_row_test_fold{fold+1}.png\"), \"Test Row-level\")\n",
    "        plot_confusion_matrix(val_cm_block, os.path.join(save_folder, f\"confmat_block_val_fold{fold+1}.png\"), \"Val Block-level\")\n",
    "        plot_confusion_matrix(test_cm_block, os.path.join(save_folder, f\"confmat_block_test_fold{fold+1}.png\"), \"Test Block-level\")\n",
    "\n",
    "        # training time range\n",
    "        t_min = float(np.min(train_times)) if len(train_times) else 0.0\n",
    "        t_med = float(np.median(train_times)) if len(train_times) else 0.0\n",
    "        t_max = float(np.max(train_times)) if len(train_times) else 0.0\n",
    "\n",
    "        # ======== inference benchmark =========\n",
    "        # pick one row sample + one block sample from test set\n",
    "        # row sample: first row of first test block\n",
    "        xb0 = torch.tensor(X_test_blocks[0, 0:1], dtype=torch.float32)          # (1,T,2)\n",
    "        # block sample: all rows of first test block\n",
    "        xb_blk = torch.tensor(X_test_blocks[0], dtype=torch.float32)            # (S,T,2)\n",
    "\n",
    "        row_mean, row_p50, row_p95 = benchmark_inference(model, xb0, device, warmup=20, iters=100)\n",
    "        blk_mean, blk_p50, blk_p95 = benchmark_inference(model, xb_blk, device, warmup=20, iters=100)\n",
    "\n",
    "        fold_summary = {\n",
    "            \"method\": method_name,\n",
    "            \"backbone\": backbone_name,\n",
    "            \"fold\": fold + 1,\n",
    "            \"epochs_used\": int(epochs_used),\n",
    "            \"train_epoch_time_s_min\": t_min,\n",
    "            \"train_epoch_time_s_med\": t_med,\n",
    "            \"train_epoch_time_s_max\": t_max,\n",
    "            \"val_acc_row\": float(val_acc_row_final),\n",
    "            \"test_acc_row\": float(test_acc_row),\n",
    "            \"val_acc_block\": float(val_acc_block),\n",
    "            \"test_acc_block\": float(test_acc_block),\n",
    "            \"params\": int(params),\n",
    "            \"param_bytes_est\": int(params_bytes_est),\n",
    "            \"model_file_bytes\": int(model_file_bytes),\n",
    "            \"infer_row_ms_mean\": row_mean,\n",
    "            \"infer_row_ms_p50\": row_p50,\n",
    "            \"infer_row_ms_p95\": row_p95,\n",
    "            \"infer_block_ms_mean\": blk_mean,\n",
    "            \"infer_block_ms_p50\": blk_p50,\n",
    "            \"infer_block_ms_p95\": blk_p95,\n",
    "            \"time_len_T\": int(T_test),\n",
    "            \"sample_len_S_test\": int(S_test),\n",
    "        }\n",
    "        fold_summaries.append(fold_summary)\n",
    "\n",
    "        fold_results.append({\n",
    "            \"train_loss\": train_losses,\n",
    "            \"val_loss\": val_losses,\n",
    "        })\n",
    "\n",
    "        msg2 = (f\"[FOLD{fold+1}] test_row={test_acc_row:.2f}% test_block={test_acc_block:.2f}% | \"\n",
    "                f\"epochs={epochs_used} | train_time(s) min/med/max={t_min:.3f}/{t_med:.3f}/{t_max:.3f} | \"\n",
    "                f\"params={params/1e6:.3f}M | model={model_file_bytes/1024/1024:.2f}MB | \"\n",
    "                f\"infer_row_mean={row_mean:.3f}ms infer_block_mean={blk_mean:.3f}ms\")\n",
    "        print(msg2)\n",
    "        with open(results_txt, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(msg2 + \"\\n\")\n",
    "\n",
    "    # loss curves\n",
    "    plot_training_curves(fold_results, save_folder)\n",
    "\n",
    "    # dump per-fold summary\n",
    "    with open(os.path.join(save_folder, \"fold_summaries.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(fold_summaries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return fold_summaries, meta\n",
    "\n",
    "\n",
    "# ================= 主程序：跑完所有 method × backbone =================\n",
    "def main():\n",
    "    seed_everything(seed)\n",
    "    os.makedirs(out_root, exist_ok=True)\n",
    "\n",
    "    fd_int = int(compute_doppler_shift(v_kmh, fc))\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    root_folder = os.path.join(\n",
    "        out_root,\n",
    "        f\"{ts}_LTEV_CrossDomainXFR_Ablations_SNR{SNR_FIXED}dB_fd{fd_int}_m{group_size}\"\n",
    "    )\n",
    "    os.makedirs(root_folder, exist_ok=True)\n",
    "\n",
    "    global_csv = os.path.join(root_folder, \"global_summary.csv\")\n",
    "    with open(global_csv, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\",\".join([\n",
    "            \"method\",\"backbone\",\n",
    "            \"fold\",\"epochs_used\",\n",
    "            \"train_epoch_time_s_min\",\"train_epoch_time_s_med\",\"train_epoch_time_s_max\",\n",
    "            \"val_acc_row\",\"test_acc_row\",\"val_acc_block\",\"test_acc_block\",\n",
    "            \"params\",\"param_bytes_est\",\"model_file_bytes\",\n",
    "            \"infer_row_ms_mean\",\"infer_row_ms_p50\",\"infer_row_ms_p95\",\n",
    "            \"infer_block_ms_mean\",\"infer_block_ms_p50\",\"infer_block_ms_p95\",\n",
    "            \"time_len_T\",\"sample_len_S_test\"\n",
    "        ]) + \"\\n\")\n",
    "\n",
    "    all_records = []\n",
    "\n",
    "    for method_name, method_key in METHODS:\n",
    "        for backbone_name, backbone_key in BACKBONES:\n",
    "            combo_folder = os.path.join(root_folder, f\"{method_name}__{backbone_name}\")\n",
    "            os.makedirs(combo_folder, exist_ok=True)\n",
    "\n",
    "            fold_summaries, meta = train_one_combo(\n",
    "                method_name, method_key, backbone_name, backbone_key, combo_folder\n",
    "            )\n",
    "\n",
    "            # append to global csv\n",
    "            with open(global_csv, \"a\", encoding=\"utf-8\") as f:\n",
    "                for r in fold_summaries:\n",
    "                    f.write(\",\".join([\n",
    "                        r[\"method\"], r[\"backbone\"],\n",
    "                        str(r[\"fold\"]), str(r[\"epochs_used\"]),\n",
    "                        f\"{r['train_epoch_time_s_min']:.6f}\", f\"{r['train_epoch_time_s_med']:.6f}\", f\"{r['train_epoch_time_s_max']:.6f}\",\n",
    "                        f\"{r['val_acc_row']:.6f}\", f\"{r['test_acc_row']:.6f}\",\n",
    "                        f\"{r['val_acc_block']:.6f}\", f\"{r['test_acc_block']:.6f}\",\n",
    "                        str(r[\"params\"]), str(r[\"param_bytes_est\"]), str(r[\"model_file_bytes\"]),\n",
    "                        f\"{r['infer_row_ms_mean']:.6f}\", f\"{r['infer_row_ms_p50']:.6f}\", f\"{r['infer_row_ms_p95']:.6f}\",\n",
    "                        f\"{r['infer_block_ms_mean']:.6f}\", f\"{r['infer_block_ms_p50']:.6f}\", f\"{r['infer_block_ms_p95']:.6f}\",\n",
    "                        str(r[\"time_len_T\"]), str(r[\"sample_len_S_test\"]),\n",
    "                    ]) + \"\\n\")\n",
    "\n",
    "            all_records.extend(fold_summaries)\n",
    "\n",
    "    # 全局汇总（按 method+backbone 聚合 mean/std）\n",
    "    def group_key(r): return (r[\"method\"], r[\"backbone\"])\n",
    "    groups = {}\n",
    "    for r in all_records:\n",
    "        groups.setdefault(group_key(r), []).append(r)\n",
    "\n",
    "    agg = []\n",
    "    for (m, b), lst in groups.items():\n",
    "        def mean_std(x):\n",
    "            x = np.array(x, dtype=np.float64)\n",
    "            return float(x.mean()), float(x.std())\n",
    "\n",
    "        epochs = [x[\"epochs_used\"] for x in lst]\n",
    "        row_acc = [x[\"test_acc_row\"] for x in lst]\n",
    "        blk_acc = [x[\"test_acc_block\"] for x in lst]\n",
    "        t_med = [x[\"train_epoch_time_s_med\"] for x in lst]\n",
    "        infer_row = [x[\"infer_row_ms_mean\"] for x in lst]\n",
    "        infer_blk = [x[\"infer_block_ms_mean\"] for x in lst]\n",
    "        model_mb = [x[\"model_file_bytes\"]/1024/1024 for x in lst]\n",
    "        params = lst[0][\"params\"]\n",
    "\n",
    "        agg.append({\n",
    "            \"method\": m, \"backbone\": b,\n",
    "            \"epochs_mean\": float(np.mean(epochs)), \"epochs_std\": float(np.std(epochs)),\n",
    "            \"test_row_mean\": mean_std(row_acc)[0], \"test_row_std\": mean_std(row_acc)[1],\n",
    "            \"test_block_mean\": mean_std(blk_acc)[0], \"test_block_std\": mean_std(blk_acc)[1],\n",
    "            \"train_epoch_time_med_s_mean\": mean_std(t_med)[0], \"train_epoch_time_med_s_std\": mean_std(t_med)[1],\n",
    "            \"infer_row_ms_mean\": mean_std(infer_row)[0], \"infer_row_ms_std\": mean_std(infer_row)[1],\n",
    "            \"infer_block_ms_mean\": mean_std(infer_blk)[0], \"infer_block_ms_std\": mean_std(infer_blk)[1],\n",
    "            \"params\": int(params),\n",
    "            \"model_file_MB_mean\": float(np.mean(model_mb)), \"model_file_MB_std\": float(np.std(model_mb)),\n",
    "        })\n",
    "\n",
    "    with open(os.path.join(root_folder, \"aggregate_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(agg, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[DONE] root_folder: {root_folder}\")\n",
    "    print(f\"[DONE] global_summary.csv: {global_csv}\")\n",
    "    print(f\"[DONE] aggregate_summary.json saved.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
